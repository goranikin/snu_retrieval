{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f48faf-1525-4373-85ed-576acf20687c",
   "metadata": {},
   "source": [
    "Writer: 최장혁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9fd4d4a-4a8d-40d4-861c-46caaeabe39f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
      "Requirement already satisfied: adapters in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
      "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
      "Requirement already satisfied: hf-xet in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
      "Collecting omegaconf\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.12)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "\u001b[33m  DEPRECATION: Building 'antlr4-python3-runtime' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'antlr4-python3-runtime'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=63a3ba98d73ff30059c858e7977217f4a9774f07dff1cb6cc9af6a78488d37ff\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [omegaconf]\n",
      "\u001b[1A\u001b[2KSuccessfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets adapters faiss-gpu tqdm hf-xet omegaconf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b0a5e2-9bbb-4042-8758-4dcab7f4a7f7",
   "metadata": {},
   "source": [
    "Load Base class and util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e28c35d-4233-4f35-b7c3-e1eea72a5b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class TextType(Enum):\n",
    "    KEY = 1\n",
    "    QUERY = 2\n",
    "\n",
    "\n",
    "class Retrieval:\n",
    "    def __init__(self, index_name: str = \"\", index_type: str = \"\") -> None:\n",
    "        self.index_name = index_name\n",
    "        self.index_type = index_type\n",
    "\n",
    "        self.keys = []\n",
    "        self.values = []\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.keys)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.keys = []\n",
    "        self.values = []\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "    def _encode_text(self, input_ids, attention_mask, adapter_type=\"proximity\"):\n",
    "        \"\"\"\n",
    "        input: tokenized value\n",
    "        output: embedding value\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def encode_query(self, query_text: str):\n",
    "        \"\"\"\n",
    "        embed query text\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def encode_paper(self, title: str, abstract: str):\n",
    "        \"\"\"\n",
    "        embed paper using the concat of title and abstract\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _query(self, query_embedding: torch.Tensor, top_k: int = 10) -> List[int]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def query(self, query_text: str, n: int, return_keys: bool = False) -> List[Any]:\n",
    "        query_embedding = self.encode_query(query_text)\n",
    "        indices = self._query(query_embedding, n)\n",
    "        if return_keys:\n",
    "            results = [(self.keys[i], self.values[i]) for i in indices]\n",
    "        else:\n",
    "            results = [self.values[i] for i in indices]\n",
    "        return results\n",
    "\n",
    "    def _encode_paper_batch(\n",
    "        self, text_list: list[str], show_progress_bar: bool = False\n",
    "    ) -> Any:\n",
    "        \"\"\"\n",
    "        embed batch of papers using the concat of title and abstract\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def create_index(self, key_value_pairs: Dict[str, int]) -> None:\n",
    "        if len(self.keys) > 0:\n",
    "            raise ValueError(\n",
    "                \"Index is not empty. Please create a new index or clear the existing one.\"\n",
    "            )\n",
    "\n",
    "        for key, value in key_value_pairs.items():\n",
    "            self.keys.append(key)\n",
    "            self.values.append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d347fea-6bfb-4812-9312-b73ae521ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Any\n",
    "from datasets import Dataset\n",
    "\n",
    "def get_clean_corpusid(item: dict) -> int:\n",
    "    return item['corpusid']\n",
    "\n",
    "def get_clean_title(item: dict) -> str:\n",
    "    return item['title']\n",
    "\n",
    "def get_clean_abstract(item: dict) -> str:\n",
    "    return item['abstract']\n",
    "\n",
    "def get_clean_title_abstract(item: dict) -> str:\n",
    "    title = get_clean_title(item)\n",
    "    abstract = get_clean_abstract(item)\n",
    "    return f\"Title: {title}\\nAbstract: {abstract}\"\n",
    "\n",
    "def get_clean_full_paper(item: dict) -> str:\n",
    "    return item['full_paper']\n",
    "\n",
    "def get_clean_paragraph_indices(item: dict) -> List[Tuple[int, int]]:\n",
    "    text = get_clean_full_paper(item)\n",
    "    paragraph_indices = []\n",
    "    paragraph_start = 0\n",
    "    paragraph_end = 0\n",
    "    while paragraph_start < len(text):\n",
    "        paragraph_end = text.find(\"\\n\\n\", paragraph_start)\n",
    "        if paragraph_end == -1:\n",
    "            paragraph_end = len(text)\n",
    "        paragraph_indices.append((paragraph_start, paragraph_end))\n",
    "        paragraph_start = paragraph_end + 2\n",
    "    return paragraph_indices\n",
    "\n",
    "def get_clean_text(item: dict, start_idx: int, end_idx: int) -> str:\n",
    "    text = get_clean_full_paper(item)\n",
    "    assert start_idx >= 0 and end_idx >= 0\n",
    "    assert start_idx <= end_idx\n",
    "    assert end_idx <= len(text)\n",
    "    return text[start_idx:end_idx]\n",
    "\n",
    "def get_clean_paragraphs(item: dict, min_words: int = 10) -> List[str]:\n",
    "    paragraph_indices = get_clean_paragraph_indices(item)\n",
    "    paragraphs = [get_clean_text(item, paragraph_start, paragraph_end) for paragraph_start, paragraph_end in paragraph_indices]\n",
    "    paragraphs = [paragraph for paragraph in paragraphs if len(paragraph.split()) >= min_words]\n",
    "    return paragraphs\n",
    "\n",
    "def get_clean_citations(item: dict) -> List[int]:\n",
    "    return item['citations']\n",
    "\n",
    "def get_clean_dict(data: Dataset) -> dict:\n",
    "    return {get_clean_corpusid(item): item for item in data}\n",
    "\n",
    "def create_kv_pairs(data: List[dict], key: str) -> dict:\n",
    "    if key == \"title_abstract\":\n",
    "        kv_pairs = {get_clean_title_abstract(record): get_clean_corpusid(record) for record in data}\n",
    "    elif key == \"full_paper\":\n",
    "        kv_pairs = {get_clean_full_paper(record): get_clean_corpusid(record) for record in data}\n",
    "    elif key == \"paragraphs\":\n",
    "        kv_pairs = {}\n",
    "        for record in data:\n",
    "            corpusid = get_clean_corpusid(record)\n",
    "            paragraphs = get_clean_paragraphs(record)\n",
    "            for paragraph_idx, paragraph in enumerate(paragraphs):\n",
    "                kv_pairs[paragraph] = (corpusid, paragraph_idx)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid key\")\n",
    "    return kv_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5eef8a0-1767-4fbc-9af1-a990227fa676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_recall(corpusids: list, retrieved: list, k: int):\n",
    "    top_k = retrieved[:k]\n",
    "    intersection = set(corpusids) & set(top_k)\n",
    "    return len(intersection) / len(corpusids) if corpusids else 0.0\n",
    "\n",
    "def mean_recall(dataset, k):\n",
    "    recalls = [\n",
    "        calculate_recall(example['corpusids'], example['retrieved'], k)\n",
    "        for example in dataset\n",
    "    ]\n",
    "    return np.mean(recalls) if recalls else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f962268-e06a-4a37-ade5-3ca047ffd1d1",
   "metadata": {},
   "source": [
    "Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49722444-cd49-4bf0-b033-55bc97b57125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "query_data = load_dataset(\"princeton-nlp/LitSearch\", \"query\", split=\"full\")\n",
    "corpus_clean_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_clean\", split=\"full\")\n",
    "corpus_s2orc_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_s2orc\", split=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7450d88-f3da-4351-b872-e96fb2145afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 442 120 35 231 211\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def classify(example):\n",
    "    if example['specificity'] == 0:\n",
    "        if example['query_set'].startswith('inline'):\n",
    "            return 'spec0_inline'\n",
    "        else:\n",
    "            return 'spec0_manual'\n",
    "    else:\n",
    "        if example['query_set'].startswith('inline'):\n",
    "            return 'spec1_inline'\n",
    "        else:\n",
    "            return 'spec1_manual'\n",
    "\n",
    "query_data = query_data.map(lambda x: {\"class\": classify(x)})\n",
    "\n",
    "spec0_ds = query_data.filter(lambda x: x['specificity'] == 0)\n",
    "spec1_ds = query_data.filter(lambda x: x['specificity'] == 1)\n",
    "spec0_inline_ds = query_data.filter(lambda x: x['class'] == 'spec0_inline')\n",
    "spec0_manual_ds = query_data.filter(lambda x: x['class'] == 'spec0_manual')\n",
    "spec1_inline_ds = query_data.filter(lambda x: x['class'] == 'spec1_inline')\n",
    "spec1_manual_ds = query_data.filter(lambda x: x['class'] == 'spec1_manual')\n",
    "\n",
    "print(spec0_ds.num_rows, spec1_ds.num_rows, spec0_inline_ds.num_rows, spec0_manual_ds.num_rows, spec1_inline_ds.num_rows, spec1_manual_ds.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6791035-6e4d-4ae1-9242-8ce331d11dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv_pairs = create_kv_pairs(corpus_clean_data, \"title_abstract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f53d3e-45a5-461f-a3ef-8fec35bc7710",
   "metadata": {},
   "source": [
    "Loss and Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b831cd-6613-40a2-af47-b3ea47f2872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class TripletMarginLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletMarginLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, query_emb, pos_emb, neg_emb):\n",
    "        # L2 거리 계산\n",
    "        pos_dist = torch.norm(query_emb - pos_emb, p=2, dim=1)\n",
    "        neg_dist = torch.norm(query_emb - neg_emb, p=2, dim=1)\n",
    "\n",
    "        # max(0, pos_dist - neg_dist + margin) 형태의 손실\n",
    "        loss = torch.clamp(pos_dist - neg_dist + self.margin, min=0.0)\n",
    "        return loss.mean()\n",
    "\n",
    "class LitSearchTripletDataset(Dataset):\n",
    "    def __init__(self, data: list[dict[str, str]], tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"query\": item[\"query\"],\n",
    "            \"positive_title\": item[\"positive_title\"],\n",
    "            \"positive_abstract\": item[\"positive_abstract\"],\n",
    "            \"negative_title\": item[\"negative_title\"],\n",
    "            \"negative_abstract\": item[\"negative_abstract\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f844e2-786c-4516-b9d8-f66531988172",
   "metadata": {},
   "source": [
    "SPECTER2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87ae52-e3d1-48c7-920a-234be13390c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import faiss\n",
    "import torch\n",
    "from adapters import AutoAdapterModel\n",
    "from tqdm import tqdm\n",
    "from transformers.models.auto.tokenization_auto import AutoTokenizer\n",
    "\n",
    "\n",
    "class Specter2(Retrieval):\n",
    "    def __init__(self, base_model_name=\"allenai/specter2_base\", device=None):\n",
    "        super().__init__()\n",
    "        self.keys = []\n",
    "        self.values = []\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                self.device = torch.device(\"cuda\")\n",
    "            elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "                self.device = torch.device(\"mps\")\n",
    "            else:\n",
    "                self.device = torch.device(\"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "        self.model = AutoAdapterModel.from_pretrained(base_model_name)\n",
    "\n",
    "        self.model.load_adapter(\"allenai/specter2\", source=\"hf\", load_as=\"proximity\")\n",
    "\n",
    "        self.model.load_adapter(\n",
    "            \"allenai/specter2_adhoc_query\", source=\"hf\", load_as=\"adhoc_query\"\n",
    "        )\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if \"adapters.adhoc_query\" in name:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.model.parameters()\n",
    "\n",
    "    def clear(self):\n",
    "        super().clear()\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "    def save_model(self, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        self.model.save_adapter(output_dir, \"adhoc_query\")\n",
    "\n",
    "        self.tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "        print(f\"어댑터가 {output_dir}에 저장되었습니다.\")\n",
    "\n",
    "    def _encode_text(self, input_ids, attention_mask, adapter_type=\"proximity\"):\n",
    "        \"\"\"\n",
    "\n",
    "        adapter_type: query -> \"adhoc_query\", paper -> \"proximity\"\n",
    "        \"\"\"\n",
    "        self.model.set_active_adapters(adapter_type)\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids.to(self.device),\n",
    "            attention_mask=attention_mask.to(self.device),\n",
    "        )\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        return embeddings\n",
    "\n",
    "    def encode_query(self, query_text: str, no_grad=True):\n",
    "        self.model.eval()\n",
    "        if no_grad:\n",
    "            with torch.no_grad():\n",
    "                tokens = self.tokenizer(\n",
    "                    query_text,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "                return self._encode_text(\n",
    "                    tokens[\"input_ids\"],\n",
    "                    tokens[\"attention_mask\"],\n",
    "                    adapter_type=\"adhoc_query\",\n",
    "                )\n",
    "        else:\n",
    "            tokens = self.tokenizer(\n",
    "                query_text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            return self._encode_text(\n",
    "                tokens[\"input_ids\"],\n",
    "                tokens[\"attention_mask\"],\n",
    "                adapter_type=\"adhoc_query\",\n",
    "            )\n",
    "\n",
    "    def encode_paper(self, title: str, abstract: str, no_grad=True):\n",
    "        self.model.eval()\n",
    "        sep_token = self.tokenizer.sep_token\n",
    "        if isinstance(title, list) and isinstance(abstract, list):\n",
    "            text = [t + sep_token + a for t, a in zip(title, abstract)]\n",
    "        else:\n",
    "            text = title + sep_token + abstract\n",
    "        if no_grad:\n",
    "            with torch.no_grad():\n",
    "                tokens = self.tokenizer(\n",
    "                    text,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "                return self._encode_text(\n",
    "                    tokens[\"input_ids\"],\n",
    "                    tokens[\"attention_mask\"],\n",
    "                    adapter_type=\"proximity\",\n",
    "                )\n",
    "        else:\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            return self._encode_text(\n",
    "                tokens[\"input_ids\"], tokens[\"attention_mask\"], adapter_type=\"proximity\"\n",
    "            )\n",
    "\n",
    "    def _query(self, query_embedding: torch.Tensor, top_k: int = 20) -> list[int]:\n",
    "        if self.faiss_index is None:\n",
    "            raise ValueError(\n",
    "                \"FAISS index has not been created yet. Call create_index first.\"\n",
    "            )\n",
    "\n",
    "        query_vector = query_embedding.cpu().numpy()\n",
    "        faiss.normalize_L2(query_vector)\n",
    "        distances, indices = self.faiss_index.search(query_vector, top_k)\n",
    "\n",
    "        return indices[0].tolist()\n",
    "\n",
    "    def query(self, query_text: str, n: int, return_keys: bool = False) -> list:\n",
    "        query_embedding = self.encode_query(query_text)\n",
    "        indices = self._query(query_embedding, n)\n",
    "\n",
    "        if return_keys:\n",
    "            results = [(self.keys[i], self.values[i]) for i in indices]\n",
    "        else:\n",
    "            results = [self.values[i] for i in indices]\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _encode_paper_batch(\n",
    "        self, textList: list[str], show_progress_bar: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        self.model.set_active_adapters(\"proximity\")\n",
    "        batch_size = 256\n",
    "        embeddings = []\n",
    "\n",
    "        should_show_progress = show_progress_bar\n",
    "\n",
    "        iterator = range(0, len(textList), batch_size)\n",
    "        if should_show_progress:\n",
    "            iterator = tqdm(iterator, desc=\"Processing document embeddings\")\n",
    "\n",
    "        for i in iterator:\n",
    "            batch_texts = textList[i : i + batch_size]\n",
    "            encoded = self.tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=512,\n",
    "            ).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**encoded)\n",
    "\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu()\n",
    "            embeddings.append(batch_embeddings)\n",
    "\n",
    "            if i % (batch_size * 10) == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "        return embeddings\n",
    "\n",
    "    def create_index(self, key_value_pairs: dict[str, int]) -> None:\n",
    "        super().create_index(key_value_pairs)\n",
    "        self.index = self._encode_paper_batch(self.keys)\n",
    "\n",
    "        vector_dim = self.index.shape[1]\n",
    "        index_flat = faiss.IndexFlatIP(vector_dim)\n",
    "        index_vectors = self.index.numpy()\n",
    "        faiss.normalize_L2(index_vectors)\n",
    "\n",
    "        index_flat.add(index_vectors)\n",
    "        self.faiss_index = index_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "265a96a6-48a8-48dd-a6bf-0f924728a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Specter2Trainer:\n",
    "    def __init__(self, model_wrapper):\n",
    "        self.model_wrapper = model_wrapper\n",
    "        self.model = model_wrapper.model\n",
    "        self.tokenizer = model_wrapper.tokenizer\n",
    "        self.device = model_wrapper.device\n",
    "        print(\"Trainer initialized\")\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        train_data,\n",
    "        val_data=None,\n",
    "        output_dir=\"./specter2_adhoc_query_finetuned\",\n",
    "        lr=2e-5,\n",
    "        batch_size=2,\n",
    "        epochs=3,\n",
    "        margin=1.0,\n",
    "        eval_steps=100,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "    ):\n",
    "        train_dataset = LitSearchTripletDataset(train_data, self.tokenizer)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        optimizer = AdamW(\n",
    "            [p for p in self.model.parameters() if p.requires_grad],\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "\n",
    "        total_steps = len(train_loader) * epochs\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=lr,\n",
    "            total_steps=total_steps,\n",
    "            pct_start=warmup_ratio,\n",
    "            anneal_strategy=\"linear\",\n",
    "        )\n",
    "\n",
    "        triplet_loss = TripletMarginLoss(margin=margin)\n",
    "        global_step = 0\n",
    "        best_val_loss = float(\"inf\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "            for batch in progress_bar:\n",
    "                query_emb = self.model_wrapper.encode_query(\n",
    "                    batch[\"query\"], no_grad=False\n",
    "                )\n",
    "                pos_emb = self.model_wrapper.encode_paper(\n",
    "                    batch[\"positive_title\"], batch[\"positive_abstract\"], no_grad=False\n",
    "                )\n",
    "                neg_emb = self.model_wrapper.encode_paper(\n",
    "                    batch[\"negative_title\"], batch[\"negative_abstract\"], no_grad=False\n",
    "                )\n",
    "\n",
    "                loss = triplet_loss(query_emb, pos_emb, neg_emb)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    [p for p in self.model.parameters() if p.requires_grad], 1.0\n",
    "                )\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "                del query_emb, pos_emb, neg_emb, loss\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                global_step += 1\n",
    "                if val_data is not None and global_step % eval_steps == 0:\n",
    "                    val_loss = self.evaluate(val_data, batch_size)\n",
    "                    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        self.save_model(output_dir)\n",
    "                        print(f\"Model saved to {output_dir} (val_loss: {val_loss:.4f})\")\n",
    "\n",
    "                    self.model.train()\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs} - Avg Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "        if val_data is None or epochs % eval_steps != 0:\n",
    "            self.save_model(output_dir)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def evaluate(self, val_data, batch_size=8):\n",
    "        val_dataset = LitSearchTripletDataset(val_data, self.tokenizer)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        self.model.eval()\n",
    "        triplet_loss = TripletMarginLoss(margin=1.0)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                query_emb = self.model_wrapper.encode_query(\n",
    "                    batch[\"query\"], no_grad=False\n",
    "                )\n",
    "                pos_emb = self.model_wrapper.encode_paper(\n",
    "                    batch[\"positive_title\"], batch[\"positive_abstract\"], no_grad=False\n",
    "                )\n",
    "                neg_emb = self.model_wrapper.encode_paper(\n",
    "                    batch[\"negative_title\"], batch[\"negative_abstract\"], no_grad=False\n",
    "                )\n",
    "\n",
    "                loss = triplet_loss(query_emb, pos_emb, neg_emb)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(val_loader)\n",
    "\n",
    "    def save_model(self, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.model_wrapper.save_model(output_dir)\n",
    "        self.tokenizer.save_pretrained(output_dir)\n",
    "        print(f\"어댑터가 {output_dir}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4ac387-c2cf-44d5-a511-b7b56cc07edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def main():\n",
    "    file_path = \"./triplet_data.json\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    n_total = len(data)\n",
    "    n_train = int(n_total * 0.8)\n",
    "    train_data = data[:n_train]\n",
    "    val_data = data[n_train:]\n",
    "\n",
    "    print(f\"# of train: {len(train_data)}\")\n",
    "    print(f\"# of val: {len(val_data)}\")\n",
    "\n",
    "    print(\"Specter2 생성 시작\")\n",
    "    model = Specter2()\n",
    "    print(\"Specter2 생성 완료\")\n",
    "    print(\"Specter2Trainer 생성 시작\")\n",
    "    trainer = Specter2Trainer(model)\n",
    "    print(\"Specter2Trainer 생성 완료\")\n",
    "    print(\"train 호출\")\n",
    "    trainer.train(\n",
    "        train_data=train_data,\n",
    "        val_data=val_data,\n",
    "        output_dir=\"./output\",\n",
    "        lr=2e-4,\n",
    "        batch_size=8,\n",
    "        epochs=5,\n",
    "        margin=1.0,\n",
    "        eval_steps=50,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "    )\n",
    "    print(\"Fine-tuning complete and model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86939abd-78e1-4c26-98bc-275d330973bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341bd71c-d004-42b6-84c3-021a3e87f9a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train: 4196\n",
      "# of val: 1049\n",
      "Specter2 생성 시작\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd1488cf7f24418b67612b80e932799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6588983c550944099b3ad1d087330c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specter2 생성 완료\n",
      "Specter2Trainer 생성 시작\n",
      "Trainer initialized\n",
      "Specter2Trainer 생성 완료\n",
      "train 호출\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/525 [00:00<?, ?it/s]There are adapters available but none are activated for the forward pass.\n",
      "Epoch 1/5:  10%|▉         | 50/525 [01:15<2:00:35, 15.23s/it, loss=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2097\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.2097)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  19%|█▉        | 100/525 [02:30<1:47:44, 15.21s/it, loss=0.243]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1588\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1588)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  29%|██▊       | 150/525 [03:45<1:35:04, 15.21s/it, loss=0.00058]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1435\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1435)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  38%|███▊      | 200/525 [05:00<1:22:23, 15.21s/it, loss=0.275]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1384\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  48%|████▊     | 250/525 [06:14<1:09:37, 15.19s/it, loss=0.0385]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1337\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1337)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  57%|█████▋    | 300/525 [07:29<57:01, 15.20s/it, loss=0.00809] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1286\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1286)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  67%|██████▋   | 350/525 [08:44<44:20, 15.20s/it, loss=0.138]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1205\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1205)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  76%|███████▌  | 400/525 [09:59<31:40, 15.20s/it, loss=0]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1162\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1162)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  86%|████████▌ | 450/525 [11:14<19:00, 15.21s/it, loss=0.242]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1136\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1136)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  95%|█████████▌| 500/525 [12:29<06:20, 15.21s/it, loss=0.304] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 525/525 [12:41<00:00,  1.45s/it, loss=0.146]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Avg Loss: 0.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:   5%|▍         | 25/525 [01:01<2:06:43, 15.21s/it, loss=0.115]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  14%|█▍        | 75/525 [02:16<1:54:09, 15.22s/it, loss=0]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1092\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1092)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  24%|██▍       | 125/525 [03:31<1:41:25, 15.21s/it, loss=0.00829]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1083\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1083)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  33%|███▎      | 175/525 [04:46<1:28:45, 15.22s/it, loss=0.314]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1013\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.1013)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  43%|████▎     | 225/525 [06:01<1:16:05, 15.22s/it, loss=0.0192]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0978\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0978)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  52%|█████▏    | 275/525 [07:16<1:03:18, 15.19s/it, loss=0]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  62%|██████▏   | 325/525 [08:31<50:43, 15.22s/it, loss=0]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  71%|███████▏  | 375/525 [09:46<38:05, 15.24s/it, loss=0.205] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0976\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0976)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  81%|████████  | 425/525 [11:01<25:21, 15.22s/it, loss=0.00455]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  90%|█████████ | 475/525 [12:16<12:42, 15.24s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0961\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0961)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 525/525 [13:31<00:00,  1.55s/it, loss=0.432]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0918\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0918)\n",
      "Epoch 2/5 - Avg Loss: 0.0674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  10%|▉         | 50/525 [01:14<2:00:29, 15.22s/it, loss=0.0569]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0912\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0912)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  19%|█▉        | 100/525 [02:29<1:47:44, 15.21s/it, loss=0]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0895\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  29%|██▊       | 150/525 [03:44<1:34:59, 15.20s/it, loss=0.0328]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  38%|███▊      | 200/525 [04:59<1:22:21, 15.21s/it, loss=0.0716]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  48%|████▊     | 250/525 [06:14<1:09:42, 15.21s/it, loss=0.00726]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0895\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0895)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  57%|█████▋    | 300/525 [07:29<57:09, 15.24s/it, loss=0.0276]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0875\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  67%|██████▋   | 350/525 [08:44<44:24, 15.23s/it, loss=0.0115] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0810\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0810)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  76%|███████▌  | 400/525 [09:59<31:39, 15.20s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  86%|████████▌ | 450/525 [11:14<19:00, 15.21s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  95%|█████████▌| 500/525 [12:29<06:20, 15.21s/it, loss=0]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 525/525 [12:41<00:00,  1.45s/it, loss=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Avg Loss: 0.0289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:   5%|▍         | 25/525 [01:02<2:07:01, 15.24s/it, loss=0]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0802\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0802)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  14%|█▍        | 75/525 [02:17<1:54:12, 15.23s/it, loss=0]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0796\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0796)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  24%|██▍       | 125/525 [03:32<1:41:23, 15.21s/it, loss=0.0439]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  33%|███▎      | 175/525 [04:47<1:28:51, 15.23s/it, loss=0.022] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  43%|████▎     | 225/525 [06:02<1:16:14, 15.25s/it, loss=0]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0775\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0775)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  52%|█████▏    | 275/525 [07:17<1:03:27, 15.23s/it, loss=0]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0775\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0775)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  62%|██████▏   | 325/525 [08:32<50:44, 15.22s/it, loss=0.0645] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  71%|███████▏  | 375/525 [09:47<38:09, 15.26s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  81%|████████  | 425/525 [11:02<25:26, 15.27s/it, loss=0]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0773\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0773)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  90%|█████████ | 475/525 [12:17<12:43, 15.27s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0772\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0772)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|█████████▉| 524/525 [12:43<00:00,  1.92it/s, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0757\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0757)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 525/525 [13:32<00:00,  1.55s/it, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Avg Loss: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  10%|▉         | 50/525 [01:15<2:00:58, 15.28s/it, loss=0]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0750\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  19%|█▉        | 100/525 [02:30<1:48:06, 15.26s/it, loss=0]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0748\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0748)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  29%|██▊       | 150/525 [03:45<1:35:28, 15.28s/it, loss=0]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0747\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Model saved to ./output (val_loss: 0.0747)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  38%|███▊      | 200/525 [05:00<1:22:35, 15.25s/it, loss=0]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  48%|████▊     | 250/525 [06:15<1:09:53, 15.25s/it, loss=0.0549]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  57%|█████▋    | 300/525 [07:31<57:08, 15.24s/it, loss=0]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  67%|██████▋   | 350/525 [08:46<44:29, 15.25s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  76%|███████▌  | 400/525 [10:01<31:47, 15.26s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  86%|████████▌ | 450/525 [11:17<19:05, 15.28s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  95%|█████████▌| 500/525 [12:32<06:21, 15.26s/it, loss=0.0361] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 525/525 [12:45<00:00,  1.46s/it, loss=0]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Avg Loss: 0.0044\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "어댑터가 ./output에 저장되었습니다.\n",
      "Fine-tuning complete and model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb64c9-9ff6-4aa4-a4cc-b2a6387ddbec",
   "metadata": {},
   "source": [
    "Load finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02a6e842-a336-4f91-90d1-de2b8bf3d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import faiss\n",
    "import torch\n",
    "from adapters import AutoAdapterModel\n",
    "from tqdm import tqdm\n",
    "from transformers.models.auto.tokenization_auto import AutoTokenizer\n",
    "\n",
    "\n",
    "class Finetuned_Specter2(Retrieval):\n",
    "    def __init__(self, base_model_name=\"allenai/specter2_base\", device=None):\n",
    "        super().__init__()\n",
    "        self.keys = []\n",
    "        self.values = []\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "        output_dir = \"./output\"\n",
    "\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                self.device = torch.device(\"cuda\")\n",
    "            elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "                self.device = torch.device(\"mps\")\n",
    "            else:\n",
    "                self.device = torch.device(\"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "        self.model = AutoAdapterModel.from_pretrained(base_model_name)\n",
    "        self.model.load_adapter(\"allenai/specter2\", source=\"hf\", load_as=\"proximity\")\n",
    "        self.model.load_adapter(output_dir, load_as=\"adhoc_query\")\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if \"adapters.adhoc_query\" in name:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.model.parameters()\n",
    "\n",
    "    def clear(self):\n",
    "        super().clear()\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "    def save_model(self, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        self.model.save_adapter(output_dir, \"adhoc_query\")\n",
    "\n",
    "        self.tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "        print(f\"어댑터가 {output_dir}에 저장되었습니다.\")\n",
    "\n",
    "    def _encode_text(self, input_ids, attention_mask, adapter_type=\"proximity\"):\n",
    "        \"\"\"\n",
    "\n",
    "        adapter_type: query -> \"adhoc_query\", paper -> \"proximity\"\n",
    "        \"\"\"\n",
    "        self.model.set_active_adapters(adapter_type)\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids.to(self.device),\n",
    "            attention_mask=attention_mask.to(self.device),\n",
    "        )\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        return embeddings\n",
    "\n",
    "    def encode_query(self, query_text: str, no_grad=True):\n",
    "        self.model.eval()\n",
    "        if no_grad:\n",
    "            with torch.no_grad():\n",
    "                tokens = self.tokenizer(\n",
    "                    query_text,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "                return self._encode_text(\n",
    "                    tokens[\"input_ids\"],\n",
    "                    tokens[\"attention_mask\"],\n",
    "                    adapter_type=\"adhoc_query\",\n",
    "                )\n",
    "        else:\n",
    "            tokens = self.tokenizer(\n",
    "                query_text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            return self._encode_text(\n",
    "                tokens[\"input_ids\"],\n",
    "                tokens[\"attention_mask\"],\n",
    "                adapter_type=\"adhoc_query\",\n",
    "            )\n",
    "\n",
    "    def encode_paper(self, title: str, abstract: str, no_grad=True):\n",
    "        self.model.eval()\n",
    "        sep_token = self.tokenizer.sep_token\n",
    "        if isinstance(title, list) and isinstance(abstract, list):\n",
    "            text = [t + sep_token + a for t, a in zip(title, abstract)]\n",
    "        else:\n",
    "            text = title + sep_token + abstract\n",
    "        if no_grad:\n",
    "            with torch.no_grad():\n",
    "                tokens = self.tokenizer(\n",
    "                    text,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    max_length=512,\n",
    "                    return_tensors=\"pt\",\n",
    "                )\n",
    "                return self._encode_text(\n",
    "                    tokens[\"input_ids\"],\n",
    "                    tokens[\"attention_mask\"],\n",
    "                    adapter_type=\"proximity\",\n",
    "                )\n",
    "        else:\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            return self._encode_text(\n",
    "                tokens[\"input_ids\"], tokens[\"attention_mask\"], adapter_type=\"proximity\"\n",
    "            )\n",
    "\n",
    "    def _query(self, query_embedding: torch.Tensor, top_k: int = 20) -> list[int]:\n",
    "        if self.faiss_index is None:\n",
    "            raise ValueError(\n",
    "                \"FAISS index has not been created yet. Call create_index first.\"\n",
    "            )\n",
    "\n",
    "        query_vector = query_embedding.cpu().numpy()\n",
    "        faiss.normalize_L2(query_vector)\n",
    "        distances, indices = self.faiss_index.search(query_vector, top_k)\n",
    "\n",
    "        return indices[0].tolist()\n",
    "\n",
    "    def query(self, query_text: str, n: int, return_keys: bool = False) -> list:\n",
    "        query_embedding = self.encode_query(query_text)\n",
    "        indices = self._query(query_embedding, n)\n",
    "\n",
    "        if return_keys:\n",
    "            results = [(self.keys[i], self.values[i]) for i in indices]\n",
    "        else:\n",
    "            results = [self.values[i] for i in indices]\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _encode_paper_batch(\n",
    "        self, textList: list[str], show_progress_bar: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        self.model.set_active_adapters(\"proximity\")\n",
    "        batch_size = 256\n",
    "        embeddings = []\n",
    "\n",
    "        should_show_progress = show_progress_bar\n",
    "\n",
    "        iterator = range(0, len(textList), batch_size)\n",
    "        if should_show_progress:\n",
    "            iterator = tqdm(iterator, desc=\"Processing document embeddings\")\n",
    "\n",
    "        for i in iterator:\n",
    "            batch_texts = textList[i : i + batch_size]\n",
    "            encoded = self.tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=512,\n",
    "            ).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**encoded)\n",
    "\n",
    "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu()\n",
    "            embeddings.append(batch_embeddings)\n",
    "\n",
    "            if i % (batch_size * 10) == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "        return embeddings\n",
    "\n",
    "    def create_index(self, key_value_pairs: dict[str, int]) -> None:\n",
    "        super().create_index(key_value_pairs)\n",
    "        self.index = self._encode_paper_batch(self.keys)\n",
    "\n",
    "        vector_dim = self.index.shape[1]\n",
    "        index_flat = faiss.IndexFlatIP(vector_dim)\n",
    "        index_vectors = self.index.numpy()\n",
    "        faiss.normalize_L2(index_vectors)\n",
    "\n",
    "        index_flat.add(index_vectors)\n",
    "        self.faiss_index = index_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "007246fe-bc50-4c20-8da2-f1c96ed6d82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdc88797ba14e9f8825b70b86c9ed59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Finetuned_Specter2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb26de53-8ab5-440c-846e-3ea07861c5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There are adapters available but none are activated for the forward pass.\n",
      "Processing document embeddings: 100%|██████████| 226/226 [14:09<00:00,  3.76s/it]\n"
     ]
    }
   ],
   "source": [
    "model.create_index(kv_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afeaffdc-7e47-4f27-850b-960fd825936f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query_set', 'query', 'specificity', 'quality', 'corpusids'],\n",
       "    num_rows: 597\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0063ba-4bf8-4d2b-9076-142eecb26597",
   "metadata": {},
   "source": [
    "evaluate finetuned_specter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00caf0b5-c54f-4522-a1f0-bf7a03085861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_for_dataset(dataset, model, k=20):\n",
    "    def retrieval_fn(example):\n",
    "        top_k = model.query(example[\"query\"], k)\n",
    "        example[\"retrieved\"] = top_k\n",
    "        return example\n",
    "    return dataset.map(retrieval_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7624895-0b7b-4e6f-bfd9-b6f56eee1622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3bdda2254e4039a7bd4a64034f0197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c23ade2e194110a9e55604db3ad42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b2c576987a4d9fa8e34294a6dff5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/231 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd72ccaee16f4b6991a7ab34f358ec33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ef5ee7597d4fa9913ed2123716afba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb01d7dfe0364794a7f73fac30722238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/442 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spec0_inline_ds = retrieve_for_dataset(spec0_inline_ds, model)\n",
    "spec0_manual_ds = retrieve_for_dataset(spec0_manual_ds, model)\n",
    "spec1_inline_ds = retrieve_for_dataset(spec1_inline_ds, model)\n",
    "spec1_manual_ds = retrieve_for_dataset(spec1_manual_ds, model)\n",
    "spec0_ds = retrieve_for_dataset(spec0_ds, model)\n",
    "spec1_ds = retrieve_for_dataset(spec1_ds, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f183bf9-8e69-4c1f-8c29-0894a5bc7be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec0 inline Recall@20: 0.4637\n",
      "spec0 manual Recall@20: 0.4286\n",
      "spec0 avg Recall@20:    0.4558\n",
      "\n",
      "spec1 inline Recall@5:  0.4069\n",
      "spec1 inline Recall@20: 0.6190\n",
      "spec1 manual Recall@5:  0.4360\n",
      "spec1 manual Recall@20: 0.5924\n",
      "spec1 avg Recall@20:    0.6063\n"
     ]
    }
   ],
   "source": [
    "spec0_inline_recall20 = mean_recall(spec0_inline_ds, 20)\n",
    "spec0_manual_recall20 = mean_recall(spec0_manual_ds, 20)\n",
    "spec0_avg_recall20 = mean_recall(spec0_ds, 20)\n",
    "\n",
    "spec1_inline_recall5 = mean_recall(spec1_inline_ds, 5)\n",
    "spec1_inline_recall20 = mean_recall(spec1_inline_ds, 20)\n",
    "spec1_manual_recall5 = mean_recall(spec1_manual_ds, 5)\n",
    "spec1_manual_recall20 = mean_recall(spec1_manual_ds, 20)\n",
    "spec1_avg_recall20 = mean_recall(spec1_ds, 20)\n",
    "\n",
    "print(f\"spec0 inline Recall@20: {spec0_inline_recall20:.4f}\")\n",
    "print(f\"spec0 manual Recall@20: {spec0_manual_recall20:.4f}\")\n",
    "print(f\"spec0 avg Recall@20:    {spec0_avg_recall20:.4f}\")\n",
    "print()\n",
    "print(f\"spec1 inline Recall@5:  {spec1_inline_recall5:.4f}\")\n",
    "print(f\"spec1 inline Recall@20: {spec1_inline_recall20:.4f}\")\n",
    "print(f\"spec1 manual Recall@5:  {spec1_manual_recall5:.4f}\")\n",
    "print(f\"spec1 manual Recall@20: {spec1_manual_recall20:.4f}\")\n",
    "print(f\"spec1 avg Recall@20:    {spec1_avg_recall20:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
