[
  {
    "index": 0,
    "source_corpus_id": 252715594,
    "ref_id": "b57",
    "citation_corpus_id": 238582653,
    "start": 11564,
    "end": 11568,
    "title": "VECTOR-QUANTIZED IMAGE MODELING WITH IM- PROVED VQGAN",
    "abstract": "Pretraining language models with next-token prediction on massive text corpora has delivered phenomenal zero-shot, few-shot, transfer learning and multi-tasking capabilities on both generative and discriminative language tasks. Motivated by this success, we explore a Vector-quantized Image Modeling (VIM) approach that involves pretraining a Transformer to predict rasterized image tokens autoregressively. The discrete image tokens are encoded from a learned Vision-Transformerbased VQGAN (ViT-VQGAN). We first propose multiple improvements over vanilla VQGAN from architecture to codebook learning, yielding better efficiency and reconstruction fidelity. The improved ViT-VQGAN further improves vectorquantized image modeling tasks, including unconditional, class-conditioned image generation and unsupervised representation learning. When trained on Im-ageNet at 256 \u00d7 256 resolution, we achieve Inception Score (IS) of 175.1 and Fr\u00e9chet Inception Distance (FID) of 4.17, a dramatic improvement over the vanilla VQGAN, which obtains 70.6 and 17.04 for IS and FID, respectively. Based on ViT-VQGAN and unsupervised pretraining, we further evaluate the pretrained Transformer by averaging intermediate features, similar to Image GPT (iGPT). This ImageNet-pretrained VIM-L significantly beats iGPT-L on linear-probe accuracy from 60.3% to 73.2% for a similar model size. VIM-L also outperforms iGPT-XL which is trained with extra web image data and larger model size.arXiv:2110.04627v3 [cs.CV] 5 Jun 2022Published as a conference paper at ICLR 2022 Figure 1: Overview of ViT-VQGAN (left) and Vector-quantized Image Modeling (right) for both image generation and image understanding.Remarkable image generation results have been achieved by pre-quantizing images into discrete latent variables and modeling them autoregressively, including VQVAE (Oord et al., 2017), DALL-E (Ramesh et al., 2021)  and VQGAN (Esser et al., 2021). In these approaches, a convolution neural network (CNN) is learned to auto-encode an image and a second stage CNN or Transformer is learned to model the density of encoded latent variables. These have been proved effective for image generation, but few studies have evaluated the learned representation in discriminative tasks (Ramesh et al., 2021; Esser et al., 2021).We explore an approach we refer to as Vector-quantized Image Modeling (VIM) and apply it to both image generation and image understanding tasks. VIM follows a two-stage approach:",
    "prev": "Quantization and Losses:\n\nTo learn a discrete latent space, we quantize our encoder outputs into the entries of a learned codebook via the vector quantization (VQ) objective in VQVAEs [45],\nL VQ = sg(z) \u2212 e 2 2 + \u03b2 z \u2212 sg(e) 2 2 ,(1)\nwhere sg(x) \u2261 x, and d dx sg(x) \u2261 0 is the stop-gradient operator, \u03b2 is the commitment loss weight, and e is a codebook vector from codebook E. The index to the codebook vector closest to z is found by i = argmin j z \u2212 E j 2 2 .",
    "curr": "In addition to the VQ objective, we adopt the factorized and 2normalized codes from ViT-VQGAN [58] to improve codebook usage and reconstruction quality.",
    "next": "To train our model, we use a combination of L 2 loss, image perceptual loss L IP [20,61], video perceptual loss L VP by using the I3D network [6] as feature extractor, and adversarial loss L Adv with StyleGAN architecture [21].",
    "hard_negative": [
      222125075,
      227127234,
      3568073,
      52967399,
      84591,
      4009713,
      52889459
    ],
    "easy_negative": [
      15913934,
      2549397,
      222133227
    ]
  },
  {
    "index": 15,
    "source_corpus_id": 253523474,
    "ref_id": "b10",
    "citation_corpus_id": 245906072,
    "start": 3522,
    "end": 3546,
    "title": "Implicit Bias of MSE Gradient Optimization in Underparameterized Neural Networks",
    "abstract": "We study the dynamics of a neural network in function space when optimizing the mean squared error via gradient flow. We show that in the underparameterized regime the network learns eigenfunctions of an integral operator TK\u221e determined by the Neural Tangent Kernel (NTK) at rates corresponding to their eigenvalues. For example, for uniformly distributed data on the sphere S d\u22121 and rotation invariant weight distributions, the eigenfunctions of TK\u221e are the spherical harmonics. Our results can be understood as describing a spectral bias in the underparameterized regime. The proofs use the concept of \"Damped Deviations\", where deviations of the NTK matter less for eigendirections with large eigenvalues due to the occurence of a damping factor. Aside from the underparameterized regime, the damped deviations point-of-view can be used to track the dynamics of the empirical risk in the overparameterized setting, allowing us to extend certain results in the literature. We conclude that damped deviations offers a simple and unifying perspective of the dynamics when optimizing the squared error.",
    "prev": "In particular, bounding the smallest eigenvalue of the NTK Gram matrix is a staple technique for establishing convergence guarantees for the optimization (Du et al., 2019a,b;Oymak & Soltanolkotabi, 2020).",
    "curr": "Furthermore, the full spectrum of the NTK Gram matrix governs the dynamics of the empirical risk (Arora et al., 2019b), and the eigenvalues of the associated integral operator characterize the dynamics of the generalization error outside the training set (Bowman & Montufar, 2022;Bowman & Mont\u00fafar, 2022).",
    "next": "Moreover, the decay rate of the generalization error for Gaussian process regression using the NTK can be characterized by the decay rate of the spectrum (Caponnetto & De Vito, 2007;Cui et al., 2021;Jin et al., 2022).",
    "hard_negative": [
      6212000,
      52920808,
      3458474
    ],
    "easy_negative": [
      30162029,
      259376745,
      7355762
    ]
  },
  {
    "index": 24,
    "source_corpus_id": 246904522,
    "ref_id": "b38",
    "citation_corpus_id": 5034059,
    "start": 1944,
    "end": 1964,
    "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    "abstract": "For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusively tailored to a specific task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating and analyzing the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and find that multi-task training on all our tasks yields better results than training a separate model for each task. However, the low absolute performance of our best model indicates the need for improved general NLU systems. son. 2013. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint 1312.3005.",
    "prev": "* Equal contribution.",
    "curr": "INTRODUCTION\n\nOver the past few years, Transformer (Vaswani et al., 2017) has been widely used in various natural language processing (NLP) tasks, including text classification (Wang et al., 2018a), text translation (Ott et al., 2018), question answering (Rajpurkar et al., 2016; and text generation (Brown et al., 2020).",
    "next": "The recent application of Transformer in computer vision (CV) field also demonstrate the potential capacity of Transformer architecture.",
    "hard_negative": [
      5074049,
      388,
      2937095,
      2213896,
      25422730,
      4537113,
      16661147,
      1957433,
      3626819,
      1994584,
      2135897,
      3264224,
      4567927
    ],
    "easy_negative": [
      7604036,
      6039355,
      237304281
    ]
  },
  {
    "index": 26,
    "source_corpus_id": 257834209,
    "ref_id": "b41",
    "citation_corpus_id": 3626819,
    "start": 1592,
    "end": 1612,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "In our experiments, SPIN reduces memory requirements, improves accuracy across a range of metalearning tasks, and improves state-of-the-art performance on an important practical problem, genotype imputation.",
    "curr": "INTRODUCTION\n\nRecent advances in deep learning have been driven by large-scale parametric models (Krizhevsky et al., 2012;Peters et al., 2018;Devlin et al., 2019;Ramesh et al., 2022).",
    "next": "Modern parametric models rely on large numbers of weights to capture the signal contained in the training set and to facilitate generalization (Frankle & Carbin, 2018;; as a result, they require non-trivial computational resources (Hoffmann et al., 2022), have limited interpretability (Belinkov, 2022), and impose a significant carbon footprint (Bender et al., 2021).",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      8535316,
      11336213,
      990233,
      9917468,
      20472740,
      34032948,
      10489017,
      1957433,
      1222212,
      12688069,
      15026764,
      11816014,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      18471591,
      16036657,
      13600036
    ]
  },
  {
    "index": 32,
    "source_corpus_id": 21850704,
    "ref_id": "b5",
    "citation_corpus_id": 1729177,
    "start": 1836,
    "end": 1854,
    "title": "Hedge Trimmer: A Parse-and-Trim Approach to Headline Generation",
    "abstract": "This paper presents Hedge Trimmer, a HEaDline GEneration system that creates a headline for a newspaper story using linguistically-motivated heuristics to guide the choice of a potential headline. We present feasibility tests used to establish the validity of an approach that constructs a headline by selecting words in order from a story. In addition, we describe experimental results that demonstrate the effectiveness of our linguistically-motivated approach over a HMM-based model, using both human evaluation and automatic metrics for comparing the two approaches.",
    "prev": "There are two prominent types of summarization algorithms.",
    "curr": "First, extractive summarization systems form summaries by copying parts of the input (Neto et al., 2002;Dorr et al., 2003;Nallapati et al., 2017).",
    "next": "Second, abstractive summarization systems generate new phrases, possibly rephrasing or using words that were not in the original text (Chopra et al., 2016;Zeng et al., 2016).",
    "hard_negative": [
      9952653,
      8945340,
      1345,
      10019526,
      11846745
    ],
    "easy_negative": [
      7116755,
      232021761,
      236179533
    ]
  },
  {
    "index": 33,
    "source_corpus_id": 239009555,
    "ref_id": "b26",
    "citation_corpus_id": 3536221,
    "start": 3973,
    "end": 3995,
    "title": "MODEL-ENSEMBLE TRUST-REGION POLICY OPTI- MIZATION",
    "abstract": "Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning. However, they tend to suffer from high sample complexity which hinders their use in real-world domains. Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and, to date, it has succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and we show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks 1 2 .Published as a conference paper at ICLR 2018 assumption in this approach, henceforth termed vanilla model-based RL, is that with enough data, the learned model will be accurate enough, such that a policy optimized on it will also perform well in the real environment.Although vanilla model-based RL can work well on low-dimensional tasks with relatively simple dynamics, we find that on more challenging continuous control tasks, performance was highly unstable. The reason is that the policy optimization tends to exploit regions where insufficient data is available to train the model, leading to catastrophic failures. Previous work has pointed out this issue as model biasWhile this issue can be regarded as a form of overfitting, we emphasize that standard countermeasures from the supervised learning literature, such as regularization or cross validation, are not sufficient here -supervised learning can guarantee generalization to states from the same distribution as the data, but the policy optimization stage steers the optimization exactly towards areas where data is scarce and the model is inaccurate. This problem is severely aggravated when expressive models such as deep neural networks are employed.",
    "prev": "Model-based RL (MBRL) reduces the amount of data required for policy optimization by approximating the environment with a learned model, which we can use to generate simulated state transitions (Sutton, 1990;Racani\u00e8re et al., 2017;Moerland et al., 2020).",
    "curr": "While early approaches on lowdimensional tasks by Schneider (1997); Deisenroth & Rasmussen (2011) used probabilistic models with closed-form posteriors, recent methods rely on neural networks to scale to complex tasks on discrete (Kaiser et al., 2020) and continuous (Chua et al., 2018;Kurutach et al., 2018) action spaces.",
    "next": "However, the learned representation of the true environment always remains imperfect, which introduces approximation errors to the RL problem (Atkeson & Santamaria, 1997;Abbeel et al., 2006).",
    "hard_negative": [
      5176587,
      3075448
    ],
    "easy_negative": [
      51870186,
      232478685,
      529467
    ]
  },
  {
    "index": 36,
    "source_corpus_id": 261697392,
    "ref_id": "b16",
    "citation_corpus_id": 227209335,
    "start": 2939,
    "end": 2942,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "However, despite their impressive generation quality, these models often suffer from excessive inference time and computational consumption [5,7,8,9,10].",
    "curr": "This can be attributed to the fact that most of these models are either auto-regressive [13,14,15] or diffusion models [16,17].",
    "next": "For instance, Stable Diffusion, even when using a state-of-the-art sampler [18,19,20], typically requires more than 20 steps to generate acceptable images.",
    "hard_negative": [
      52889459,
      52908831
    ],
    "easy_negative": [
      219309715,
      167217367,
      235358557
    ]
  },
  {
    "index": 38,
    "source_corpus_id": 220302524,
    "ref_id": "b1",
    "citation_corpus_id": 3618568,
    "start": 1983,
    "end": 1986,
    "title": "Reading Wikipedia to Answer Open-Domain Questions",
    "abstract": "This paper proposes to tackle opendomain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.",
    "prev": "Introduction\n\nMany language systems rely on text retrieval as their first step to find relevant information.",
    "curr": "For example, search ranking [1], open domain question answering [2], and fact verification [3,4] all first retrieve relevant documents as the input to their later stage reranking, machine reading, and reasoning models.",
    "next": "All these later-stage models enjoy the advancements of deep learning techniques [5,6], while, in contrast, the first stage retrieval still mainly relies on matching discrete bag-of-words [1,2,3,7].",
    "hard_negative": [
      6360322,
      14068874,
      12384779,
      1957433,
      10910955,
      5541486,
      216034672,
      11212020,
      14915449,
      2711679
    ],
    "easy_negative": [
      52834905,
      252847464,
      14715715
    ]
  },
  {
    "index": 39,
    "source_corpus_id": 252596001,
    "ref_id": "b20",
    "citation_corpus_id": 209439843,
    "start": 6589,
    "end": 6611,
    "title": "MEASURING COMPOSITIONAL GENERALIZATION: A COMPREHENSIVE METHOD ON REALISTIC DATA",
    "abstract": "State-of-the-art machine learning methods exhibit limited compositional generalization. At the same time, there is a lack of realistic benchmarks that comprehensively measure this ability, which makes it challenging to find and evaluate improvements. We introduce a novel method to systematically construct such benchmarks by maximizing compound divergence while guaranteeing a small atom divergence between train and test sets, and we quantitatively compare this method to other approaches for creating compositional generalization benchmarks. We present a large and realistic natural language question answering dataset that is constructed according to this method, and we use it to analyze the compositional generalization ability of three machine learning architectures. We find that they fail to generalize compositionally and that there is a surprisingly strong negative correlation between compound divergence and accuracy. We also demonstrate how our method can be used to create new compositionality benchmarks on top of the existing SCAN dataset, which confirms these findings. Radev. Improving text-to-SQL evaluation methodology. In ACL, 2018. URL http://aclweb.org/anthology/P18-1033.Jerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical analysis. Cognition, 28(1-2):3-71, 1988. URL https://pdfs.semanticscholar.org/d806/ 76034bfabfea59f35698af0f715a555fcf50.pdf.",
    "prev": "d and wrote N1 A: that (edited and wrote) (N1) Q: whose N1 was employed by and founded M1 A: whose (N1) (was employed by and founded) (M1) Q: whose N1 married M2 and married N2 A: whose (N1) ((married M2) and (married N2)) Q: that played M2 , played M3 , and played M4 A: that ((played M2) , (played M3) , and (played M4)) Q: that wrote , edited , executive produced , and directed N1 A: that (wrote , edited , executive produced , and directed) (N1) Q: that N3 were written by and art directed by A: that (N3) (were written by and art directed by) Q: Was N1 N2\n\nINTRODUCTION\n\nCompositionality is a key part of human intelligence as it allows us to understand and produce a potentially infinite number of novel combinations of known components (Chomsky, 1957;Montague, 1970;Lake et al., 2017).",
    "curr": "In contrast, standard neural sequence models, transformers and recurrent neural networks, often fail to capture the compositional structure of the problem domain and thus fail to generalize compositionally (Keysers et al., 2020;.",
    "next": "Prior efforts to improve compositional generalization primarily rely on specialized architectures or training procedures (Lake, 2019;Nye et al., 2020;Andreas, 2020;Conklin et al., 2021;Liu et al., 2021).",
    "hard_negative": [
      969059,
      3728944,
      348944,
      108296442,
      85504763,
      3986974,
      2711679
    ],
    "easy_negative": [
      252818938,
      252199584,
      218974553
    ]
  },
  {
    "index": 40,
    "source_corpus_id": 259095643,
    "ref_id": "b15",
    "citation_corpus_id": 10494183,
    "start": 3887,
    "end": 3906,
    "title": "Generating Steganographic Text with LSTMs",
    "abstract": "Motivated by concerns for user privacy, we design a steganographic system (\"stegosystem\") that enables two users to exchange encrypted messages without an adversary detecting that such an exchange is taking place. We propose a new linguistic stegosystem based on a Long Short-Term Memory (LSTM) neural network. We demonstrate our approach on the Twitter and Enron email datasets and show that it yields high-quality steganographic text while significantly improving capacity (encrypted bits per word) relative to the state-of-the-art.",
    "prev": "This can lead to low accuracy or impractical false positive rates that especially impact vulnerable subgroups, such as non-native speakers [Liang et al., 2023].",
    "curr": "One way to enable accurate detection of machine-generated text is through watermarking, where generated text is marked imperceptibly so that its origin can be determined [Atallah et al., 2001, Fang et al., 2017, Kirchenbauer et al., 2023.",
    "next": "Because watermarks rely on subtle patterns in text that are statistically unlikely to be replicated by a human, watermarking enables detectors that achieve high levels of accuracy on relatively short fragments of text.",
    "hard_negative": [
      367269,
      1957433,
      11205459,
      16096
    ],
    "easy_negative": [
      4978914,
      14405310,
      219301746
    ]
  },
  {
    "index": 42,
    "source_corpus_id": 259342096,
    "ref_id": "b43",
    "citation_corpus_id": 237416585,
    "start": 7349,
    "end": 7352,
    "title": "Published as a conference paper at ICLR 2022 FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS",
    "abstract": "This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning-finetuning language models on a collection of datasets described via instructions-substantially improves zeroshot performance on unseen tasks.",
    "prev": "Among these models, transformer-based language models [49] have emerged as the de facto standard for a wide range of NLP tasks, owing to their unparalleled capabilities in capturing complex linguistic patterns and generalizing across diverse contexts.",
    "curr": "One particularly successful paradigm for training such models is instruction-tuning [44,52,4,28,34,38], which enhances their performance on specific tasks by adapting their pre-trained representations to follow natural language instructions.",
    "next": "While the benefits of Large Language Models (LLMs) are indisputable, their rapidly growing size and computational requirements pose significant challenges in terms of training efficiency, memory footprint, and deployment costs.",
    "hard_negative": [
      210838924,
      220045465,
      102353817,
      52055325,
      52057510,
      202540839,
      3432876,
      195218742,
      9586240,
      182953152,
      3626819,
      220364230,
      11816014,
      207756753,
      165163607,
      233231453,
      10766958,
      85464175,
      47018994,
      215768182,
      219165306,
      85504763
    ],
    "easy_negative": [
      212736862,
      5291877,
      60330510
    ]
  },
  {
    "index": 43,
    "source_corpus_id": 21196492,
    "ref_id": "b20",
    "citation_corpus_id": 11816014,
    "start": 4490,
    "end": 4514,
    "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
    "abstract": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com.",
    "prev": "(2016) show that skip layer connections facilitate signal propagation and alleviate gradient degradation.",
    "curr": "The combination of the deep residual coattention encoder and the mixed objective leads to higher performance across question types, question lengths, and answer lengths on the Stanford Question Answering Dataset (SQuAD) (Rajpurkar et al., 2016) compared to our DCN baseline.",
    "next": "The improvement is especially apparent on long questions, which require the model to capture long-range dependencies between the document and the question.",
    "hard_negative": [
      6360322,
      2337034,
      15425307,
      9846946,
      428579,
      8764466,
      14071482,
      1199934,
      8471750,
      1373518,
      12451537,
      2100831,
      15197674,
      5541486,
      226541,
      14915449,
      252796
    ],
    "easy_negative": [
      256461015,
      261341546,
      8644172
    ]
  },
  {
    "index": 45,
    "source_corpus_id": 254926490,
    "ref_id": "b48",
    "citation_corpus_id": 237491751,
    "start": 5512,
    "end": 5531,
    "title": "SITUATEDQA: Incorporating Extra-Linguistic Contexts into QA",
    "abstract": "Answers to the same question may change depending on the extra-linguistic contexts (when and where the question was asked). To study this challenge, we introduce SITUATEDQA, an open-retrieval QA dataset where systems must produce the correct answer to a question given the temporal or geographical context. To construct SITUATEDQA, we first identify such questions in existing QA datasets. We find that a significant proportion of information seeking questions have context-dependent answers (e.g. roughly 16.5% of NQ-Open). For such context-dependent questions, we then crowdsource alternative contexts and their corresponding answers. Our study shows that existing models struggle with producing answers that are frequently updated or from uncommon locations. We further quantify how existing models, which are trained on data collected in the past, fail to generalize to answering questions asked in the present, even when provided with an updated evidence corpus (a roughly 15 point drop in accuracy). Our analysis suggests that open-retrieval QA benchmarks should incorporate extra-linguistic context to stay relevant globally and in the future. Our data, code, and datasheet are available at https: //situatedqa.github.io/.",
    "prev": "Evaluate humans and models on a new benchmark of ambiguously-specified tasks, demonstrating that while pure language models fail to disambiguate the intended task well, sufficiently-large models trained with human feedback data are able to approach or even exceed the performance of our human participants to resolve the ambiguity between tasks 3.",
    "curr": "Show how finetuning on ambiguous in-context prompts and examples can enable traditional language models to surpass the performance of HFD models when evaluated on unseen tasks, providing a promising route towards models that capably manage task ambiguity 2 RELATED WORK\n\n\nAMBIGUITY IN NATURAL LANGUAGE PROCESSING\n\nAmbiguity is a well-studied topic in NLP, with work spanning topics as diverse as search queries (Cronen-Townsend & Croft, 2002;Wang & Agichtein, 2010), question answering (Min et al., 2020;Zhang & Choi, 2021), named entities (Bunescu & Pasca, 2006;Cucerzan, 2007;Dredze et al., 2010), coreference resolution (Webster et al., 2018), machine translation (Stanovsky et al., 2019), and information-seeking dialogues (Aliannejadi et al., 2019;Guo et al., 2021;Aliannejadi et al., 2021;Sun et al., 2022;.",
    "next": "Our work differs from these prior streams of work by studying task ambiguity (Finn et al., 2018;Tamkin et al., 2022c), where the task the agent is being asked to perform is ambiguous, rather than an ambiguous input for a clear task.",
    "hard_negative": [
      208117506,
      218581125,
      3618568,
      233219849,
      220047370,
      6401679,
      6187154,
      225066771,
      196201373,
      202539551,
      173990818,
      52057510,
      7294125,
      52019251,
      7942973,
      21695934,
      229923903,
      215768768,
      2597568,
      211205183,
      59599681,
      204960716,
      11816014,
      218628691,
      230433881,
      2381275,
      215737187,
      235313508,
      235669861,
      52967399,
      47018994,
      232233599
    ],
    "easy_negative": [
      237433536,
      5964257,
      48358519
    ]
  },
  {
    "index": 46,
    "source_corpus_id": 52912260,
    "ref_id": "b22",
    "citation_corpus_id": 14124313,
    "start": 1763,
    "end": 1792,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "ckle this problem by learning a generic classifier across a large number of multiclass classification tasks and generalizing the model to a new task.Yet, even with such meta-learning, the low-data problem in the novel classification task still remains.In this paper, we propose Transductive Propagation Network (TPN), a novel meta-learning framework for transductive inference that classifies the entire test set at once to alleviate the low-data problem.Specifically, we propose to learn to propagate labels from labeled instances to unlabeled test instances, by learning a graph construction module that exploits the manifold structure in the data.TPN jointly learns both the parameters of feature embedding and the graph construction in an end-to-end manner.We validate TPN on multiple benchmark datasets, on which it largely outperforms existing few-shot learning approaches and achieves the state-of-the-art results.",
    "curr": "INTRODUCTION\n\nRecent breakthroughs in deep learning (Krizhevsky et al., 2012;Simonyan and Zisserman, 2015;He et al., 2016) highly rely on the availability of large amounts of labeled data.However, this reliance on large data increases the burden of data collection, which hinders its potential applications to the low-data regime where the labeled data is rare and difficult to gather.On the contrary, humans have the ability to recognize new objects after observing only one or few instances (Lake et al., 2011).For example, children can generalize the concept of \"apple\" after given a single instance of it.This significant gap between human and deep learning has reawakened the research interest on few-shot learning (Vinyals et al., 2016;Snell et al., 2017;Finn et al., 2017;Ravi and Larochelle, 2017;Lee and Choi, 2018;Xu et al., 2017;Wang et al., 2018).",
    "next": "Few-shot learning aims to learn a classifier that generalizes well with a few examples of each of these classes.Traditional techniques such as fine-tuning (Jia et al., 2014) that work well with deep learning models would severely overfit on this",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      259370598,
      167401,
      16723397
    ]
  },
  {
    "index": 54,
    "source_corpus_id": 235293695,
    "ref_id": "b7",
    "citation_corpus_id": 54443381,
    "start": 2354,
    "end": 2377,
    "title": "EFFICIENT LIFELONG LEARNING WITH A-GEM",
    "abstract": "In lifelong learning, the learner is presented with a sequence of tasks, incrementally building a data-driven prior which may be leveraged to speed up learning of a new task. In this work, we investigate the efficiency of current lifelong approaches, in terms of sample complexity, computational and memory cost. Towards this end, we first introduce a new and a more realistic evaluation protocol, whereby learners observe each example only once and hyper-parameter selection is done on a small and disjoint set of tasks, which is not used for the actual learning experience and evaluation. Second, we introduce a new metric measuring how quickly a learner acquires a new skill. Third, we propose an improved version of GEM (Lopez-Paz & Ranzato, 2017), dubbed Averaged GEM (A-GEM), which enjoys the same or even better performance as GEM, while being almost as computationally and memory efficient as EWC  and other regularizationbased methods. Finally, we show that all algorithms including A-GEM can learn even more quickly if they are provided with task descriptors specifying the classification tasks under consideration. Our experiments on several standard lifelong learning benchmarks demonstrate that A-GEM has the best trade-off between accuracy and efficiency. 1",
    "prev": "Building a system resembling human learning abilities is a deep-rooted desire since sustainable learning over a long-term period is essential for general artificial intelligence.",
    "curr": "In light of this need, continual learning (CL) (Thrun, 1995), or lifelong learning, tackles a learning scenario where a model continuously learns over a sequence of tasks (Kumar & Daume III, 2012;Li & Hoiem, 2016) within a broad research area, such as classification (Kirkpatrick et al., 2017;Chaudhry et al., 2019a), image generation (Zhai et al., 2019), language learning (Li et al., 2019b;Biesialska et al., 2020), clinical application (Lee & Lee, 2020;Lenga et al., 2020), speech recognition (Sadhu & Hermansky, 2020), and federated learning (Yoon et al., 2021).",
    "next": "A well-known challenge for continual learning is catastrophic forgetting (McCloskey & Cohen, 1989), where the continual learner loses the fidelity for past tasks after adapting the previously learned knowledge to future tasks.",
    "hard_negative": [
      22014305,
      49667227
    ],
    "easy_negative": [
      19898591,
      32388613,
      18324496
    ]
  },
  {
    "index": 61,
    "source_corpus_id": 211132990,
    "ref_id": "b32",
    "citation_corpus_id": 3536221,
    "start": 4217,
    "end": 4240,
    "title": "MODEL-ENSEMBLE TRUST-REGION POLICY OPTI- MIZATION",
    "abstract": "Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning. However, they tend to suffer from high sample complexity which hinders their use in real-world domains. Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and, to date, it has succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and we show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks 1 2 .Published as a conference paper at ICLR 2018 assumption in this approach, henceforth termed vanilla model-based RL, is that with enough data, the learned model will be accurate enough, such that a policy optimized on it will also perform well in the real environment.Although vanilla model-based RL can work well on low-dimensional tasks with relatively simple dynamics, we find that on more challenging continuous control tasks, performance was highly unstable. The reason is that the policy optimization tends to exploit regions where insufficient data is available to train the model, leading to catastrophic failures. Previous work has pointed out this issue as model biasWhile this issue can be regarded as a form of overfitting, we emphasize that standard countermeasures from the supervised learning literature, such as regularization or cross validation, are not sufficient here -supervised learning can guarantee generalization to states from the same distribution as the data, but the policy optimization stage steers the optimization exactly towards areas where data is scarce and the model is inaccurate. This problem is severely aggravated when expressive models such as deep neural networks are employed.",
    "prev": "A further study confirms that deep ensembles generally achieves the best performance on out-of-distribution uncertainty benchmarks (Ovadia et al., 2019;Gustafsson et al., 2019), compared to other methods such as MC-dropout (Gal & Ghahramani, 2015).",
    "curr": "In other applications such as model-based reinforcement learning (Deisenroth & Rasmussen, 2011;Wang et al., 2019), ensembles of neural networks can be used to estimate model uncertainty, leading to better overall performance (Kurutach et al., 2018).",
    "next": "Despite their success on benchmarks, ensembles are limited in practice due to their expensive computational and memory costs, which increase linearly with the ensemble size in both training and testing.",
    "hard_negative": [
      5176587,
      3075448
    ],
    "easy_negative": [
      125656511,
      4385980,
      6554837
    ]
  },
  {
    "index": 64,
    "source_corpus_id": 259375870,
    "ref_id": "b23",
    "citation_corpus_id": 243865663,
    "start": 12470,
    "end": 12488,
    "title": "Have You Seen That Number? Investigating Extrapolation in Question Answering Models",
    "abstract": "Numerical reasoning in machine reading comprehension (MRC) has shown drastic improvements over the past few years. While the previous models for numerical MRC are able to interpolate the learned numerical reasoning capabilities, it is not clear whether they can perform just as well on numbers unseen in the training dataset. Our work rigorously tests state-of-the-art models on DROP, a numerical MRC dataset, to see if they can handle passages that contain out-of-range numbers. One of the key findings is that the models fail to extrapolate to unseen numbers. Presenting numbers as digit-by-digit input to the model, we also propose the E-digit number form that alleviates the lack of extrapolation in models and reveals the need to treat numbers differently from regular words in the text. Our work provides a valuable insight into the numerical MRC models and the way to represent number forms in MRC. * Equal contribution.",
    "prev": "Our work focuses on decoder-only models since they are well-suited for text generation and are widely used in LLMs (Brown et al., 2020;Touvron et al., 2023;MosaicML, 2023).",
    "curr": "However, encoder-decoder models have also been extensively studied in the literature in the context of learning arithmetic (Kim et al., 2021;Wang et al., 2021).",
    "next": "Qian et al.",
    "hard_negative": [
      215548225,
      52967399,
      202541516,
      202583694,
      199668626,
      210180949,
      232335764,
      209202200,
      221738937,
      202558815
    ],
    "easy_negative": [
      6836806,
      15854992,
      234487227
    ]
  },
  {
    "index": 65,
    "source_corpus_id": 222141728,
    "ref_id": "b2",
    "citation_corpus_id": 52922363,
    "start": 4476,
    "end": 4496,
    "title": "A CONVERGENCE ANALYSIS OF GRADIENT DESCENT FOR DEEP LINEAR NEURAL NETWORKS",
    "abstract": "We analyze speed of convergence to global optimum for gradient descent training a deep linear neural network (parameterized as x \u2192 W N W N \u22121 \u00b7 \u00b7 \u00b7 W 1 x) by minimizing the 2 loss over whitened data. Convergence at a linear rate is guaranteed when the following hold: (i) dimensions of hidden layers are at least the minimum of the input and output dimensions; (ii) weight matrices at initialization are approximately balanced; and (iii) the initial loss is smaller than the loss of any rank-deficient solution. The assumptions on initialization (conditions (ii) and (iii)) are necessary, in the sense that violating any one of them may lead to convergence failure. Moreover, in the important case of output dimension 1, i.e. scalar regression, they are met, and thus convergence to global optimum holds, with constant probability under a random initialization scheme. Our results significantly extend previous analyses, e.g., of deep linear residual networks(Bartlett et al., 2018).",
    "prev": "(2018); Oymak & Soltanolkotabi (2020), and many more).",
    "curr": "There are also convergence results that focus on linear networks, without nonlinear activations (Bartlett et al., 2018;Arora et al., 2019a;Wu et al., 2019;Du & Hu, 2019;Hu et al., 2020).",
    "next": "These results typically focus on the convergence of loss, hence do not address which of the many global minima is reached.",
    "hard_negative": [
      30745030,
      3624410
    ],
    "easy_negative": [
      32616705,
      235258269,
      920499
    ]
  },
  {
    "index": 68,
    "source_corpus_id": 253080406,
    "ref_id": "b24",
    "citation_corpus_id": 3626819,
    "start": 7137,
    "end": 7158,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "Language models.",
    "curr": "Large language models, such as ELMo (Peters et al., 2018), BERT (Devlin et al., 2018), and GPT-2 (Radford et al., 2019), are able to achieve state-of-the-art performance on many standard NLP benchmarks.",
    "next": "More recent works, such as GPT-3 (Brown et al., 2020), PALM (Chowdhery et al., 2022), and Chinchilla (Hoffmann et al., 2022) further enable few-shot learning from textual prompts.",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      8535316,
      11336213,
      990233,
      9917468,
      20472740,
      34032948,
      10489017,
      1957433,
      1222212,
      12688069,
      15026764,
      11816014,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      258762392,
      406912,
      236486190
    ]
  },
  {
    "index": 69,
    "source_corpus_id": 259833441,
    "ref_id": "b16",
    "citation_corpus_id": 13046179,
    "start": 5144,
    "end": 5148,
    "title": "A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS",
    "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.Published as a conference paper at ICLR 2017 one method which outperforms the baseline on some (but not all) tasks. This new method evaluates the quality of a neural network's input reconstruction to determine if an example is abnormal.",
    "prev": "However, in real-world classifier deployment, one may encounter out-of-distribution (OOD) test samples, i.e., samples drawn from some distinct distribution P out = P in (e.g., images of aeroplanes).",
    "curr": "Out-ofdistribution detection is the problem of accurately identifying such OOD samples, and has received considerable study of late [18,30,20,43,23,22,48,51,3,26,52,46,21].",
    "next": "An accurate OOD detector allows one to abstain from making a prediction on OOD samples, rather than making an egregiously incorrect prediction; this yields more reliable and trust-worthy classifiers.",
    "hard_negative": [
      6628106,
      7105713,
      2879445,
      1428702,
      6706414
    ],
    "easy_negative": [
      248986378,
      28217923,
      11828778
    ]
  },
  {
    "index": 76,
    "source_corpus_id": 7942973,
    "ref_id": "b1",
    "citation_corpus_id": 6015236,
    "start": 1542,
    "end": 1562,
    "title": "Leveraging Linguistic Structure For Open Domain Information Extraction",
    "abstract": "Relation triples produced by open domaininformation extraction (open IE) systems are useful for question answering, inference, and other IE tasks. Traditionally these are extracted using a large set of patterns; however, this approach is brittle on out-of-domain text and long-range dependencies, and gives no insight into the substructure of the arguments. We replace this large pattern set with a few patterns for canonically structured sentences, and shift the focus to a classifier which learns to extract self-contained clauses from longer sentences. We then run natural logic inference over these short clauses to determine the maximally specific arguments for each candidate triple. We show that our approach outperforms a state-of-the-art open IE system on the end-to-end TAC-KBP 2013 Slot Filling task.",
    "prev": "We also show which hyperparameter choices had a significant effect on parsing accuracy, allowing us to achieve large gains over other graph-based approaches.",
    "curr": "INTRODUCTION\n\nDependency parsers-which annotate sentences in a way designed to be easy for humans and computers alike to understand-have been found to be extremely useful for a sizable number of NLP tasks, especially those involving natural language understanding in some way (Bowman et al., 2016;Angeli et al., 2015;Levy & Goldberg, 2014;Toutanova et al., 2016;Parikh et al., 2015).",
    "next": "However, frequent incorrect parses can severely inhibit final performance, so improving the quality of dependency parsers is needed for the improvement and success of these downstream tasks.",
    "hard_negative": [
      171268,
      2687019,
      6018348,
      3542573,
      228019,
      618047,
      1359050,
      6338379,
      74065,
      7826003,
      6430811,
      10318045,
      1455080,
      10910955,
      18391662
    ],
    "easy_negative": [
      30154782,
      6917126,
      222290919
    ]
  },
  {
    "index": 80,
    "source_corpus_id": 246996534,
    "ref_id": "b1",
    "citation_corpus_id": 52889459,
    "start": 2032,
    "end": 2051,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "* Indicates equal contribution arXiv:2202.08937v2 [cs.LG]\n\nINTRODUCTION\n\nThese days, generative adversarial networks (GANs) (Goodfellow et al., 2014) can successfully approximate the high-dimensional distributions of real images.",
    "curr": "The exceptional quality of the state-ofthe-art GANs (Karras et al., 2020b;Brock et al., 2019) makes them a key ingredient in applications, including semantic editing (Isola et al., 2017;Zhu et al., 2018;Shen et al., 2020;Voynov & Babenko, 2020), image processing (Pan et al., 2020;Ledig et al., 2017;Menon et al., 2020), video generation (Wang et al., 2018a), producing high-quality synthetics (Zhang et al., 2021;Voynov et al., 2020).",
    "next": "To extend the success of GANs to the limited-data regime, it is common to use pretraining, i.e., to initialize the optimization process by the GAN checkpoint pretrained on some large dataset.",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      33346914,
      11861671,
      2909838
    ]
  },
  {
    "index": 85,
    "source_corpus_id": 249210151,
    "ref_id": "b71",
    "citation_corpus_id": 238419650,
    "start": 2237,
    "end": 2256,
    "title": "GENERATIVE MODELING WITH OPTIMAL TRANSPORT MAPS",
    "abstract": "With the discovery of Wasserstein GANs, Optimal Transport (OT) has become a powerful tool for large-scale generative modeling tasks. In these tasks, OT cost is typically used as the loss for training GANs. In contrast to this approach, we show that the OT map itself can be used as a generative model, providing comparable performance. Previous analogous approaches consider OT maps as generative models only in the latent spaces due to their poor performance in the original high-dimensional ambient space. In contrast, we apply OT maps directly in the ambient space, e.g., a space of high-dimensional images. First, we derive a minmax optimization algorithm to efficiently compute OT maps for the quadratic cost (Wasserstein-2 distance). Next, we extend the approach to the case when the input and output distributions are located in the spaces of different dimensions and derive error bounds for the computed OT map. We evaluate the algorithm on image generation and unpaired image restoration tasks. In particular, we consider denoising, colorization, and inpainting, where the optimality of the restoration map is a desired attribute, since the output (restored) image is expected to be close to the input (degraded) one.Published as a conference paper at ICLR 2022 (a) OT cost as the loss for the generative model. (b) OT map as the generative model. DC Dowson and BV Landau. The fr\u00e9chet distance between multivariate normal distributions. Journal of multivariate analysis, 12(3):450-455, 1982.Yilun Du and Igor Mordatch. Implicit generation and generalization in energy-based models. arXiv preprint arXiv:1903.08689, 2019.",
    "prev": "Optimal transport (OT) is a powerful framework to solve mass-moving problems for data distributions which finds many applications in machine learning and computer vision (Bonneel & Digne, 2023).Most existing methods to compute OT plans are designed for discrete distributions (Flamary et al., 2021;Peyr\u00e9 et al., 2019;Cuturi, 2013).These methods have good flexibility: they allow to control the properties of the plan via choosing the cost function.However, discrete methods find an optimal matching between two given (train) sets which does not generalize to new (test) data points.This limits the applications of discrete OT plan methods to scenarios when one needs to generate new data, e.g., image-to-image transfer (Zhu et al., 2017).",
    "curr": "Recent works (Rout et al., 2022;Korotin et al., 2023b;2021b;Fan et al., 2021a;Daniels et al., 2021) propose continuous methods to compute OT plans.Thanks to employing neural networks to parameterize OT solutions, the learned transport plan can be used directly as the generative model in data synthesis (Rout et al., 2022) and unpaired learning (Korotin et al., 2023b;Rout et al., 2022;Daniels et al., 2021;Gazdieva et al., 2022).",
    "next": "Existing continuous OT methods mostly focus on classic cost functions such as \u2113 2 (Korotin et al., 2021b;2023b;Fan et al., 2021a;Gazdieva et al., 2022) which estimate the closeness of input and 1 BACKGROUND AND NOTATIONS\n\nIn this section, we provide key concepts of the optimal transport theory.Throughout the paper, we consider compact X = Y \u2282 R D and P, Q \u2208 P(X ), P(Y).",
    "hard_negative": [
      1758096,
      3366315,
      11758569,
      52889459
    ],
    "easy_negative": [
      235097644,
      225062898,
      233364998
    ]
  },
  {
    "index": 86,
    "source_corpus_id": 252668614,
    "ref_id": "b4",
    "citation_corpus_id": 10550488,
    "start": 7484,
    "end": 7504,
    "title": "Findings of the 2015 Workshop on Statistical Machine Translation",
    "abstract": "This paper presents the results of the WMT15 shared tasks, which included a standard news translation task, a metrics task, a tuning task, a task for run-time estimation of machine translation quality, and an automatic post-editing task. This year, 68 machine translation systems from 24 institutions were submitted to the ten translation directions in the standard translation task. An additional 7 anonymized systems were included, and were then evaluated both automatically and manually. The quality estimation task had three subtasks, with a total of 10 teams, submitting 34 entries. The pilot automatic postediting task had a total of 4 teams, submitting 7 entries. ID Institution AALTO Aalto University (Gr\u00f6nroos et al., 2015) ABUMATRAN Abu-MaTran (Rubino et al., 2015) AFRL-MIT-* Air Force Research Laboratory / MIT Lincoln Lab (Gwinnup et al., 2015) CHALMERS Chalmers University of Technology (Kolachina and Ranta, 2015) CIMS University of Stuttgart and Munich (Cap et al., 2015) CMU Carnegie Mellon University CU-CHIMERA Charles University (Bojar and Tamchyna, 2015) CU-TECTO Charles University (Du\u0161ek et al., 2015) DFKI Deutsches Forschungszentrum f\u00fcr K\u00fcnstliche Intelligenz (Avramidis et al., 2015) ILLINOIS University of Illinois (Schwartz et al., 2015) IMS University of Stuttgart (Quernheim, 2015) KIT Karsruhe Institut of Technology (Cho et al., 2015) KIT-LIMSI Karsruhe Institut of Technology / LIMSI (Ha et al., 2015) LIMSI LIMSI (Marie et al., 2015) MACAU University of Macau MONTREAL University of Montreal (Jean et al., 2015) PROMT ProMT RWTH RWTH Aachen (Peter et al., 2015)",
    "prev": "Furthermore, perplexity assigns cnn dailymail even lower scores than the in-domain xsum.",
    "curr": "For translation, the model is trained on WMT15 dataset and evaluated on other WMT test splits (Bojar et al., 2015), OPUS100 (Aulamo & Tiedemann, 2019), and MTNT (Michel & Neubig, 2018).",
    "next": "The in-domain and OOD datasets perplexity densities overlap even more.",
    "hard_negative": [
      5810690,
      8227591,
      15535376,
      16391184,
      8313873,
      13559036,
      824597,
      6470935,
      359451,
      63423276,
      61951283,
      7626806,
      15416634,
      12171581,
      2119998,
      6055237,
      14669383,
      7397197,
      15119437,
      13263697,
      1551956,
      7164502,
      44699483,
      1655131,
      15032680,
      7130985,
      1101161,
      2942573,
      16293762,
      1470353,
      30817944,
      736936,
      13138861,
      7470516,
      219306423,
      4895939,
      219304915,
      715221,
      8383964,
      9479394,
      18074084,
      14547438,
      16052726,
      5147390
    ],
    "easy_negative": [
      17217684,
      12161321,
      231821644
    ]
  },
  {
    "index": 91,
    "source_corpus_id": 203593909,
    "ref_id": "b17",
    "citation_corpus_id": 10480989,
    "start": 2616,
    "end": 2638,
    "title": "Language as a Latent Variable: Discrete Generative Models for Sentence Compression",
    "abstract": "In this work we explore deep generative models of text in which the latent representation of a document is itself drawn from a discrete language model distribution. We formulate a variational auto-encoder for inference in this model and apply it to the task of compressing sentences. In this application the generative model first draws a latent summary sentence from a background language model, and then subsequently draws the observed sentence conditioned on this latent summary. In our empirical evaluation we show that generative formulations of both abstractive and extractive compression yield state-of-the-art results when trained on a large amount of supervised data. Further, we explore semi-supervised compression scenarios where we show that it is possible to achieve performance competitive with previously proposed supervised models while training on a fraction of the supervised data.",
    "prev": "In the context of sequence generation problems, semi-supervised approaches have been shown to work well in some cases.",
    "curr": "For example, back-translation (Sennrich et al., 2015) makes use of the monolingual data on the target side to improve machine translation systems, latent variable models  are employed to incorporate unlabeled source data to facilitate sentence compression (Miao & Blunsom, 2016) or code generation (Yin et al., 2018).",
    "next": "In this work, we revisit a much older and simpler semi-supervised method, self-training (ST, Scudder (1965)), where a base model trained with labeled data acts as a \"teacher\" to label the unannotated data, which is then used to augment the original small training set.",
    "hard_negative": [
      7658338,
      11212020,
      8174613,
      1992250
    ],
    "easy_negative": [
      256460906,
      14046508,
      237347097
    ]
  },
  {
    "index": 93,
    "source_corpus_id": 220768638,
    "ref_id": "b8",
    "citation_corpus_id": 57189211,
    "start": 5159,
    "end": 5162,
    "title": "REASONING ABOUT PHYSICAL INTERACTIONS WITH OBJECT-ORIENTED PREDICTION AND PLANNING",
    "abstract": "Object-based factorizations provide a useful level of abstraction for interacting with the world. Building explicit object representations, however, often requires supervisory signals that are difficult to obtain in practice. We present a paradigm for learning object-centric representations for physical scene understanding without direct supervision of object properties. Our model, Object-Oriented Prediction and Planning (O2P2), jointly learns a perception function to map from image observations to object representations, a pairwise physics interaction function to predict the time evolution of a collection of objects, and a rendering function to map objects back to pixels. For evaluation, we consider not only the accuracy of the physical predictions of the model, but also its utility for downstream tasks that require an actionable representation of intuitive physics. After training our model on an image prediction task, we can use its learned representations to build block towers more complicated than those observed during training.",
    "prev": "Developing a factorized scene representation has been a core research topic in computer vision for decades.",
    "curr": "Most learning-based prior works are supervised, requiring annotated specification such as segmentations [9], patches [5], or simulation engines [27,10].",
    "next": "These supervised approaches face two challenges.",
    "hard_negative": [
      6981893,
      6628106,
      1803861,
      9128667
    ],
    "easy_negative": [
      253735201,
      18599375,
      258486927
    ]
  },
  {
    "index": 94,
    "source_corpus_id": 84186721,
    "ref_id": "b1",
    "citation_corpus_id": 5590763,
    "start": 33895,
    "end": 33913,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "At the first time step these messages, m\n\nv , are initialized with the respective atom features shown in Table 4.",
    "curr": "GGNNs then update these messages in a recursive nature:\nm (s) v = GRU \uf8eb \uf8ed m (s\u22121) v , i\u2208Ne1(v) f single m (s\u22121) i + j\u2208Ne2(v) f double m (s\u22121) j + k\u2208Ne3(v) f triple m (s\u22121) k \uf8f6 \uf8f8(7)\nWhere GRU is a Gated Recurrent Unit (Cho et al., 2014), the functions N e1 (v), N e2 (v), N e3 (v) index the nodes connected by single, double and triple bonds to node v respectively and f single (\u00b7), f double (\u00b7) and f triple (\u00b7) are linear transformations with learnable parameters.",
    "next": "This process continues for S steps (where we choose S = 4).",
    "hard_negative": [
      17272965,
      3065236,
      7417943,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      38407095,
      5552894
    ],
    "easy_negative": [
      218974531,
      15576328,
      1746814
    ]
  },
  {
    "index": 97,
    "source_corpus_id": 1880070,
    "ref_id": "b33",
    "citation_corpus_id": 780171,
    "start": 6329,
    "end": 6350,
    "title": "Data-Driven Response Generation in Social Media",
    "abstract": "We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.",
    "prev": "There are many obvious cases where these metrics fail, as they are often incapable of considering the semantic similarity between responses (see Figure 1).",
    "curr": "Despite this, many researchers still use BLEU to evaluate their dialogue models (Ritter et al., 2011;Sordoni et al., 2015b;Li et al., 2015;Galley et al., 2015;Li et al., 2016a), as there are few alternatives available that correlate with human judgements.",
    "next": "While human evaluation should always be used to evaluate dialogue models, it is often too expensive and time-consuming to do this for every model specification (for example, for every combination of model hyperparameters).",
    "hard_negative": [
      14386564,
      12305296,
      1060508,
      59940,
      1963942,
      10534951,
      12131372,
      2713391,
      5219389,
      17309374,
      9482302,
      13043395,
      6990165,
      11169623,
      1922162,
      10181753,
      7785983
    ],
    "easy_negative": [
      227231262,
      220059860,
      249455600
    ]
  },
  {
    "index": 98,
    "source_corpus_id": 263829563,
    "ref_id": "b2",
    "citation_corpus_id": 237561567,
    "start": 7856,
    "end": 7873,
    "title": "Trafilatura: A Web Scraping Library and Command-Line Tool for Text Discovery and Extraction",
    "abstract": "An essential operation in web corpus construction consists in retaining the desired content while discarding the rest. Another challenge finding one's way through websites. This article introduces a text discovery and extraction tool published under open-source license. Its installation and use is straightforward, notably from Python and on the command-line. The software allows for main text, comments and metadata extraction, while also providing building blocks for web crawling tasks. A comparative evaluation on real-world data also shows its interest as well as the performance of other available solutions.The contributions of this paper are threefold: it references the software, features a benchmark, and provides a meaningful baseline for similar tasks. The tool performs significantly better than other open-source solutions in this evaluation and in external benchmarks.",
    "prev": "he Pile (Gao et al., 2020), and GPT-3 (Brown et al., 2020) introduce various pipelines for extracting quality data from Common Crawl for the purposes of language model training.These pipelines typically consist of three primary steps: text extraction, filtering, and deduplication.",
    "curr": "Text extraction\n\nExtracting plain text from HTML files is a critical step in the creation of Common Crawl-based datasets.The easiest way to extract text from Common Crawl documents is to use the WET corresponding to each webpage, which contains pre-extracted plain text of the webpage.CCNet and C4 both use Common Crawl's WET files.However, the text extracted in WET files may contain too much boilerplate or miss out on important content such as L A T E X equations.It is also possible to extract text directly from the raw HTML found in Common Crawl WARC files.The Pile uses an open source library called jusText (Endr\u00e9dy & Nov\u00e1k, 2013) to extract text from HTML while RefinedWeb uses a library called Trafilatura (Barbaresi, 2021).These text extraction approaches differ in terms of extraction speed, customization, and their precision and recall for removing boilerplate content.",
    "next": "Filtering The first layer of filtering often involves language identification (Wenzek et al., 2019).Language filtering is used because certain other parts of the pipeline only work for specific languages, and is often done with simple linear classifiers such as from fastText (Joulin et al., 2016).Quality filtering can be done with a combination of perplexity, classifier, and rule-based methods.CCNet uses a 5-gram Kneser-Ney language model implemented in the KenLM library (Heafield, 2011) trained on the target domain.The documents in the dataset are then sorted and filtered by their perplexity under this model.Other datasets such as the one used to train GPT-3 (Brown et al., 2020) use a classifier-based approach.This involves training a classifier on known-high-quality documents, such as those from Wikipedia, as positive examples and unf",
    "hard_negative": [
      218973696,
      7987482,
      9709731,
      8343210,
      42692268,
      8148275,
      225094586,
      1152099,
      218974307,
      225746789,
      218974065,
      36197626
    ],
    "easy_negative": [
      252531622,
      17338596,
      257353790
    ]
  },
  {
    "index": 100,
    "source_corpus_id": 261696510,
    "ref_id": "b9",
    "citation_corpus_id": 215745286,
    "start": 3723,
    "end": 3744,
    "title": "Unsupervised Commonsense Question Answering with Self-Talk",
    "abstract": "Natural language understanding involves reading between the lines with implicit background knowledge. Current systems either rely on pretrained language models as the sole implicit source of world knowledge, or resort to external knowledge bases (KBs) to incorporate additional relevant knowledge. We propose an unsupervised framework based on self-talk as a novel alternative to multiple-choice commonsense tasks. Inspired by inquiry-based discovery learning (Bruner, 1961), our approach inquires language models with a number of information seeking questions such as \"what is the definition of ...\" to discover additional background knowledge. Empirical results demonstrate that the self-talk procedure substantially improves the performance of zero-shot language model baselines on four out of six commonsense benchmarks, and competes with models that obtain knowledge from external KBs. While our approach improves performance on several benchmarks, the self-talk induced knowledge even when leading to correct answers is not always seen as useful by human judges, raising interesting questions about the inner-workings of pre-trained language models for commonsense reasoning.",
    "prev": "Select Implement def transform_grid(grid): out_grid = np.zeros_like(grid) for col in range(grid.shape[1]): non_zeros = \\ grid[:, col][grid[:, col] != 0] if len(non_zeros) > 0: out_grid[-len(non_zeros):,col]= \\ on_zeros return out_grid def transform_grid(grid): return ...\n\nINTRODUCTION\n\nInductive reasoning -the ability to infer general principles from specific examples and apply them to novel situations -is a core aspect of human intelligence (Peirce, 1868).",
    "curr": "Recently, large-scale pre-trained language models have received significant interest for their performance across a diverse range of reasoning tasks such as commonsense, arithmetic and symbolic reasoning (Rajani et al., 2019;Shwartz et al., 2020;Nye et al., 2021;Wei et al., 2022;Marasovi\u0107 et al., 2021;Lampinen et al., 2022;Zelikman et al., 2022;Zhou et al., 2022).",
    "next": "There has been extensive discussion of language models' impressive \"in-context learning\" capabilities, a form of inductive reasoning.",
    "hard_negative": [
      52290656,
      202541184,
      44156126,
      1726501,
      52165754,
      174803111,
      128296356,
      52019251,
      211258645,
      44130298,
      102353371,
      90261373,
      196171642
    ],
    "easy_negative": [
      247011082,
      1890344,
      239049598
    ]
  },
  {
    "index": 104,
    "source_corpus_id": 247451000,
    "ref_id": "b6",
    "citation_corpus_id": 231662264,
    "start": 27174,
    "end": 27194,
    "title": "Published as a conference paper at ICLR 2021 CHARACTERIZING SIGNAL PROPAGATION TO CLOSE THE PERFORMANCE GAP IN UNNORMALIZED RESNETS",
    "abstract": "Batch Normalization is a key component in almost all state-of-the-art image classifiers, but it also introduces practical challenges: it breaks the independence between training examples within a batch, can incur compute and memory overhead, and often results in unexpected bugs. Building on recent theoretical analyses of deep ResNets at initialization, we propose a simple set of analysis tools to characterize signal propagation on the forward pass, and leverage these tools to design highly performant ResNets without activation normalization layers. Crucial to our success is an adapted version of the recently proposed Weight Standardization. Our analysis tools show how this technique preserves the signal in networks with ReLU or Swish activation functions by ensuring that the per-channel activation means do not grow with depth. Across a range of FLOP budgets, our networks attain performance competitive with the state-of-the-art EfficientNets on ImageNet.Published as a conference paper at ICLR 2021 works. Leveraging these SPPs, we show how to design unnormalized ResNets which are constrained to have signal propagation properties similar to batch-normalized ResNets.\u2022 We identify a key failure mode in unnormalized ResNets with ReLU or Swish activations and Gaussian weights. Because the mean output of these non-linearities is positive, the squared mean of the hidden activations on each channel grows rapidly as the network depth increases. To resolve this, we propose Scaled Weight Standardization, a minor modification of the recently proposed Weight Standardization (Qiao et al., 2019; Huang et al., 2017b), which prevents the growth in the mean signal, leading to a substantial boost in performance.\u2022 We apply our normalization-free network structure in conjunction with Scaled Weight Standardization to ResNets on ImageNet, where we for the first time attain performance which is comparable or better than batch-normalized ResNets on networks as deep as 288 layers.\u2022 Finally, we apply our normalization-free approach to the RegNet architecture (Radosavovic  et al., 2020). By combining this architecture with the compound scaling strategy proposed byTan& Le (2019), we develop a class of models without normalization layers which are competitive with the current ImageNet state of the art across a range of FLOP budgets. . Shufflenet v2: Practical guidelines for efficient cnn architecture design. In . Spectral normalization for generative adversarial networks. In ICLR, 2018. Y. Nesterov. A method for unconstrained convex minimization problem with the rate of convergence O(1/k 2 ). Doklady AN USSR, pp. (269), 543-547, 1983. Art B Owen. A robust hybrid of lasso and ridge regression. 2007. . ImageNet large scale visual recognition challenge. IJCV, 115:211-252, 2015. Tim Salimans and Durk P Kingma. Weight normalization: A simple reparameterization to accelerate training of deep neural networks. In Advances in neural information processing systems, pp. 901-909, 2016.",
    "prev": "This suggests that one can compensate for the removal of BN layers, at least in terms of their effect on the behaviour of the network at initialization time, by down-scaling the residual branch of each residual block.",
    "curr": "Arguably, almost all recent work on training deep networks without normalization layers (Zhang et al., 2018;Shao et al., 2020;Bachlechner et al., 2020;Brock et al., 2021a;b) has adopted this idea by introducing multipliers on the residual branches (which may or may not be optimized during training).",
    "next": "In Table 2, we show that one can close most of the gap with standard ResNets by simply adopting the modification in equation 6 without using BN layers.",
    "hard_negative": [
      59317031,
      3162051
    ],
    "easy_negative": [
      252624766,
      8713824,
      7009609
    ]
  },
  {
    "index": 107,
    "source_corpus_id": 264555202,
    "ref_id": "b28",
    "citation_corpus_id": 52115700,
    "start": 30655,
    "end": 30680,
    "title": "Evaluating Theory of Mind in Question Answering",
    "abstract": "We propose a new dataset for evaluating question answering models with respect to their capacity to reason about beliefs. Our tasks are inspired by theory-of-mind experiments that examine whether children are able to reason about the beliefs of others, in particular when those beliefs differ from reality. We evaluate a number of recent neural models with memory augmentation. We find that all fail on our tasks, which require keeping track of inconsistent states of the world; moreover, the models' accuracy decreases notably when random sentences are introduced to the tasks at test. 1",
    "prev": "All these works, however, focus on protecting training data, without considering context, and rely heavily on having a well-defined notion of a single record.While this is ideal for tabular data, it is extremely Preprint   hard to define for language, as drawing borders around a unit of language that needs protection is not always feasible (Brown et al., 2022) and different units might need different levels of protection, based on information type and context.Our work, however, differs from existing literature in two main aspects: (1) we focus on the impact that context has on privacy, and how reasoning about this context is crucial in making judgments when it comes to language, and (2) we shift attention away from training data and towards interactions with the model, as providing lengthy history for the model is becoming more and more relevant.",
    "curr": "Theory of Mind (ToM) and LLMs\n\nThe development of ToM abilities has been a long-standing goal in AI research (Nematzadeh et al., 2018;Le et al., 2019;Sap et al., 2019;Shapira et al., 2023b;Kim et al., 2023).Although qualitative assessments might imply a degree of ToM in LLMs (Whang, 2023), more comprehensive quantitative investigations reveal that LLMs still struggle to reason ToM robustly (Sap et al., 2022;Shapira et al., 2023a;Ullman, 2023;Kim et al., 2023).This might account for the poor performance of LLMs on our benchmark.",
    "next": "Ethics and morality for LLMs Revealing secrets often involves making moral decisions in the real world.Many previous works focus on inferring the morality of the behavior based on textual descriptions Preprint of scenarios (Jiang et al., 2021;Zhou et al., 2023a;Forbes et al., 2020), while more works start to integrate social contexts into the machine morality discourse (Kim et al., 2022b;Pyatkin et al., 2023;Jin et al., 2022).",
    "hard_negative": [
      3178759,
      11243593,
      8221720
    ],
    "easy_negative": [
      9337134,
      14758649,
      247922557
    ]
  },
  {
    "index": 112,
    "source_corpus_id": 53452703,
    "ref_id": "b5",
    "citation_corpus_id": 28971531,
    "start": 2480,
    "end": 2502,
    "title": "Supervised Learning of Universal Sentence Representations from Natural Language Inference Data",
    "abstract": "Many modern NLP systems rely on word embeddings, previously trained in an unsupervised manner on large corpora, as base features. Efforts to obtain embeddings for larger chunks of text, such as sentences, have however not been so successful. Several attempts at learning unsupervised representations of sentences have not reached satisfactory enough performance to be widely adopted. In this paper, we show how universal sentence representations trained using the supervised data of the Stanford Natural Language Inference datasets can consistently outperform unsupervised methods like SkipThought vectors (Kiros et al., 2015) on a wide range of transfer tasks. Much like how computer vision uses ImageNet to obtain features, which can then be transferred to other tasks, our work tends to indicate the suitability of natural language inference for transfer learning to other NLP tasks. Our encoder is publicly available 1 .",
    "prev": "Perone et al.",
    "curr": "(2018) have shown that the best encoding architectures are based on recurrent neural networks (RNNs) (Conneau et al., 2017;Peters et al., 2018) or the Transformer architecture (Cer et al., 2018).",
    "next": "These techniques are, however, substantially more expensive to train and apply than word embeddings (Hill et al., 2016;Cer et al., 2018).",
    "hard_negative": [
      11336213,
      6067240,
      15280949,
      3033526,
      1957433,
      14169402,
      11650107,
      10421567,
      3202289
    ],
    "easy_negative": [
      257985178,
      21732517,
      236460069
    ]
  },
  {
    "index": 114,
    "source_corpus_id": 232320210,
    "ref_id": "b4",
    "citation_corpus_id": 51979536,
    "start": 1995,
    "end": 2015,
    "title": "Large-Scale Study of Curiosity-Driven Learning",
    "abstract": "Reinforcement learning algorithms rely on carefully engineering environment rewards that are extrinsic to the agent. However, annotating each environment with hand-designed, dense rewards is not scalable, motivating the need for developing reward functions that are intrinsic to the agent. Curiosity is a type of intrinsic reward function which uses prediction error as reward signal. In this paper: (a) We perform the first large-scale study of purely curiosity-driven learning, i.e. without any extrinsic rewards, across 54 standard benchmark environments, including the Atari game suite. Our results show surprisingly good performance, and a high degree of alignment between the intrinsic curiosity objective and the handdesigned extrinsic rewards of many game environments. (b) We investigate the effect of using different feature spaces for computing prediction error and show that random features are sufficient for many popular RL game benchmarks, but learned features appear to generalize better (e.g. to novel game levels in Super Mario Bros.). (c) We demonstrate limitations of the prediction-based rewards in stochastic setups. Game-play videos and code are at https://pathak22.github. io/large-scale-curiosity/. * Alphabetical ordering; the first three authors contributed equally.Preprint. Work in progress.",
    "prev": "ut also additionally provides a deterministic compressed representation of the input variable, which is useful for inference tasks that require consistent representation.Moreover, it can jointly learn a feature extractor and select features considering each feature dimension's relevance to the target task, which is unattainable by most neural network-based IB methods.We propose an exploration method based on Drop-Bottleneck for reinforcement learning tasks.In a multitude of noisy and reward sparse maze navigation tasks in VizDoom(Kempka et al., 2016)and DM-Lab (Beattie et al., 2016), our exploration method achieves state-of-the-art performance.As a new IB framework, we demonstrate that Drop-Bottleneck outperforms Variational Information Bottleneck (VIB)(Alemi et al., 2017)in multiple aspects including adversarial robustness and dimensionality reduction.",
    "curr": "INTRODUCTION\n\nData with noise or task-irrelevant information easily harm the training of a model; for instance, the noisy-TV problem (Burda et al., 2019a) is one of well-known such phenomena in reinforcement learning.If observations from the environment are modified to contain a TV screen, which changes its channel randomly based on the agent's actions, the performance of curiosity-based exploration methods dramatically degrades (Burda et al., 2019a;b;Kim et al., 2019;Savinov et al., 2019).",
    "next": "The information bottleneck (IB) theory (Tishby et al., 2000;Tishby & Zaslavsky, 2015) provides a framework for dealing with such task-irrelevant information, and has been actively adopted to exploration in reinforcement learning (Kim et al., 2019;Igl et al., 2019).For an input variable X and a target variable Y , the IB theory introduces another variable Z, which is a compressed representation of X.The IB objective trains Z to contain less information about X but more information about Y as possible, where the two are quantified by mutual information terms of I(Z; X) and I(Z; Y ), respectively.IB methods such as Variational Information Bottleneck (",
    "hard_negative": [
      12256925,
      5037032
    ],
    "easy_negative": [
      52013137,
      10925735,
      252693055
    ]
  },
  {
    "index": 121,
    "source_corpus_id": 11243593,
    "ref_id": "b10",
    "citation_corpus_id": 14915449,
    "start": 6466,
    "end": 6485,
    "title": "THE GOLDILOCKS PRINCIPLE: READING CHILDREN'S BOOKS WITH EXPLICIT MEMORY REPRESENTATIONS",
    "abstract": "We introduce a new test of how well language models capture meaning in children's books. Unlike standard language modelling benchmarks, it distinguishes the task of predicting syntactic function words from that of predicting lowerfrequency words, which carry greater semantic content. We compare a range of state-of-the-art models, each with a different way of encoding what has been previously read. We show that models which store explicit representations of long-term contexts outperform state-of-the-art neural language models at predicting semantic content words, although this advantage is not observed for syntactic function words. Interestingly, we find that the amount of text encoded in a single memory representation is highly influential to the performance: there is a sweet-spot, not too big and not too small, between single words and full sentences that allows the most meaningful information in a text to be effectively retained and recalled. Further, the attention over such window-based memories can be trained effectively through self-supervision. We then assess the generality of this principle by applying it to the CNN QA benchmark, which involves identifying named entities in paraphrased summaries of news articles, and achieve state-of-the-art performance.",
    "prev": "It is also able to generalize to sequences longer than those seen during training.",
    "curr": "Finally, our model also obtains competitive results on the Childrens Book Test (Hill et al., 2016), and performs best among models that read the text in a single pass before receiving knowledge of the question.",
    "next": "MODEL\n\nOur model is designed to process data in sequential form, and consists of three main parts: an input encoder, a dynamic memory and an output layer, which we now describe in detail.",
    "hard_negative": [
      14068874,
      2561041,
      1918428,
      2100831
    ],
    "easy_negative": [
      248780172,
      261348926,
      218974146
    ]
  },
  {
    "index": 123,
    "source_corpus_id": 3525802,
    "ref_id": "b19",
    "citation_corpus_id": 9615470,
    "start": 7912,
    "end": 7928,
    "title": "A Model of Coherence Based on Distributed Sentence Representation",
    "abstract": "Coherence is what makes a multi-sentence text meaningful, both logically and syntactically. To solve the challenge of ordering a set of sentences into coherent order, existing approaches focus mostly on defining and using sophisticated features to capture the cross-sentence argumentation logic and syntactic relationships. But both argumentation semantics and crosssentence syntax (such as coreference and tense rules) are very hard to formalize. In this paper, we introduce a neural network model for the coherence task based on distributed sentence representation. The proposed approach learns a syntacticosemantic representation for sentences automatically, using either recurrent or recursive neural networks. The architecture obviated the need for feature engineering, and learns sentence representations, which are to some extent able to capture the 'rules' governing coherent sentence structure. The proposed approach outperforms existing baselines and generates the stateof-art performance in standard coherence evaluation tasks 1 .",
    "prev": "Given the first three sentences of a paragraph, choose the next sentence from five sentences later in the paragraph.",
    "curr": "Related to our objective is the local coherence model of Li & Hovy (2014) where a binary classifier is trained to identify coherent/incoherent sentence windows.",
    "next": "In contrast, we only encourage observed contexts to be more plausible than contrastive ones and formulate it as a multi-class classification problem.",
    "hard_negative": [
      2717698,
      11609990,
      16139657,
      13335215,
      806709,
      14859321,
      9482302,
      1906241,
      3071041,
      217537,
      1502408,
      259144,
      17337432,
      5942882,
      931054,
      1851389,
      92531,
      6399480,
      2570492,
      7176829
    ],
    "easy_negative": [
      7149733,
      207925764,
      7502134
    ]
  },
  {
    "index": 125,
    "source_corpus_id": 53081529,
    "ref_id": "b42",
    "citation_corpus_id": 11174813,
    "start": 3303,
    "end": 3322,
    "title": "Learning Distributed Representations for Multilingual Text Sequences",
    "abstract": "We propose a novel approach to learning distributed representations of variable-length text sequences in multiple languages simultaneously. Unlike previous work which often derive representations of multi-word sequences as weighted sums of individual word vectors, our model learns distributed representations for phrases and sentences as a whole. Our work is similar in spirit to the recent paragraph vector approach but extends to the bilingual context so as to efficiently encode meaning-equivalent text sequences of multiple languages in the same semantic space. Our learned embeddings achieve state-of-theart performance in the often used crosslingual document classification task (CLDC) with an accuracy of 92.7 for English to German and 91.5 for German to English. By learning text sequence representations as a whole, our model performs equally well in both classification directions in the CLDC task in which past work did not achieve.",
    "prev": "In our experiments on 9 benchmark text classification datasets and 22 textual similarity tasks, the proposed technique consistently matches or outperforms state-of-the-art techniques, with significantly higher accuracy on problems of short length.",
    "curr": "Introduction\n\nText representation plays an important role in many NLP-based tasks such as document classification and clustering (Zhang et al., 2018;Gui et al., 2016Gui et al., , 2014, sense disambiguation (Gong et al., 2017(Gong et al., , 2018a, machine translation (Mikolov et al., 2013b), document matching (Pham et al., 2015), and sequential alignment (Peng et al., 2016(Peng et al., , 2015.",
    "next": "Since there are no explicit features in text, much work has aimed to develop effective text representations.",
    "hard_negative": [
      6758088,
      931054,
      14687186,
      11616343,
      38407095,
      5959482
    ],
    "easy_negative": [
      5709441,
      231592390,
      258835696
    ]
  },
  {
    "index": 130,
    "source_corpus_id": 221139843,
    "ref_id": "b44",
    "citation_corpus_id": 7186165,
    "start": 30522,
    "end": 30526,
    "title": "Model-Portability Experiments for Textual Temporal Analysis",
    "abstract": "We explore a semi-supervised approach for improving the portability of time expression recognition to non-newswire domains: we generate additional training examples by substituting temporal expression words with potential synonyms. We explore using synonyms both from WordNet and from the Latent Words Language Model (LWLM), which predicts synonyms in context using an unsupervised approach. We evaluate a state-of-the-art time expression recognition system trained both with and without the additional training examples using data from TempEval 2010, Reuters and Wikipedia. We find that the LWLM provides substantial improvements on the Reuters corpus, and smaller improvements on the Wikipedia corpus. We find that WordNet alone never improves performance, though intersecting the examples from the LWLM and WordNet provides more stable results for Wikipedia.",
    "prev": "A Glossary of Notation\n\nWe provide a glossary of notation used throughout the paper.Total consistency loss (Eq 3) L : X 2 \u2192 R A distance function, used for CycleGAN consistency losses \u03bb\n\nHyperparameter controlling the strength of the consistency loss KL(\u2022)\n\nThe KL divergence JS(\u2022)\n\nThe Jensen-Shannon divergence (Definition 2)\nI(\u2022)\nThe Mutual Information\n\n\nB Extended Related Work\n\nWe provide a comprehensive overview of related work and highlight connections to our work below.",
    "curr": "B.1 Overview of Data Augmentation\n\nData augmentation is widely used for improving the aggregate performance of machine learning models in computer vision [46,79], natural language processing [45,71,95] and audio [18,43].The theoretical motivation for data augmentation is largely based on the tangent propagation formalism [19,73,74,76] which expresses the desired invariances induced by a data augmentation as tangent constraints on the directional derivatives of the learned model.",
    "next": "Early work considered augmentations as image defects [5] or stroke warping [90] for character recognition.Since then, augmentation is considered an essential ingredient in computer vision [47,75], with commonly used augmentations including random flips, rotations and crops [31,46,79].Applications of augmentation in computer vision include object detection [23,98] and scene understanding [22] In natural language processing, common data augmentation techniques include back-translation [71,91], synonym or word substitution [25,44,45,83,95], noising [89], grammar induction [39], text editing [85] and other heuristics [20,72].In speech and audio applications, augmentation is also commonly used, through tec",
    "hard_negative": [
      15275617,
      1671874,
      15426180,
      12126440,
      926750,
      859162,
      1506909,
      1487550
    ],
    "easy_negative": [
      45694917,
      257404922,
      184482694
    ]
  },
  {
    "index": 131,
    "source_corpus_id": 258461359,
    "ref_id": "b0",
    "citation_corpus_id": 67855815,
    "start": 2219,
    "end": 2241,
    "title": "Massively Multilingual Neural Machine Translation",
    "abstract": "Multilingual neural machine translation (NMT) enables training a single model that supports translation from multiple source languages into multiple target languages. In this paper, we push the limits of multilingual NMT in terms of the number of languages being used. We perform extensive experiments in training massively multilingual NMT models, translating up to 102 languages to and from English within a single model. We explore different setups for training such models and analyze the trade-offs between translation quality and various modeling decisions. We report results on the publicly available TED talks multilingual corpus where we show that massively multilingual many-to-many models are effective in low resource settings, outperforming the previous state-of-the-art while supporting up to 59 languages. Our experiments on a large-scale dataset with 102 languages to and from English and up to one million examples per direction also show promising results, surpassing strong bilingual baselines and encouraging future work on massively multilingual NMT.",
    "prev": "INTRODUCTION\n\nThe rapid development of neural networks opens the path towards the ambitious goal of universal translation that allows converting information between any languages regardless of data modalities (text, audio or video) (Zhang, 2022).",
    "curr": "While the translation for spoken languages (in text and speech) has gained wide attention (Aharoni et al., 2019;Inaguma et al., 2019;Jia et al., 2019), the study of sign language translation (SLT) -a task translating from sign language videos to spoken language texts -still lags behind despite its significance in facilitating the communication between Deaf communities and spoken language communities (Camgoz et al., 2018;.",
    "next": "SLT represents unique challenges: it demands the capability of video understanding and sequence generation.",
    "hard_negative": [
      23943173,
      52154258,
      52100117,
      3295641,
      21675165,
      47005349,
      60440615,
      12639289,
      9752897,
      51875779,
      44131019,
      53079244,
      51976920,
      6359641,
      14421595,
      53247198,
      3526501,
      16631020,
      5067886,
      3666937
    ],
    "easy_negative": [
      171316964,
      250150903,
      5575206
    ]
  },
  {
    "index": 134,
    "source_corpus_id": 220665925,
    "ref_id": "b28",
    "citation_corpus_id": 68137503,
    "start": 2547,
    "end": 2551,
    "title": "FUNCTIONAL VARIATIONAL BAYESIAN NEURAL NETWORKS",
    "abstract": "Variational Bayesian neural networks (BNNs) perform variational inference over weights, but it is difficult to specify meaningful priors and approximate posteriors in a high-dimensional weight space. We introduce functional variational Bayesian neural networks (fBNNs), which maximize an Evidence Lower BOund (ELBO) defined directly on stochastic processes, i.e. distributions over functions. We prove that the KL divergence between stochastic processes equals the supremum of marginal KL divergences over all finite sets of inputs. Based on this, we introduce a practical training objective which approximates the functional ELBO using finite measurement sets and the spectral Stein gradient estimator. With fBNNs, we can specify priors entailing rich structures, including Gaussian processes and implicit stochastic processes. Empirically, we find fBNNs extrapolate well using various structured priors, provide reliable uncertainty estimates, and scale to large datasets. * Equal contribution.Theorem 7. For two stochastic processes P, M on a cylindrical measurable space (\u2126 T , F T ), the KL divergence of P with respect to M satisfies,where the supremum is over all finite indices subsets T d \u2286 T , and P T d , M T d represent the canonical projection maps \u03c0 T \u2192T d of P, M , respectively.Proof. Recall that stochastic processes are defined over a cylindrical \u03c3-algebra F T . By Lemma 6, for every set H \u2208 F T , the restricted index set \u03c4 (H) is countable. Our proof proceeds in two steps:",
    "prev": "The variational approach is limited in posterior expressiveness while the implicit approach is computationally slow and costly in terms of storage.",
    "curr": "Moreover, specifying meaningful priors in parameter space is known to be difficult due to the complex relationship between weights and functions in deep networks [29].",
    "next": "In this paper, we present a Bayesian approach to FSC based on Gaussian processes (GPs) [36] that enables efficient marginalization over functions rather than model parameters.",
    "hard_negative": [
      3708505,
      3502463
    ],
    "easy_negative": [
      496923,
      17537518,
      250390846
    ]
  },
  {
    "index": 135,
    "source_corpus_id": 263611938,
    "ref_id": "b21",
    "citation_corpus_id": 252683312,
    "start": 8855,
    "end": 8862,
    "title": "OMNIGROK: GROKKING BEYOND ALGORITHMIC DATA",
    "abstract": "Grokking, the unusual phenomenon for algorithmic datasets where generalization happens long after overfitting the training data, has remained elusive. We aim to understand grokking by analyzing the loss landscapes of neural networks, identifying the mismatch between training and test loss landscapes as the cause for grokking. We refer to this as the \"LU mechanism\" because training and test losses (against model weight norm) typically resemble \"L\" and \"U\", respectively. This simple mechanism can nicely explain many aspects of grokking: data size dependence, weight decay dependence, the emergence of representations, etc. Guided by the intuitive picture, we are able to induce grokking on tasks involving images, language and molecules. In the reverse direction, we are able to eliminate grokking for algorithmic datasets. We attribute the dramatic nature of grokking for algorithmic datasets to representation learning.Partial answers to Q1 are provided in recent studies: Liu et al. (2022) attribute grokking to the slow formation of good representations,Thilak et al. (2022)attempts to link grokking to the slingshot mechanism of adaptive optimizers, andBarak et al. (2022)uses Fourier gap to describe hidden progress. This paper aims to understand grokking through the lens of neural loss landscapes. Our landscape analysis is able to explain many aspects of grokking: data size dependence, weight decay dependence, emergence of representations, etc.The paper is organized as follows: In Section 2, we review background on generalization, and introduce the LU mechanism. In Section 3, we show how the LU mechanism leads to grokking for a toy teacher-student setup. In Section 4, we show that the intuition gained from the toy problem can",
    "prev": "[Thi+22] attributed grokking to the slingshot mechanism, which can be measured by the cyclic phase transitions between stable and unstable training regimes.\u017dunkovi\u010d and Ilievski [\u017dI22] showed a time separation between achieving zero training error and zero test error in a binary classification task on a linearly separable distribution.",
    "curr": "Liu, Michaud, and Tegmark [LMT23] identified a large initialization scale together with weight decay as a mechanism for grokking.",
    "next": "Barak et al.",
    "hard_negative": [
      207808916,
      255749430,
      1428702
    ],
    "easy_negative": [
      38650676,
      202565869,
      743967
    ]
  },
  {
    "index": 137,
    "source_corpus_id": 34984289,
    "ref_id": "b2",
    "citation_corpus_id": 9716222,
    "start": 1855,
    "end": 1881,
    "title": "Training with Exploration Improves a Greedy Stack LSTM Parser",
    "abstract": "We adapt the greedy stack LSTM dependency parser ofDyer et al. (2015)to support a training-with-exploration procedure using dynamic oracles (Goldberg and Nivre, 2013) instead of assuming an error-free action history. This form of training, which accounts for model predictions at training time, improves parsing accuracies. We discuss some modifications needed in order to get training with exploration to work well for a probabilistic neural network dependency parser.",
    "prev": "* Equal contribution.",
    "curr": "Introduction\n\nRecurrent neural networks (RNNs) have been recently quite successful in structured prediction applications such as machine translation (Sutskever et al., 2014), parsing (Ballesteros et al., 2016) or caption generation (Vinyals et al., 2015).",
    "next": "These models use the same repeated cell (or unit) to output a sequence of tokens one by one.",
    "hard_negative": [
      14800772,
      815755,
      2512012,
      59829005,
      5464204,
      8298000,
      12822570,
      7147309,
      131767086,
      3913537,
      1195002,
      14358598,
      2952144,
      11616343,
      9210201,
      13156058,
      16667486,
      11599080,
      63346,
      12121080,
      10901371
    ],
    "easy_negative": [
      1778388,
      11869911,
      5603500
    ]
  },
  {
    "index": 150,
    "source_corpus_id": 222209080,
    "ref_id": "b18",
    "citation_corpus_id": 1487550,
    "start": 3081,
    "end": 3097,
    "title": "UNSUPERVISED WORD SENSE DISAMBIGUATION RIVALING SUPERVISED METHODS",
    "abstract": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints -that words tend to have one sense per discourse and one sense per collocation -exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%.",
    "prev": "Self-training is a common algorithmic paradigm for leveraging unlabeled data with deep networks.",
    "curr": "Self-training methods train a model to fit pseudolabels, that is, predictions on unlabeled data made by a previously-learned model (Yarowsky, 1995;Grandvalet & Bengio, 2005;Lee, 2013).",
    "next": "Recent work also extends these methods to enforce stability of predictions under input transformations such as adversarial perturbations (Miyato et al., 2018) and data augmentation (Xie et al., 2019).",
    "hard_negative": [
      11329942,
      1693468,
      3166885,
      1580335,
      5458997,
      2946526,
      9537399
    ],
    "easy_negative": [
      256461461,
      235266005,
      209063610
    ]
  },
  {
    "index": 157,
    "source_corpus_id": 222125116,
    "ref_id": "b9",
    "citation_corpus_id": 5590763,
    "start": 2351,
    "end": 2355,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "A variety of approaches have been suggested to mitigate the exploding and vanishing gradient problem.",
    "curr": "These include adding gating mechanisms to the RNN in order to control the flow of information in the network, leading to architectures such as long short-term memory (LSTM) [21] and gated recurring units (GRU) [10], that can overcome the vanishing gradient problem on account of the underlying additive structure.",
    "next": "However, the gradients might still explode and learning very long term dependencies remains a challenge [30].",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      3189871,
      1329417,
      52112656
    ]
  },
  {
    "index": 160,
    "source_corpus_id": 88514953,
    "ref_id": "b17",
    "citation_corpus_id": 16209268,
    "start": 3397,
    "end": 3421,
    "title": "Published as a conference paper at ICLR 2015 QUALITATIVELY CHARACTERIZING NEURAL NETWORK OPTIMIZATION PROBLEMS",
    "abstract": "Training neural networks involves solving large-scale non-convex optimization problems. This task has long been believed to be extremely difficult, with fear of local minima and other obstacles motivating a variety of schemes to improve optimization, such as unsupervised pretraining. However, modern neural networks are able to achieve negligible training error on complex tasks, using only direct training with stochastic gradient descent. We introduce a simple analysis technique to look for evidence that such networks are overcoming local optima. We find that, in fact, on a straight path from initialization to solution, a variety of state of the art neural networks never encounter any significant obstacles.",
    "prev": "Ideally, we would like to quantify the probability to converge to a local minimum as a function of the error at this minimum, where the probability is taken with the respect to the randomness of the initialization of the weights, the data and SGD.",
    "curr": "Specifically, we would like to know, under which conditions this probability is very small if the error is high, as was observed empirically (e.g., (Dauphin et al., 2014;Goodfellow et al., 2015)).",
    "next": "However, this seems to be a daunting task for realistic MNNs, since it requires a characterization of the sizes and distributions of the basins of attraction for all local minima.",
    "hard_negative": [
      17272965,
      252796
    ],
    "easy_negative": [
      146621,
      184483263,
      235658908
    ]
  },
  {
    "index": 163,
    "source_corpus_id": 263671510,
    "ref_id": "b31",
    "citation_corpus_id": 247595263,
    "start": 10710,
    "end": 10730,
    "title": "SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS",
    "abstract": "Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and ARC-challenge (+3.9%).",
    "prev": "We also investigated using only GSM8K to create difficult problems, but we found that the new problems were too similar to the original ones, and the large gap to MATH still exists (more information can be found in Appendix C).",
    "curr": "Self-distillation.Given that we do not have ground truth answers for the new problems, we then generate n different LCE solutions as depicted in (Wang et al., 2023a) for each new problem with our initial MathCoder models, keeping only those solutions for which all n answers match (n is set to 3 in this paper), thus ensuring our dataset's quality.We use MathCoder-Initial here because it demonstrates the potential for effective model distillation using a model much weaker than the powerful closed-source models.As MathCoder-Initial already has an accuracy of 77.3% on GSM8K and 44.0% on MATH, it is plausible that distilling it can produce good results.It also reduces the cost compared to using GPT-4.Some examples can be found in Appendix A.",
    "next": "Combining the new data D 1 with the seed data D 0 yields the MathCodeInstruct dataset D = {D 0 , D 1 }.We fine-tune the base Llama-2 (Touvron et al., 2023) and CodeLlama (Rozi\u00e8re et al., 2023) models using MathCodeInstruct to derive our final MathCoder models.For clarity, we refer to the supervised fine-tuning of base Llama-2 as \"MathCoder-L\" and that of CodeLlama as \"MathCoder-CL\", as shown in Fig.",
    "hard_negative": [
      235368289,
      53296520,
      211066379,
      248377325,
      560565,
      165163607,
      203905467,
      247447167
    ],
    "easy_negative": [
      62713436,
      7645153,
      261494507
    ]
  },
  {
    "index": 165,
    "source_corpus_id": 52978527,
    "ref_id": "b53",
    "citation_corpus_id": 27494814,
    "start": 10231,
    "end": 10249,
    "title": "To prune, or not to prune: exploring the efficacy of pruning for model compression",
    "abstract": "Model pruning seeks to induce sparsity in a deep neural network's various connection matrices, thereby reducing the number of nonzero-valued parameters in the model. Recent reports(Han et al., 2015a;Narang et al., 2017)prune deep networks at the cost of only a marginal loss in accuracy and achieve a sizable reduction in model size. This hints at the possibility that the baseline models in these experiments are perhaps severely over-parameterized at the outset and a viable alternative for model compression might be to simply reduce the number of hidden units while maintaining the model's dense connection structure, exposing a similar trade-off in model size and accuracy. We investigate these two distinct paths for model compression within the context of energy-efficient inference in resource-constrained environments and propose a new gradual pruning technique that is simple and straightforward to apply across a variety of models/datasets with minimal tuning and can be seamlessly incorporated within the training process. We compare the accuracy of large, but pruned models (large-sparse) and their smaller, but dense (small-dense) counterparts with identical memory footprint. Across a broad range of neural network architectures (deep CNNs, stacked LSTM, and seq2seq LSTM models), we find large-sparse models to consistently outperform small-dense models and achieve up to 10x reduction in number of non-zero parameters with minimal loss in accuracy.",
    "prev": "Frankle & Carbin (2018) hypothesizes that certain connections, together with their randomly initialized weights, is particularly effective for training, and a pruning algorithm can help find such sub-networks.",
    "curr": "Zhu & Gupta (2018) shows that training a small-dense model cannot achieve the same accuracy as a pruned large-sparse model with identical memory footprint.",
    "next": "In this work, we reveal a different and rather surprising characteristic of network pruning methods: fine-tuning the pruned model with inherited weights is no better than training it from scratch.",
    "hard_negative": [
      2134321,
      2973141
    ],
    "easy_negative": [
      11771220,
      2063643,
      64865
    ]
  },
  {
    "index": 169,
    "source_corpus_id": 256615813,
    "ref_id": "b27",
    "citation_corpus_id": 3144218,
    "start": 6513,
    "end": 6535,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "Bounding Shape Mask R- CNN (Kang et al., 2020) improves performance on object detection and instance segmentation by its bounding shape mask branch.",
    "curr": "BCNet (Ke et al., 2021) uses two GCN (Welling & Kipf, 2016) layers to detect overlapping instances.",
    "next": "Although these algorithms have yielded promising results, they are still restricted in the low-resolution mask representation and thus do not generate high-quality masks.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      235652287,
      245857009,
      252918531
    ]
  },
  {
    "index": 171,
    "source_corpus_id": 263609164,
    "ref_id": "b22",
    "citation_corpus_id": 219530969,
    "start": 33805,
    "end": 33830,
    "title": "Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization",
    "abstract": "Most reinforcement learning (RL) algorithms assume online access to the environment, in which one may readily interleave updates to the policy with experience collection using that policy. However, in many real-world applications such as health, education, dialogue agents, and robotics, the cost or potential risk of deploying a new data-collection policy is high, to the point that it can become prohibitive to update the data-collection policy more than a few times during learning. With this view, we propose a novel concept of deployment efficiency, measuring the number of distinct data-collection policies that are used during policy learning. We observe that na\u00efvely applying existing model-free offline RL algorithms recursively does not lead to a practical deployment-efficient and sample-efficient algorithm. We propose a novel model-based algorithm, Behavior-Regularized Model-ENsemble (BREMEN) that can effectively optimize a policy offline using 10-20 times fewer data than prior works. Furthermore, the recursive application of BREMEN is able to achieve impressive deployment efficiency while maintaining the same or better sample efficiency, learning successful policies from scratch on simulated robotic environments with only 5-10 deployments, compared to typical values of hundreds to millions in standard RL baselines. Codes and pre-trained models are available at https://github.com/matsuolab/BREMEN. * Equal contribution.Preprint. Under review.",
    "prev": "minimising the number of times the policy used changes from one episode to the next.These works are not directly comparable because they study regret-minimisation for finite-horizon MDPs and we study BPI and PE in the discounted setting.Nevertheless, there are works on tabular MDPs (Qiao et al., 2022;Bai et al., 2019;Zhang et al., 2020), linear MDPs (Gao et al., 2021;Wang et al., 2021;Qiao & Wang, 2023) and MDPs with a linear representation for the action values (Qiao et al., 2023).",
    "curr": "The multi-batch learning model has been studied extensively for bandit algorithms (Perchet et al., 2015;Jun et al., 2016;Gao et al., 2019;Esfandiari et al., 2021;Duchi et al., 2018;Han et al., 2020;Ruan et al., 2021).In RL, it has been studied in the regret-minimisation setting for finite-horizon tabular (Zihan et al., 2022) and linear MDPs (Wang et al., 2021) and MDPs under general function approximation (Xiong et al., 2023).A closely related notion is deployment efficiency (Matsushima et al., 2021), which constrains batches to be of a fixed size consisting of trajectories from a single policy.In finite-horizon linear MDPs, it has been shown that BPI can be solved to arbitrary accuracy with a number of deployments independent of the dimension d (Huang et al., 2022;Qiao & Wang, 2023) where the deployed policy is a finite mixture of deterministic policies.Our results suggest that infinite-horizon discounted MDPs under more general linear representation of action-values are fundamentally harder since the number of deployments must scale with dimension.",
    "next": "The policy finetuning setting assumes access to an offline dataset that can be complemented with online trajectories (Xie et al., 2021) but is different from our setting since there is no adaptivity constraint in the online algorithm, i.e.",
    "hard_negative": [
      3517962,
      6628106,
      211204780,
      27254961,
      28202810,
      3536221,
      16326763,
      14048239
    ],
    "easy_negative": [
      252595603,
      11250372,
      256461093
    ]
  },
  {
    "index": 172,
    "source_corpus_id": 44096233,
    "ref_id": "b23",
    "citation_corpus_id": 2100831,
    "start": 5974,
    "end": 5998,
    "title": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text",
    "abstract": "We present MCTest, a freely available set of stories and associated questions intended for research on the machine comprehension of text. Previous work on machine comprehension (e.g., semantic modeling) has made great strides, but primarily focuses either on limited-domain datasets, or on solving a more restricted goal (e.g., open-domain relation extraction). In contrast, MCTest requires machines to answer multiple-choice reading comprehension questions about fictional stories, directly tackling the high-level goal of open-domain machine comprehension. Reading comprehension can test advanced abilities such as causal reasoning and understanding the world, yet, by being multiple-choice, still provide a clear metric. By being fictional, the answer typically can be found only in the story itself. The stories and questions are also carefully limited to those a young child would understand, reducing the world knowledge that is required for the task. We present the scalable crowd-sourcing methods that allow us to cheaply construct a dataset of 500 stories and 2000 questions. By screening workers (with grammar tests) and stories (with grading), we have ensured that the data is the same quality as another set that we manually edited, but at one tenth the editing cost. By being open-domain, yet carefully restricted, we hope MCTest will serve to encourage research and provide a clear metric for advancement on the machine comprehension of text.",
    "prev": "Third, we demonstrate that on synthetic data, DSMN achieves superior performance for answering questions that require visual thinking.",
    "curr": "Related Work\n\nNatural language datasets for QA: Several natural language QA datasets have been proposed to test AI systems on various reasoning abilities (Levesque et al., 2011;Richardson et al., 2013).",
    "next": "Our work differs from them in two key aspects: first, we use synthetic data instead of natural data; and second, we specialize in geometrical reasoning instead of general language understanding.",
    "hard_negative": [
      1321,
      3038382,
      5734707,
      9111381,
      15197674,
      12131065
    ],
    "easy_negative": [
      184482880,
      2531372,
      14629655
    ]
  },
  {
    "index": 175,
    "source_corpus_id": 220769181,
    "ref_id": "b10",
    "citation_corpus_id": 204512179,
    "start": 1924,
    "end": 1928,
    "title": "LEARNING NEARLY DECOMPOSABLE VALUE FUNC- TIONS VIA COMMUNICATION MINIMIZATION",
    "abstract": "Reinforcement learning encounters major challenges in multi-agent settings, such as scalability and non-stationarity. Recently, value function factorization learning emerges as a promising way to address these challenges in collaborative multi-agent systems. However, existing methods have been focusing on learning fully decentralized value function, which are not efficient for tasks requiring communication. To address this limitation, this paper presents a novel framework for learning nearly decomposable value functions with communication, with which agents act on their own most of the time but occasionally send messages to other agents in order for effective coordination. This framework hybridizes value function factorization learning and communication learning by introducing two information-theoretic regularizers. These regularizers are maximizing mutual information between decentralized Q functions and communication messages while minimizing the entropy of messages between agents. We show how to optimize these regularizers in a way that is easily integrated with existing value function factorization methods such as QMIX. Finally, we demonstrate that, on the StarCraft unit micromanagement benchmark, our framework significantly outperforms baseline methods and allows to cut off more than 80% communication without sacrificing the performance. The video of our experiments is available at",
    "prev": "Demonstrative videos are available at https\n\nIntroduction\n\nCooperative multi-agent reinforcement learning (MARL) has achieved great progress in recent years [1][2][3][4][5][6][7].",
    "curr": "Advances in valued-based MARL [8][9][10][11] contribute significantly to the progress, achieving state-of-the-art performance on challenging tasks, such as StarCraft II micromanagement [12].",
    "next": "However, these value-based methods present a major challenge for stability and convergence in multi-agent settings [13], which is further exacerbated in continuous action spaces.",
    "hard_negative": [
      59604361,
      7167114,
      56895453
    ],
    "easy_negative": [
      202542690,
      261349588,
      16332736
    ]
  },
  {
    "index": 179,
    "source_corpus_id": 211069439,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 2487,
    "end": 2510,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "INTRODUCTION\n\nText sequence transduction systems convert a given text sequence from one domain to another.",
    "curr": "These techniques can be applied to a wide range of natural language processing applications such as machine translation (Bahdanau et al., 2015), summarization (Rush et al., 2015), and dialogue response generation (Zhao et al., 2017).",
    "next": "In many cases, however, parallel corpora for the task at hand are scarce.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      6249954,
      232021547,
      259376836
    ]
  },
  {
    "index": 181,
    "source_corpus_id": 232105052,
    "ref_id": "b44",
    "citation_corpus_id": 44131019,
    "start": 3421,
    "end": 3439,
    "title": "Scaling Neural Machine Translation",
    "abstract": "Sequence to sequence learning models still require several days to reach state of the art performance on large benchmark datasets using a single machine. This paper shows that reduced precision and large batch training can speedup training by nearly 5x on a single 8-GPU machine with careful tuning and implementation. 1 On WMT'14 English-German translation, we match the accuracy ofVaswani et al. (2017)in under 5 hours when training on 8 GPUs and we obtain a new state of the art of 29.3 BLEU after training for 85 minutes on 128 GPUs. We further improve these results to 29.8 BLEU by training on the much larger Paracrawl dataset. On the WMT'14 English-French task, we obtain a state-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs.",
    "prev": "tion, and explore its application in transformers.RFA can be used as a drop-in replacement for conventional softmax attention and offers a straightforward way of learning with recency bias through an optional gating mechanism.Experiments on language modeling and machine translation demonstrate that RFA achieves similar or better performance compared to strong transformer baselines.In the machine translation experiment, RFA decodes twice as fast as a vanilla transformer.Compared to existing efficient transformer variants, RFA is competitive in terms of both accuracy and efficiency on three long text classification datasets.Our analysis shows that RFA's efficiency gains are especially notable on long sequences, suggesting that RFA will be particularly useful in tasks that require working with large inputs, fast decoding speed, or low memory footprints.",
    "curr": "INTRODUCTION\n\nTransformer architectures (Vaswani et al., 2017) have achieved tremendous success on a variety of sequence modeling tasks (Ott et al., 2018;Radford et al., 2018;Parmar et al., 2018;Devlin et al., 2019;Parisotto et al., 2020, inter alia).Under the hood, the key component is attention (Bahdanau et al., 2015), which models pairwise interactions of the inputs, regardless of their distances from each other.This comes with quadratic time and memory costs, making the transformers computationally expensive, especially for long sequences.A large body of research has been devoted to improving their time and memory efficiency (Tay et al., 2020c).Although better asymptotic complexity and prominent gains for long sequences have been achieved (Lee et al., 2019;Child et al., 2019;Beltagy et al., 2020, inter alia), in practice, many existing approaches are less well-suited for moderatelength ones: the additional computation steps required by some approaches can overshadow the time and memory they save (Kitaev et al., 2020;Wang et al., 2020;Roy et al., 2020, inter alia).",
    "next": "This work proposes random feature attention (RFA), an efficient atte",
    "hard_negative": [
      3297437,
      9545399,
      21850704,
      3516266,
      6380915,
      3725815
    ],
    "easy_negative": [
      9882071,
      227231099,
      218974491
    ]
  },
  {
    "index": 182,
    "source_corpus_id": 257102434,
    "ref_id": "b15",
    "citation_corpus_id": 13046179,
    "start": 10346,
    "end": 10372,
    "title": "A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS",
    "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.Published as a conference paper at ICLR 2017 one method which outperforms the baseline on some (but not all) tasks. This new method evaluates the quality of a neural network's input reconstruction to determine if an example is abnormal.",
    "prev": "This function should induce a partial order over instances in X .",
    "curr": "The most common and well-known \u03ba function for a classification model f (with softmax at its last layer) is its softmax response values -\u03ba(x,\u0177|f ) f (x)\u0177 (Cordella et al., 1995;De Stefano et al., 2000) -which is also widely accepted as a baseline in the OOD literature (Hendrycks & Gimpel, 2017;Hendrycks et al., 2021;Berger et al., 2021;Shalev et al., 2018).",
    "next": "While this is the primary \u03ba we evaluate for the sake of simplicity, various other \u03ba functions, which are also utilized for OOD detection, exist.",
    "hard_negative": [
      6628106,
      7105713,
      2879445,
      1428702
    ],
    "easy_negative": [
      204893632,
      14528916,
      20205425
    ]
  },
  {
    "index": 185,
    "source_corpus_id": 225067229,
    "ref_id": "b32",
    "citation_corpus_id": 216553145,
    "start": 2479,
    "end": 2498,
    "title": "Multi-Domain Dialogue Acts and Response Co-Generation",
    "abstract": "Generating fluent and informative responses is of critical importance for task-oriented dialogue systems. Existing pipeline approaches generally predict multiple dialogue acts first and use them to assist response generation. There are at least two shortcomings with such approaches. First, the inherent structures of multi-domain dialogue acts are neglected. Second, the semantic associations between acts and responses are not taken into account for response generation. To address these issues, we propose a neural co-generation model that generates dialogue acts and responses concurrently. Unlike those pipeline approaches, our act generation module preserves the semantic structures of multi-domain dialogue acts and our response generation module dynamically attends to different acts as needed. We train the two modules jointly using an uncertainty loss to adjust their task weights adaptively. Extensive experiments are conducted on the largescale MultiWOZ dataset and the results show that our model achieves very favorable improvement over several state-of-the-art models in both automatic and human evaluations.",
    "prev": "Human evaluations show that COCO-generated conversations perfectly reflect the underlying user goal with more than 95% accuracy and are as human-like as the original conversations, further strengthening its reliability and promise to be adopted as part of the robustness evaluation of DST models.",
    "curr": "INTRODUCTION\n\nTask-oriented dialogue (TOD) systems have recently attracted growing attention and achieved substantial progress (Zhang et al., 2019b;Peng et al., 2020;Wang et al., 2020b;a), partly made possible by the construction of large-scale datasets (Budzianowski et al., 2018;Byrne et al., 2019;Rastogi et al., 2019).",
    "next": "Dialogue state tracking (DST) is a backbone of TOD systems, where it is responsible for extracting the user's goal represented as a set of slot-value pairs (e.g., (area, center), (food, British)), as illustrated in the upper part of Figure 1.",
    "hard_negative": [
      6628106,
      31004450,
      437687,
      67856324,
      21850704,
      44091475,
      2129889,
      53017700,
      739696,
      28821374
    ],
    "easy_negative": [
      15241522,
      1419832,
      13603486
    ]
  },
  {
    "index": 186,
    "source_corpus_id": 215814169,
    "ref_id": "b24",
    "citation_corpus_id": 59310641,
    "start": 7411,
    "end": 7414,
    "title": "PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS",
    "abstract": "Self-attention is a useful mechanism to build generative models for language and images. It determines the importance of context elements by comparing each element to the current time step. In this paper, we show that a very lightweight convolution can perform competitively to the best reported self-attention results. Next, we introduce dynamic convolutions which are simpler and more efficient than self-attention. We predict separate convolution kernels based solely on the current time-step in order to determine the importance of context elements. The number of operations required by this approach scales linearly in the input length, whereas self-attention is quadratic. Experiments on large-scale machine translation, language modeling and abstractive summarization show that dynamic convolutions improve over strong self-attention models. On the WMT'14 English-German test set dynamic convolutions achieve a new state of the art of 29.7 BLEU. 1 * Work done during an internship at Facebook. 1 Code and pre-trained models available at",
    "prev": "[23] for a review of different pruning strategies.",
    "curr": "Others have worked on lightweight architectures, by modifying existing models [24,25,26] or developing new networks, such as MobileNet [16], ShuffleNet [15], and EfficientNet [4] in vision.",
    "next": "Finally, knowledge distillation [6] has been applied to sentence representation [13,27,28,29,30], to reduce the size of a BERT model [31].",
    "hard_negative": [
      6628106,
      53082905,
      12462234,
      9545399,
      52100282,
      964287,
      3718988,
      44131019,
      1998416,
      3480671,
      11212020,
      3725815,
      836219
    ],
    "easy_negative": [
      44425337,
      17646396,
      222290886
    ]
  },
  {
    "index": 191,
    "source_corpus_id": 263829348,
    "ref_id": "b12",
    "citation_corpus_id": 209315300,
    "start": 2766,
    "end": 2786,
    "title": "REFORMER: THE EFFICIENT TRANSFORMER",
    "abstract": "Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O(L 2 ) to O(L log L), where L is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of N times, where N is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.Published as a conference paper at ICLR 2020We introduce the Reformer model which solves these problems using the following techniques:\u2022 Reversible layers, first introduced in Gomez et al.(2017), enable storing only a single copy of activations in the whole model, so the N factor disappears. \u2022 Splitting activations inside feed-forward layers and processing them in chunks removes the d f f factor and saves memory inside feed-forward layers.",
    "prev": "INTRODUCTION\n\nTime series forecasting, i.e., predicting future data based on historical observations, has broad realworld applications, such as health, transportation, finance and so on.",
    "curr": "In the past decade, numerous deep neural network architectures have been applied to time series modeling, including convolutional neural networks (CNN) (Bai et al., 2018), recurrent neural networks (RNN) (Siami-Namini et al., 2018), graph neural networks (GNN) (Li et al., 2018;Cao et al., 2020), and Transformers (Liu et al., 2021;Wu et al., 2021;Zhou et al., 2021;Wu et al., 2023;Zhou et al., 2022;Woo et al., 2022;Kitaev et al., 2020;Nie et al., 2023), leading to state-of-the-arts results.",
    "next": "While achieving strong prediction performance, the previous works on time series mostly benefit from the advance in sequence modeling (from RNN and GNN, to transformers) that captures temporal dependencies but overlooks a series of intricate patterns within time series data, such as seasonality, trend, and residual.",
    "hard_negative": [
      44131019,
      13751870
    ],
    "easy_negative": [
      219310235,
      237366274,
      1745463
    ]
  },
  {
    "index": 198,
    "source_corpus_id": 253255190,
    "ref_id": "b2",
    "citation_corpus_id": 54203451,
    "start": 3304,
    "end": 3326,
    "title": "SYSTEMATIC GENERALIZATION: WHAT IS REQUIRED AND CAN IT BE LEARNED?",
    "abstract": "Numerous models for grounded language understanding have been recently proposed, including (i) generic models that can be easily adapted to any given task with little adaptation and (ii) intuitively appealing modular models that require background knowledge to be instantiated. We compare both types of models in how much they lend themselves to a particular form of systematic generalization. Using a synthetic VQA test, we evaluate which models are capable of reasoning about all possible object pairs after training on only a small subset of them. Our findings show that the generalization of modular models is much more systematic and that it is highly sensitive to the module layout, i.e. to how exactly the modules are connected. We furthermore investigate if modular models that generalize well could be made more end-to-end by learning their layout and parametrization. We find that end-to-end methods from prior work often learn a wrong layout and a spurious parametrization that do not facilitate systematic generalization. Our results suggest that, in addition to modularity, systematic generalization in language understanding may require explicit regularizers or priors.",
    "prev": "In practice, when trained on language data, do transformers instead constrain their computation to look equivalent to a tree-structured bottom-up computation?",
    "curr": "While generalization tests on benchmarks (Lake & Baroni, 2018;Bahdanau et al., 2019;Hupkes et al., 2019;Kim & Linzen, 2020, among others) assess if a transformer's behavior is aligned with tree-like models, they do not measure if the transformer's computation is tree-structured, largely because model behavior on benchmarks could entirely be due to orthogonal properties of the dataset (Patel et al., 2022).",
    "next": "Thus, to understand if transformers implement tree-structured computations, the approach we take is based on directly approximating them with a separate, tree-structured computation.",
    "hard_negative": [
      12304778,
      6628106,
      4537113,
      7228830,
      20472740,
      3728944,
      52116963,
      11212020
    ],
    "easy_negative": [
      795809,
      15541081,
      18894280
    ]
  },
  {
    "index": 200,
    "source_corpus_id": 229923250,
    "ref_id": "b1",
    "citation_corpus_id": 11212020,
    "start": 2344,
    "end": 2367,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "arXiv, 2020.",
    "curr": "INTRODUCTION\n\nSequence-to-Sequence (Seq2Seq) learning  has advanced the state of the art in various natural language processing (NLP) tasks, such as machine translation (Bahdanau et al., 2015;Vaswani et al., 2017;Wu et al., 2019), text summarization (Wang et al., 2019b;Zhang et al., 2020), and grammatical error correction (Kiyono et al., 2019;Kaneko et al., 2020).",
    "next": "Seq2Seq models are generally implemented with an encoder-decoder framework, in which a multi-layer encoder summarizes a source sequence into a sequence of representation and another multi-layer decoder produces the target sequence conditioned on the encoded representation.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      5432501,
      2621672,
      44144456
    ]
  },
  {
    "index": 202,
    "source_corpus_id": 219969405,
    "ref_id": "b19",
    "citation_corpus_id": 71145737,
    "start": 2905,
    "end": 2909,
    "title": "Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples",
    "abstract": "Few-shot classification refers to learning a classifier for new classes given only a few examples. While a plethora of models have emerged to tackle this recently, we find the current procedure and datasets that are used to systematically assess progress in this setting lacking. To address this, we propose META-DATASET: a new benchmark for training and evaluating few-shot classifiers that is large-scale, consists of multiple datasets, and presents more natural and realistic tasks. The aim is to measure the ability of state-ofthe-art models to leverage diverse sources of data to achieve higher generalization, and to evaluate that generalization ability in a more challenging setting. We additionally measure robustness of current methods to variations in the number of available examples and the number of classes. Finally our extensive empirical evaluation leads us to identify weaknesses in Prototypical Networks and MAML, two popular few-shot classification methods, and to propose a new method, Proto-MAML, which achieves improved performance on our benchmark.",
    "prev": "Recently, Triantafillou et al.",
    "curr": "[20] proposed a benchmark for multi-domain few-shot classification, Meta-Dataset, and highlighted some of the challenges that current methods face when training data is heterogeneous.",
    "next": "Crucially, they found that methods which trained on all available domains would normally obtain improved performance on some domains at the expense of others.",
    "hard_negative": [
      53036488,
      3431470,
      29153681,
      49868626
    ],
    "easy_negative": [
      5316234,
      6707318,
      10518348
    ]
  },
  {
    "index": 204,
    "source_corpus_id": 252815987,
    "ref_id": "b13",
    "citation_corpus_id": 3480671,
    "start": 6503,
    "end": 6520,
    "title": "NON-AUTOREGRESSIVE NEURAL MACHINE TRANSLATION",
    "abstract": "Existing approaches to neural machine translation condition each output word on previously generated outputs. We introduce a model that avoids this autoregressive property and produces its outputs in parallel, allowing an order of magnitude lower latency during inference. Through knowledge distillation, the use of input token fertilities as a latent variable, and policy gradient fine-tuning, we achieve this at a cost of as little as 2.0 BLEU points relative to the autoregressive Transformer network used as a teacher. We demonstrate substantial cumulative improvements associated with each of the three aspects of our training strategy, and validate our approach on IWSLT 2016 English-German and two WMT language pairs. By sampling fertilities in parallel at inference time, our non-autoregressive model achieves near-state-of-the-art performance of 29.8 BLEU on WMT 2016 English-Romanian.",
    "prev": "For example, including an extra mathematical symbol can push everything one line further down.",
    "curr": "Some datasets also have long-term symbolic dependencies, which may be difficult for non-sequential models to handle, analogous to some of the challenges observed in nonautoregressive machine translation (Gu et al., 2018).",
    "next": "Generation with Diffusion Models Denoising diffusion probabilistic models (DDPM) (Ho et al., 2020) parameterize a probabilistic distribution P (y 0 |x) as a Markov chain P (y t\u22121 |y t ) with an initial distribution P (y T ).",
    "hard_negative": [
      8451212,
      8476273,
      11212020
    ],
    "easy_negative": [
      2760413,
      248780314,
      18256594
    ]
  },
  {
    "index": 207,
    "source_corpus_id": 222208810,
    "ref_id": "b12",
    "citation_corpus_id": 969555,
    "start": 13384,
    "end": 13406,
    "title": "Pointing the Unknown Words",
    "abstract": "The problem of rare and unknown words is an important issue that can potentially effect the performance of many NLP systems, including both traditional countbased and deep learning models. We propose a novel way to deal with the rare and unseen words for the neural network models with attention. Our model uses two softmax layers in order to predict the next word in conditional language models: one of the softmax layers predicts the location of a word in the source sentence, and the other softmax layer predicts a word in the shortlist vocabulary. The decision of which softmax layer to use at each timestep is adaptively made by an MLP which is conditioned on the context. We motivate this work from a psychological evidence that humans naturally have a tendency to point towards objects in the context or the environment when the name of an object is not known. Using our proposed model, we observe improvements in two tasks, neural machine translation on the Europarl English to French parallel corpora and text summarization on the Gigaword dataset.",
    "prev": "The decoder generates an action sentence a t token-by-token to interact with the game.",
    "curr": "The encoder and decoder are based on a Transformer Seq2Seq model with pointer softmax mechanism (Gulcehre et al., 2016 When playing a game, an agent might get stuck at certain states due to various failures (e.g., action is grammatically incorrect, wrong object name).",
    "next": "The observation for a failed action does not contain any useful feedback, so a fully deterministic model tends to produce the same (wrong) action repeatedly.",
    "hard_negative": [
      2863491,
      1245593,
      1918428
    ],
    "easy_negative": [
      10457485,
      17126451,
      198167364
    ]
  },
  {
    "index": 213,
    "source_corpus_id": 226237047,
    "ref_id": "b24",
    "citation_corpus_id": 40100965,
    "start": 1791,
    "end": 1812,
    "title": "Universal Language Model Fine-tuning for Text Classification",
    "abstract": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\u00d7 more data. We opensource our pretrained models and code 1 .",
    "prev": "We also demonstrate that the new objective leads to models that are more robust to different levels of noise in the training data, and can generalize better to related tasks with limited labeled task data.",
    "curr": "INTRODUCTION\n\nState-of-the-art for most existing natural language processing (NLP) classification tasks is currently achieved by systems that are first pre-trained on auxiliary language modeling tasks and then fine-tuned on the task of interest with cross-entropy loss (Radford et al., 2019;Howard & Ruder, 2018;Liu et al., 2019;Devlin et al., 2019).",
    "next": "Although commonly used, cross-entropy loss -the KL-divergence between one-hot vectors of labels and the distribution of model's output logits -has several shortcomings.",
    "hard_negative": [
      16299141,
      28971531,
      16386838,
      7928230,
      7942973,
      3626819,
      10728540,
      1428702,
      14337532,
      4460159
    ],
    "easy_negative": [
      14391663,
      388111,
      5491644
    ]
  },
  {
    "index": 216,
    "source_corpus_id": 245836975,
    "ref_id": "b25",
    "citation_corpus_id": 5959482,
    "start": 3603,
    "end": 3625,
    "title": "Efficient Estimation of Word Representations in Vector Space",
    "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities. arXiv:1301.3781v3 [cs.CL] 7 Sep 2013 1 The test set is available at www.fit.vutbr.cz/\u02dcimikolov/rnnlm/word-test.v1.txt 2",
    "prev": "Zero-shot methods, on the other hand, commonly leverage word embeddings to discover or generate related features between seen and unseen classes (Bucher et al., 2019;Gu et al., 2020) without the need for additional annotations.",
    "curr": "Existing works in this space use standard word embeddings (Mikolov et al., 2013) and focus on the image encoder.",
    "next": "In this work, we present a simple approach to leveraging modern language models to increase the flexibility and generality of semantic segmentation models.",
    "hard_negative": [
      633992,
      5278106,
      1428702,
      629094
    ],
    "easy_negative": [
      383,
      14989896,
      237353087
    ]
  },
  {
    "index": 221,
    "source_corpus_id": 249097375,
    "ref_id": "b6",
    "citation_corpus_id": 211146562,
    "start": 6732,
    "end": 6749,
    "title": "Published as a conference paper at ICLR 2020 DIVIDEMIX: LEARNING WITH NOISY LABELS AS SEMI-SUPERVISED LEARNING",
    "abstract": "Deep neural networks are known to be annotation-hungry. Numerous efforts have been devoted to reducing the annotation cost when learning with deep networks. Two prominent directions include learning with noisy labels and semi-supervised learning by exploiting unlabeled data. In this work, we propose DivideMix, a novel framework for learning with noisy labels by leveraging semi-supervised learning techniques. In particular, DivideMix models the per-sample loss distribution with a mixture model to dynamically divide the training data into a labeled set with clean samples and an unlabeled set with noisy samples, and trains the model on both the labeled and unlabeled data in a semi-supervised manner. To avoid confirmation bias, we simultaneously train two diverged networks where each network uses the dataset division from the other network. During the semi-supervised training phase, we improve the MixMatch strategy by performing label co-refinement and label co-guessing on labeled and unlabeled samples, respectively. Experiments on multiple benchmark datasets demonstrate substantial improvements over state-of-the-art methods. Code is available at",
    "prev": "Semi-supervised learning is also popular and effective on learning with noisy labels in recent years.",
    "curr": "Some works [Li et al., 2020a, Nguyen et al., 2020 first perform clustering on the sample loss and divide the samples into clean ones and noisy ones.",
    "next": "Then drop the labels of the \"noisy samples\" and perform semi-supervised learning on all the samples.",
    "hard_negative": [
      13123084,
      9545399,
      3162051,
      2181703
    ],
    "easy_negative": [
      232021923,
      25492437,
      227905641
    ]
  },
  {
    "index": 224,
    "source_corpus_id": 246607791,
    "ref_id": "b6",
    "citation_corpus_id": 213896662,
    "start": 4842,
    "end": 4858,
    "title": "Published as a conference paper at ICLR 2020 GRADIENTS AS FEATURES FOR DEEP REPRESENTATION LEARNING",
    "abstract": "We address the challenging problem of deep representation learning -the efficient adaption of a pre-trained deep network to different tasks. Specifically, we propose to explore gradient-based features. These features are gradients of the model parameters with respect to a task-specific loss given an input sample. Our key innovation is the design of a linear model that incorporates both gradient and activation of the pre-trained network. We demonstrate that our model provides a local linear approximation to an underlying deep model, and discuss important theoretical insights. Moreover, we present an efficient algorithm for the training and inference of our model without computing the actual gradients. Our method is evaluated across a number of representation-learning tasks on several datasets and using different network architectures. Strong results are obtained in all settings, and are well-aligned with our theoretical insights 1 .arXiv:2004.05529v1 [cs.LG] 12 Apr 2020Published as a conference paper at ICLR 2020 is evaluated across tasks, datasets and network architectures and compared against a set of baseline methods. We observe empirically that our model with the gradient features outperforms the traditional activation-based logistic regressor by a significant margin in all settings. Moreover, our model compares favorably against fine-tuning of network parameters.Our main contributions are thus summarized as follows.\u2022 We propose a novel representation-learning method. At the core of our method lies in a linear model that builds on gradients of model parameters as the feature representation. \u2022 From a theoretical perspective, we claim that our linear model provides a local approximation of fine-tuning an underlying deep model. From a practical perspective, we devise an efficient and scalable algorithm for the training and inference of our method. \u2022 We demonstrate strong results of our method across various representation-learning tasks, different network architectures and several datasets. Furthermore, these empirical results are wellaligned with our theoretical insight.",
    "prev": "Furthermore, although that GANs and VAEs are known to be able to generate high-quality samples from the data distribution, there is no strong evidence that they encode explicit layerwise representations to similar quality as in supervised learning models, which implies that there does not exist a natural way to explicitly extract a representation from intermediate layer activations in unsupervisedly pre-trained generative models.",
    "curr": "Additionally, layer activations alone do not suffice to reach the full power of learned representations hidden in neural network models, as shown in recent works (Mu et al., 2020) that incorporating additional gradients-based features into representation leads to substantial improvement over solely using activations-based features.",
    "next": "In light of these constraints, we are interested in the question: is there a principled method for representation extraction beyond layer activations?",
    "hard_negative": [
      6628106,
      49876500,
      52908831,
      6104263,
      8768364,
      6706414,
      84591
    ],
    "easy_negative": [
      250390627,
      6433813,
      5327463
    ]
  },
  {
    "index": 226,
    "source_corpus_id": 262083735,
    "ref_id": "b9",
    "citation_corpus_id": 212747810,
    "start": 20442,
    "end": 20466,
    "title": "Calibration of Pre-trained Transformers",
    "abstract": "Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated. Specifically, do these models' posterior probabilities provide an accurate empirical measure of how likely the model is to be correct on a given example? We focus on BERT (Devlin et al., 2019)  and RoBERTa  (Liu et al., 2019)  in this work, and analyze their calibration across three tasks: natural language inference, paraphrase detection, and commonsense reasoning. For each task, we consider in-domain as well as challenging outof-domain settings, where models face more examples they should be uncertain about. We show that: (1) when used out-of-the-box, pretrained models are calibrated in-domain, and compared to baselines, their calibration error out-of-domain can be as much as 3.5\u00d7 lower;(2) temperature scaling is effective at further reducing calibration error in-domain, and using label smoothing to deliberately increase empirical uncertainty helps calibrate posteriors out-of-domain. 1",
    "prev": "onstructed by the meteorological community.Hallenbeck (1920), for example, presents the performance of a certain rain forecasting method by aggregating results over 6 months into a table: Among the days forecast to have between 10%\u221220% chance of rain, the table records the true fraction of days which were rainy -and similarly for every forecast interval.This early account of calibration already applies the practice of binning-discretizing predictions into bins, and estimating frequencies conditional on each bin.Plots of these tables turned into binned reliability diagrams (Murphy and Winkler, 1977;DeGroot and Fienberg, 1983), which was recently popularized in the machine learning community by a series of works including Zadrozny and Elkan (2001); Niculescu-Mizil and Caruana (2005); Guo et al.",
    "curr": "(2017).Binned reliability diagrams continue to be used in studies of calibration in machine learning, including in the GPT-4 tech report (Guo et al., 2017;Nixon et al., 2019;Minderer et al., 2021;Desai and Durrett, 2020;?",
    "next": ";OpenAI, 2023).",
    "hard_negative": [
      8495258,
      202888986,
      51879969,
      13046179,
      3432876,
      34032948,
      52019251,
      1957433,
      213152193,
      9387600,
      2879445,
      201645145,
      184486746,
      3464416,
      52967399,
      3994096,
      3526391
    ],
    "easy_negative": [
      2838830,
      18931348,
      12829285
    ]
  },
  {
    "index": 227,
    "source_corpus_id": 253107476,
    "ref_id": "b20",
    "citation_corpus_id": 3144218,
    "start": 2476,
    "end": 2498,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "* Equal contribution.",
    "curr": "INTRODUCTION\n\nDeep learning has made tremendous advances in the past decade, leading to state-of-the-art performance on various learning tasks such as computer vision (He et al., 2016), natural language processing (Devlin et al., 2019) and graph learning (Kipf & Welling, 2017).",
    "next": "While some progress has been made regarding the theoretical understanding of these deep models (Arora et al., 2018;Bartlett et al., 2019;Neyshabur et al., 2015;Dziugaite & Roy, 2017), the considered settings are unfortunately often very restrictive and the insights made are only qualitative or very loose.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      14630989,
      8764553,
      220837131
    ]
  },
  {
    "index": 231,
    "source_corpus_id": 29154793,
    "ref_id": "b12",
    "citation_corpus_id": 26100519,
    "start": 8200,
    "end": 8204,
    "title": "DEEP VOICE 3: 2000-SPEAKER NEURAL TEXT-TO-SPEECH",
    "abstract": "We present Deep Voice 3, a fully-convolutional attention-based neural textto-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster. We scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods. We also describe how to scale inference to ten million queries per day on one single-GPU server.2. We show that our architecture trains quickly and scales to the LibriSpeech dataset(Panayotov et al., 2015), which consists of nearly 820 hours of audio data from 2484 speakers.3. We demonstrate that we can generate monotonic attention behavior, avoiding error modes commonly occurred in speech synthesis. 4. We compare the quality of several waveform synthesis methods for a single speaker, including WORLD (Morise et al., 2016), Griffin-Lim (Griffin & Lim, 1984), and WaveNet (Oord et al., 2016). 5. We describe the implementation of an inference kernel for Deep Voice 3, which can serve up to ten million queries per day on one single-GPU server. * Authors listed in reverse alphabetical order. \u2020 These authors contributed to this work while members of Baidu Research. Under review as a conference paper at ICLR 2018 2 RELATED WORK Our work builds upon the state-of-the-art in neural speech synthesis and attention-based sequenceto-sequence learning. Several recent works tackle the problem of synthesizing speech with neural networks, including Deep Voice 1 (Ar\u0131k et al., 2017), Deep Voice 2 (Ar\u0131k et al., 2017), Tacotron (Wang et al., 2017), Char2Wav (Sotelo et al., 2017), VoiceLoop (Taigman et al., 2017), SampleRNN (Mehri et al., 2017), and WaveNet (Oord et al., 2016). Deep Voice 1 & 2 retain the traditional structure of TTS pipelines, separating grapheme-to-phoneme conversion, duration and frequency prediction, and waveform synthesis. In contrast to Deep Voice 1 & 2, Deep Voice 3 employs an attention-based sequenceto-sequence model, yielding a more compact architecture. Similar to Deep Voice 3, Tacotron and Char2Wav are the two proposed sequence-to-sequence models for neural TTS. Tacotron is a neural text-to-spectrogram conversion model, used with Griffin-Lim for spectrogram-to-waveform synthesis. Char2Wav predicts the parameters of WORLD vocoder (Morise et al., 2016) and uses a Sam-pleRNN conditioned upon WORLD parameters for waveform generation. In contrast to Char2Wav and Tacotron, Deep Voice 3 avoids Recurrent Neural Networks (RNNs) 1 to speed up training and alleviates several challenging error modes that attention models fall into. Thus, Deep Voice 3 makes attention-based TTS feasible for a production TTS system with no compromise on accuracy. Finally, WaveNet and SampleRNN are proposed as neural vocoder models for waveform synthesis. It is also worth noting that there are numerous alternatives for high-quality hand-engineered vocoders in the literature, such as STRAIGHT(Kawahara et al., 1999), Vocaine (Agiomyrgiannakis, 2015), and WORLD (Morise et al., 2016). Deep Voice 3 adds no novel vocoder, but has the potential to be integrated with different waveform synthesis methods with slight modifications of its architecture.",
    "prev": "In [12], the authors have used it for denoising waveforms by predicting the middle ground-truth sample from its noisy input support.",
    "curr": "Recent contributions in Text-To-Speech(TTS) [13,14] have successfully conditioned wavenet on linguistic and acoustic features to obtain state of the art performance.",
    "next": "In our encoder-decoder architecture, we use WaveNet as the output of the decoder, and backpropagate through it down to the encoder.",
    "hard_negative": [
      1918428,
      5590763,
      11212020
    ],
    "easy_negative": [
      233365191,
      52345788,
      9847040
    ]
  },
  {
    "index": 242,
    "source_corpus_id": 252531169,
    "ref_id": "b0",
    "citation_corpus_id": 11212020,
    "start": 1690,
    "end": 1713,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "INTRODUCTION\n\nSummarization is the process of condensing a source text into a shorter version while preserving its information content.",
    "curr": "Thanks to neural encoder-decoder models (Bahdanau et al., 2015;Sutskever et al., 2014), Transformer-based architectures (Vaswani et al., 2017), and large-scale pretraining (Liu & Lapata, 2019;Zhang et al., 2020;Lewis et al., 2020), the past few years have witnessed a huge leap forward in summarization technology.",
    "next": "Abstractive methods fluently paraphrase the main content of the input, using a vocabulary different from the original document, while extractive approaches are less creative -they produce summaries by identifying and subsequently concatenating the most important sentences in a document -but manage to avoid hallucinations, false statements and inconsistencies.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      6398883,
      18527573,
      251980399
    ]
  },
  {
    "index": 243,
    "source_corpus_id": 245837268,
    "ref_id": "b18",
    "citation_corpus_id": 13046179,
    "start": 2607,
    "end": 2633,
    "title": "A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS",
    "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.Published as a conference paper at ICLR 2017 one method which outperforms the baseline on some (but not all) tasks. This new method evaluates the quality of a neural network's input reconstruction to determine if an example is abnormal.",
    "prev": "Since there is little prior warning of phase transitions, they pose a challenge to monitoring the safety of ML systems.",
    "curr": "Spurred by this challenge, we propose an anomaly detection task (Hendrycks & Gimpel, 2017;Tack et al., 2020): Can we detect when the true reward starts to drop, while maintaining a low false positive rate in benign cases?",
    "next": "We instantiate our proposed task, POLYNOMALY, for the traffic and COVID environments (Section 5).",
    "hard_negative": [
      6628106,
      7105713,
      2879445,
      1428702,
      6706414
    ],
    "easy_negative": [
      257255014,
      8256930,
      5951182
    ]
  },
  {
    "index": 245,
    "source_corpus_id": 20472740,
    "ref_id": "b51",
    "citation_corpus_id": 1957433,
    "start": 9627,
    "end": 9652,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "Embedding Layer converts each word or phrase to a vector representation and construct the representation matrix for sentences.",
    "curr": "In embedding layer, a model can map tokens to vectors with the pre-trained word representation such as GloVe (Pennington et al., 2014), word2Vec (Mikolov et al., 2013) and fasttext (Joulin et al., 2016).",
    "next": "It can also utilize the preprocessing tool, e.g.",
    "hard_negative": [
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      5959482,
      1104123
    ],
    "easy_negative": [
      198163236,
      16557250,
      219301186
    ]
  },
  {
    "index": 249,
    "source_corpus_id": 1859294,
    "ref_id": "b10",
    "citation_corpus_id": 5590763,
    "start": 1836,
    "end": 1840,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "Such success has been enabled by the appearance of larger datasets, more powerful computing resources and improved architectures and training algorithms.",
    "curr": "Gated units, such as the Long Short-Term Memory [24] (LSTM) and the Gated Recurrent Unit [11] (GRU), were designed to deal with the vanishing gradients problem commonly found in RNNs [8].",
    "next": "These architectures have become popularized thanks to their impressive results in a variety of tasks such as machine translation [5], language modeling [53] or speech recognition [19].",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      7417943,
      38407095,
      5552894
    ],
    "easy_negative": [
      227210092,
      8032424,
      12501332
    ]
  },
  {
    "index": 252,
    "source_corpus_id": 9655643,
    "ref_id": "b5",
    "citation_corpus_id": 5590763,
    "start": 1799,
    "end": 1816,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "* Work done at Google Brain.",
    "curr": "INTRODUCTION\n\nSequence-to-sequence (seq2seq) models (Sutskever et al., 2014;Cho et al., 2014) with attention  have been successfully applied to many applications including machine translation (Luong et al., 2015;Jean et al., 2015), parsing (Vinyals et al., 2015a), image captioning (Vinyals et al., 2015b;Xu et al., 2015) and Automatic Speech Recognition (ASR) (Chan et al., 2016;Bahdanau et al., 2016a).",
    "next": "Previous work has assumed a fixed deterministic decomposition for each output sequence.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      1377275,
      5185315,
      174799399
    ]
  },
  {
    "index": 254,
    "source_corpus_id": 8728609,
    "ref_id": "b35",
    "citation_corpus_id": 1957433,
    "start": 2450,
    "end": 2474,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "1\n\nINTRODUCTION\n\nWord embeddings-continuous-valued vector representations of words-are an almost ubiquitous component of recent natural language processing (NLP) research.",
    "curr": "Word embeddings can be learned using spectral methods (Deerwester et al., 1990) or, more commonly in recent work, via neural networks (Bengio et al., 2003;Mnih & Hinton, 2007;Mikolov et al., 2013;Pennington et al., 2014).",
    "next": "Word embeddings can also be composed to form embeddings of phrases, sentences, or documents Kiros et al., 2015;Wieting et al., 2016;Iyyer et al., 2015).",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      260446846,
      8812081,
      259376710
    ]
  },
  {
    "index": 260,
    "source_corpus_id": 52895589,
    "ref_id": "b14",
    "citation_corpus_id": 3292002,
    "start": 2047,
    "end": 2071,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "INTRODUCTION\n\nLearning with graph structured data, such as molecules, social, biological, and financial networks, requires effective representation of their graph structure (Hamilton et al., 2017b).",
    "curr": "Recently, there has been a surge of interest in Graph Neural Network (GNN) approaches for representation learning of graphs (Li et al., 2016;Hamilton et al., 2017a;Kipf & Welling, 2017;Velickovic et al., 2018;Xu et al., 2018).",
    "next": "GNNs broadly follow a recursive neighborhood aggregation (or message passing) scheme, where each node aggregates feature vectors of its neighbors to compute its new feature vector (Gilmer et al., 2017;Xu et al., 2018).",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      2357939,
      220286796,
      14629655
    ]
  },
  {
    "index": 264,
    "source_corpus_id": 238198403,
    "ref_id": "b3",
    "citation_corpus_id": 221447287,
    "start": 4451,
    "end": 4471,
    "title": "WAVEGRAD: ESTIMATING GRADIENTS FOR WAVEFORM GENERATION",
    "abstract": "This paper introduces WaveGrad, a conditional model for waveform generation through estimating gradients of the data density. This model is built on the prior work on score matching and diffusion probabilistic models. It starts from Gaussian white noise and iteratively refines the signal via a gradient-based sampler conditioned on the mel-spectrogram. WaveGrad is non-autoregressive, and requires only a constant number of generation steps during inference. It can use as few as 6 iterations to generate high fidelity audio samples. WaveGrad is simple to train, and implicitly optimizes for the weighted variational lower-bound of the log-likelihood. Empirical experiments reveal WaveGrad to generate high fidelity audio samples matching a strong likelihood-based autoregressive baseline with less sequential operations. * Work done during an internship at Google Brain. \u2020 Equal contribution.",
    "prev": "Among other popular solutions of the disentanglement problem one can mention applying vector quantization technique to the content information (Wu et al., 2020;Wang et al., 2021), utilizing features of Variational AutoEncoders (Luong & Tran, 2021; The model we propose in this paper solves the disentanglement problem by employing the encoder predicting \"average voice\": it is trained to transform mel features corresponding to each phoneme into mel features corresponding to this phoneme averaged across a large multi-speaker dataset.",
    "curr": "As for decoder, in our VC model, it is designed as a part of a Diffusion Probabilistic Model (DPM) since this class of generative models has shown very good results in speech-related tasks like raw waveform generation (Chen et al., 2021a;Kong et al., 2021) and mel feature generation (Popov et al., 2021;Jeong et al., 2021).",
    "next": "However, this decoder choice poses a problem of slow inference because DPM forward pass scheme is iterative and to obtain high-quality results it is typically necessary to run it for hundreds of iterations (Ho et al., 2020;Nichol & Dhariwal, 2021).",
    "hard_negative": [
      49882757,
      17272965,
      3438497,
      52909749,
      202749904,
      204949712,
      52967399,
      202538740
    ],
    "easy_negative": [
      232257793,
      3850558,
      235195626
    ]
  },
  {
    "index": 268,
    "source_corpus_id": 264490454,
    "ref_id": "b9",
    "citation_corpus_id": 246285344,
    "start": 1626,
    "end": 1649,
    "title": "NATURAL LANGUAGE DESCRIPTIONS OF DEEP VISUAL FEATURES",
    "abstract": "Some neurons in deep networks specialize in recognizing highly specific perceptual, structural, or semantic features of inputs. In computer vision, techniques exist for identifying neurons that respond to individual concept categories like colors, textures, and object classes. But these techniques are limited in scope, labeling only a small subset of neurons and behaviors in any network. Is a richer characterization of neuron-level computation possible? We introduce a procedure (called MILAN, for mutual-information-guided linguistic annotation of neurons) that automatically labels neurons with open-ended, compositional, natural language descriptions. Given a neuron, MILAN generates a description by searching for a natural language string that maximizes pointwise mutual information with the image regions in which the neuron is active. MILAN produces fine-grained descriptions that capture categorical, relational, and logical structure in learned features. These descriptions obtain high agreement with human-generated feature descriptions across a diverse set of model architectures and tasks, and can aid in understanding and controlling learned models. We highlight three applications of natural language neuron descriptions. First, we use MILAN for analysis, characterizing the distribution and importance of neurons selective for attribute, category, and relational information in vision models. Second, we use MILAN for auditing, surfacing neurons sensitive to human faces in datasets designed to obscure them. Finally, we use MILAN for editing, improving robustness in an image classifier by deleting neurons sensitive to text features spuriously correlated with class labels. 1",
    "prev": "iently large model from the Pythia and LLaMA families.Using causal interventions, we show that LMs' internal activations represent binding information by attaching binding ID vectors to corresponding entities and attributes.We further show that binding ID vectors form a continuous subspace, in which distances between binding ID vectors reflect their discernability.Overall, our results uncover interpretable strategies in LMs for representing symbolic knowledge in-context, providing a step towards understanding general in-context reasoning in large-scale LMs.",
    "curr": "INTRODUCTION\n\nModern language models (LMs) excel at many reasoning benchmarks, suggesting that they can perform general purpose reasoning across many domains.However, the mechanisms that underlie LM reasoning remain largely unknown (R\u00e4uker et al., 2023).The deployment of LMs in society has led to calls to better understand these mechanisms (Hendrycks et al., 2021), so as to know why they work and when they fail (Mu & Andreas, 2020;Hernandez et al., 2021;Vig et al., 2020b).",
    "next": "In this work, we seek to understand binding, a foundational skill that underlies reasoning.How humans solve binding, i.e.",
    "hard_negative": [
      53215110,
      225039882,
      5623056,
      14124313,
      635609,
      53729760,
      52889459,
      11212020
    ],
    "easy_negative": [
      232216972,
      120360213,
      216553060
    ]
  },
  {
    "index": 270,
    "source_corpus_id": 51926976,
    "ref_id": "b14",
    "citation_corpus_id": 8820379,
    "start": 1483,
    "end": 1502,
    "title": "Summarizing Source Code using a Neural Attention Model",
    "abstract": "High quality source code is often paired with high level summaries of the computation it performs, for example in code documentation or in descriptions posted in online forums. Such summaries are extremely useful for applications such as code search but are expensive to manually author, hence only done for a small fraction of all code that is produced. In this paper, we present the first completely datadriven approach for generating high level summaries of source code. Our model, CODE-NN , uses Long Short Term Memory (LSTM) networks with attention to produce sentences that describe C# code snippets and SQL queries. CODE-NN is trained on a new corpus that is automatically collected from StackOverflow, which we release. Experiments demonstrate strong performance on two tasks: (1) code summarization, where we establish the first end-to-end learning results and outperform strong baselines, and (2) code retrieval, where our learned model improves the state of the art on a recently introduced C# benchmark by a large margin.",
    "prev": "Our model significantly outperforms previous models that were specifically designed for programming languages, as well as state-of-the-art NMT models.",
    "curr": "INTRODUCTION\n\nModeling the relation between source code and natural language can be used for automatic code summarization (Allamanis et al., 2016), documentation (Iyer et al., 2016), retrieval (Allamanis et al., 2015b), and even generation (Balog et al., 2016;Rabinovich et al., 2017;Yin and Neubig, 2017;Devlin et al., 2017;Murali et al., 2017).",
    "next": "In this work, we consider the general problem of generating a natural language sequence from a given snippet of source code.",
    "hard_negative": [
      12964363,
      8313873,
      3033526,
      5959482,
      1354459,
      258794,
      739696,
      6706547,
      13830525
    ],
    "easy_negative": [
      237295809,
      6145841,
      245117320
    ]
  },
  {
    "index": 273,
    "source_corpus_id": 3300406,
    "ref_id": "b8",
    "citation_corpus_id": 7774489,
    "start": 2328,
    "end": 2350,
    "title": "Published as a conference paper at ICLR 2017 STOCHASTIC NEURAL NETWORKS FOR HIERARCHICAL REINFORCEMENT LEARNING",
    "abstract": "Deep reinforcement learning has achieved many impressive results in recent years. However, tasks with sparse rewards or long horizons continue to pose significant challenges. To tackle these important problems, we propose a general framework that first learns useful skills in a pre-training environment, and then leverages the acquired skills for learning faster in downstream tasks. Our approach brings together some of the strengths of intrinsic motivation and hierarchical methods: the learning of useful skill is guided by a single proxy reward, the design of which requires very minimal domain knowledge about the downstream tasks. Then a high-level policy is trained on top of these skills, providing a significant improvement of the exploration and allowing to tackle sparse rewards in the downstream tasks. To efficiently pre-train a large span of skills, we use Stochastic Neural Networks combined with an information-theoretic regularizer. Our experiments 1 show 2 that this combination is effective in learning a wide span of interpretable skills in a sample-efficient way, and can significantly boost the learning performance uniformly across a wide range of downstream tasks.",
    "prev": "This problem is known as the problem of option discovery.",
    "curr": "Option discovery has received ample attention over many years, with varied solutions being proposed (e.g., Bacon et al., 2017;\u015e imsek & Barto, 2004;Daniel et al., 2016;Florensa et al., 2017;Konidaris & Barto, 2009;Mankowitz et al., 2016;McGovern & Barto, 2001).",
    "next": "Recently, Machado et al.",
    "hard_negative": [
      2428314,
      14307651,
      3075448
    ],
    "easy_negative": [
      10074544,
      18594903,
      16907615
    ]
  },
  {
    "index": 279,
    "source_corpus_id": 235899205,
    "ref_id": "b26",
    "citation_corpus_id": 9586240,
    "start": 14851,
    "end": 14873,
    "title": "Annotated Gigaword",
    "abstract": "We have created layers of annotation on the English Gigaword v.5 corpus to render it useful as a standardized corpus for knowledge extraction and distributional semantics. Most existing large-scale work is based on inconsistent corpora which often have needed to be re-annotated by research teams independently, each time introducing biases that manifest as results that are only comparable at a high level. We provide to the community a public reference set based on current state-of-the-art syntactic analysis and coreference resolution, along with an interface for programmatic access. Our goal is to enable broader involvement in large-scale knowledge-acquisition efforts by researchers that otherwise may not have had the ability to produce such a resource on their own.",
    "prev": "summary/article).",
    "curr": "We provide an example of auto-prompting for a sample from the Gigaword summarization dataset (Napoles et al., 2012) with the respective masking in Figure 2 .",
    "next": "For our generation experiments, we denote HTLM-Auto-NS (not-sized) as the auto-prompt without using size hints, where HTLM-Auto-S uses the size hints based policy described in the previous section.",
    "hard_negative": [
      1455080,
      9558665,
      2471050,
      5337047,
      618047
    ],
    "easy_negative": [
      17488075,
      3212747,
      15541958
    ]
  },
  {
    "index": 284,
    "source_corpus_id": 231648113,
    "ref_id": "b37",
    "citation_corpus_id": 12713052,
    "start": 2086,
    "end": 2102,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "INTRODUCTION\n\nInstead of manually designing neural networks, neural architecture search (NAS) algorithms are used to automatically discover the best ones (Tan & Le, 2019a;Bender et al., 2018).",
    "curr": "Early work by Zoph & Le (2017) proposed using a reinforcement learning (RL) controller that constructs candidate architectures, these are evaluated and then feedback is provided to the controller based on the performance of the candidate.",
    "next": "One major problem with this basic NAS methodology is that each evaluation is very costly -typically on the order of hours or days to train a single neural network fully.",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      233474778,
      5641858,
      2085726
    ]
  },
  {
    "index": 289,
    "source_corpus_id": 13206339,
    "ref_id": "b25",
    "citation_corpus_id": 6018348,
    "start": 2374,
    "end": 2392,
    "title": "Distant Supervision for Relation Extraction with an Incomplete Knowledge Base",
    "abstract": "Distant supervision, heuristically labeling a corpus using a knowledge base, has emerged as a popular choice for training relation extractors. In this paper, we show that a significant number of \"negative\" examples generated by the labeling process are false negatives because the knowledge base is incomplete. Therefore the heuristic for generating negative examples has a serious flaw. Building on a state-of-the-art distantly-supervised extraction algorithm, we proposed an algorithm that learns from only positive and unlabeled labels at the pair-of-entity level. Experimental results demonstrate its advantage over existing algorithms.",
    "prev": "We are interested in automated reasoning on large knowledge bases (KB) with rich and diverse semantics (Suchanek et al., 2007;Bollacker et al., 2008;Carlson et al., 2010).",
    "curr": "KBs are highly incomplete (Min et al., 2013), and facts not directly stored in a KB can often be inferred from those that are, creating exciting opportunities and challenges for automated reasoning.",
    "next": "For example, consider the small knowledge graph in figure 1.",
    "hard_negative": [
      3179848,
      10910955,
      17069935,
      12995507,
      16483125,
      5869747,
      8945340,
      11494526
    ],
    "easy_negative": [
      247292052,
      7212475,
      250390569
    ]
  },
  {
    "index": 290,
    "source_corpus_id": 247058691,
    "ref_id": "b12",
    "citation_corpus_id": 12639289,
    "start": 2684,
    "end": 2714,
    "title": "Recurrent Continuous Translation Models",
    "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
    "prev": "This search problem is a hard combinatorial optimization problem, and as a result, constraints are frequently imposed on the structure of the model to make solving or approximating the search problem easier.",
    "curr": "In neural machine translation, an autoregressive factorization of the output probability distribution is widely used (Kalchbrenner & Blunsom, 2013;Sutskever et al., 2014;Vaswani et al., 2017), and a variety of conditional independence assumptions are made in other model classes from statistical translation models (Brown et al., 1993;Koehn et al., 2003) to non-autoregressive neural models (Lee et al., 2018).",
    "next": "Although these assumptions enable fast and accurate approximations to the search problem with simple and efficient algorithms (e.g., beam search), which can be crucial for efficient production applications, they limit the form of the models and thereby restricting the kinds of architectures that can be used to address observed model failures.",
    "hard_negative": [
      1274371,
      10691183,
      16391184,
      8476273,
      8608051,
      806709
    ],
    "easy_negative": [
      7346113,
      15149329,
      219306693
    ]
  },
  {
    "index": 293,
    "source_corpus_id": 3481593,
    "ref_id": "b10",
    "citation_corpus_id": 17597823,
    "start": 22717,
    "end": 22736,
    "title": "SwissCheese at SemEval-2016 Task 4: Sentiment Classification Using an Ensemble of Convolutional Neural Networks with Distant Supervision",
    "abstract": "In this paper, we propose a classifier for predicting message-level sentiments of English micro-blog messages from Twitter. Our method builds upon the convolutional sentence embedding approach proposed by (Severyn and Moschitti, 2015a; Severyn and Moschitti, 2015b). We leverage large amounts of data with distant supervision to train an ensemble of 2-layer convolutional neural networks whose predictions are combined using a random forest classifier. Our approach was evaluated on the datasets of the SemEval-2016 competition (Task 4) outperforming all other approaches for the Message Polarity Classification task.",
    "prev": "Each training sample x consists of a sentence s and its sentiment label\u1ef9.",
    "curr": "The student for the sentiment classification task is a convolutional model which has been shown to perform best on the dataset we used (Deriu et al., 2017;Severyn & Moschitti, 2015a;b;Deriu et al., 2016).",
    "next": "The first layer of the network learns the function \u03c8(.)",
    "hard_negative": [
      9672033,
      12596803,
      14113765,
      1306065,
      1957433
    ],
    "easy_negative": [
      1890099,
      220058855,
      257353833
    ]
  },
  {
    "index": 295,
    "source_corpus_id": 257219926,
    "ref_id": "b0",
    "citation_corpus_id": 246867209,
    "start": 11467,
    "end": 11490,
    "title": "Published as a conference paper at ICLR 2022 PROSPECT PRUNING: FINDING TRAINABLE WEIGHTS AT INITIALIZATION USING META-GRADIENTS",
    "abstract": "Pruning neural networks at initialization would enable us to find sparse models that retain the accuracy of the original network while consuming fewer computational resources for training and inference. However, current methods are insufficient to enable this optimization and lead to a large degradation in model performance. In this paper, we identify a fundamental limitation in the formulation of current methods, namely that their saliency criteria look at a single step at the start of training without taking into account the trainability of the network. While pruning iteratively and gradually has been shown to improve pruning performance, explicit consideration of the training stage that will immediately follow pruning has so far been absent from the computation of the saliency criterion. To overcome the short-sightedness of existing methods, we propose Prospect Pruning (ProsPr), which uses meta-gradients through the first few steps of optimization to determine which weights to prune. ProsPr combines an estimate of the higherorder effects of pruning on the loss and the optimization trajectory to identify the trainable sub-network. Our method achieves state-of-the-art pruning performance on a variety of vision classification tasks, with less data and in a single shot compared to existing pruning-at-initialization methods. Our code is available online at https://github.com/",
    "prev": "We refer to a variant of sparsify-during-training as early pruning here, which only exerts pruning to network in the early stage of training.",
    "curr": "It includes pruning at initialization, e.g., GraSP , SynFlow (Tanaka et al., 2020), SBP-SR (Hayou et al., 2021), ProsPr (Alizadeh et al., 2022), and the conventional early pruning methods which stop pruning after several epochs of training (You et al., 2020;Liu et al., 2021b;Rachwan et al., 2022).",
    "next": "Most of these works are inspired by the discovery of Lottery Ticket Hypothesis (LTH) (Frankle & Carbin, 2019) or SNIP (Lee et al., 2019), if not both.",
    "hard_negative": [
      219708931,
      221802286,
      53388625
    ],
    "easy_negative": [
      9202726,
      524970,
      7637949
    ]
  },
  {
    "index": 297,
    "source_corpus_id": 202750230,
    "ref_id": "b35",
    "citation_corpus_id": 44131019,
    "start": 1691,
    "end": 1708,
    "title": "Scaling Neural Machine Translation",
    "abstract": "Sequence to sequence learning models still require several days to reach state of the art performance on large benchmark datasets using a single machine. This paper shows that reduced precision and large batch training can speedup training by nearly 5x on a single 8-GPU machine with careful tuning and implementation. 1 On WMT'14 English-German translation, we match the accuracy ofVaswani et al. (2017)in under 5 hours when training on 8 GPUs and we obtain a new state of the art of 29.3 BLEU after training for 85 minutes on 128 GPUs. We further improve these results to 29.8 BLEU by training on the much larger Paracrawl dataset. On the WMT'14 English-French task, we obtain a state-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs.",
    "prev": "Moreover, we show that our approach leads to small BERT-like models of higher quality compared to training from scratch or using distillation.",
    "curr": "INTRODUCTION\n\nTransformer architectures (Vaswani et al., 2017) have become the dominant architecture in natural language processing, with state-of-the-art performance across a variety of tasks, including machine translation (Vaswani et al., 2017;Ott et al., 2018), language modeling Baevski & Auli, 2018) and sentence representation (Devlin et al., 2018;.",
    "next": "Each of its layers contains millions of parameters accessed during the forward pass, making it computationally demanding in terms of memory and latency during both training and inference.",
    "hard_negative": [
      6628106,
      3297437,
      9545399,
      21850704,
      3516266,
      11212020,
      6380915,
      3725815
    ],
    "easy_negative": [
      254854448,
      6834924,
      225039786
    ]
  },
  {
    "index": 303,
    "source_corpus_id": 214002473,
    "ref_id": "b31",
    "citation_corpus_id": 76667896,
    "start": 2633,
    "end": 2650,
    "title": "UNSUPERVISED DISCOVERY OF PARTS, STRUCTURE, AND DYNAMICS",
    "abstract": "Humans easily recognize object parts and their hierarchical structure by watching how they move; they can then predict how each part moves in the future. In this paper, we propose a novel formulation that simultaneously learns a hierarchical, disentangled object representation and a dynamics model for object parts from unlabeled videos. Our Parts, Structure, and Dynamics (PSD) model learns to, first, recognize the object parts via a layered image representation; second, predict hierarchy via a structural descriptor that composes low-level concepts into a hierarchical structure; and third, model the system dynamics by predicting the future. Experiments on multiple real and synthetic datasets demonstrate that our PSD model works well on all three tasks: segmenting object parts, building their hierarchical structure, and capturing their motion distributions.",
    "prev": "INTRODUCTION\n\nSystem identification or physical parameter estimation is commonly required for control or state estimation for physical modelling, and typically relies on dedicated sensing equipment and carefully constructed experiments.",
    "curr": "Current machine learning approaches to physical modeling from video either require training by supervised regression from video to object coordinates before estimating explicit physics (Watters et al., 2017;Wu et al., 2017b;Belbute-Peres et al., 2018), or are able to discover and segment objects from video in an unsupervised manner, but do not naturally integrate with a physics engine for long-term predictions or generation of interpretable locations and physical parameters for physical reasoning (Xu et al., 2019;van Steenkiste et al., 2018).",
    "next": "In this work, we bridge the gap between unsupervised discovery of objects from video and learning the physical dynamics of a system, by learning unknown physical parameters and explicit trajectory coordinates.",
    "hard_negative": [
      6981893,
      6628106,
      205514,
      1803861,
      71638
    ],
    "easy_negative": [
      203690445,
      250390537,
      225041022
    ]
  },
  {
    "index": 305,
    "source_corpus_id": 220793552,
    "ref_id": "b6",
    "citation_corpus_id": 54101493,
    "start": 3214,
    "end": 3217,
    "title": "IMAGENET-TRAINED CNNS ARE BIASED TOWARDS TEXTURE; INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS",
    "abstract": "Convolutional Neural Networks (CNNs) are commonly thought to recognise objects by learning increasingly complex representations of object shapes. Some recent studies suggest a more important role of image textures. We here put these conflicting hypotheses to a quantitative test by evaluating CNNs and human observers on images with a texture-shape cue conflict. We show that ImageNettrained CNNs are strongly biased towards recognising textures rather than shapes, which is in stark contrast to human behavioural evidence and reveals fundamentally different classification strategies. We then demonstrate that the same standard architecture (ResNet-50) that learns a texture-based representation on ImageNet is able to learn a shape-based representation instead when trained on 'Stylized-ImageNet', a stylized version of ImageNet. This provides a much better fit for human behavioural performance in our well-controlled psychophysical lab setting (nine experiments totalling 48,560 psychophysical trials across 97 observers) and comes with a number of unexpected emergent benefits such as improved object detection performance and previously unseen robustness towards a wide range of image distortions, highlighting advantages of a shape-based representation. de Beeck. Deep neural networks as a computational model for human shape sensitivity. DiCarlo. Performance-optimized hierarchical models predict neural responses in higher visual cortex.",
    "prev": "While we are collecting datasets with millions of training samples, DNNs are still vulnerable to domain shift, small perturbations, and adversarial examples to which humans are remarkably robust [20,4].",
    "curr": "Recent research has shown that neural networks tend to use superficial features rather than global shape information for prediction even when trained on large scale datasets such as ImageNet [7].",
    "next": "These superficial features can be local textures or even patterns imperceptible to humans but detectable to the DNNs, as is the case for adversarial examples [11].",
    "hard_negative": [
      56657912,
      68222714
    ],
    "easy_negative": [
      219604274,
      253098734,
      253156390
    ]
  },
  {
    "index": 306,
    "source_corpus_id": 256105351,
    "ref_id": "b2",
    "citation_corpus_id": 67855617,
    "start": 3840,
    "end": 3857,
    "title": "ROTATE: KNOWLEDGE GRAPH EMBEDDING BY RELA- TIONAL ROTATION IN COMPLEX SPACE",
    "abstract": "We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.Published as a conference paper at ICLR 2019ModelScore FunctionSE (Bordes et al., 2011)\u2212 Wr,1h \u2212 Wr,2t h, t \u2208 R k , Wr,\u00b7 \u2208 R k\u00d7k TransE(Bordes et al., 2013)\u2212 h + r \u2212 t h, r, t \u2208 R k TransX \u2212 gr,1(h) + r \u2212 gr,2(t) h, r, t \u2208 R k DistMult(Yang et al., 2014)r, h, t h, r, t \u2208 R k ComplEx(Trouillon et al., 2016)Re( r, h, t ) h, r, t \u2208 C k HolE(Nickel et al., 2016)r, h \u2297 t h, r, t \u2208 R k ConvE(Dettmers et al., 2017)\u03c3 (vec(\u03c3([r, h]   * \u2126))W ), t h, r, t \u2208 R k RotatE \u2212 h \u2022 r \u2212 t 2 h, r, t \u2208 C k , |ri| = 1",
    "prev": "This issue is well known as the Open World Assumption (OWA) (Ji et al., 2021).",
    "curr": "Representation learning methods are employed to mitigate the incompleteness issue by learning representations from the observed KG triples and generalizing them to unseen triples (Bordes et al., 2013;Trouillon et al., 2016;Sun et al., 2018;Zhang et al., 2019;Chami et al., 2020).",
    "next": "When considering logical queries over incomplete knowledge graphs, the query answering models are required to not only predict the unseen knowledge but also execute logical operators, such as conjunction, disjunction, and negation (Ren & Leskovec, 2020;Wang et al., 2021b).",
    "hard_negative": [
      1619841,
      5378837,
      3896491,
      1671874
    ],
    "easy_negative": [
      51875405,
      16619607,
      245279384
    ]
  },
  {
    "index": 308,
    "source_corpus_id": 259075184,
    "ref_id": "b25",
    "citation_corpus_id": 245704504,
    "start": 3001,
    "end": 3020,
    "title": "SDEDIT: GUIDED IMAGE SYNTHESIS AND EDITING WITH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Guided image synthesis enables everyday users to create and edit photo-realistic images with minimum effort. The key challenge is balancing faithfulness to the user inputs (e.g., hand-drawn colored strokes) and realism of the synthesized images. Existing GAN-based methods attempt to achieve such balance using either conditional GANs or GAN inversions, which are challenging and often require additional training data or loss functions for individual applications. To address these issues, we introduce a new image synthesis and editing method, Stochastic Differential Editing (SDEdit), based on a diffusion model generative prior, which synthesizes realistic images by iteratively denoising through a stochastic differential equation (SDE). Given an input image with user guide in a form of manipulating RGB pixels, SDEdit first adds noise to the input, then subsequently denoises the resulting image through the SDE prior to increase its realism. SDEdit does not require task-specific training or inversions and can naturally achieve the balance between realism and faithfulness. SDEdit outperforms state-of-the-art GAN-based methods by up to 98.09% on realism and 91.72% on overall satisfaction scores, according to a human perception study, on multiple tasks, including stroke-based image synthesis and editing as well as image compositing.",
    "prev": " in various applications, including but not limited to object detection (Misra et al., 2021;Liu et al., 2021b;Wang et al., 2022a), segmentation (Qian et al., 2022;Tang et al., 2022;Zhao et al., 2021), and tracking (Qi et al., 2020;Zheng et al., 2021;Shan et al., 2021).",
    "curr": "Despite the significant advances in 3D point cloud processing, acquiring task-specific 3D annotations is a highly expensive and severely limited process due to the geometric complexity.The shortage of data annotations highlights the need for adapting pre-training paradigms.Instead of training the deep network from randomly initialized weights, prior work suggests that pre-training the network on a relevant but different pre-task and later fine-tuning the weights using task-specific labels often leads to superior performance.In natural language processing and 2D vision, pre-trained models are the backbones of many exciting applications, such as real-time chatbots (Touvron et al., 2023;OpenAI, 2023) and graphic designers (Meng et al., 2021;Wang et al., 2022b).However, pre-training on point clouds has yet to demonstrate a universal performance improvement.From-scratch training remains a common practice in 3D vision.",
    "next": "Initial attempts towards 3D point-cloud pre-training primarily leverage contrastive learning (Chopra et al., 2005), especially when the point clouds are collected from indoor scenes (Xie et al., 2020;Rao et al., 2021;Liu et al., 2021a;Zhang et al., 2021;Chen et al., 2022).However, the broad application of contrastive learning-based pre-training techniques is impeded by the requirement of large batch sizes and the necessity to carefully define positive and negative pairs.In contrast to natural language processing and 2D vision, pre-training on 3D point clouds presents two unique challenges.First, the data is extremely scarce, even without annotations.Public 3D datasets are orders of magnitude smaller than 2D image datasets.Second, the lack of data annotations necessitates 3D pre-training methods to adhere to t",
    "hard_negative": [
      13890001,
      227209335
    ],
    "easy_negative": [
      39065986,
      237635086,
      2051151
    ]
  },
  {
    "index": 313,
    "source_corpus_id": 252715881,
    "ref_id": "b22",
    "citation_corpus_id": 235614244,
    "start": 9912,
    "end": 9916,
    "title": "IS ATTENTION BETTER THAN MATRIX DECOMPOSITION?",
    "abstract": "As an essential ingredient of modern deep learning, attention mechanism, especially self-attention, plays a vital role in the global correlation discovery. However, is hand-crafted attention irreplaceable when modeling the global context? Our intriguing finding is that self-attention is not better than the matrix decomposition (MD) model developed 20 years ago regarding the performance and computational cost for encoding the long-distance dependencies. We model the global context issue as a low-rank recovery problem and show that its optimization algorithms can help design global information blocks. This paper then proposes a series of Hamburgers, in which we employ the optimization algorithms for solving MDs to factorize the input representations into sub-matrices and reconstruct a low-rank embedding. Hamburgers with different MDs can perform favorably against the popular global context module self-attention when carefully coping with gradients back-propagated through MDs. Comprehensive experiments are conducted in the vision tasks where it is crucial to learn the global context, including semantic segmentation and image generation, demonstrating significant improvements over self-attention and its variants. Code is available.",
    "prev": "In terms of training implicit models, [25] also proposed a novel gradient estimate called phantom gradient which relies on fixed-point unrolling and a Neumann series to provide a new update direction; computation of precise gradient is forgone.",
    "curr": "Implicit models have also been extended to more complex learning frameworks, such as attention mechanisms [24] and Graph Neural Networks [30].",
    "next": "Preliminary: Differentiable optimization layers\n\nWe consider a parameterized convex optimization problems with polyhedral constraints:\nmin x f (x; \u03b8) s.t.",
    "hard_negative": [
      6628106,
      182953113,
      8495258,
      202888986,
      3366315,
      3566136,
      1998416,
      202889315,
      3633127,
      222125298,
      52889459,
      11212020,
      199552244,
      67855860
    ],
    "easy_negative": [
      5294010,
      225041226,
      8849620
    ]
  },
  {
    "index": 314,
    "source_corpus_id": 52894384,
    "ref_id": "b5",
    "citation_corpus_id": 17263016,
    "start": 4997,
    "end": 5017,
    "title": "Low Resource Dependency Parsing: Cross-lingual Parameter Sharing in a Neural Network Parser",
    "abstract": "Training a high-accuracy dependency parser requires a large treebank. However, these are costly and time-consuming to build. We propose a learning method that needs less data, based on the observation that there are underlying shared structures across languages. We exploit cues from a different source language in order to guide the learning process. Our model saves at least half of the annotation effort to reach the same accuracy compared with using the purely supervised method.",
    "prev": "RELATED WORK\n\nMulti-task learning.",
    "curr": "The dominant approach to multi-task learning is to have a model that shares parameters in a soft (Duong et al., 2015;Yang & Hospedales, 2017) or hard way (Caruana, 1993).",
    "next": "Soft sharing refers to each task having independent weights that are constrained to be similar (e.g.",
    "hard_negative": [
      10674977,
      1114215,
      5851561,
      2037646,
      3075215,
      12926517,
      38407095,
      11616343,
      6698104
    ],
    "easy_negative": [
      7122898,
      921822,
      7811669
    ]
  },
  {
    "index": 317,
    "source_corpus_id": 257631995,
    "ref_id": "b22",
    "citation_corpus_id": 3687922,
    "start": 2887,
    "end": 2909,
    "title": "SEMI-PARAMETRIC TOPOLOGICAL MEMORY FOR NAVIGATION",
    "abstract": "We introduce a new memory architecture for navigation in previously unseen environments, inspired by landmark-based navigation in animals. The proposed semiparametric topological memory (SPTM) consists of a (non-parametric) graph with nodes corresponding to locations in the environment and a (parametric) deep network capable of retrieving nodes from the graph based on observations. The graph stores no metric information, only connectivity of locations corresponding to the nodes. We use SPTM as a planning module in a navigation system. Given only 5 minutes of footage of a previously unseen maze, an SPTM-based navigation agent can build a topological map of the environment and use it to confidently navigate towards goals. The average success rate of the SPTM agent in goal-directed navigation across test environments is higher than the best-performing baseline by a factor of three.",
    "prev": "This implies that a goal-conditioned policy is replaceable by a policy conditioned on a \"subgoal\" existing between the goal and the agent.",
    "curr": "Based on this insight, researchers have investigated graph-based planning to construct a goal-reaching path by (a) proposing a series of subgoals and (b) executing policies conditioned on the nearest subgoal (Savinov et al., 2018;Eysenbach et al., 2019;Huang et al., 2019).",
    "next": "Since the nearby subgoals are easier to reach than the faraway goal, such planning improves the success ratio of the agent reaching the target-goal during sample collection.",
    "hard_negative": [
      6628106,
      534043,
      13298214,
      16134629
    ],
    "easy_negative": [
      207847868,
      220445954,
      209442672
    ]
  },
  {
    "index": 320,
    "source_corpus_id": 67856680,
    "ref_id": "b1",
    "citation_corpus_id": 2129889,
    "start": 1851,
    "end": 1874,
    "title": "Learning End-to-End Goal-Oriented Dialog",
    "abstract": "End-to-end dialog systems, in which all components are learnt simultaneously, have recently obtained encouraging successes. However these were mostly on conversations related to chit-chat with no clear objective and for which evaluation is difficult. This paper proposes a set of tasks to test the capabilities of such systems on goal-oriented dialogs, where goal completion ensures a well-defined measure of performance. Built in the context of restaurant reservation, our tasks require to manipulate sentences and symbols, in order to properly conduct conversations, issue API calls and use the outputs of such calls. We show that an end-to-end dialog system based on Memory Networks can reach promising, yet imperfect, performance and learn to perform non-trivial operations. We confirm those results by comparing our system to a hand-crafted slot-filling baseline on data from the second Dialog State Tracking Challenge(Henderson et al., 2014a).Currently, the most useful applications of dialog systems are goal-oriented and transactional: the system is expected to understand a user request and complete a related task with a clear goal within",
    "prev": "Based on our results, we argue that AQM+ is a general task-oriented dialog algorithm that can be applied for non-yes-or-no responses.",
    "curr": "INTRODUCTION\n\nRecent advances in deep learning have led an end-to-end neural approach to task-oriented dialog problems that can reduce a laborious labeling task on states and intents (Bordes & Weston, 2017).",
    "next": "Many researchers have applied sequence-to-sequence models (Vinyals & Le, 2015) that are trained in a supervised learning (SL) and a reinforcement learning (RL) fashion to generate an appropriate sentence for the task.",
    "hard_negative": [
      2239496,
      1294169,
      780171,
      8109232,
      8004345,
      244187
    ],
    "easy_negative": [
      10605496,
      7668349,
      248780524
    ]
  },
  {
    "index": 331,
    "source_corpus_id": 204734215,
    "ref_id": "b4",
    "citation_corpus_id": 52889459,
    "start": 20843,
    "end": 20862,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "(2019) attempt to solve the undesirable convergence issue of GDA by exploiting curvature information, but they focus on simultaneous game on finding local Nash and it is unclear how to extend their algorithm to sequential games.",
    "curr": "For GAN training, there is a rich literature on different strategies to make the GAN-game welldefined, e.g., by adding instance noise (Salimans et al., 2016), by using different objectives (Nowozin et al., 2016;Gulrajani et al., 2017;Mao et al., 2017) or by tweaking the architectures (Radford et al., 2015;Brock et al., 2019).",
    "next": "While these strategies try to make the overall optimization problem easily, our work deals with a specific optimization problem and convergence issues arise in theory and in practice; hence our algorithm is orthogonal to these work.",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      67855733,
      32731852,
      8895303
    ]
  },
  {
    "index": 334,
    "source_corpus_id": 234790212,
    "ref_id": "b26",
    "citation_corpus_id": 1957433,
    "start": 25519,
    "end": 25544,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "Scene Prior (SP) (Yang et al., 2018) learns a graph neural network from the FastText database (Joulin et al., 2016) and leverages the scene prior knowledge and category relationships for navigation.",
    "curr": "Word Embedding (WE) uses GloVe embedding (Pennington et al., 2014) to indicate the target category rather than detection.",
    "next": "The association between object appearances and GloVe embeddings is learned through trail and error.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      224704618,
      261345019,
      250390867
    ]
  },
  {
    "index": 336,
    "source_corpus_id": 247518687,
    "ref_id": "b3",
    "citation_corpus_id": 231592851,
    "start": 3189,
    "end": 3215,
    "title": "Published as a conference paper at ICLR 2021 ESTIMATING AND EVALUATING REGRESSION PREDIC- TIVE UNCERTAINTY IN DEEP OBJECT DETECTORS",
    "abstract": "Predictive uncertainty estimation is an essential next step for the reliable deployment of deep object detectors in safety-critical tasks. In this work, we focus on estimating predictive distributions for bounding box regression output with variance networks. We show that in the context of object detection, training variance networks with negative log likelihood (NLL) can lead to high entropy predictive distributions regardless of the correctness of the output mean. We propose to use the energy score as a non-local proper scoring rule and find that when used for training, the energy score leads to better calibrated and lower entropy predictive distributions than NLL. We also address the widespread use of non-proper scoring metrics for evaluating predictive distributions from deep object detectors by proposing an alternate evaluation approach founded on proper scoring rules. Using the proposed evaluation tools, we show that although variance networks can be used to produce high quality predictive distributions, adhoc approaches used by seminal object detectors for choosing regression targets during training do not provide wide enough data support for reliable variance learning. We hope that our work helps shift evaluation in probabilistic object detection to better align with predictive uncertainty evaluation in other machine learning domains. Code for all models, evaluation, and datasets is available at: https://github.com/asharakeh/probdet.git. distance-sensitive proper scoring rule based on energy statistics(Sz\u00e9kely & Rizzo, 2013), as an alternative for training variance networks. We show that predictive distributions learnt with the energy score are lower entropy, better calibrated, and of higher quality when evaluated using proper scoring rules.Pitfalls of EvaluationWe address the widespread use of non-proper scoring rules for evaluating probabilistic object detectors by providing evaluation tools based on well established proper scoring rules(Gneiting & Raftery, 2007)that are only minimized if the estimated predictive distribution is equal to the true target distribution, for both classification and regression. Using the proposed tools, we benchmark probabilistic extensions of three common object detection architectures on in-distribution, shifted, and out-of-distribution data. Our results show that variance networks can differentiate between in-distribution, shifted, and out-of-distribution data using their predictive entropy. We find that ad-hoc approaches used by seminal object detectors for choosing their regression targets during training do not provide a wide enough data support for reliable learning in variance networks. Finally, we provide clear recommendations in Sec. 5 to avoid the pitfalls described above.",
    "prev": "On the other hand, quantifying aleatoric uncertainty enables learning of dynamics models of stochastic processes (e.g.",
    "curr": "for model-based or offline reinforcement learning) (Chua et al., 2018;Yu et al., 2020), improves performance in semantic segmentation, depth regression and object detection (Kendall & Gal, 2017;Harakeh & Waslander, 2021), and allows for risk-sensitive decision making (Dabney et al., 2018;Vlastelica et al., 2021).",
    "next": "We examine a common approach for quantifying aleatoric uncertainty in neural network regression.",
    "hard_negative": [
      209314627,
      56657912
    ],
    "easy_negative": [
      256461051,
      225039884,
      247222761
    ]
  },
  {
    "index": 339,
    "source_corpus_id": 5034059,
    "ref_id": "b27",
    "citation_corpus_id": 3626819,
    "start": 3984,
    "end": 4005,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "We find that unified multi-task trained models slightly outperform comparable models trained on each task separately.",
    "curr": "Our best multitask model makes use of ELMo (Peters et al., 2018), a recently proposed pre-training technique.",
    "next": "However, this model still achieves a fairly low absolute score, indicating room for improved general NLU systems.",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      8535316,
      11336213,
      9917468,
      20472740,
      34032948,
      10489017,
      1222212,
      12688069,
      15026764,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      638874,
      18619139,
      174800499
    ]
  },
  {
    "index": 343,
    "source_corpus_id": 257365037,
    "ref_id": "b21",
    "citation_corpus_id": 3366315,
    "start": 3577,
    "end": 3598,
    "title": "Published as a conference paper at ICLR 2018 SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.Published as a conference paper at ICLR 2018\u2022 Lipschitz constant is the only hyper-parameter to be tuned, and the algorithm does not require intensive tuning of the only hyper-parameter for satisfactory performance. \u2022 Implementation is simple and the additional computational cost is small.",
    "prev": " in our original ICLR paper are not accurate.We elaborate on the issue and provides some fix in Appendix D.\n\nINTRODUCTION\n\nThe robustness of deep neural networks is nowadays a great challenge to establish confidence in their decisions for real-life applications.Addressing this challenge requires guarantees on the stability of the prediction, with respect to adversarial attacks.In this context, the Lipschitz constant of neural networks is a key property at the core of many recent advances.Along with the margin of the classifier, this property allows us to certify the robustness against worst-case adversarial perturbations.This certification is based on a sphere of stability within which the decision remains the same for any perturbation inside the sphere (Tsuzuku et al., 2018).",
    "curr": "The design of 1-Lipschitz layers provides a successful approach to enforce this property for the whole neural network.For this purpose, many different techniques have been devised such as spectral normalization (Miyato et al., 2018;Farnia et al., 2019), orthogonal parameterization (Trockman et al., 2021;Li et al., 2019;Singla et al., 2021;Yu et al., 2022;Xu et al., 2022), Convex Potential Layers (CPL) (Meunier et al., 2022), and Almost-Orthogonal-Layers (AOL) (Prach et al., 2022).While all these techniques share the same goal, their motivations, and derivations can greatly differ, delivering different solutions.Nevertheless, their raw experimental comparison fails to really gain insight into their peculiar performance, soundness, and in the end their possible complementarity.Therefore a question acts as a barrier for an in-depth analysis and future development:\n\nAre there common principles underlying the developments of 1-Lipschitz Layers?",
    "next": "In this paper, we propose a novel perspective to answer this question based on a unified Semidefinite Programming (SDP) approach.We introduce a common algebraic condition underlying various types of methods like spectral normalization, orthogonality-based methods, AOL, and CPL",
    "hard_negative": [
      5687613,
      18828233,
      3633127,
      14570343,
      11758569
    ],
    "easy_negative": [
      184483500,
      9918276,
      226283741
    ]
  },
  {
    "index": 347,
    "source_corpus_id": 247618912,
    "ref_id": "b13",
    "citation_corpus_id": 3633127,
    "start": 67142,
    "end": 67164,
    "title": "Published as a conference paper at ICLR 2018 CGANS WITH PROJECTION DISCRIMINATOR",
    "abstract": "We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. This approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. With this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (Im-ageNet) 1000-class image dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. We were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. This new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_projection.",
    "prev": "A potential downside to modeling latent factors in generative models is a decrease in image quality of generated samples that has been noted when disentanglement terms are added(Burgess et al., 2018; Khrulkov et al., 2021).",
    "curr": "Prior work has studied how to integrate additional information into GAN training, in particular ground truth class labels(Mirza & Osindero, 2014;Salimans et al., 2016;Odena, 2016;Odena et al., 2017;  Brock et al., 2019;Thekumparampil et al., 2018;Miyato & Koyama, 2018; Lu\u010di\u0107 et al., 2019), also considering noisy scenarios(Kaneko et al., 2019).",
    "next": "However, in the programmatic weak supervision setting, having multiple noisy sources of imperfect labels that include abstains present large hurdles to similar conditional modeling.",
    "hard_negative": [
      3366315,
      5687613,
      6104263,
      11758569
    ],
    "easy_negative": [
      238407713,
      226283732,
      221516387
    ]
  },
  {
    "index": 348,
    "source_corpus_id": 238857286,
    "ref_id": "b25",
    "citation_corpus_id": 14124313,
    "start": 13094,
    "end": 13122,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "The pixel-wise loss L pixel combines 1 and 2 distance as:\nL pixel (p,p) = \u03bb 1 1 (p,p) + \u03bb 2 2 (p,p),(9)\nwhere \u03bb 1 and \u03bb 2 are two hyper-parameters to control the relative importance.",
    "curr": "For the perceptual loss L perceptual , we extract features from conv5 in a VGG-16 network (Simonyan & Zisserman, 2015) pretrained on ImageNet (Krizhevsky et al., 2012) and combine the 1 and 2 distance as:\nL perceptual (p,p) = \u03bb 3 1 (\u03c6(p), \u03c6(p)) + \u03bb 4 2 (\u03c6(p), \u03c6(p)),(10)\nwhere \u03c6(\u00b7) represents the output of conv5 in the VGG-16 network, and \u03bb 3 and \u03bb 4 are two hyperparameters.",
    "next": "Compared to the pixel-wise loss, the perceptual loss is better to capture the region-wise structure, which reflects the waveform coherence.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      224803224,
      252438755,
      6460734
    ]
  },
  {
    "index": 349,
    "source_corpus_id": 259287063,
    "ref_id": "b46",
    "citation_corpus_id": 213729382,
    "start": 2381,
    "end": 2398,
    "title": "Published as a conference paper at ICLR 2020 DYNAMIC MODEL PRUNING WITH FEEDBACK",
    "abstract": "Deep neural networks often have millions of parameters. This can hinder their deployment to low-end devices, not only due to high memory requirements but also because of increased latency at inference. We propose a novel model compression method that generates a sparse trained model without additional overhead: by allowing (i) dynamic allocation of the sparsity pattern and (ii) incorporating feedback signal to reactivate prematurely pruned weights we obtain a performant sparse model in one single training pass (retraining is not needed, but can further improve the performance). We evaluate our method on CIFAR-10 and ImageNet, and show that the obtained sparse models can reach the state-of-the-art performance of dense models. Moreover, their performance surpasses that of models generated by all previously proposed pruning schemes. arXiv:2006.07253v1 [cs.LG] 12 Jun 2020 2 RELATED WORK Previous works on obtaining pruned networks can (loosely) be divided into three main categories.Pruning after training. Training approaches to obtain sparse networks usually include a three stage pipeline-training of a dense model, one-shot pruning and fine-tuning-e.g., (Han et al.",
    "prev": "weight decay yields models suitable for averaging, sharing identical sparse connectivity by design.Averaging these models significantly enhances generalization and OOD performance over their individual counterparts.Building on this, we introduce SPARSE MODEL SOUPS (SMS), a novel method for merging sparse models by initiating each prune-retrain cycle with the averaged model from the previous phase.SMS preserves sparsity, exploits sparse network benefits, is modular and fully parallelizable, and substantially improves IMP's performance.We further demonstrate that SMS can be adapted to enhance state-of-the-art pruning-during-training approaches.",
    "curr": "INTRODUCTION\n\nState-of-the-art Neural Network architectures typically rely on extensive over-parameterization with millions or billions of parameters (Zhang et al., 2016).In consequence, these models have significant memory requirements and the training and inference process is computationally demanding.However, recent work (e.g.Han et al., 2015;Lin et al., 2020;Renda et al., 2020;Zimmer et al., 2022) has demonstrated that these resource demands can be significantly reduced by pruning the model, i.e., removing redundant structures such as individual parameters or groups thereof.The resulting sparse models demand considerably less storage and floating-point operations (FLOPs) during inference, while retaining performance comparable to dense models.",
    "next": "A different line of research has shown that the performance of a predictor can be significantly enhanced by leveraging multiple models, instead of selecting the best one on a hold-out validation dataset and discarding the rest.Such ensembles combine the predictions of m \u2208 N individually trained models by averaging their output predictions (Ganaie et al., 2021;Mehrtash et al., 2020;Chandak et al., 2023;Fort et al., 2019).Prediction ensembles have been shown to improve the predictive performance and positively impact predictive uncertainty metrics such as calibration, out-of-distribution generalizatio",
    "hard_negative": [
      53466896,
      14124313,
      3635880,
      10135357,
      2835189
    ],
    "easy_negative": [
      9709731,
      209064083,
      225066797
    ]
  },
  {
    "index": 350,
    "source_corpus_id": 249097923,
    "ref_id": "b16",
    "citation_corpus_id": 3526769,
    "start": 6705,
    "end": 6724,
    "title": "MITIGATING ADVERSARIAL EFFECTS THROUGH RAN- DOMIZATION",
    "abstract": "Convolutional neural networks have demonstrated their powerful ability on various tasks in recent years. However, they are extremely vulnerable to adversarial examples. I.e., clean images, with imperceptible perturbations added, can easily cause convolutional neural networks to fail. In this paper, we propose to utilize randomization to mitigate adversarial effects. Specifically, we use two randomization operations: random resizing, which resizes the input images to a random size, and random padding, which pads zeros around the input images in a random manner. Extensive experiments demonstrate that the proposed randomization method is very effective at defending against both single-step and iterative attacks. Our method also enjoys the following advantages: 1) no additional training or fine-tuning, 2) very few additional computations, 3) compatible with other adversarial defense methods. By combining the proposed randomization method with an adversarially trained model, it achieves a normalized score of 0.924 (ranked No.2 among 107 defense teams) in the NIPS 2017 adversarial examples defense challenge, which is far better than using adversarial training alone with a normalized score of 0.773 (ranked No.56). The code is public available at https: /. R-fcn: Object detection via region-based fully convolutional networks.",
    "prev": "In addition to the attention terms, AoA and ATA also include the typical attack losses, e.g., logit output in their objective functions, and use a hyperparameter to balance the two terms.",
    "curr": "Adversarial Perturbations (TAP) (Zhou et al., 2018), Activation attack (AA) (Inkawhich et al., 2019) and Intermediate Level Attack (ILA) (Huang et al., 2019), which all directly maximize the distance between feature maps of benign images and adversarial examples, also belong to this category.",
    "next": "TAP and AA generate adversarial examples by employing multi-layer and single-layer feature maps respectively.",
    "hard_negative": [
      7071211,
      17707860,
      14124313,
      9059612
    ],
    "easy_negative": [
      259833801,
      102352060,
      67855269
    ]
  },
  {
    "index": 355,
    "source_corpus_id": 3525232,
    "ref_id": "b13",
    "citation_corpus_id": 12639289,
    "start": 2536,
    "end": 2566,
    "title": "Recurrent Continuous Translation Models",
    "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
    "prev": "Neural network architectures lie at the heart of a variety of applications.",
    "curr": "They are practically ubiquitous across vision tasks (LeCun et al., 1995;Krizhevsky et al., 2012;Simonyan & Zisserman, 2014) and natural language understanding, from machine translation (Kalchbrenner & Blunsom, 2013;Sutskever et al., 2014;Bahdanau et al., 2014) to textual entailment (Bowman et al., 2015;Rockt\u00e4schel et al., 2015) via sentiment analysis (Socher et al., 2013;Kalchbrenner et al., 2014) and reading comprehension Hill et al., 2015;Rajpurkar et al., 2016).",
    "next": "They have been used to synthesise programs (Ling et al., 2016;Parisotto et al., 2016;Devlin et al., 2017) or internalise algorithms (Graves et al., 2016;Joulin & Mikolov, 2015;Kaiser & Sutskever, 2015;Reed & De Freitas, 2015).",
    "hard_negative": [
      1274371,
      10691183,
      16391184,
      8476273,
      8608051
    ],
    "easy_negative": [
      218977355,
      236486161,
      3555598
    ]
  },
  {
    "index": 360,
    "source_corpus_id": 232478335,
    "ref_id": "b28",
    "citation_corpus_id": 67856276,
    "start": 1815,
    "end": 1832,
    "title": "MULTILINGUAL NEURAL MACHINE TRANSLATION WITH KNOWLEDGE DISTILLATION",
    "abstract": "Multilingual machine translation, which translates multiple languages with a single model, has attracted much attention due to its efficiency of offline training and online serving. However, traditional multilingual translation usually yields inferior accuracy compared with the counterpart using individual models for each language pair, due to language diversity and model capacity limitations. In this paper, we propose a distillation-based approach to boost the accuracy of multilingual machine translation. Specifically, individual models are first trained and regarded as teachers, and then the multilingual model is trained to fit the training data and match the outputs of individual models simultaneously through knowledge distillation. Experiments on IWSLT, WMT and Ted talk translation datasets demonstrate the effectiveness of our method. Particularly, we show that one model is enough to handle multiple languages (up to 44 languages in our experiment), with comparable or even better accuracy than individual models. * Authors contribute equally to this work.",
    "prev": "Finally, we broadly discuss several circumstances wherein label smoothing will indeed lose its effectiveness.",
    "curr": "INTRODUCTION\n\nLabel smoothing (Szegedy et al., 2016) and knowledge distillation (Hinton et al., 2015) are two commonly recognized techniques in training deep neural networks and have been applied in many state-of-the-art models, such as language translation (Vaswani et al., 2017;Tan et al., 2019;Zhou et al., 2020), image classification  and speech recognition (Chiu et al., 2018;Pereyra et al., 2017;Chorowski & Jaitly, 2017).",
    "next": "Recently a large body of studies is focusing on exploring the underlying relationships between these two methods, for instance, M\u00fcller et al.",
    "hard_negative": [
      8451212,
      3295641,
      49195318,
      44172616,
      52155342,
      1998416,
      6359641,
      6053988,
      3666937
    ],
    "easy_negative": [
      227068662,
      231855774,
      219301634
    ]
  },
  {
    "index": 365,
    "source_corpus_id": 256390058,
    "ref_id": "b10",
    "citation_corpus_id": 3484654,
    "start": 21628,
    "end": 21647,
    "title": "RECASTING GRADIENT-BASED META-LEARNING AS HIERARCHICAL BAYES",
    "abstract": "Meta-learning allows an intelligent agent to leverage prior learning episodes as a basis for quickly improving performance on a novel task. Bayesian hierarchical modeling provides a theoretical framework for formalizing meta-learning as inference for a set of parameters that are shared across tasks. Here, we reformulate the model-agnostic meta-learning algorithm (MAML) of Finn et al.(2017)as a method for probabilistic inference in a hierarchical Bayesian model. In contrast to prior methods for meta-learning via hierarchical Bayes, MAML is naturally applicable to complex function approximators through its use of a scalable gradient descent procedure for posterior inference. Furthermore, the identification of MAML as hierarchical Bayes provides a way to understand the algorithm's operation as a meta-learning procedure, as well as an opportunity to make use of computational strategies for efficient inference. We use this opportunity to propose an improvement to the MAML algorithm that makes use of techniques from approximate inference and curvature estimation.",
    "prev": "Meta learning is a learning framework that aims to adapt or generalize well on new tasks.",
    "curr": "There are three approaches in meta learning: metric-based (Koch et al., 2015;Vinyals et al., 2016;Sung et al., 2018;Snell et al., 2017), model-based (Santoro et al., 2016Munkhdalai & Yu, 2017;Grant et al., 2018) and optimization-based (Finn et al., 2017;Nichol et al., 2018).",
    "next": "Neural processes (NPs) is the model-based meta learning with stochasticity.",
    "hard_negative": [
      4994434,
      15085443,
      6628106
    ],
    "easy_negative": [
      44135464,
      9328025,
      17798294
    ]
  },
  {
    "index": 366,
    "source_corpus_id": 67856276,
    "ref_id": "b26",
    "citation_corpus_id": 1998416,
    "start": 1685,
    "end": 1705,
    "title": "Effective Approaches to Attention-based Neural Machine Translation",
    "abstract": "An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. 1",
    "prev": "* Authors contribute equally to this work.",
    "curr": "INTRODUCTION\n\nNeural Machine Translation (NMT) has witnessed rapid development in recent years (Bahdanau et al., 2015;Luong et al., 2015b;Wu et al., 2016;Gehring et al., 2017;Vaswani et al., 2017;Guo et al., 2018;Shen et al., 2018), including advanced model structures (Gehring et al., 2017;Vaswani et al., 2017; and human parity achievements .",
    "next": "While conventional NMT can well handle single pair translation, training a separate model for each language pair is resource consuming, considering there are thousands of languages in the world 1 .",
    "hard_negative": [
      9709731,
      2863491,
      5590763,
      8884845,
      11212020,
      1245593,
      12639289
    ],
    "easy_negative": [
      225066692,
      252564353,
      21730259
    ]
  },
  {
    "index": 367,
    "source_corpus_id": 235293986,
    "ref_id": "b8",
    "citation_corpus_id": 56657912,
    "start": 26709,
    "end": 26739,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "Response to gradual domain shift.",
    "curr": "In order to assess how well models can cope with a gradual transition from their native domain, we evaluate their ECE performance on data perturbed by 19 types of corruption (Hendrycks & Dietterich, 2019) at five different severity levels.",
    "next": "Figure 3 depicts the performance of models averaged across all corruptions.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      41859858,
      258378287,
      4094265
    ]
  },
  {
    "index": 373,
    "source_corpus_id": 54101493,
    "ref_id": "b1",
    "citation_corpus_id": 68222714,
    "start": 5709,
    "end": 5732,
    "title": "APPROXIMATING CNNS WITH BAG-OF-LOCAL- FEATURES MODELS WORKS SURPRISINGLY WELL ON IMAGENET",
    "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 33 \u00d7 33 px features and Alexnet performance for 17 \u00d7 17 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.",
    "prev": "On the other hand, some rather disconnected findings point to an important role of object textures for CNN object recognition.",
    "curr": "CNNs can still classify texturised images perfectly well, even if the global shape structure is completely destroyed Brendel & Bethge, 2019).",
    "next": "Conversely, standard CNNs are bad at recognising object sketches where object shapes are preserved yet all texture cues are missing (Ballester & de Ara\u00fajo, 2016).",
    "hard_negative": [
      2103669,
      32654687
    ],
    "easy_negative": [
      48364557,
      6807655,
      18981789
    ]
  },
  {
    "index": 381,
    "source_corpus_id": 225067567,
    "ref_id": "b23",
    "citation_corpus_id": 40100965,
    "start": 2198,
    "end": 2220,
    "title": "Universal Language Model Fine-tuning for Text Classification",
    "abstract": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\u00d7 more data. We opensource our pretrained models and code 1 .",
    "prev": "2  We focus on encoder-only models, and do not consider encoder-decoder models like T5 (Raffel et al.,  2020)  where none of the embedding matrices are discarded after pre-training.",
    "curr": "Output embeddings may also be\n\nINTRODUCTION\n\nThe performance of models in natural language processing (NLP) has dramatically improved in recent years, mainly driven by advances in transfer learning from large amounts of unlabeled data (Howard & Ruder, 2018;Devlin et al., 2019).",
    "next": "The most successful paradigm consists of pre-training a large Transformer (Vaswani et al., 2017) model with a self-supervised loss and fine-tuning it on data of a downstream task (Ruder et al., 2019).",
    "hard_negative": [
      16299141,
      28971531,
      16386838,
      7928230,
      7942973,
      3626819,
      10728540,
      1428702,
      14337532,
      4460159
    ],
    "easy_negative": [
      210722384,
      6225233,
      64901898
    ]
  },
  {
    "index": 383,
    "source_corpus_id": 259108558,
    "ref_id": "b35",
    "citation_corpus_id": 174802916,
    "start": 2625,
    "end": 2629,
    "title": "Published as a conference paper at ICLR 2020 SCALING AUTOREGRESSIVE VIDEO MODELS",
    "abstract": "Due to the statistical complexity of video, the high degree of inherent stochasticity, and the sheer amount of data, generating natural video remains a challenging task. State-of-the-art video generation models often attempt to address these issues by combining sometimes complex, usually video-specific neural network architectures, latent variable models, adversarial training and a range of other methods. Despite their often high complexity, these approaches still fall short of generating high quality video continuations outside of narrow domains and often struggle with fidelity. In contrast, we show that conceptually simple autoregressive video generation models based on a three-dimensional self-attention mechanism achieve competitive results across multiple metrics on popular benchmark datasets, for which they produce continuations of high fidelity and realism. We also present results from training our models on Kinetics, a large scale action recognition dataset comprised of YouTube videos exhibiting phenomena such as camera movement, complex object interactions and diverse human movement. While modeling these phenomena consistently remains elusive, we hope that our results, which include occasional realistic continuations encourage further research on comparatively complex, large scale datasets such as Kinetics.Published as a conference paper at ICLR 2020We obtain strong results on popular benchmarks (Section 4.2, Appendix A) and produce high fidelity video continuations on the BAIR robot pushing dataset(Ebert et al., 2017)exhibiting plausible object interactions. Furthermore, our model achieves an almost 50% reduction in perplexity compared to prior work on autoregressive models on another robot pushing dataset.Finally, we apply our models to down-sampled videos from the Kinetics-600 dataset(Section 4.3). While modeling the full range of Kinetics-600 videos still poses a major challenge, we see encouraging video continuations for a more limited subset, namely cooking videos. These feature camera movement, complex object interactions and still cover diverse subjects.We hope that these initial results will encourage future video generation work to evaluate models on more challenging datasets such as Kinetics.",
    "prev": "These include generating the same token or series of token repeatedly, or generating gibberish outputs.",
    "curr": "This phenomenon of degeneration for longer continuations has also been observed in autoregressive models for video [36].",
    "next": "This problem of neural text degeneration has been linked to the training objective for LLMs, which trains a conditional distribution for the next token given a (partial) sentence [10].",
    "hard_negative": [
      8495258,
      54458552,
      52892477,
      205514
    ],
    "easy_negative": [
      8852106,
      193799747,
      17535854
    ]
  },
  {
    "index": 387,
    "source_corpus_id": 249538510,
    "ref_id": "b2",
    "citation_corpus_id": 202749904,
    "start": 5114,
    "end": 5137,
    "title": "HIGH FIDELITY SPEECH SYNTHESIS WITH ADVERSARIAL NETWORKS",
    "abstract": "Generative adversarial networks have seen rapid development in recent years and have led to remarkable improvements in generative modelling of images. However, their application in the audio domain has received limited attention, and autoregressive models, such as WaveNet, remain the state of the art in generative modelling of audio signals such as human speech. To address this paucity, we introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech. Our architecture is composed of a conditional feed-forward generator producing raw speech audio, and an ensemble of discriminators which operate on random windows of different sizes. The discriminators analyse the audio both in terms of general realism, as well as how well the audio corresponds to the utterance that should be pronounced. To measure the performance of GAN-TTS, we employ both subjective human evaluation (MOS -Mean Opinion Score), as well as novel quantitative metrics (Fr\u00e9chet DeepSpeech Distance and Kernel DeepSpeech Distance), which we find to be well correlated with MOS. We show that GAN-TTS is capable of generating high-fidelity speech with naturalness comparable to the state-of-the-art models, and unlike autoregressive models, it is highly parallelisable thanks to an efficient feed-forward generator. Listen to GAN-TTS reading this abstract at https://storage.googleapis.com/ deepmind-media/research/abstract.wav.",
    "prev": "INTRODUCTION\n\nDeep generative models have demonstrated noticeable successes for modeling raw audio.",
    "curr": "The successful methods include, autoregressive models (van den Oord et al., 2016;Mehri et al., 2017;Kalchbrenner et al., 2018), flow-based models (van den Oord et al., 2018;Ping et al., 2019;Prenger et al., 2019;Kim et al., 2019;Ping et al., 2020;Lee et al., 2020), GAN-based models Kumar et al., 2019;Bi\u0144kowski et al., 2020;Yamamoto et al., 2020;Kong et al., 2020), and diffusion models (Kong et al., 2021;Chen et al., 2021;Lee et al., 2022).",
    "next": "Among these methods, GAN-based vocoders (e.g., Kong et al., 2020) can generate high-fidelity raw audio conditioned on mel spectrogram, while synthesizing hundreds of times faster than real-time on a single GPU.",
    "hard_negative": [
      49882757,
      17272965,
      6628106,
      17127188,
      26100519,
      3366315,
      5687613,
      6104263,
      3568073,
      13890001,
      67856213,
      84591
    ],
    "easy_negative": [
      249674893,
      227230647,
      235359141
    ]
  },
  {
    "index": 392,
    "source_corpus_id": 252716080,
    "ref_id": "b9",
    "citation_corpus_id": 56895453,
    "start": 1430,
    "end": 1449,
    "title": "LEARNING WHEN TO COMMUNICATE AT SCALE IN MULTIAGENT COOPERATIVE AND COMPETITIVE TASKS",
    "abstract": "Learning when to communicate and doing that effectively is essential in multi-agent tasks. Recent works show that continuous communication allows efficient training with back-propagation in multiagent scenarios, but have been restricted to fullycooperative tasks. In this paper, we present Individualized Controlled Continuous Communication Model (IC3Net) which has better training efficiency than simple continuous communication model, and can be applied to semi-cooperative and competitive settings along with the cooperative settings. IC3Net controls continuous communication with a gating mechanism and uses individualized rewards for each agent to gain better performance and scalability while fixing credit assignment issues. Using variety of tasks including StarCraft BroodWars TM explore and combat scenarios, we show that our network yields improved performance and convergence rates than the baselines as the scale increases. Our results convey that IC3Net agents learn when to communicate based on the scenario and profitability.Published as a conference paper at ICLR 2019Teaching agents how to communicate makes it is unnecessary to hand code the communication protocol with expert knowledge(Sukhbaatar et al., 2016)(Kottur et al., 2017. While the content of communication is important, it is also important to know when to communicate either to increase scalability and performance or to increase competitive edge. For example, a prey needs to learn when to communicate to avoid communicating its location with predators.Sukhbaatar et al. (2016)showed that agents communicating through a continuous vector are easier to train and have a higher information throughput than communication based on discrete symbols. Their continuous communication is differentiable, so it can be trained efficiently with back-propagation. However, their model assumes full-cooperation between agents and uses average global rewards. This restricts the model from being used in mixed or competitive scenarios as full-cooperation involves sharing hidden states to everyone; exposing everything and leading to poor performance by all agents as shown by our results. Furthermore, the average global reward for all agents makes the credit assignment problem even harder and difficult to scale as agents don't know their individual contributions in mixed or competitive scenarios where they want themselves to succeed before others.To solve above mentioned issues, we make the following contributions:",
    "prev": "Self-play (Samuel, 1967;Tesauro, 1995) has not only demonstrated the ability to abstract highdimensional state spaces as typified by AlphaGo (Silver et al., 2017), but also improved exploration coverage in partially observable environments.",
    "curr": "Communication (Sukhbaatar et al., 2016;Singh et al., 2019) exchanges their internal representations such as explored observation and hidden state in RNNs.",
    "next": "Evolutionary learning is expected to be a general framework for creating superhuman AIs as such learning can generate a high-level abstract representation without any bias in supervision.",
    "hard_negative": [
      2705742,
      6683636
    ],
    "easy_negative": [
      14431662,
      14667791,
      60755318
    ]
  },
  {
    "index": 394,
    "source_corpus_id": 237353080,
    "ref_id": "b6",
    "citation_corpus_id": 215814169,
    "start": 2957,
    "end": 2974,
    "title": "Training with Quantization Noise for Extreme Model Compression",
    "abstract": "We tackle the problem of producing compact models, maximizing their accuracy for a given model size. A standard solution is to train networks with Quantization Aware Training [1], where the weights are quantized during training and the gradients approximated with the Straight-Through Estimator[2]. In this paper, we extend this approach to work with extreme compression methods where the approximations introduced by STE are severe. Our proposal is to only quantize a different random subset of weights during each forward, allowing for unbiased gradients to flow through the other weights. Controlling the amount of noise and its form allows for extreme compression rates while maintaining the performance of the original model. As a result we establish new state-of-the-art compromises between accuracy and model size both in natural language processing and image classification. For example, applying our method to state-of-the-art Transformer and ConvNet architectures, we can achieve 82.5% accuracy on MNLI by compressing RoBERTa to 14 MB and 80.0% top-1 accuracy on ImageNet by compressing an EfficientNet-B3 to 3.3 MB. * Equal",
    "prev": "Another solution is to compress a model with small accuracy degradation so that it takes less storage and reduces System-on-Chip (SoC) memory bandwidth utilization, which can minimize power-consumption and latency.",
    "curr": "To this end, various DNN compression techniques have been proposed (Wang et al., 2019b;Dong et al., 2020;Park et al., 2018;Rastegari et al., 2016;Fan et al., 2021;Stock et al., 2020;Zhou et al., 2019;Park et al., 2019;Yu et al., 2018;Polino et al., 2018).",
    "next": "Among them, weight-clustering/sharing (Han et al., 2016;Wu et al., 2018;Ullrich et al., 2017;Stock et al., 2020) has shown a high DNN compression ratio where weights are clustered into a few shareable weight values (or centroids) based on k-means clustering.",
    "hard_negative": [
      91184134,
      3432876,
      1870512,
      59310641,
      201670719
    ],
    "easy_negative": [
      241583555,
      38854531,
      17482681
    ]
  },
  {
    "index": 395,
    "source_corpus_id": 204008396,
    "ref_id": "b40",
    "citation_corpus_id": 1957433,
    "start": 2782,
    "end": 2806,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "1 Published as a conference paper at ICLR 2020The joint vocabulary is composed of three disjoint sets:is the shared vocabulary set and V i J is the set of tokens that appear in the ith language only.",
    "curr": "Note that a key difference of existing supervised joint training methods is that embeddings corresponding to V s J are not shared between E L1 and E L2 , meaning that they are disjoint, as in alignment methods.DISCUSSIONWhile alignment methods have had great success, there are still some critical downsides, among which we stress the following points:\n\nINTRODUCTION\n\nContinuous word representations (Mikolov et al., 2013a;Pennington et al., 2014;Bojanowski et al., 2017) have become ubiquitous across a wide range of NLP tasks.",
    "next": "In particular, methods for crosslingual word embeddings (CLWE) have proven a powerful tool for cross-lingual transfer for downstream tasks, such as text classification (Klementiev et al., 2012), dependency parsing (Ahmad et al., 2019), named entity recognition (NER) (Xie et al., 2018;Chen et al., 2019), natural language inference , language modeling (Adams et al., 2017), and machine translation (MT) (Zou et al., 2013;Artetxe et al., 2018b;.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      201641861,
      18517859,
      715424
    ]
  },
  {
    "index": 398,
    "source_corpus_id": 256598122,
    "ref_id": "b0",
    "citation_corpus_id": 15978939,
    "start": 6162,
    "end": 6184,
    "title": "Domain Adaptation with Structural Correspondence Learning",
    "abstract": "Discriminative learning methods are widely used in natural language processing. These methods work best when their training and test data are drawn from the same distribution. For many NLP tasks, however, we are confronted with new domains in which labeled data is scarce or non-existent. In such cases, we seek to adapt existing models from a resourcerich source domain to a resource-poor target domain. We introduce structural correspondence learning to automatically induce correspondences among features from different domains. We test our technique on part of speech tagging and show performance gains for varying amounts of source and target training data, as well as improvements in target domain parsing accuracy using our improved tagger.",
    "prev": "Domain Adaptation Typically domain adaptations consider data distributions and deviations to search for mappings aligning domains.",
    "curr": "Early literature suggested that assuming data drawn from certain probabilities (Blitzer et al., 2006) can be used to model and compensate for the domain mismatch.",
    "next": "Some studies then looked for theoretical arguments when a successful adaptation can be yielded.",
    "hard_negative": [
      6376593,
      5914287,
      12926517,
      13936575,
      10986188,
      892890,
      6713452,
      252796
    ],
    "easy_negative": [
      227231766,
      9906701,
      17441657
    ]
  },
  {
    "index": 399,
    "source_corpus_id": 203592088,
    "ref_id": "b17",
    "citation_corpus_id": 3366315,
    "start": 4120,
    "end": 4140,
    "title": "Published as a conference paper at ICLR 2018 SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.Published as a conference paper at ICLR 2018\u2022 Lipschitz constant is the only hyper-parameter to be tuned, and the algorithm does not require intensive tuning of the only hyper-parameter for satisfactory performance. \u2022 Implementation is simple and the additional computational cost is small.",
    "prev": "As such, the distribution of training images can be estimated precisely without supervision.",
    "curr": "Recent interests in generative models pertain to their training stability Gulrajani et al., 2017;Miyato et al., 2018) and improvement in quality and diversity (Karras et al., 2018;Brock et al., 2019;Karras et al., 2019).",
    "next": "Furthermore, methods to learn 3D representation from 2D images by constructing a generative model conditioned on camera parameters have been proposed (Shen et al., 2018;Sitzmann et al., 2019;Nguyen-Phuoc et al., 2019).",
    "hard_negative": [
      6628106,
      5687613,
      18828233,
      3633127,
      14570343,
      11758569
    ],
    "easy_negative": [
      51801236,
      209202200,
      11386337
    ]
  },
  {
    "index": 408,
    "source_corpus_id": 263909446,
    "ref_id": "b40",
    "citation_corpus_id": 227209335,
    "start": 1900,
    "end": 1918,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "s generalize DDIM, mapping the reverse diffusion dynamics to a more amenable space for sampling.In contrast, splitting-based integrators, commonly used in molecular dynamics, reduce the numerical simulation error by cleverly alternating between numerical updates involving the data and auxiliary variables.After extensively studying these methods empirically and theoretically, we present a hybrid method that leads to the best-reported performance for diffusion models in augmented spaces.Applied to Phase Space Langevin Diffusion[Pandey & Mandt, 2023]on CIFAR-10, our deterministic and stochastic samplers achieve FID scores of 2.11 and 2.36 in only 100 network function evaluations (NFE) as compared to 2.57 and 2.63 for the best-performing baselines, respectively.Our code and model checkpoints will be made publicly available at https://github.com/mandt-lab/PSLD.",
    "curr": "INTRODUCTION\n\nScore-based Generative models (or Diffusion models) (Sohl-Dickstein et al., 2015;Song & Ermon, 2019;Ho et al., 2020;Song et al., 2020) have demonstrated impressive performance on various tasks, such as image and video synthesis (Dhariwal & Nichol, 2021;Ho et al., 2022a;Rombach et al., 2022;Ramesh et al., 2022;Saharia et al., 2022a;Yang et al., 2022;Ho et al., 2022b;Harvey et al., 2022), image super-resolution (Saharia et al., 2022b), and audio and speech synthesis (Chen et al., 2021;Lam et al., 2021).",
    "next": "However, high-quality sample generation in standard diffusion models requires hundreds to thousands of expensive score function evaluations.While there have been recent advances in improving the sampling efficiency (Song et al., 2021;Lu et al., 2022;Zhang & Chen, 2023), most of these efforts have been focused towards a specific family of models that perform diffusion in the data space (Song et al., 2020;Karras et al., 2022).Interestingly, recent work (Dockhorn et al., 2022b;Pandey & Mandt, 2023;Singhal et al., 2023) indicates that performing diffusion in a joint space, where the data space is augmented with auxiliary v",
    "hard_negative": [
      52889459,
      52908831
    ],
    "easy_negative": [
      14159046,
      14532621,
      1283622
    ]
  },
  {
    "index": 410,
    "source_corpus_id": 264825556,
    "ref_id": "b34",
    "citation_corpus_id": 246823323,
    "start": 4366,
    "end": 4387,
    "title": "Published as a conference paper at ICLR 2022 LEARNING FAST SAMPLERS FOR DIFFUSION MODELS BY DIFFERENTIATING THROUGH SAMPLE QUALITY",
    "abstract": "Diffusion models have emerged as an expressive family of generative models rivaling GANs in sample quality and autoregressive models in likelihood scores. Standard diffusion models typically require hundreds of forward passes through the model to generate a single high-fidelity sample. We introduce Differentiable Diffusion Sampler Search (DDSS): a method that optimizes fast samplers for any pre-trained diffusion model by differentiating through sample quality scores. We present Generalized Gaussian Diffusion Models (GGDM), a family of flexible non-Markovian samplers for diffusion models. We show that optimizing the degrees of freedom of GGDM samplers by maximizing sample quality scores via gradient descent leads to improved sample quality. Our optimization procedure backpropagates through the sampling process using the reparametrization trick and gradient rematerialization. DDSS achieves strong results on unconditional image generation across various datasets (e.g., FID scores on LSUN church 128x128 of 11.6 with only 10 inference steps, and 4.82 with 20 steps, compared to 51.1 and 14.9 with strongest DDPM/DDIM baselines). Our method is compatible with any pre-trained diffusion model without fine-tuning or re-training required. * Work done as part of the Google AI Residency.",
    "prev": "n training, it is shown to empirically generate samples of comparable quality to the original model (Salimans & Ho, 2022;Meng et al., 2023).Unfortunately, the GPU time required to distill a model is comparable to the training time of the original model Salimans & Ho (2022), which is often considerable.",
    "curr": "(ii) Dedicated solvers: where the specific structure of the ODE is used to design a more efficient solver (Song et al., 2020a;Lu et al., 2022a;b) and/or employ a suitable solver family from the literature of numerical analysis (Zhang & Chen, 2022;Zhang et al., 2023).The main benefit of this approach is two-fold: First, it is consistent, i.e., as the number of steps (NFE) increases, the samples converge to those of the pre-trained model.Second, it does not require further training/fine-tuning of the pre-trained model, consequently avoiding long additional training times and access to training data.Related to our approach, some works have tried to learn an ODE solver within a certain class (Watson et al., 2021;Duan et al., 2023); however, they do not guarantee consistency and usually introduce moderate improvements over generic dedicated solvers.In this paper, we introduce Bespoke solvers, a framework for learning consistent ODE solvers custom-tailored to pre-trained flow models.The main motivation for Bespoke solvers is that different models exhibit sampling paths with different characteristics, leading to local truncation errors that are specific to each instance of a trained model.A key observation of this paper is that optimizing a solver for a particular model can significantly improve quality of samples for low NFE compared to existing dedicated solvers.Furthermore, Bespoke solvers use a very small number of learnable parameters and consequently are efficient to train.For example, we have trained n \u2208 {5, 8, 10} steps Bespoke solvers for a pretrained ImageNet-64\u00d764 flow model with {40, 64, 80} learnable parameters (resp.",
    "next": ")producing images with Fr\u00e9chet Inception Distances (FID) of 2.2, 1.",
    "hard_negative": [
      6628106,
      227209335,
      221447287
    ],
    "easy_negative": [
      241583379,
      10700106,
      17640849
    ]
  },
  {
    "index": 413,
    "source_corpus_id": 259375820,
    "ref_id": "b11",
    "citation_corpus_id": 241035330,
    "start": 2653,
    "end": 2671,
    "title": "An Explanation of In-context Learning as Implicit Bayesian Inference",
    "abstract": "Large language models (LMs) such as GPT-3 have the surprising ability to do in-context learning, where the model learns to do a downstream task simply by conditioning on a prompt consisting of input-output examples. The LM learns from these examples without being explicitly pretrained to learn. Thus, it is unclear what enables in-context learning. In this paper, we study how in-context learning can emerge when pretraining documents have long-range coherence. Here, the LM must infer a latent document-level concept to generate coherent next tokens during pretraining. At test time, in-context learning occurs when the LM also infers a shared latent concept between examples in a prompt. We prove when this occurs despite a distribution mismatch between prompts and pretraining data in a setting where the pretraining distribution is a mixture of HMMs. In contrast to messy large-scale datasets used to train LMs capable of in-context learning, we generate a small-scale synthetic dataset (GINC) where Transformers and LSTMs both exhibit in-context learning 1 . Beyond the theory, experiments on GINC exhibit large-scale real-world phenomena including improved in-context performance with model scaling (despite the same pretraining loss), sensitivity to example order, and instances where zero-shot is better than few-shot in-context learning.",
    "prev": "Introduction\n\nLarge language models (LLMs) demonstrate the surprising ability of in-context learning, where an LLM \"learns\" to solve a task by conditioning on a prompt containing input-output exemplars [Brown et al., 2020, Lieber et al., 2021, Radford et al., 2019, Wang and Komatsuzaki, 2021.",
    "curr": "Recent works have advanced the understanding of in-context learning via empirical analysis [Min et al., 2022, Aky\u00fcrek et al., 2023, von Oswald et al., 2022, Dai et al., 2023, but theoretical analysis remains limited [Xie et al., 2022].",
    "next": "A recent line of work [Garg et al., 2022, Aky\u00fcrek et al., 2023, von Oswald et al., 2022, Dai et al., 2023 empirically finds that transformers can be trained to implement algorithms that solve linear regression problems in-context.",
    "hard_negative": [
      6628106,
      26501419,
      204960716,
      230433941,
      2381275
    ],
    "easy_negative": [
      246996551,
      257038592,
      248722191
    ]
  },
  {
    "index": 418,
    "source_corpus_id": 53034786,
    "ref_id": "b42",
    "citation_corpus_id": 990233,
    "start": 2951,
    "end": 2972,
    "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
    "prev": "RNNs explicitly imposes a chain structure on the data.",
    "curr": "This chain structure may seem at odds with the latent non-sequential structure of language and poses several difficulties for the processing of natural language data with deep learning methods, such as capturing long-term dependencies (Bengio et al., 2009), achieving good generalization (Bowman et al., 2015), handling negation (Socher et al., 2013), etc.",
    "next": "Meanwhile, some evidence exists that an RNN with sufficient capacity has the potential to encode such a tree structure implicitly .",
    "hard_negative": [
      5584134,
      2279432,
      3116311,
      7747235,
      15659560,
      1588782,
      806709,
      2678583,
      3264224,
      15616495,
      2091504
    ],
    "easy_negative": [
      236119,
      2462970,
      207870430
    ]
  },
  {
    "index": 421,
    "source_corpus_id": 252715598,
    "ref_id": "b3",
    "citation_corpus_id": 11212020,
    "start": 2344,
    "end": 2367,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "Code is publicly available.",
    "curr": "INTRODUCTION\n\nThe vision community has witnessed the prevalence of self-attention (Bahdanau et al., 2015) and Transformers (Vaswani et al., 2017).",
    "next": "The success of Transformers in natural language processing motivates the creation of their variants for vision recognition.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      247447758,
      162552,
      7653072
    ]
  },
  {
    "index": 423,
    "source_corpus_id": 237372712,
    "ref_id": "b18",
    "citation_corpus_id": 5034059,
    "start": 1429,
    "end": 1448,
    "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    "abstract": "For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusively tailored to a specific task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating and analyzing the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and find that multi-task training on all our tasks yields better results than training a separate model for each task. However, the low absolute performance of our best model indicates the need for improved general NLU systems. son. 2013. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint 1312.3005.",
    "prev": "INTRODUCTION\n\nShared benchmarks and datasets have historically played a crucial role in driving advances in largescale applications of deep learning, e.g.",
    "curr": "in computer vision (Deng et al., 2009) and natural language processing (Wang et al., 2019;Rajpurkar et al., 2016;Paperno et al., 2016).",
    "next": "Neural theorem proving is a rapidly developing area which aims to apply techniques from deep learning to interactive theorem proving.",
    "hard_negative": [
      5074049,
      388,
      2937095,
      2213896,
      25422730,
      4537113,
      990233,
      16661147,
      3432876,
      1957433,
      3626819,
      1994584,
      2135897,
      3264224,
      4421747,
      16639476,
      4567927
    ],
    "easy_negative": [
      5567881,
      8629740,
      238638495
    ]
  },
  {
    "index": 425,
    "source_corpus_id": 259187750,
    "ref_id": "b11",
    "citation_corpus_id": 232185279,
    "start": 12657,
    "end": 12661,
    "title": "Published as a conference paper at ICLR 2021 FAIR MIXUP: FAIRNESS VIA INTERPOLATION",
    "abstract": "Training classifiers under fairness constraints such as group fairness, regularizes the disparities of predictions between the groups. Nevertheless, even though the constraints are satisfied during training, they might not generalize at evaluation time. To improve the generalizability of fair classifiers, we propose fair mixup, a new data augmentation strategy for imposing the fairness constraint. In particular, we show that fairness can be achieved by regularizing the models on paths of interpolated samples between the groups. We use mixup, a powerful data augmentation strategy to generate these interpolates. We analyze fair mixup and empirically show that it ensures a better generalization for both accuracy and fairness measurement in tabular, vision, and language benchmarks. The code is available at https://github.com/chingyaoc/fair-mixup. * Work done during an internship at IBM Research AI",
    "prev": "In particular, we consider the following three types of in-processing methods.",
    "curr": "Gap Regularization [12] simplifies optimization by offering a smooth approximation to real loss functions, which are often non-convex or difficult to optimize directly.",
    "next": "This approach includes DiffDP, DiffEodd, and DiffEopp.",
    "hard_negative": [
      212718244,
      52967399,
      209444850,
      49876500
    ],
    "easy_negative": [
      17826787,
      17522253,
      247291883
    ]
  },
  {
    "index": 429,
    "source_corpus_id": 238419003,
    "ref_id": "b2",
    "citation_corpus_id": 52156206,
    "start": 8524,
    "end": 8556,
    "title": "Gromov-Wasserstein Alignment of Word Embedding Spaces",
    "abstract": "Cross-lingual or cross-domain correspondences play key roles in tasks ranging from machine translation to transfer learning. Recently, purely unsupervised methods operating on monolingual embeddings have become effective alignment tools. Current state-of-theart methods, however, involve multiple steps, including heuristic post-hoc refinement strategies. In this paper, we cast the correspondence problem directly as an optimal transport (OT) problem, building on the idea that word embeddings arise from metric recovery algorithms. Indeed, we exploit the Gromov-Wasserstein distance that measures how similarities between pairs of words relate across languages. We show that our OT objective can be estimated efficiently, requires little or no tuning, and results in performance comparable with the state-of-the-art in various unsupervised word translation tasks.",
    "prev": "Finally, other domain adaptation and transfer learning settings use Gromov-Wasserstein variants, e.g.",
    "curr": "for transfer between word embedding spaces (Alvarez-Melis & Jaakkola, 2018) and image spaces (Vayer et al., 2020b).",
    "next": "PRELIMINARIES\n\nMetric Markov Decision Process.",
    "hard_negative": [
      7822594,
      12479653,
      1040556,
      874413,
      158652,
      3470398,
      11591887,
      207556454,
      3518190,
      26873455,
      32923127
    ],
    "easy_negative": [
      14146585,
      216056404,
      227230671
    ]
  },
  {
    "index": 435,
    "source_corpus_id": 253098972,
    "ref_id": "b5",
    "citation_corpus_id": 165163607,
    "start": 2447,
    "end": 2473,
    "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions",
    "abstract": "In this paper we study yes/no questions that are naturally occurring -meaning that they are generated in unprompted and unconstrained settings. We build a reading comprehension dataset, BoolQ, of such questions, and show that they are unexpectedly challenging. They often query for complex, non-factoid information, and require difficult entailment-like inference to solve. We also explore the effectiveness of a range of transfer learning baselines. We find that transferring from entailment data is more effective than transferring from paraphrase or extractive QA data, and that it, surprisingly, continues to be very beneficial even when starting from massive pre-trained language models such as BERT. Our best method trains BERT on MultiNLI and then re-trains it on our train set. It achieves 80.4% accuracy compared to 90% accuracy of human annotators (and 62% majority-baseline), leaving a significant gap for future work.",
    "prev": "We conduct experiments across a diverse set of eight NLP tasks using models of different scales (T5-{base, large, XL}) and find that SESoM consistently outperforms the existing models of the same as well as larger parametric scale by a large margin.",
    "curr": "INTRODUCTION\n\nRecent few years have witnessed the great success of large pre-trained language models (PLM) (Kenton & Toutanova, 2019;Liu et al., 2019;Radford et al., 2019;Raffel et al., 2020;Brown et al., 2020).",
    "next": "The size of pre-trained models which can easily go to billions of parameters (Brown et al., 2020;Raffel et al., 2020), however, hinder their real-world deployments and applications.",
    "hard_negative": [
      3178759,
      9192723,
      8535316,
      8495258,
      52055325,
      7228830,
      52019251,
      34032948,
      3626819,
      52183757,
      11816014,
      52123220,
      52165754
    ],
    "easy_negative": [
      14783099,
      2727624,
      227230696
    ]
  },
  {
    "index": 440,
    "source_corpus_id": 258865444,
    "ref_id": "b14",
    "citation_corpus_id": 248987078,
    "start": 3398,
    "end": 3420,
    "title": "Context Matters for Image Descriptions for Accessibility: Challenges for Referenceless Evaluation Metrics",
    "abstract": "Few images on the Web receive alt-text descriptions that would make them accessible to blind and low vision (BLV) users. Imagebased NLG systems have progressed to the point where they can begin to address this persistent societal problem, but these systems will not be fully successful unless we evaluate them on metrics that guide their development correctly. Here, we argue against current referenceless metrics -those that don't rely on human-generated ground-truth descriptions -on the grounds that they do not align with the needs of BLV users. The fundamental shortcoming of these metrics is that they do not take context into account, whereas contextual information is highly valued by BLV users. To substantiate these claims, we present a study with BLV participants who rated descriptions along a variety of dimensions. An in-depth analysis reveals that the lack of context-awareness makes current referenceless metrics inadequate for advancing image accessibility. As a proof-of-concept, we provide a contextual version of the referenceless metric CLIPScoreSculpture GazeboImage descriptionA freestanding, open, hexagonal gazebo with a dome-like roof in an idyllic park area.",
    "prev": "onto the users, who frequently either for convenience or lack of awareness simply do not choose to do so (Gleason et al., 2019).We find that as many as 98% of images uploaded to Twitter even after the widespread feature rollout do not have alt-text, to say nothing of the quality of those that do.When a screen reader encounters such an image, it will simply say \"Image\", leaving the user with no meaningful information about what the image is actually of.Even when images on Twitter do have accompanying user-written alt-text, the quality is inconsistent as not all users are well informed regarding best practices.",
    "curr": "Note that while there is a long line of existing research on the broader task of captioning images more generally, alt-text generation for social media is a special case of this task, which in turn comes with its own challenges.Well written alt-text is generally more explicitly descriptive than a high level caption and may emphasize specific details in the image based on context (Kreiss et al., 2022a).See Figure 1 for an example.Furthermore, the distribution of image types on Twitter differs substantially from those found in traditional captioning datasets, and may contain digital artwork, promotional graphics, or screenshots containing text.An additional challenge is that Twitter users are not well trained in the practice of writing alt-text, and therefore native \"gold\" examples can vary  ()   Alt-text: Delicious pink margarita sits on a table full of salsa and chips\n\nCaption: having cocktail at person who wants to join ?",
    "next": "Our Dataset Conceptual Captions\n\nFigure 1: Left: An image that requires textual context to write accurate alt-text for.Without conditioning on the tweet text, the election flyers are indistinguishable from books to a traditional captioning system.Right: Two similar images from our dataset and Conceptual Captions with their gold labels.The alt-text for the first image is literally descriptive while the second is more colloquial.",
    "hard_negative": [
      235313922,
      244954786,
      244270388,
      964287,
      235658821,
      233296711,
      44151373,
      17829732,
      201676778,
      218487791
    ],
    "easy_negative": [
      216847732,
      252819045,
      20059328
    ]
  },
  {
    "index": 442,
    "source_corpus_id": 3497822,
    "ref_id": "b4",
    "citation_corpus_id": 51559,
    "start": 3308,
    "end": 3311,
    "title": "QUASI-RECURRENT NEURAL NETWORKS",
    "abstract": "Recurrent neural networks are a powerful tool for modeling sequential data, but the dependence of each timestep's computation on the previous timestep's output limits parallelism and makes RNNs unwieldy for very long sequences. We introduce quasi-recurrent neural networks (QRNNs), an approach to neural sequence modeling that alternates convolutional layers, which apply in parallel across timesteps, and a minimalist recurrent pooling function that applies in parallel across channels. Despite lacking trainable recurrent layers, stacked QRNNs have better predictive accuracy than stacked LSTMs of the same hidden size. Due to their increased parallelism, they are up to 16 times faster at train and test time. Experiments on language modeling, sentiment classification, and character-level neural machine translation demonstrate these advantages and underline the viability of QRNNs as a basic building block for a variety of sequence tasks. * Equal contribution",
    "prev": "Bradbury et al.",
    "curr": "[5], Kalchbrenner et al.",
    "next": "[12], Gehring et al.",
    "hard_negative": [
      217537,
      7147309,
      14410414,
      1998416,
      1952530,
      11212020,
      1957433
    ],
    "easy_negative": [
      61514482,
      567820,
      237485627
    ]
  },
  {
    "index": 444,
    "source_corpus_id": 27494814,
    "ref_id": "b24",
    "citation_corpus_id": 2973141,
    "start": 6807,
    "end": 6824,
    "title": "Compression of Neural Machine Translation Models via Pruning",
    "abstract": "Neural Machine Translation (NMT), like many other deep learning domains, typically suffers from over-parameterization, resulting in large storage sizes. This paper examines three simple magnitude-based pruning schemes to compress NMT models, namely class-blind, class-uniform, and class-distribution, which differ in terms of how pruning thresholds are computed for the different classes of weights in the NMT architecture. We demonstrate the efficacy of weight pruning as a compression technique for a state-of-the-art NMT system. We show that an NMT model with over 200 million parameters can be pruned by 40% with very little performance loss as measured on the WMT'14 English-German translation task. This sheds light on the distribution of redundancy in the NMT architecture. Our main result is that with retraining, we can recover and even surpass the original performance with an 80%-pruned model.",
    "prev": "In Optimal Brain Surgeon (Hassibi et al., 1993), the saliency for each parameter was computed using the inverse Hessian matrix, and the low-saliency weights are pruned and all other weights in the network are updated using the second-order information.",
    "curr": "More recently, magnitude-based weight pruning methods have become popular techniques for network pruning (Han et al., 2015b,a;See et al., 2016;Narang et al., 2017).",
    "next": "Magnitude-based weight pruning techniques are computationally efficient, scaling to large networks and datasets.",
    "hard_negative": [
      2863491,
      3036949,
      1245593,
      359451,
      12639289,
      13972671,
      5590763,
      11212020,
      2753399
    ],
    "easy_negative": [
      255096726,
      44179224,
      1755973
    ]
  },
  {
    "index": 449,
    "source_corpus_id": 220249871,
    "ref_id": "b3",
    "citation_corpus_id": 213152193,
    "start": 9504,
    "end": 9524,
    "title": "ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS",
    "abstract": "Masked language modeling (MLM) pre-training methods such as BERT corrupt the input by replacing some tokens with [MASK]  and then train a model to reconstruct the original tokens. While they produce good results when transferred to downstream NLP tasks, they generally require large amounts of compute to be effective. As an alternative, we propose a more sample-efficient pre-training task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pre-training task is more efficient than MLM because the task is defined over all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by BERT given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where it performs comparably to RoBERTa and XLNet while using less than 1/4 of their compute and outperforms them when using the same amount of compute.",
    "prev": "(2017), a hand-craft positional encoding based on sinusoid function is proposed.",
    "curr": "But learnable positional encoding, i.e., treating p i as parameters, is often used in the recent works Devlin et al., 2018;Clark et al., 2019b).",
    "next": "Relative Positional Encoding.",
    "hard_negative": [
      3655946,
      990233,
      53113638,
      3432876,
      5959482,
      3626819,
      259144,
      5034059,
      11816014,
      40100965,
      52967399,
      11758569,
      85464175,
      4421747,
      16639476
    ],
    "easy_negative": [
      5226139,
      3933075,
      11404292
    ]
  },
  {
    "index": 450,
    "source_corpus_id": 60440615,
    "ref_id": "b24",
    "citation_corpus_id": 16631020,
    "start": 1779,
    "end": 1798,
    "title": "Transfer Learning for Low-Resource Neural Machine Translation",
    "abstract": "The encoder-decoder framework for neural machine translation (NMT) has been shown effective in large data scenarios, but is much less effective for low-resource languages. We present a transfer learning method that significantly improves BLEU scores across a range of low-resource languages. Our key idea is to first train a high-resource language pair (the parent model), then transfer some of the learned parameters to the low-resource pair (the child model) to initialize and constrain training. Using our transfer learning method we improve baseline NMT models by an average of 5.6 BLEU on four low-resource language pairs. Ensembling and unknown word replacement add another 2 BLEU which brings the NMT performance on low-resource machine translation close to a strong syntax based machine translation (SBMT) system, exceeding its performance on one language pair. Additionally, using the transfer learning model for re-scoring, we can improve the SBMT system by an average of 1.3 BLEU, improving the state-of-the-art on low-resource machine translation.",
    "prev": "Experiments on a standard dataset of four low-resource languages show consistent improvements over strong multilingual NMT baselines, with gains of up to 2 BLEU on one of the tested languages, achieving the new state-of-the-art on all four language pairs 1 .",
    "curr": "INTRODUCTION\n\nMultilingual Neural Machine Translation (NMT) has shown great potential both in creating parameter-efficient MT systems for many languages (Johnson et al., 2016), and in improving translation quality of low-resource languages (Zoph et al., 2016;Firat et al., 2016;Gu et al., 2018;Neubig & Hu, 2018;Nguyen & Chiang, 2018).",
    "next": "Despite the success of multilingual NMT, it remains a research question how to represent the words from multiple languages in a way that is both parameter efficient and conducive to cross-lingual generalization.",
    "hard_negative": [
      3065236,
      1245593,
      1557806,
      1998416,
      6359641,
      765547,
      3666937
    ],
    "easy_negative": [
      15555528,
      15346148,
      243865368
    ]
  },
  {
    "index": 452,
    "source_corpus_id": 253098739,
    "ref_id": "b33",
    "citation_corpus_id": 68137503,
    "start": 3821,
    "end": 3838,
    "title": "FUNCTIONAL VARIATIONAL BAYESIAN NEURAL NETWORKS",
    "abstract": "Variational Bayesian neural networks (BNNs) perform variational inference over weights, but it is difficult to specify meaningful priors and approximate posteriors in a high-dimensional weight space. We introduce functional variational Bayesian neural networks (fBNNs), which maximize an Evidence Lower BOund (ELBO) defined directly on stochastic processes, i.e. distributions over functions. We prove that the KL divergence between stochastic processes equals the supremum of marginal KL divergences over all finite sets of inputs. Based on this, we introduce a practical training objective which approximates the functional ELBO using finite measurement sets and the spectral Stein gradient estimator. With fBNNs, we can specify priors entailing rich structures, including Gaussian processes and implicit stochastic processes. Empirically, we find fBNNs extrapolate well using various structured priors, provide reliable uncertainty estimates, and scale to large datasets. * Equal contribution.Theorem 7. For two stochastic processes P, M on a cylindrical measurable space (\u2126 T , F T ), the KL divergence of P with respect to M satisfies,where the supremum is over all finite indices subsets T d \u2286 T , and P T d , M T d represent the canonical projection maps \u03c0 T \u2192T d of P, M , respectively.Proof. Recall that stochastic processes are defined over a cylindrical \u03c3-algebra F T . By Lemma 6, for every set H \u2208 F T , the restricted index set \u03c4 (H) is countable. Our proof proceeds in two steps:",
    "prev": "To address these shortcomings, we take a new approach to formulating the meta-learning problem and represent prior knowledge in a novel way.",
    "curr": "We build on recent advances in functional approximate inference for BNNs that perform Bayesian inference in the function space rather than in the parameter space of neural networks (Wang et al., 2018;Sun et al., 2019).",
    "next": "When viewing the BNN prior and posterior as stochastic processes, the perfect Bayesian prior is the (true) data-generating stochastic process itself.",
    "hard_negative": [
      3708505,
      3502463
    ],
    "easy_negative": [
      22236307,
      221266836,
      213348459
    ]
  },
  {
    "index": 458,
    "source_corpus_id": 221447287,
    "ref_id": "b36",
    "citation_corpus_id": 49882757,
    "start": 2654,
    "end": 2672,
    "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech",
    "abstract": "In this work, we propose an alternative solution for parallel wave generation by WaveNet. In contrast to parallel WaveNet (Oord et al., 2018), we distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet by minimizing a novel regularized KL divergence between their highly-peaked output distributions. Our method computes the KL divergence in closed-form, which simplifies the training algorithm and provides very efficient distillation. In addition, we propose the first text-to-wave neural architecture for speech synthesis, which is fully convolutional and enables fast end-to-end training from scratch. It significantly outperforms the previous pipeline that connects a text-to-spectrogram model to a separately trained WaveNet (Ping et al., 2018). We also successfully distill a parallel waveform synthesizer conditioned on the hidden representation in this end-to-end model. 2 * These authors contributed equally to this work. Correspondence to <weiping.thu@gmail.com>. Our method is named after the musical instrument clarinet, whose sound resembles human voice.2 Audio samples are in https://clarinet-demo.github.io/ arXiv:1807.07281v2 [cs.CL] 30 Jul 2018",
    "prev": "However, autoregressive models require a large number of sequential computational steps to generate one audio sample, which makes it challenging to deploy these models in real-world production applications, such as digital voice assistants on smart speakers, even using specialized hardware designed for neural networks.",
    "curr": "There has been a plethora of research into non-autoregressive models for audio generation, including normalizing flow (NF) models like inverse autoregressive flow (IAF) Ping et al., 2019), generative flow (Glow) (Prenger et al., 2019;Kim et al., 2019), and continuous normalizing flow (CNF) Wu & Ling, 2020), implicit generative models like generative adversarial network (GAN) (Donahue et al., 2018;Engel et al., 2019;Yamamoto et al., 2020;Bikowski et al., 2020;McCarthy & Ahmed, 2020) and energy score (Gritsenko et al., 2020), variational models like variational auto-encoder (VAE) (Peng et al., 2020), models inspired by digital signal processing (Ai & Ling, 2020;Engel et al., 2020), and those by the speech production mechanism (Juvela et al., 2019;Wang et al., 2020).",
    "next": "Although these models improve inference speed thanks to their architectures offering less sequential operations, they often yield lower quality samples than the autoregressive models.",
    "hard_negative": [
      6628106,
      8451212,
      3480671,
      8768364,
      11212020
    ],
    "easy_negative": [
      248780411,
      257232328,
      225040886
    ]
  },
  {
    "index": 463,
    "source_corpus_id": 231719730,
    "ref_id": "b5",
    "citation_corpus_id": 213152193,
    "start": 20388,
    "end": 20408,
    "title": "ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS",
    "abstract": "Masked language modeling (MLM) pre-training methods such as BERT corrupt the input by replacing some tokens with [MASK]  and then train a model to reconstruct the original tokens. While they produce good results when transferred to downstream NLP tasks, they generally require large amounts of compute to be effective. As an alternative, we propose a more sample-efficient pre-training task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pre-training task is more efficient than MLM because the task is defined over all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by BERT given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where it performs comparably to RoBERTa and XLNet while using less than 1/4 of their compute and outperforms them when using the same amount of compute.",
    "prev": "Unlike the training datasets, the evaluation document was translated to plain L A T E X manually using the PDF as a reference, in order to avoid possible spurious patterns in automatically expanded sT E X.",
    "curr": "S T E X-ANNOTATING WITH MACHINE LEARNING AS AN NMT TASK\n\nIn the course of our experiments, we considered our disambiguation task as a machine translation (NMT) problem, the models for which have been proven to be quite effective even beyond natural language translations (Clark et al., 2020).",
    "next": "In fact, the autoformalization projects mentiond in Section 3, which are spiritually closest to our task, all used NMT models with positive results.",
    "hard_negative": [
      3655946,
      990233,
      53113638,
      3432876,
      1957433,
      5959482,
      3626819,
      259144,
      5034059,
      11816014,
      40100965,
      52967399,
      11758569,
      85464175,
      4421747,
      16639476
    ],
    "easy_negative": [
      246015914,
      14408501,
      3207944
    ]
  },
  {
    "index": 465,
    "source_corpus_id": 58014184,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 10881,
    "end": 10904,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "The queried values are invariant to the ordering of the key-value pairs; this permutation invariance property of attention is key in its application to NPs.",
    "curr": "The idea of using a differentiable addressing mechanism that can be learned from the data has been applied successfully in various areas of Deep Learning, namely handwriting generation and recognition (Graves, 2012) and neural machine translation (Bahdanau et al., 2015).",
    "next": "More recently, there has been work employing self-attention (where keys and queries are identical) to give expressive sequence-to-sequence mappings in natural language processing (Vaswani et al., 2017) and image modelling (Parmar et al., 2018).",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      1059863,
      219310342,
      8595603
    ]
  },
  {
    "index": 470,
    "source_corpus_id": 264406180,
    "ref_id": "b6",
    "citation_corpus_id": 229923720,
    "start": 17860,
    "end": 17880,
    "title": "Transformer Feed-Forward Layers Are Key-Value Memories",
    "abstract": "Feed-forward layers constitute two-thirds of a transformer model's parameters, yet their role in the network remains under-explored. We show that feed-forward layers in transformerbased language models operate as key-value memories, where each key correlates with textual patterns in the training examples, and each value induces a distribution over the output vocabulary. Our experiments show that the learned patterns are human-interpretable, and that lower layers tend to capture shallow patterns, while upper layers learn more semantic ones. The values complement the keys' input patterns by inducing output distributions that concentrate probability mass on tokens likely to appear immediately after each pattern, particularly in the upper layers. Finally, we demonstrate that the output of a feed-forward layer is a composition of its memories, which is subsequently refined throughout the model's layers via residual connections to produce the final output distribution.",
    "prev": "Mean ablating the 1st or 2nd head slightly increased the average loss for BA questions from 0.05 to 0.08, whereas ablating the 3rd head substantially increased the loss to 3.7, confirming that the 3rd head is doing the BA task.",
    "curr": "The MLP can be thought of as a \"key-value pair\" memory [Meng et al., 2022, Geva et al., 2021] that can hold many bigrams and trigrams.We claim our MLP pulls together the two-state 1st head result, the tri-state 2nd head result and the ten-state 3rd head result value, treating them as a trigram with 60 (2 x 3 x 10) possible keys.For each digit, the MLP has memorised the mapping of these 60 keys to the 60 correct digit answers (0 to 9).We haven't proven this experimentally.Our MLP is sufficiently large to store this many mappings with zero interference between mappings [Elhage et al., 2022].",
    "next": "Despite being feasible, the model does not calculate the task MC1 in layers 7 to 11.Instead it completes each digit calculation in 1 layer, possibly because there are training optimisation benefits in generating a \"compact\" algorithm.",
    "hard_negative": [
      3626819,
      16299141,
      218628619,
      52346770,
      184486746,
      162183964,
      195477534,
      184486755,
      155092004,
      52967399,
      199552244,
      207853045,
      52892477
    ],
    "easy_negative": [
      254994143,
      41324867,
      249204409
    ]
  },
  {
    "index": 473,
    "source_corpus_id": 238419359,
    "ref_id": "b5",
    "citation_corpus_id": 189762527,
    "start": 2107,
    "end": 2129,
    "title": "COMET : Commonsense Transformers for Automatic Knowledge Graph Construction",
    "abstract": "We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs: ATOMIC (Sap et al., 2019) and Con-ceptNet (Speer et al., 2017). Contrary to many conventional KBs that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET ) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when implicit knowledge from deep pre-trained language models is transferred to generate explicit knowledge in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5% (ATOMIC) and 91.7% (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.",
    "prev": "Such knowledge can be implicitly encoded or explicitly stored in structured knowledge graphs (KGs).",
    "curr": "Large pre-trained language models (Devlin et al., 2018;Radford et al., 2018;Brown et al., 2020) are found to be effective in learning broad and rich implicit knowledge (Petroni et al., 2019;Bosselut et al., 2019;Talmor et al., 2020) and thus demonstrate much success for QA tasks.",
    "next": "Nevertheless, pretrained LMs struggle a lot with structured reasoning such as handling negation (Ribeiro et al., 2020;Yasunaga et al., 2021).",
    "hard_negative": [
      2257688,
      1125916,
      1671874,
      74065,
      10318045,
      207556454
    ],
    "easy_negative": [
      8200466,
      36303109,
      1183270
    ]
  },
  {
    "index": 476,
    "source_corpus_id": 253510295,
    "ref_id": "b2",
    "citation_corpus_id": 53729760,
    "start": 3778,
    "end": 3780,
    "title": "GAN DISSECTION: VISUALIZING AND UNDERSTANDING GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "Generative Adversarial Networks (GANs) have recently achieved impressive results for many real-world applications, and many GAN variants have emerged with improvements in sample quality and training stability. However, they have not been well visualized or understood. How does a GAN represent our visual world internally? What causes the artifacts in GAN results? How do architectural choices affect GAN learning? Answering such questions could enable us to develop new insights and better models. In this work, we present an analytic framework to visualize and understand GANs at the unit-, object-, and scene-level. We first identify a group of interpretable units that are closely related to object concepts using a segmentation-based network dissection method. Then, we quantify the causal effect of interpretable units by measuring the ability of interventions to control objects in the output. We examine the contextual relationship between these units and their surroundings by inserting the discovered object concepts into new images. We show several practical applications enabled by our framework, from comparing internal representations across different layers, models, and datasets, to improving GANs by locating and removing artifact-causing units, to interactively manipulating objects in a scene. We provide open source interpretation tools to help researchers and practitioners better understand their GAN models * . * Interactive demos, video, code, and data are available at GitHub and gandissect.",
    "prev": "6\n\nINTRODUCTION\n\nSemantic image synthesis refers to generating photo-realistic images conditioned on pixel-level semantic labels.",
    "curr": "This task has a wide range of applications such as image editing and content generation (Chen & Koltun, 2017;Isola et al., 2017;Guo et al., 2022;Gu et al., 2019;Bau et al., 2019a;b;Liu et al., 2019;Qi et al., 2018;Jiang et al., 2020).",
    "next": "Although existing methods conducted interesting explorations, we still observe unsatisfactory aspects, mainly in the generated local structures and details, as well as small-scale objects, which we believe are mainly due to three reasons: 1) Conventional methods (Park et al., 2019;Wang et al., 2018;Liu et al., 2019) generally take the semantic label map as input directly.",
    "hard_negative": [
      6104263,
      3568073,
      8768364,
      205514,
      84591,
      3366315
    ],
    "easy_negative": [
      184482715,
      219301815,
      250390650
    ]
  },
  {
    "index": 478,
    "source_corpus_id": 14298291,
    "ref_id": "b21",
    "citation_corpus_id": 806709,
    "start": 3895,
    "end": 3916,
    "title": "Semantic Compositionality through Recursive Matrix-Vector Spaces",
    "abstract": "Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them.",
    "prev": "(2014), who focus on learning expression representations to aid the search for computationally efficient identities.",
    "curr": "They use recursive neural networks (TREENN) 1 (Socher et al., 2012) for modeling homogenous, single-variable polynomial expressions.",
    "next": "While they present impressive results, we find that the TREENN model fails when applied to more complex symbolic polynomial and boolean expressions.",
    "hard_negative": [
      5584134,
      7747235,
      17121460,
      436023,
      2678583,
      15698938,
      8360910,
      6430811,
      3264224
    ],
    "easy_negative": [
      16392208,
      244051004,
      222133972
    ]
  },
  {
    "index": 481,
    "source_corpus_id": 256846551,
    "ref_id": "b19",
    "citation_corpus_id": 67855860,
    "start": 2396,
    "end": 2418,
    "title": "Attention is not Explanation",
    "abstract": "Attention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful \"explanations\" for predictions. We find that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our findings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do. Code to reproduce all experiments is available at https://github.com/successar/ AttentionExplanation.",
    "prev": "Some recent works in the field of question-answering (QA) have demonstrated that language models can bypass some of these issues and learn to reason directly over natural language , allowing for more flexible and adaptable reasoning capabilities.",
    "curr": "Another advantage of performing multi-step reasoning over natural language is that it allows for more inspectable outputs, improving the explainability of models that are otherwise regarded as black box systems (Jain & Wallace, 2019;Rajani et al., 2019a;Danilevsky et al., 2020).",
    "next": "Despite the recent progress, we notice that there is still a gap in resources for training and evaluating general reasoning capabilities over natural language.",
    "hard_negative": [
      990233,
      8495258,
      12664997,
      7205805,
      51979567,
      52113465,
      5509327,
      1428702,
      982761
    ],
    "easy_negative": [
      259187750,
      36159928,
      247582113
    ]
  },
  {
    "index": 482,
    "source_corpus_id": 252683429,
    "ref_id": "b0",
    "citation_corpus_id": 245334722,
    "start": 3939,
    "end": 3958,
    "title": "TRANSFORMERS CAN DO BAYESIAN INFERENCE",
    "abstract": "Currently, it is hard to reap the benefits of deep learning for Bayesian methods, which allow the explicit specification of prior knowledge and accurately capture model uncertainty. We present Prior-Data Fitted Networks (PFNs). PFNs leverage large-scale machine learning techniques to approximate a large set of posteriors. The only requirement for PFNs to work is the ability to sample from a prior distribution over supervised learning tasks (or functions). Our method restates the objective of posterior approximation as a supervised classification problem with a set-valued input: it repeatedly draws a task (or function) from the prior, draws a set of data points and their labels from it, masks one of the labels and learns to make probabilistic predictions for it based on the set-valued input of the rest of the data points. Presented with a set of samples from a new supervised learning task as input, PFNs make probabilistic predictions for arbitrary other data points in a single forward propagation, having learned to approximate Bayesian inference. We demonstrate that PFNs can near-perfectly mimic Gaussian processes and also enable efficient Bayesian inference for intractable problems, with over 200-fold speedups in multiple setups compared to current methods. We obtain strong results in very diverse areas such as Gaussian process regression, Bayesian neural networks, classification for small tabular data sets, and few-shot image classification, demonstrating the generality of PFNs. Code and trained PFNs are released at https://github. com/automl/TransformersCanDoBayesianInference.",
    "prev": "Instead, we replace this step by performing a single forward pass with a large Transformer that has been pre-trained to solve artificially generated classification tasks from a tabular dataset prior.",
    "curr": "Our method builds on Prior-Data Fitted Networks (PFNs; M\u00fcller et al., 2022; see Section 2), which learn the training and prediction algorithm itself.",
    "next": "PFNs approximate Bayesian inference given any prior one can sample from and approximate the posterior predictive distribution (PPD) directly.",
    "hard_negative": [
      49411844,
      6628106
    ],
    "easy_negative": [
      17546960,
      12737086,
      247434729
    ]
  },
  {
    "index": 494,
    "source_corpus_id": 231648391,
    "ref_id": "b11",
    "citation_corpus_id": 13123084,
    "start": 8985,
    "end": 9005,
    "title": "Published as a conference paper at ICLR 2017 TEMPORAL ENSEMBLING FOR SEMI-SUPERVISED LEARNING",
    "abstract": "In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels.",
    "prev": "Another technique is a consistency regularization which states that realistic perturbations of input examples from unlabeled dataset should not significantly change the output of a neural network.",
    "curr": "Consistency regularization is used in \u03a0-model (Laine & Aila, 2017) and further improved by Temporal Ensembling (Laine & Aila, 2017) which maintains an exponential moving average prediction for each training example and Mean Teacher (Tarvainen & Valpola, 2017) that averages model weights instead of model predictions.",
    "next": "Recent methods UDA (Xie et al., 2019), ReMixMatch  and FixMatch ) use a combination of consistency loss, pseudo-labeling and advanced augmentation techniques in addition to color perturbations and spatial transformations.",
    "hard_negative": [
      1487550,
      1965764,
      2780493,
      6230637,
      9398766
    ],
    "easy_negative": [
      18866953,
      29008704,
      16474892
    ]
  },
  {
    "index": 498,
    "source_corpus_id": 15816492,
    "ref_id": "b21",
    "citation_corpus_id": 12639289,
    "start": 1364,
    "end": 1394,
    "title": "Recurrent Continuous Translation Models",
    "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
    "prev": "Experimental results on abstractive sentence summarisation, morphological inflection, and machine translation show that noisy channel models outperform direct models, and that they significantly benefit from increased amounts of unpaired output data that direct models cannot easily use.",
    "curr": "INTRODUCTION\n\nRecurrent neural network sequence to sequence models (Kalchbrenner & Blunsom, 2013;Sutskever et al., 2014;Bahdanau et al., 2015) are excellent models of p(output sequence y | input sequence x), provided sufficient input-output (x, y) pairs are available for estimating their parameters.",
    "next": "However, in many domains, vastly more unpaired output examples are available than input-output pairs (e.g., transcribed speech is relatively rare although non-spoken texts are abundant; Swahili-English translations are rare although English texts are abundant; etc.).",
    "hard_negative": [
      1274371,
      10691183,
      16391184,
      8476273,
      8608051,
      806709
    ],
    "easy_negative": [
      16686441,
      52847536,
      214612873
    ]
  },
  {
    "index": 499,
    "source_corpus_id": 265038424,
    "ref_id": "b14",
    "citation_corpus_id": 3366315,
    "start": 2403,
    "end": 2423,
    "title": "Published as a conference paper at ICLR 2018 SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.Published as a conference paper at ICLR 2018\u2022 Lipschitz constant is the only hyper-parameter to be tuned, and the algorithm does not require intensive tuning of the only hyper-parameter for satisfactory performance. \u2022 Implementation is simple and the additional computational cost is small.",
    "prev": "The original GAN is, however, highly unstable and often suffers from mode collapse.",
    "curr": "Much of recent researches has focused on improving the stability of GANs (Radford et al., 2015;Heusel et al., 2017;Miyato et al., 2018;Karras et al., 2018).",
    "next": "On the theoretical aspect, Nagarajan & Kolter (2017) proved that gradient based training of the original GAN is locally stable.",
    "hard_negative": [
      6628106,
      5687613,
      18828233,
      3633127,
      14570343,
      11758569
    ],
    "easy_negative": [
      252375764,
      198166008,
      10334488
    ]
  },
  {
    "index": 502,
    "source_corpus_id": 261214750,
    "ref_id": "b2",
    "citation_corpus_id": 215416146,
    "start": 2521,
    "end": 2524,
    "title": "S2ORC: The Semantic Scholar Open Research Corpus",
    "abstract": "We introduce S2ORC, 1 a large corpus of 81.1M English-language academic papers spanning many academic disciplines. The corpus consists of rich metadata, paper abstracts, resolved bibliographic references, as well as structured full text for 8.1M open access papers. Full text is annotated with automaticallydetected inline mentions of citations, figures, and tables, each linked to their corresponding paper objects. In S2ORC, we aggregate papers from hundreds of academic publishers and digital archives into a unified source, and create the largest publicly-available collection of machine-readable academic text to date. We hope this resource will facilitate research and development of tools and tasks for text mining over academic text. * denotes equal contribution 1 Instructions for access to the data and model are available at https://github.com/allenai/s2orc/.2 https://arxiv.org Figure 1: Inline citations and references to figures and tables are annotated in S2ORC's structured full text. Citations are linked to bibliography entries, which are linked to other papers in S2ORC. Figure and table references are linked to their captions.3 https://www.ncbi.nlm.nih.gov/pmc 4 https://citeseerx.ist.psu.edu 5 https://www.aclweb.org/anthology 6 http://aan.how/",
    "prev": "The information of millions of academic papers can not be fully accessed because they are locked behind an unreadable format.",
    "curr": "Existing corpora, such as the S2ORC dataset [3], capture the text of 12M 2 papers using GROBID [4], but are missing meaningful representations of the mathematical equations.",
    "next": "To this end, we introduce Nougat, a transformer based model that can convert images of document pages to formatted markup text.",
    "hard_negative": [
      48353672,
      6628106,
      14655999,
      5523604,
      2279586,
      67788603,
      3626819,
      51917388,
      7985741,
      102483154,
      52967399,
      52118895
    ],
    "easy_negative": [
      16987118,
      235097256,
      156052697
    ]
  },
  {
    "index": 503,
    "source_corpus_id": 247594694,
    "ref_id": "b6",
    "citation_corpus_id": 222272028,
    "start": 29905,
    "end": 29928,
    "title": "LINEAR MODE CONNECTIVITY IN MULTITASK AND CONTINUAL LEARNING",
    "abstract": "Continual (sequential) training and multitask (simultaneous) training are often attempting to solve the same overall objective: to find a solution that performs well on all considered tasks. The main difference is in the training regimes, where continual learning can only have access to one task at a time, which for neural networks typically leads to catastrophic forgetting. That is, the solution found for a subsequent task does not perform well on the previous ones anymore. However, the relationship between the different minima that the two training regimes arrive at is not well understood. What sets them apart? Is there a local structure that could explain the difference in performance achieved by the two different schemes? Motivated by recent work showing that different minima of the same task are typically connected by very simple curves of low error, we investigate whether multitask and continual solutions are similarly connected. We empirically find that indeed such connectivity can be reliably achieved and, more interestingly, it can be done by a linear path, conditioned on having the same initialization for both. We thoroughly analyze this observation and discuss its significance for the continual learning process. Furthermore, we exploit this finding to propose an effective algorithm that constrains the sequentially learned minima to behave as the multitask solution. We show that our method outperforms several state of the art continual learning algorithms on various vision benchmarks 1 . * Equal contribution 1 The code is available at: https://github.com/imirzadeh/MC-SGD arXiv:2010.04495v1 [cs.LG]",
    "prev": "More implementation details are in Appendix C.4.",
    "curr": "Moreover, we also conduct the visualization of relative loss change g over a linear path like (Mirzadeh et al., 2020) in Appendix C.4.",
    "next": "The loss change of SSL is slower than that of SL along the linear interpolation path, demonstrating the flatter minima of SSL.",
    "hard_negative": [
      27494814,
      3693512,
      54443381
    ],
    "easy_negative": [
      227231347,
      2023843,
      11318724
    ]
  },
  {
    "index": 505,
    "source_corpus_id": 256105083,
    "ref_id": "b23",
    "citation_corpus_id": 218487034,
    "start": 1176,
    "end": 1197,
    "title": "On Faithfulness and Factuality in Abstractive Summarization",
    "abstract": "It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria.",
    "prev": "Introduction\n\nLarge language models, often trained with billions of parameters, have achieved impressive performance in recent years (Raffel et al., 2019) and are used in a wide variety of natural language generation tasks.",
    "curr": "However, their output is sometimes undesirable, with hallucinated content (Maynez et al., 2020;Filippova, 2020), and much work remains to fully understand their properties.",
    "next": "In many applications, such as healthcare, question-answering systems, or customer service, incorrect predictions are particularly costly and must be avoided.",
    "hard_negative": [
      4940548,
      23892230,
      1046281,
      202734604,
      1238927,
      3510042,
      189762081,
      3608234,
      3432876,
      21850704,
      86611921,
      199551982,
      215768182,
      196181887
    ],
    "easy_negative": [
      9399737,
      252819426,
      10496324
    ]
  },
  {
    "index": 523,
    "source_corpus_id": 1463401,
    "ref_id": "b5",
    "citation_corpus_id": 5590763,
    "start": 2354,
    "end": 2371,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "The remarkable recent successes of the deep convolutional neural networks are particularly based on this ability to learn hierarchical representation for spatial data (Krizhevsky et al., 2012).",
    "curr": "For modelling temporal data, the recent resurgence of recurrent neural networks (RNN) has led to remarkable advances (Mikolov et al., 2010;Graves, 2013;Cho et al., 2014;Vinyals et al., 2015).",
    "next": "However, unlike the spatial data, learning both hierarchical and temporal representation has been among the long-standing challenges of RNNs in spite of the fact that hierarchical multiscale structures naturally exist in many temporal data (Schmidhuber, 1991;Mozer, 1993;El Hihi & Bengio, 1995;Lin et al., 1996;Koutn\u00edk et al., 2014).",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      202775334,
      53079875,
      14686868
    ]
  },
  {
    "index": 524,
    "source_corpus_id": 3535069,
    "ref_id": "b3",
    "citation_corpus_id": 19435386,
    "start": 3234,
    "end": 3236,
    "title": "A Corpus of Natural Language for Visual Reasoning",
    "abstract": "We present a new visual reasoning language dataset, containing 92,244 pairs of examples of natural statements grounded in synthetic images with 3,962 unique sentences. We describe a method of crowdsourcing linguistically-diverse data, and present an analysis of our data. The data demonstrates a broad set of linguistic phenomena, requiring visual and set-theoretic reasoning. We experiment with various models, and show the data presents a strong challenge for future research.",
    "prev": "Machine understanding of this structured visual information could assist human analysts in extracting knowledge from the vast documentation produced by modern science.",
    "curr": "Thus motivated, and inspired by recent research in Visual Question Answering (VQA) [1,2] and relational reasoning [3,4], we introduce FigureQA.",
    "next": "FigureQA is a corpus of over one million question-answer pairs grounded in over 100, 000 figures, devised to study aspects of comprehension and reasoning in machines.",
    "hard_negative": [
      7198177,
      9027681,
      3130692,
      9682853,
      8251899,
      3104920,
      14743706
    ],
    "easy_negative": [
      9140038,
      239009573,
      1686688
    ]
  },
  {
    "index": 526,
    "source_corpus_id": 257255036,
    "ref_id": "b51",
    "citation_corpus_id": 227209335,
    "start": 2032,
    "end": 2052,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "INTRODUCTION\n\nDiffusion probabilistic modeling has quickly become a central approach for learning data distributions, obtaining impressive empirical results across multiple domains like images (Nichol & Dhariwal, 2021), videos (Ho et al., 2022) or even 3D geometry (Luo & Hu, 2021).",
    "curr": "In particular, Denoising Diffusion Probabilistic Models (often referred to as DDPMs or diffusion generative models) (Ho et al., 2020;Nichol & Dhariwal, 2021) and their continuous-time extension (Song et al., 2021b) both present a training objective that is more stable than precursors like generative adversarial nets (GANs) (Goodfellow et al., 2014) or energy-based models (EBMs) (Du et al., 2020).",
    "next": "In addition, diffusion generative models have shown to empirically outperform GANs in the image domain (Dhariwal & Nichol, 2021) and to suffer less from mode-seeking pathologies during training (Kodali et al., 2017).",
    "hard_negative": [
      52889459,
      52908831
    ],
    "easy_negative": [
      15383752,
      16897771,
      220445819
    ]
  },
  {
    "index": 527,
    "source_corpus_id": 7902640,
    "ref_id": "b21",
    "citation_corpus_id": 16299141,
    "start": 15676,
    "end": 15698,
    "title": "Pointer Sentinel Mixture Models",
    "abstract": "Recent neural network sequence models with softmax classifiers have achieved their best language modeling performance only with very large hidden states and large vocabularies. Even then they struggle to predict rare or unseen words even if the context makes the prediction unambiguous. We introduce the pointer sentinel mixture architecture for neural sequence models which has the ability to either reproduce a word from the recent context or produce a word from a standard softmax classifier. Our pointer sentinel-LSTM model achieves state of the art language modeling performance on the Penn Treebank (70.9 perplexity) while using far fewer parameters than a standard softmax LSTM. In order to evaluate how well language models can exploit longer contexts and deal with more realistic vocabularies and larger corpora we also introduce the freely available WikiText corpus. 1",
    "prev": "For machine translation, we use the extended DSL and construct candidate architectures incrementally using the RL generator without a ranking function.",
    "curr": "LANGUAGE MODELING USING RANDOM SEARCH WITH A RANKING FUNCTION\n\nFor evaluating architectures found during architecture search, we use the WikiText-2 dataset (Merity et al., 2017b).",
    "next": "When evaluating a proposed novel RNN cell c, we construct a two layer c-RNN with a 200 unit hidden size.",
    "hard_negative": [
      11212020,
      252796
    ],
    "easy_negative": [
      234345305,
      219304584,
      2002825
    ]
  },
  {
    "index": 528,
    "source_corpus_id": 263909107,
    "ref_id": "b66",
    "citation_corpus_id": 3693334,
    "start": 1863,
    "end": 1880,
    "title": "Visualizing the Loss Landscape of Neural Nets",
    "abstract": "Neural network training relies on our ability to find \"good\" minimizers of highly non-convex loss functions. It is well-known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and wellchosen training parameters (batch size, learning rate, optimizer) produce minimizers that generalize better. However, the reasons for these differences, and their effects on the underlying loss landscape, are not well understood. In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple \"filter normalization\" method that helps us visualize loss function curvature and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture affects the loss landscape, and how training parameters affect the shape of minimizers.",
    "prev": " analyze the connection between posterior quality and uncertainty quantification, delve into the impact of modes on the posterior, and explore methods for visualizing the posterior.Moreover, we uncover weight-space symmetries as a critical aspect for understanding the posterior.To this extent, we develop an in-depth assessment of the impact of both permutation and scaling symmetries that tend to obfuscate the Bayesian posterior.While the first type of transformation is known for duplicating modes, we explore the relationship between the latter and L2 regularization, challenging previous misconceptions.Finally, to help the community improve our understanding of the Bayesian posterior, we will release shortly the first large-scale checkpoint dataset, including thousands of real-world models, along with our codes.",
    "curr": "INTRODUCTION\n\nDespite substantial advancements in deep learning, Deep Neural Networks (DNNs) remain black box models.Various studies have sought to explore DNN loss landscapes (Li et al., 2018;Fort & Jastrzebski, 2019;Fort & Scherlis, 2019;Liu et al., 2022) to achieve a deeper understanding of these models.Recent works have, for instance, unveiled the interconnection of the modes obtained with Stochastic Gradient Descent (SGD) via narrow pathways that link pairs of modes, or through tunnels that connect multiple modes simultaneously (Garipov et al., 2018;Draxler et al., 2018).This mode connectivity primarily arises from scale and permutation invariances, which imply that numerous weights can represent the same exact function (e.g., Entezari et al.",
    "next": "(2022)).Several studies have delved into the relationship between these symmetries and the characteristics of the loss landscape (Entezari et al., 2022;Neyshabur et al., 2015;Brea et al., 2019).Our work investigates the connections between these symmetries and the distribution of DNN weights, a crucial aspect for uncertainty quantification.As shown in Figure 1, it is apparent that these symmetries also exert influence on DNN poster",
    "hard_negative": [
      4429876,
      16138044,
      17786716,
      16209268
    ],
    "easy_negative": [
      11233827,
      258170532,
      236772307
    ]
  },
  {
    "index": 531,
    "source_corpus_id": 209316097,
    "ref_id": "b1",
    "citation_corpus_id": 7771402,
    "start": 2049,
    "end": 2073,
    "title": "Abstract Meaning Representation for Sembanking",
    "abstract": "We describe Abstract Meaning Representation (AMR), a semantic representation language in which we are writing down the meanings of thousands of English sentences. We hope that a sembank of simple, whole-sentence semantic structures will spur new work in statistical natural language understanding and generation, like the Penn Treebank encouraged work on statistical parsing. This paper gives an overview of AMR and tools associated with it.",
    "prev": "So far, most of the existing methods focus on building statistical associations between textual inputs and semantic representations, e.g.",
    "curr": "using first-order logic (Manning et al., 1999) or other types of representations such as abstract meaning representation (Banarescu et al., 2013).",
    "next": "Recently, grounded language learning has gradually attracted attention in various domains, inspired by the hypothesis that early language learning was focused on problemsolving (Kirby & Hurford, 2002).",
    "hard_negative": [
      9936276,
      1575837,
      12183989,
      16273722,
      1987786,
      1658574,
      3545055,
      14810207,
      2486369,
      5634542,
      15351407,
      11573110,
      7785983
    ],
    "easy_negative": [
      11216810,
      257050894,
      219308302
    ]
  },
  {
    "index": 532,
    "source_corpus_id": 222133372,
    "ref_id": "b50",
    "citation_corpus_id": 3366315,
    "start": 16630,
    "end": 16634,
    "title": "Published as a conference paper at ICLR 2018 SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.Published as a conference paper at ICLR 2018\u2022 Lipschitz constant is the only hyper-parameter to be tuned, and the algorithm does not require intensive tuning of the only hyper-parameter for satisfactory performance. \u2022 Implementation is simple and the additional computational cost is small.",
    "prev": "Compared with the conditions stated in Section 2 (namely, that it is locally homogeneous with a symmetric Jacobian), our requirement on the denoiser is milder.",
    "curr": "One can train a nonexpansive D \u03c3 by constraining the Lipschitz constant of D \u03c3 via the spectral normalization, which is an active area of research in deep learning [51][52][53].",
    "next": "We can now state the theorems on ASYNC-RED.",
    "hard_negative": [
      5687613,
      18828233,
      3633127,
      14570343,
      11758569
    ],
    "easy_negative": [
      53081632,
      215768725,
      260335077
    ]
  },
  {
    "index": 536,
    "source_corpus_id": 262825568,
    "ref_id": "b48",
    "citation_corpus_id": 252715691,
    "start": 1769,
    "end": 1787,
    "title": "GLM-130B: AN OPEN BILINGUAL PRE-TRAINED MODEL",
    "abstract": "We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model at least as good as GPT-3 and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we face numerous unexpected technical and engineering challenges, particularly on loss spikes and disconvergence. In this paper, we introduce the training process of GLM-130B including its design choices, training strategies for both efficiency and stability, and engineering efforts. The resultant GLM-130B model offers significant outperformance over GPT-3 175B on a wide range of popular English benchmarks while the performance advantage is not observed in OPT-175B and BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN 3.0 260B-the largest Chinese language model-across related benchmarks. Finally, we leverage a unique scaling property of GLM-130B to reach INT4 quantization, without quantization aware training and with almost no performance loss, making it the first among 100B-scale models. More importantly, the property allows its effective inference on 4\u00d7RTX 3090 (24G) or 8\u00d7RTX 2080 Ti (11G) GPUs, the most ever affordable GPUs required for using 100B-scale models. The GLM-130B model weights are publicly accessible and its code, training logs, related toolkit, and lessons learned are open-sourced at https://github.comIn this work, we introduce the pre-training of a 100B-scale model-GLM-130B, in terms of engineering efforts, model design choices, training strategies for efficiency and stability, and quantization for affordable inference. As it has been widely realized that it is computationally unaffordable to empirically enumerate all possible designs for training 100B-scale LLMs, we present not only the successful part for training GLM-130B but also many of the failed options and lessons learned. Particularly, the training stability is the decisive factor in the success of training models of such a scale. Different from practices such as manually adjusting learning rates in OPT-175B and using embedding norm in the sacrifice of performance in BLOOM-176B, we experiment with various options and find the strategy of embedding gradient shrink can significantly stabilize the training of GLM-130B.Specifically, GLM-130B is a bilingual (English and Chinese) bidirectional dense model with 130 billion parameters, pre-trained over 400 billion tokens on a cluster of 96 NVIDIA DGX-A100 (8\u00d740G) GPU nodes between May 6 and July 3, 2022. Instead of using the GPT-style architecture, we adopt the General Language Model (GLM) algorithm (Du et al., 2022)  to leverage its bidirectional attention advantage and autoregressive blank infilling objective.Table 1summarizes the comparison between GLM-130B, GPT-3 and another two open-source efforts-OPT-175B and BLOOM-176B, as well as PaLM 540B (Chowdhery et al., 2022)-a 4\u00d7 larger model-as a reference.Altogether, the conceptual uniqueness and engineering efforts enable GLM-130B to exhibit performance that surpasses the level of GPT-3 on a wide range of benchmarks (in total 112 tasks) and also outperforms PaLM 540B in many cases, while outperformance over GPT-3 has not been observed in OPT-175B and BLOOM-176B (Cf.Figure 1 (a)). For zero-shot performance, GLM-130B is better than GPT-3 175B (+5.0%), OPT-175B (+6.5%), and BLOOM-176B (+13.0%) on LAMBADA (Paperno et al., 2016), and achieves 3\u00d7 better performance than GPT-3 on Big-bench-lite (Srivastava  et al., 2022). For the 5-shot MMLU (Hendrycks et al., 2021) tasks, it is better than GPT-3 175B (+0.9%) and BLOOM-176B (+12.7%). As a bilingual LLM also in Chinese, it offers significantly better results than ERNIE TITAN 3.0 260B (Wang et al., 2021)-the largest Chinese LLM-on 7 zero-shot CLUE (Xu et al., 2020) datasets (+24.26%) and 5 zero-shot FewCLUE  ones (+12.75%). Importantly, as summarized inFigure 1 (b), GLM-130B as an open model is associated with significantly less bias and generation toxicity than its 100B-scale counterparts.Finally, we design GLM-130B to empower as many people as possible to conduct 100B-scale LLM studies. First, instead of using 175B+ parameters as OPT and BLOOM, the 130B size is decided because such a size supports inference on a single A100 (8\u00d740G) server. Second, to further lower the GPU requirements, we quantize GLM-130B into INT4 precision without quantization aware training while OPT and BLOOM can only reach INT8. Due to a unique property of the GLM architecture, GLM-130B's INT4 quantization introduces negligible performance degradation, e.g., -0.74% on LAMBADA and even +0.05% on MMLU, making it still better than the uncompressed GPT-3. This enables GLM-130B's fast inference with performance guarantee on a server of 4\u00d7RTX 3090 (24G) or 8\u00d7RTX 2080 Ti (11G), the most ever affordable GPU required for using 100B-scale LLMs to date.We open-source the model checkpoints, code, training logs, related toolkits, and lessons learned.THE DESIGN CHOICES OF GLM-130BThe architecture of a machine learning model defines its inductive bias. However, it has been realized that it is computationally unaffordable to explore various architectural designs for LLMs. We introduce and explain the unique design choices of GLM-130B. 2.1 GLM-130B'S ARCHITECTURE GLM as Backbone. Most recent 100B-scale LLMs, such as GPT-3, PaLM, OPT, and BLOOM, follow the traditional GPT-style (Radford et al., 2019) architecture of decoder-only autoregressive language modeling. In GLM-130B, we instead make an attempt to explore the potential of a bidirectional GLM-General Language Model (Du et al., 2022)-as its backbone.GLM is a transformer-based language model that leverages autoregressive blank infilling as its training objective. Briefly, for a text sequence x = [x 1 , \u00b7 \u00b7 \u00b7 , x n ], text spans {s 1 , \u00b7 \u00b7 \u00b7 , s m } are sampled from it, each of which s i denotes a span of consecutive tokens [s i,1 , \u00b7 \u00b7 \u00b7 , s i,li ] and is replaced (i.e., corrupted) with a single mask token to form x corrupt . The model is asked to recover them autoregressively. To allow interactions between corrupted spans, their visibility to each other is decided by a He. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters.",
    "prev": "-rank adaptation (QA-LoRA) algorithm.The motivation lies in the imbalanced degrees of freedom of quantization and adaptation, and the solution is to use group-wise operators which increase the degree of freedom of quantization meanwhile decreasing that of adaptation.QA-LoRA is easily implemented with a few lines of code, and it equips the original LoRA with two-fold abilities: (i) during fine-tuning, the LLM's weights are quantized (e.g., into INT4) to reduce time and memory usage; (ii) after fine-tuning, the LLM and auxiliary weights are naturally integrated into a quantized model without loss of accuracy.We apply QA-LoRA to the LLaMA and LLaMA2 model families and validate its effectiveness in different fine-tuning datasets and downstream scenarios.Code will be made available at https://github.com/yuhuixu1993/qa-lora.",
    "curr": "INTRODUCTION\n\nRecently, large language models (LLMs) (Brown et al., 2020;Scao et al., 2022;Zhang et al., 2022;Touvron et al., 2023a;Chowdhery et al., 2022;OpenAI, 2023;Zeng et al., 2023) have shown unprecedented performance across a wide range of language understanding tasks (Wei et al., 2022a) and served as the foundation of state-of-the-art chat systems (Bubeck et al., 2023).The diversity of real-world applications calls for a pipeline in which LLMs can be fine-tuned to fit different scenarios and quantized to be deployed onto edge devices (e.g., mobile phones), and the key issue is to get rid of the heavy computational burden brought by the large number of parameters of LLMs.",
    "next": "There are two lines of research for this purpose.The first one is parameter-efficient fine-tuning (PEFT) (Houlsby et al., 2019;Li & Liang, 2021;Liu et al., 2021;He et al., 2022;Hu et al., 2021) which introduced a small number of learnable parameters while keeping most pre-trained parameters unchanged.Among them, low-rank adaptation (LoRA) (Hu et al., 2021), a popular PEFT algorithm, proposed to fine-tune low-rank matrices to complement the pre-trained weights.Despite the comparable performanc",
    "hard_negative": [
      3782112,
      215745536,
      202539496,
      237416585
    ],
    "easy_negative": [
      7371546,
      259108774,
      236999865
    ]
  },
  {
    "index": 538,
    "source_corpus_id": 252715691,
    "ref_id": "b9",
    "citation_corpus_id": 237416585,
    "start": 11827,
    "end": 11845,
    "title": "Published as a conference paper at ICLR 2022 FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS",
    "abstract": "This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning-finetuning language models on a collection of datasets described via instructions-substantially improves zeroshot performance on unseen tasks.",
    "prev": "To improve FFNs in Transformer, we pick GLU with the GeLU (Hendrycks & Gimpel, 2016) activation as the replacement.",
    "curr": "2.2 GLM-130B'S PRE-TRAINING SETUP Inspired by recent works (Aribandi et al., 2022;Wei et al., 2022a;Sanh et al., 2022), the GLM-130B pre-training objective includes not only the self-supervised GLM autoregressive blank infilling) but also multi-task learning for a small portion of tokens.",
    "next": "This is expected to help boost its downstream zero-shot performance.",
    "hard_negative": [
      210838924,
      220045465,
      102353817,
      52055325,
      52057510,
      202540839,
      3432876,
      195218742,
      9586240,
      182953152,
      3626819,
      220364230,
      11816014,
      207756753,
      165163607,
      233231453,
      10766958,
      85464175,
      47018994,
      215768182,
      219165306,
      85504763
    ],
    "easy_negative": [
      53236219,
      69370873,
      252819121
    ]
  },
  {
    "index": 541,
    "source_corpus_id": 52892477,
    "ref_id": "b1",
    "citation_corpus_id": 900029,
    "start": 1151,
    "end": 1172,
    "title": "NAACL-HLT 2012 Workshop: Will We Ever Really Replace the N-gram Model? On the Future of Language Modeling for HLT, pages 20-28, Deep Neural Network Language Models",
    "abstract": "In recent years, neural network language models (NNLMs) have shown success in both peplexity and word error rate (WER) compared to conventional n-gram language models. Most NNLMs are trained with one hidden layer. Deep neural networks (DNNs) with more hidden layers have been shown to capture higher-level discriminative information about input features, and thus produce better networks. Motivated by the success of DNNs in acoustic modeling, we explore deep neural network language models (DNN LMs) in this paper. Results on a Wall Street Journal (WSJ) task demonstrate that DNN LMs offer improvements over a single hidden layer NNLM. Furthermore, our preliminary results are competitive with a model M language model, considered to be one of the current state-of-the-art techniques for language modeling.",
    "prev": "On the WIKITEXT-103 benchmark we achieve 18.7 perplexity, an improvement of 10.5 perplexity compared to the previously best published result and on the BILLION WORD benchmark, we achieve 23.02 perplexity.",
    "curr": "1\n\nINTRODUCTION\n\nLanguage modeling is a basic task in natural language processing, with many applications such as speech recognition (Arisoy et al., 2012) and statistical machine translation (Schwenk et al., 2012;Vaswani et al., 2013;Baltescu & Blunsom, 2015).",
    "next": "Recently, much progress has been made by neural methods (Bengio et al., 2003;Mikolov et al., 2010) based on LSTMs (J\u00f3zefowicz et al., 2016), gated convolutional networks (Dauphin et al., 2017) and self-attentional networks (Al-Rfou et al., 2018).",
    "hard_negative": [
      1364780,
      12469208,
      2618014
    ],
    "easy_negative": [
      1614922,
      774866,
      27838901
    ]
  },
  {
    "index": 543,
    "source_corpus_id": 247596648,
    "ref_id": "b24",
    "citation_corpus_id": 3144218,
    "start": 8028,
    "end": 8049,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "For generalizing across parametric variations of a single morphology, various approaches have been proposed like using a learned hardware embedding (Chen et al., 2018), meta-learning for policy adaptation (Al-Shedivat et al., 2017;Ghadirzadeh et al., 2021), kinematics randomization (Exarchos et al., 2020), and dynamics randomization (Peng et al., 2018).",
    "curr": "In case of multiple different morphologies, one approach to tackle the challenge of differences in action and state spaces is to leverage Graph Neural Networks (Scarselli et al., 2008;Kipf & Welling, 2017;.",
    "next": "Wang et al.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      233365016,
      849597,
      231854181
    ]
  },
  {
    "index": 546,
    "source_corpus_id": 219530969,
    "ref_id": "b2",
    "citation_corpus_id": 3517962,
    "start": 2457,
    "end": 2460,
    "title": "Published as a conference paper at ICLR 2018 DISTRIBUTED DISTRIBUTIONAL DETERMINISTIC POLICY GRADIENTS",
    "abstract": "This work adopts the very successful distributional perspective on reinforcement learning and adapts it to the continuous control setting. We combine this within a distributed framework for off-policy learning in order to develop what we call the Distributed Distributional Deep Deterministic Policy Gradient algorithm, D4PG. We also combine this technique with a number of additional, simple improvements such as the use of N -step returns and prioritized experience replay. Experimentally we examine the contribution of each of these individual components, and show how they interact, as well as their combined contributions. Our results show that across a wide variety of simple control tasks, difficult manipulation tasks, and a set of hard obstacle-based locomotion tasks the D4PG algorithm achieves state of the art performance.arXiv:1804.08617v1 [cs.LG] 23 Apr 2018Published as a conference paper at ICLR 2018 experience, which we implement using the ApeX framework(Horgan et al., 2018). This results in significant savings in terms of wall-clock time for difficult control tasks. We will also introduce a number of small improvements to the DDPG algorithm, and in our experiments will show the individual contributions of each component. Finally, this algorithm, which we call the Distributed Distributional DDPG algorithm (D4PG), obtains state-of-the-art performance across a wide variety of control tasks, including hard manipulation and locomotion tasks.",
    "prev": "Under review.",
    "curr": "Introduction\n\nReinforcement learning (RL) algorithms have recently demonstrated impressive success in learning behaviors for a variety of sequential decision-making tasks [3,24,42].",
    "next": "Virtually all of these demonstrations have relied on highly-frequent online access to the environment, with the RL algorithms often interleaving each update to the policy with additional experience collection of that policy acting in the environment.",
    "hard_negative": [
      13022595,
      3463260
    ],
    "easy_negative": [
      258832605,
      9289604,
      12307813
    ]
  },
  {
    "index": 548,
    "source_corpus_id": 259096096,
    "ref_id": "b37",
    "citation_corpus_id": 213695995,
    "start": 2481,
    "end": 2484,
    "title": "Published as a conference paper at ICLR 2020 FEATURE INTERACTION INTERPRETABILITY: A CASE FOR EXPLAINING AD-RECOMMENDATION SYSTEMS VIA NEURAL INTERACTION DETECTION",
    "abstract": "Recommendation is a prevalent application of machine learning that affects many users; therefore, it is important for recommender models to be accurate and interpretable. In this work, we propose a method to both interpret and augment the predictions of black-box recommender systems. In particular, we propose to interpret feature interactions from a source recommender model and explicitly encode these interactions in a target recommender model, where both source and target models are black-boxes. By not assuming the structure of the recommender system, our approach can be used in general settings. In our experiments, we focus on a prominent use of machine learning recommendation: ad-click prediction. We found that our interaction interpretations are both informative and predictive, e.g., significantly outperforming existing recommender models. What's more, the same approach to interpret interactions can provide new insights into domains even beyond recommendation, such as text and image classification.",
    "prev": "Introduction\n\nA core research question in multimodal learning is to understand the nature of multimodal interactions across modalities in the context of a task: the emergence of new task-relevant information during learning from both modalities that was not present in either modality alone [6,65].",
    "curr": "In settings where labeled multimodal data is abundant, the study of multimodal interactions has inspired advances in theoretical analysis [1,43,66,84,94] and representation learning [51, 76,91,104] in language and vision [2], multimedia [9], healthcare [53], and robotics [57].",
    "next": "In this paper, we study the problem of interaction quantification in a setting where there is only unlabeled multimodal data D M = {(x 1 , x 2 )} but some labeled unimodal data D i = {(x i , y)} collected separately for each modality.",
    "hard_negative": [
      990233,
      25717172,
      49214673,
      1428702
    ],
    "easy_negative": [
      13320514,
      252624592,
      2957867
    ]
  },
  {
    "index": 558,
    "source_corpus_id": 240354066,
    "ref_id": "b12",
    "citation_corpus_id": 219965819,
    "start": 2855,
    "end": 2858,
    "title": "LIPSCHITZ RECURRENT NEURAL NETWORKS",
    "abstract": "Differential equations are a natural choice for modeling recurrent neural networks because they can be viewed as dynamical systems with a driving input. In this work, we propose a recurrent unit that describes the hidden state's evolution with two parts: a well-understood linear component plus a Lipschitz nonlinearity. This particular functional form simplifies stability analysis, which enables us to provide an asymptotic stability guarantee. Further, we demonstrate that Lipschitz recurrent units are more robust with respect to perturbations. We evaluate our approach on a range of benchmark tasks, and we show it outperforms existing recurrent units.",
    "prev": "Since LRDs are perhaps the foremost challenge for sequence models, all standard model families such as continuous-time models (CTMs), RNNs, CNNs, and Transformers include many specialized variants designed to address them.",
    "curr": "Modern examples include orthogonal and Lipschitz RNNs [1,13] to combat vanishing gradients, dilated convolutions to increase context size [3,28], and an increasingly vast family of efficient Transformers that reduce the quadratic dependence on sequence length [8,22].",
    "next": "Despite being designed for LRDs, these solutions still perform poorly on challenging benchmarks such as LRA [40] or raw audio classification [18].",
    "hard_negative": [
      58981389,
      3331622,
      604334,
      67855286
    ],
    "easy_negative": [
      7718887,
      8743015,
      59553516
    ]
  },
  {
    "index": 559,
    "source_corpus_id": 108306725,
    "ref_id": "b9",
    "citation_corpus_id": 6715185,
    "start": 35139,
    "end": 35165,
    "title": "Published as a conference paper at ICLR 2016 NEURAL PROGRAMMER: INDUCING LATENT PROGRAMS WITH GRADIENT DESCENT",
    "abstract": "Deep neural networks have achieved impressive supervised classification performance in many tasks including image recognition, speech recognition, and sequence to sequence learning. However, this success has not been translated to applications like question answering that may involve complex arithmetic and logic reasoning. A major limitation of these models is in their inability to learn even simple arithmetic and logic operations. For example, it has been shown that neural networks fail to learn to add two binary numbers reliably. In this work, we propose Neural Programmer, a neural network augmented with a small set of basic arithmetic and logic operations that can be trained end-to-end using backpropagation. Neural Programmer can call these augmented operations over several steps, thereby inducing compositional programs that are more complex than the built-in operations. The model learns from a weak supervision signal which is the result of execution of the correct program, hence it does not require expensive annotation of the correct program itself. The decisions of what operations to call, and what data segments to apply to are inferred by Neural Programmer. Such decisions, during training, are done in a differentiable fashion so that the entire network can be trained jointly by gradient descent. We find that training the model is difficult, but it can be greatly improved by adding random noise to the gradient. On a fairly complex synthetic table-comprehension dataset, traditional recurrent networks and attentional models perform poorly while Neural Programmer typically obtains nearly perfect accuracy. * Work done during an internship at Google.",
    "prev": "Neural Turing Machine (NTM) (Graves et al., 2014; enables general-purpose neural problem solving such as sorting by introducing an external memory that mimics the execution of Turing Machine.",
    "curr": "Neural program induction and synthesis (Neelakantan et al., 2016;Reed & De Freitas, 2016;Kaiser & Sutskever, 2016;Parisotto et al., 2017;Devlin et al., 2017;Bunel et al., 2018;Sun et al., 2018) are recently introduced to solve problems by synthesizing computer programs with neural augmentations.",
    "next": "Some works tackle the issue of the systematical generalization by introducing extra supervision (Cai et al., 2017).",
    "hard_negative": [
      14472576,
      1174836,
      1969092,
      9027681,
      11171811,
      216034672,
      340852
    ],
    "easy_negative": [
      15168504,
      1891955,
      252186404
    ]
  },
  {
    "index": 560,
    "source_corpus_id": 257039090,
    "ref_id": "b12",
    "citation_corpus_id": 173990158,
    "start": 7470,
    "end": 7488,
    "title": "Multimodal Transformer for Unaligned Multimodal Language Sequences",
    "abstract": "Human language is often multimodal, which comprehends a mixture of natural language, facial gestures, and acoustic behaviors. However, two major challenges in modeling such multimodal human language time-series data exist: 1) inherent data non-alignment due to variable sampling rates for the sequences from each modality; and 2) long-range dependencies between elements across modalities. In this paper, we introduce the Multimodal Transformer (MulT) to generically address the above issues in an end-to-end manner without explicitly aligning the data. At the heart of our model is the directional pairwise crossmodal attention, which attends to interactions between multimodal sequences across distinct time steps and latently adapt streams from one modality to another. Comprehensive experiments on both aligned and non-aligned multimodal time-series show that our model outperforms state-of-the-art methods by a large margin. In addition, empirical analysis suggests that correlated crossmodal signals are able to be captured by the proposed crossmodal attention mechanism in MulT.",
    "prev": "These datasets enable us to train a multimodal model y = f (x 1 , x 2 ; \u03b8) which we are interested in visualizing.",
    "curr": "Modern parameterizations of multimodal models f are typically black-box neural networks, such as multimodal transformers (Hendricks et al., 2021;Tsai et al., 2019) and pretrained models (Li et al., 2019;Lu et al., 2019).",
    "next": "How can we visualize and understand the internal modeling of multimodal information and interactions in these models?",
    "hard_negative": [
      13747425,
      51868869,
      51991738,
      14068874,
      46895984,
      5068376,
      1957433,
      23583643,
      52892477
    ],
    "easy_negative": [
      248376935,
      208202099,
      1922162
    ]
  },
  {
    "index": 562,
    "source_corpus_id": 263608118,
    "ref_id": "b24",
    "citation_corpus_id": 253098274,
    "start": 2169,
    "end": 2187,
    "title": "SUPER-NATURALINSTRUCTIONS: Generalization via Declarative Instructions on 1600+ NLP Tasks",
    "abstract": "How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce SUPER-NATURALINSTRUCTIONS, 1 a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructionstraining models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones. Furthermore, we build Tk-INSTRUCT, a transformer model trained to follow a variety of incontext instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-INSTRUCT outperforms existing instruction-following models such as Instruct-GPT by over 9% on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models. 2",
    "prev": "es the attention matrix with linear complexity via kernel-based linear attention, then creates a sparse approximation to the full attention matrix with a top-k selection to perform a sparse attention operation.For language modeling tasks (Wikitext2), previous linear and sparse attention methods show a roughly two-fold worse perplexity scores over the quadratic OPT-125M baseline, while SEA achieves an even better perplexity than OPT-125M, using roughly half as much memory as OPT-125M.Moreover, SEA maintains an interpretable attention matrix and can utilize knowledge distillation to lower the complexity of existing pretrained transformers.We believe that our work will have a large practical impact, as it opens the possibility of running large transformers on resource-limited devices with less memory.",
    "curr": "INTRODUCTION\n\nThe transformer (Vaswani et al., 2017) architecture has revolutionized various fields of artificial intelligence, such as natural language understanding (Touvron et al., 2023;Wang et al., 2022) and computer vision (Dosovitskiy et al., 2021) due to its ability to learn pairwise relationships between all T tokens in a given sequence (O(T 2 )).This has ushered in the era of large transformer-based foundation models with impressive generalization abilities (Brown et al., 2020;Chiang et al., 2023).However, since the transformer's attention mechanism comes with a quadratic space and time complexity, it becomes untenable for handling long sequences which is essential for tasks such as dialogue generation (Chen et al., 2023).To overcome this limitation, previous works have suggested approaches with linear complexity by using static or dynamic sparse attention patterns (Beltagy et al., 2020;Zaheer et al., 2020;Tay et al., 2020a;Kitaev et al., 2020;Tay et al., 2020b;Liu et al., 2021), or by replacing quadratic attention with kernel or low-rank approximations (Choromanski et al., 2021;Chen et al., 2021;Qin et al., 2022).",
    "next": "However, despite their promising aspects, previous linear attent",
    "hard_negative": [
      244478674,
      246485605,
      6645623
    ],
    "easy_negative": [
      12632594,
      248780264,
      37346375
    ]
  },
  {
    "index": 565,
    "source_corpus_id": 51969884,
    "ref_id": "b4",
    "citation_corpus_id": 5590763,
    "start": 28291,
    "end": 28309,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "\u2212E(y, h; x) = f i xiw x if j yjw y jf k h k w h kf + k w h k h k + j w y j yj = x T W x \u2022 y T W y \u2022 h T W h 1 + h T w h + y T w y(21)\nSetting aside of bias terms, the I \u00d7 J \u00d7 K parameter tensor of unfactored Higher-Order Boltzmann Machines is replaced with three matrices, W x \u2208 R I\u00d7F , W y \u2208 R J\u00d7F , and W h \u2208 R K\u00d7F .",
    "curr": "D.3 MULTIPLICATIVE INTEGRATION WITH RECURRENT NEURAL NETWORKS\n\nMost of recurrent neural networks, including vanilla RNNs, Long Short Term Memory networks (Hochreiter & Schmidhuber, 1997) and Gated Recurrent Units (Cho et al., 2014), share a common expression as follows:\n\u03c6(Wx + Uh + b)(22)\nwhere \u03c6 is a non-linear function, W \u2208 R d\u00d7n , x \u2208 R n , U \u2208 R d\u00d7m , h \u2208 R m , and b \u2208 R d is a bias vector.",
    "next": "Note that, usually, x is an input state vector and h is an hidden state vector in recurrent neural networks.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      254877046,
      10334488,
      9228040
    ]
  },
  {
    "index": 570,
    "source_corpus_id": 252873467,
    "ref_id": "b14",
    "citation_corpus_id": 233289412,
    "start": 3502,
    "end": 3523,
    "title": "Editing Factual Knowledge in Language Models",
    "abstract": "The factual knowledge acquired during pretraining and stored in the parameters of Language Models (LMs) can be useful in downstream tasks (e.g., question answering or textual inference). However, some facts can be incorrectly induced or become obsolete over time. We present KNOWLEDGEEDITOR, a method which can be used to edit this knowledge and, thus, fix 'bugs' or unexpected predictions without the need for expensive retraining or fine-tuning. Besides being computationally efficient, KNOWLEDGEEDITOR does not require any modifications in LM pretraining (e.g., the use of meta-learning). In our approach, we train a hyper-network with constrained optimization to modify a fact without affecting the rest of the knowledge; the trained hyper-network is then used to predict the weight update at test time. We show KNOWL-EDGEEDITOR's efficacy with two popular architectures and knowledge-intensive tasks: i) a BERT model fine-tuned for fact-checking, and ii) a sequence-to-sequence BART model for question answering. With our method, changing a prediction on the specific wording of a query tends to result in a consistent change in predictions also for its paraphrases. We show that this can be further encouraged by exploiting (e.g., automatically-generated) paraphrases during training. Interestingly, our hyper-network can be regarded as a 'probe' revealing which components need to be changed to manipulate factual knowledge; our analysis shows that the updates tend to be concentrated on a small subset of components. 1",
    "prev": "To that end, several knowledge-editing methods have been proposed to insert new memories directly into specific model parameters.",
    "curr": "The approaches include constrained fine-tuning (Zhu et al., 2020), hypernetwork knowledge editing (De Cao et al., 2021;Hase et al., 2021;Mitchell et al., 2021;, and rank-one model editing (Meng et al., 2022).",
    "next": "However, this body of work is typically limited to updating at most a few dozen facts; a recent study evaluates on a maximum of 75 (Mitchell et al., 2022) whereas others primarily focus on single-edit cases.",
    "hard_negative": [
      208117506,
      4711425,
      202541078,
      56657817,
      219531164,
      158046772,
      235254582,
      204960716,
      11816014,
      86611921,
      221507798
    ],
    "easy_negative": [
      202766921,
      14274642,
      224706002
    ]
  },
  {
    "index": 573,
    "source_corpus_id": 71145737,
    "ref_id": "b17",
    "citation_corpus_id": 49868626,
    "start": 27345,
    "end": 27363,
    "title": "META-LEARNING WITH LATENT EMBEDDING OPTIMIZATION",
    "abstract": "Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems. However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes. We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this lowdimensional latent space. The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters. Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks. Further analysis indicates LEO is able to capture uncertainty in the data, and can perform adaptation more effectively by optimizing in latent space. arXiv:1807.05960v3 [cs.LG]",
    "prev": "That said, in the past two years, there have been several other methods proposed for few-shot learning.",
    "curr": "Some bear similarity with MAML and correspond to a meta-learner trained to quickly adapt its parameters to various novel tasks (Ravi & Larochelle, 2017;Munkhdalai & Yu, 2017;Rusu et al., 2019;Yoon et al., 2018).",
    "next": "Others relate to Prototypical Networks by learning a data representation as well as a compact representation for a classifier of data under that representation (Bertinetto et al., 2019;Gidaris & Komodakis, 2018;Oreshkin et al., 2018;Gidaris & Komodakis, 2018).",
    "hard_negative": [
      3507990,
      3484654
    ],
    "easy_negative": [
      53234825,
      8197803,
      40328883
    ]
  },
  {
    "index": 574,
    "source_corpus_id": 238634584,
    "ref_id": "b30",
    "citation_corpus_id": 211842237,
    "start": 5855,
    "end": 5879,
    "title": "Published as a conference paper at ICLR 2020 DIRECTIONAL MESSAGE PASSING FOR MOLECULAR GRAPHS",
    "abstract": "Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes). They do not, however, consider the spatial direction from one atom to another, despite directional information playing a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions and spherical harmonics to construct theoretically well-founded, orthogonal representations that achieve better performance than the currently prevalent Gaussian radial basis representations while using fewer than 1 /4 of the parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 76 % on MD17 and by 31 % on QM9. Our implementation is available online. 1 1 https://www.daml.in.tum.de/dimenet arXiv:2003.03123v2 [cs.LG] 5 Apr 2022Published as a conference paper at ICLR 2020 embeddings are equivariant with respect to the above transformations since the directions move with the molecule. Hence, they preserve the relative directional information between neighboring atoms. We propose to let message embeddings interact based on the distance between atoms and the angle between directions. Both distances and angles are invariant to translation, rotation, and inversion of the molecule, as required. Additionally, we show that the distance and angle can be jointly represented in a principled and effective manner by using spherical Bessel functions and spherical harmonics. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet can learn both molecular properties and atomic forces. It is twice continuously differentiable and solely based on the atom types and coordinates, which are essential properties for performing molecular dynamics simulations. DimeNet outperforms previous GNNs on average by 76 % on MD17 and by 31 % on QM9. Our paper's main contributions are:",
    "prev": "The Open Catalyst Project (OCP) provides a platform for comparing different architectures by predicting energies and forces from the periodic structure of catalytic surfaces (Chanussot et al., 2021).",
    "curr": "Our encoder and decoder PGNNs directly use GNN architectures developed for the OCP (Klicpera et al., 2020b;Godwin et al., 2021), which are also closely related to SE(3) equivariant networks (Thomas et al., 2018;Fuchs et al., 2020).",
    "next": "Quantum mechanical search of stable materials.",
    "hard_negative": [
      65455367,
      3144218,
      85457862,
      21731691,
      7060599
    ],
    "easy_negative": [
      218900793,
      227905197,
      26816254
    ]
  },
  {
    "index": 576,
    "source_corpus_id": 3518190,
    "ref_id": "b0",
    "citation_corpus_id": 11212020,
    "start": 1453,
    "end": 1475,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "We demonstrate our model on two widely used datasets and two language pairs, reporting BLEU scores up to 32.8, without using even a single parallel sentence at training time.",
    "curr": "INTRODUCTION\n\nThanks to recent advances in deep learning (Sutskever et al., 2014;Bahdanau et al., 2015) and the availability of large-scale parallel corpora, machine translation has now reached impressive performance on several language pairs .",
    "next": "However, these models work very well only when provided with massive amounts of parallel data, in the order of millions of parallel sentences.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      28503960,
      18501518,
      219306067
    ]
  },
  {
    "index": 577,
    "source_corpus_id": 239009574,
    "ref_id": "b22",
    "citation_corpus_id": 213085920,
    "start": 3232,
    "end": 3236,
    "title": "Published as a conference paper at ICLR 2020 STRATEGIES FOR PRE-TRAINING GRAPH NEURAL NETWORKS",
    "abstract": "Many applications of machine learning require a model to make accurate predictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that na\u00efve strategies, which pre-train GNNs at the level of either entire graphs or individual nodes, give limited improvement and can even lead to negative transfer on many downstream tasks. In contrast, our strategy avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction. * Equal contribution. Project website, data and code: Attribute Masking Supervised Attribute Prediction Structural Similarity Prediction Structure prediction Context Prediction (b) Categorization of our pre-training methods Graph space Node space Graph embeddings Node embeddings Linear classifier Figure 1: (a.i) When only node-level pre-training is used, nodes of different shapes (semantically different nodes) can be well separated, however, node embeddings are not composable, and thus resulting graph embeddings (denoted by their classes, + and \u2212) that are created by pooling node-level embeddings are not separable. (a.ii) With graph-level pre-training only, graph embeddings are well separated, however the embeddings of individual nodes do not necessarily capture their domainspecific semantics. (a.iii) High-quality node embeddings are such that nodes of different types are well separated, while at the same time, the embedding space is also composable. This allows for accurate and robust representations of entire graphs and enables robust transfer of pre-trained models to a variety of downstream tasks. (b) Categorization of pre-training methods for GNNs. Crucially, our methods, i.e., Context Prediction, Attribute Masking, and graph-level supervised pre-training (Supervised Attribute Prediction) enable both node-level and graph-level pre-training.matter of increasing the number of labeled pre-training datasets that are from the same domain as the downstream task. Instead, it requires substantial domain expertise to carefully select examples and target labels that are correlated with the downstream task of interest. Otherwise, the transfer of knowledge from related pre-training tasks to a new downstream task can harm generalization, which is known as negative transfer(Rosenstein et al., 2005)and significantly limits the applicability and reliability of pre-trained models.Present work. Here, we focus on pre-training as an approach to transfer learning in Graph Neural Networks (GNNs)(Kipf & Welling, 2017;Hamilton et al., 2017a;Ying et al., 2018b;Xu et al., 2019;2018)for graph-level property prediction. Our work presents two key contributions.(1) We conduct the first systematic large-scale investigation of strategies for pre-training GNNs. For that, we build two large new pre-training datasets, which we share with the community: a chemistry dataset with 2 million graphs and a biology dataset with 395K graphs. We also show that large domain-specific datasets are crucial to investigate pre-training and that existing downstream benchmark datasets are too small to evaluate models in a statistically reliable way.(2) We develop an effective pretraining strategy for GNNs and demonstrate its effectiveness and its ability for out-of-distribution generalization on hard transfer-learning problems.",
    "prev": "Falling broadly into the second category, our paper studies self-supervised molecular representation learning by leveraging the consistency between 3D geometry and 2D topology.",
    "curr": "Motivated by the prominent success of the pretraining-finetuning pipeline [17], unsupervisedly pretrained graph neural networks for molecules yields promising performance on downstream tasks and becomes increasingly popular [42,54,82,90,103,104].",
    "next": "The key to pre-training lies in finding an effective proxy task (i.e., training objective) to leverage the power of large unlabeled datasets.",
    "hard_negative": [
      6628106,
      52877454,
      3144218,
      3626819,
      3292002,
      52895589,
      52967399
    ],
    "easy_negative": [
      226300126,
      1406849,
      39705974
    ]
  },
  {
    "index": 578,
    "source_corpus_id": 241035330,
    "ref_id": "b11",
    "citation_corpus_id": 2381275,
    "start": 2402,
    "end": 2424,
    "title": "The LAMBADA dataset: Word prediction requiring a broad discourse context *",
    "abstract": "We introduce LAMBADA, a dataset to evaluate the capabilities of computational models for text understanding by means of a word prediction task. LAMBADA is a collection of narrative passages sharing the characteristic that human subjects are able to guess their last word if they are exposed to the whole passage, but not if they only see the last sentence preceding the target word. To succeed on LAM-BADA, computational models cannot simply rely on local context, but must be able to keep track of information in the broader discourse. We show that LAMBADA exemplifies a wide range of linguistic phenomena, and that none of several state-ofthe-art language models reaches accuracy above 1% on this novel benchmark. We thus propose LAMBADA as a challenging test set, meant to encourage the development of new models capable of genuine understanding of broad context in natural language text. * Denis and Germ\u00e1n share first authorship. Marco, Gemma, and Raquel share senior authorship.",
    "prev": "Introduction\n\nLarge language models (LMs) such as GPT-3 (Brown et al., 2020, Lieber et al., 2021, Radford et al., 2019, Wang and Komatsuzaki, 2021 are pretrained on massive text corpora to predict the next word given previous words.",
    "curr": "They demonstrate the surprising ability to do in-context learning, where an LM \"learns\" to do a task simply by conditioning on a prompt containing input-output pairs, achieving SOTA results on LAMBADA (Paperno et al., 2016) and TriviaQA (Joshi et al., 2017) tasks (18% and 3% over previous SOTA (Brown et al., 2020)).",
    "next": "For example, consider the task of predicting nationalities from names.",
    "hard_negative": [
      14915449,
      13055268,
      14715110,
      11212020,
      2135897,
      2100831
    ],
    "easy_negative": [
      218974164,
      274239,
      250141225
    ]
  },
  {
    "index": 585,
    "source_corpus_id": 238419211,
    "ref_id": "b19",
    "citation_corpus_id": 216867841,
    "start": 2364,
    "end": 2383,
    "title": "Named Entity Recognition without Labelled Data: A Weak Supervision Approach",
    "abstract": "Named Entity Recognition (NER) performance often degrades rapidly when applied to target domains that differ from the texts observed during training. When in-domain labelled data is available, transfer learning techniques can be used to adapt existing NER models to the target domain. But what should one do when there is no hand-labelled data for the target domain? This paper presents a simple but powerful approach to learn NER models in the absence of labelled data through weak supervision. The approach relies on a broad spectrum of labelling functions to automatically annotate texts from the target domain. These annotations are then merged together using a hidden Markov model which captures the varying accuracies and confusions of the labelling functions. A sequence labelling model can finally be trained on the basis of this unified annotation. We evaluate the approach on two English datasets (CoNLL 2003 and news articles from Reuters and Bloomberg) and demonstrate an improvement of about 7 percentage points in entity-level F 1 scores compared to an out-of-domain neural NER model.",
    "prev": "s.Moreover, we provide a theoretically-principled test of the distinguishability of PLRM for unseen labels, along with a generalization bound.On both image and text classification tasks as well as an industrial advertising application, we demonstrate the advantages of PLRM by outperforming baselines by a margin of 2%-9%.",
    "curr": "INTRODUCTION\n\nOne of the greatest bottlenecks of using modern machine learning models is the need for substantial amounts of manually-labeled training data.In real-world applications, such manual annotations are typically time-consuming, labor-intensive and static.To reduce the efforts of annotation, researchers have proposed Weak Supervision (WS) frameworks (Ratner et al., 2016;2018;2019;Fu et al., 2020) for synthesizing labels from multiple weak supervision sources, e.g., heuristics, knowledge bases, or pre-trained classifiers.These frameworks have been widely applied on various machine learning tasks (Dunnmon et al., 2020;Fries et al., 2021;Safranchik et al., 2020;Lison et al., 2020;Zhou et al., 2020;Hooper et al., 2021;Zhan et al., 2019;Varma et al., 2019) and industrial data (Bach et al., 2019).Among them, data programming (Ratner et al., 2016), one representative example that generalizes many approaches in the literature, represents weak supervision sources as labeling functions (LFs) and synthesizes training labels using Probabilistic Graphical Model (PGM).",
    "next": "Given both the increasing popularity of WS and the general increase in open-source availability of machine learning models and tools, there is a rising tide of available supervision sources that WS frameworks and practitioners could potentially leverage, including pre-trained machine learning models or prediction APIs (Chen et al., 2020;d'Andrea & Mintz, 2019;Yao et al., 2017).However, existing WS frameworks only utilize weak supervision sources with the same label space as the target task.This incompatibility largely limits the scope of usable sources, necessitating manual effort from domain experts to pr",
    "hard_negative": [
      5825949,
      52010788,
      48352816,
      2570492,
      1957433,
      15978939,
      3626819,
      16633800,
      174799702,
      3003995,
      52967399,
      52012533
    ],
    "easy_negative": [
      259376714,
      9701336,
      5943646
    ]
  },
  {
    "index": 588,
    "source_corpus_id": 248887351,
    "ref_id": "b16",
    "citation_corpus_id": 9192723,
    "start": 13304,
    "end": 13323,
    "title": "Constructing Datasets for Multi-hop Reading Comprehension Across Documents",
    "abstract": "Most Reading Comprehension methods limit themselves to queries which can be answered using a single sentence, paragraph, or document. Enabling models to combine disjoint pieces of textual evidence would extend the scope of machine comprehension methods, but currently there exist no resources to train and test this capability. We propose a novel task to encourage the development of models for text understanding across multiple documents and to investigate the limits of existing methods. In our task, a model learns to seek and combine evidence -effectively performing multi-hop (alias multi-step) inference. We devise a methodology to produce datasets for this task, given a collection of query-answer pairs and thematically linked documents. Two datasets from different domains are induced, 1 and we identify potential pitfalls and devise circumvention strategies. We evaluate two previously proposed competitive models and find that one can integrate information across documents. However, both models struggle to select relevant information, as providing documents guaranteed to be relevant greatly improves their performance. While the models outperform several strong baselines, their best accuracy reaches 42.9% compared to human performance at 74.0% -leaving ample room for improvement.",
    "prev": "To this end, we evaluated LLMs from the Gopher family in a 5-shot 1 setting on a larger set of 50 tasks that touch on different aspects of logical reasoning and vary in terms of the number of reasoning steps required, presence or absence of negation, whether the relevant context information was provided, and whether the model is required to evaluate the accuracy of multiple choices or generate the answer among others.",
    "curr": "The additional tasks were collected from six sources: bAbI (Weston et al., 2015), BigBench (Ghazal et al., 2017), AAC (Betz et al., 2020), Jeopardy (Tunguz, 2019), Proof Writer (Tafjord et al., 2020) and 2WikiMultiHop (Welbl et al., 2018) (see Fig.",
    "next": "S5a in Supplementary Information for raw results).",
    "hard_negative": [
      1619841,
      6360322,
      5679499,
      6401679,
      12416658,
      8535316,
      12203802,
      7228830,
      1553193,
      2859948,
      26501419,
      2797612,
      1957433,
      11816014,
      1373518,
      1994584,
      9676646,
      2237672,
      10910955,
      9610093,
      18780529,
      528369,
      16466547,
      5761781
    ],
    "easy_negative": [
      235097557,
      258463932,
      5312054
    ]
  },
  {
    "index": 595,
    "source_corpus_id": 254408767,
    "ref_id": "b33",
    "citation_corpus_id": 239768373,
    "start": 33117,
    "end": 33135,
    "title": "Published as a conference paper at ICLR 2022 LEARNING WITH NOISY LABELS REVISITED: A STUDY USING REAL-WORLD HUMAN ANNOTATIONS",
    "abstract": "Existing research on learning with noisy labels mainly focuses on synthetic label noise. The synthetic noise, though has clean structures which greatly enabled statistical analyses, often fails to model the real-world noise patterns. The recent literature has observed several efforts to offer real-world noisy datasets, e.g., Food-101N, WebVision, and Clothing1M. Yet the existing efforts suffer from two caveats: firstly, the lack of ground-truth verification makes it hard to theoretically study the property and treatment of real-world label noise. Secondly, these efforts are often of large scales, which may result in unfair comparisons of robust methods within reasonable and accessible computation power. To better understand real-world label noise, it is important to establish controllable, easy-to-use and moderate-sized real-world noisy datasets with both ground-truth and noisy labels. This work presents two new benchmark datasets, which we name as CIFAR-10N, CIFAR-100N (jointly we call them CIFAR-N), equipping the training datasets of CIFAR-10 and CIFAR-100 with human-annotated real-world noisy labels we collected from Amazon Mechanical Turk. We quantitatively and qualitatively show that realworld noisy labels follow an instance-dependent pattern rather than the classically assumed and adopted ones (e.g., class-dependent label noise). We then initiate an effort to benchmarking a subset of the existing solutions using CIFAR-10N and CIFAR-100N. We further proceed to study the memorization of correct and wrong predictions, which further illustrates the difference between human noise and class-dependent synthetic noise. We show indeed the real-world noise patterns impose new and outstanding challenges as compared to synthetic label noise. These observations require us to rethink the treatment of noisy labels, and we hope the availability of these two datasets would facilitate the development and evaluation of future learning with noisy label solutions. The corresponding datasets and the leaderboard are available at http://noisylabels.com.",
    "prev": "We can observe that models in Region 1 have the highest test accuracies in each dataset.",
    "curr": "Computation (a) The Clothing-1M dataset (b) The Animal-10N dataset (c) The CIFAR-10N dataset Selection (d) The Clothing-1M dataset (e) The Animal-10N dataset (f) The CIFAR-10N dataset Evaluation (g) The Clothing-1M dataset (h) The Animal-10N dataset (i) The CIFAR-10N dataset\n\nExperiments on Real-world Datasets with noisy labels\n\nTo evaluate the performance of our approach on real-world datasets, we have conducted additional experiments on the Clothing-1M dataset [Xiao et al., 2015], which is a dataset with 1M images of clothes, on the Animal-10N dataset [Song et al., 2019], which is a dataset with 50k images of animals and on the CIFAR-10N dataset [Wei et al., 2022], which is the CIFAR-10 dataset with human-annotated noisy labels obtained from Amazon Mechanical Turk.",
    "next": "In the Clothing-1M dataset, the images have been labeled from the texts that accompany them, hence there are both clean and noisy labels in the set, and in the Animal-10N dataset, the images have been gathered and labeled from search engines.",
    "hard_negative": [
      211146562,
      222141668
    ],
    "easy_negative": [
      53113474,
      15990741,
      3176359
    ]
  },
  {
    "index": 597,
    "source_corpus_id": 256358777,
    "ref_id": "b13",
    "citation_corpus_id": 3144218,
    "start": 1370,
    "end": 1392,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "These new theoretical results are supported by corresponding numerical investigations.",
    "curr": "INTRODUCTION\n\nGraph Convolutional Networks (GCNs) (Kipf & Welling, 2017;Hammond et al., 2011;Defferrard et al., 2016) generalize Euclidean convolutional networks to the graph setting by replacing convolutional filters by functional calculus filters; i.e.",
    "next": "scalar functions applied to a suitably chosen graph-shift-oprator capturing the geometry of the underlying graph.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      204806122,
      3911704,
      3151714
    ]
  },
  {
    "index": 598,
    "source_corpus_id": 252683295,
    "ref_id": "b3",
    "citation_corpus_id": 247475874,
    "start": 2131,
    "end": 2150,
    "title": "E-KAR : A Benchmark for Rationalizing Natural Language Analogical Reasoning",
    "abstract": "The ability to recognize analogies is fundamental to human cognition. Existing benchmarks to test word analogy do not reveal the underneath process of analogical reasoning of neural models. Holding the belief that models capable of reasoning should be right for the right reasons, we propose a first-of-its",
    "prev": "1 Code and datasets are available in https://github.com/zjunlp/MKG_Analogy.",
    "curr": "INTRODUCTION\n\nAnalogical reasoning -the ability to perceive and use relational similarity between two situations or events -holds an important place in human cognition (Johnson-Laird, 2006;Bengio et al., 2021;Chen et al., 2022a) and can provide back-end support for various fields such as education (Thagard, 1992), creativity (Goel, 1997), thus appealing to the AI community.",
    "next": "Early, Mikolov et al.",
    "hard_negative": [
      4711425,
      208117506,
      236478211,
      209485573,
      218974368,
      21716001,
      174803111,
      225068329,
      203905467,
      964287,
      204960716,
      52183757,
      86611921,
      229371222,
      12730203,
      236459873,
      207556454,
      52967399,
      207847663,
      52966647
    ],
    "easy_negative": [
      7019269,
      165882348,
      7170202
    ]
  },
  {
    "index": 602,
    "source_corpus_id": 221041408,
    "ref_id": "b2",
    "citation_corpus_id": 213152193,
    "start": 9171,
    "end": 9191,
    "title": "ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS",
    "abstract": "Masked language modeling (MLM) pre-training methods such as BERT corrupt the input by replacing some tokens with [MASK]  and then train a model to reconstruct the original tokens. While they produce good results when transferred to downstream NLP tasks, they generally require large amounts of compute to be effective. As an alternative, we propose a more sample-efficient pre-training task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pre-training task is more efficient than MLM because the task is defined over all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by BERT given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where it performs comparably to RoBERTa and XLNet while using less than 1/4 of their compute and outperforms them when using the same amount of compute.",
    "prev": "(2019) observes that parameters in different layers have similar attention distribution, and propose a parameter distillation method from shallow layers to deep layers.",
    "curr": "Another notable work is ELECTRA (Clark et al., 2019), which develops a new task using one discriminator and one generator.",
    "next": "The generator corrupts the sentence, and the discriminator is trained to predict whether each word in the corrupted sentence is replaced or not.",
    "hard_negative": [
      3655946,
      990233,
      53113638,
      3432876,
      1957433,
      5959482,
      3626819,
      259144,
      5034059,
      11816014,
      40100965,
      52967399,
      11758569,
      85464175,
      4421747,
      16639476
    ],
    "easy_negative": [
      218974033,
      232428253,
      12014806
    ]
  },
  {
    "index": 603,
    "source_corpus_id": 247476419,
    "ref_id": "b8",
    "citation_corpus_id": 49667762,
    "start": 2546,
    "end": 2568,
    "title": "UNIVERSAL TRANSFORMERS",
    "abstract": "Recurrent neural networks (RNNs) sequentially process data by updating their state with each new data point, and have long been the de facto choice for sequence modeling tasks. However, their inherently sequential computation makes them slow to train. Feed-forward and convolutional architectures have recently been shown to achieve superior results on some sequence modeling tasks such as machine translation, with the added advantage that they concurrently process all inputs in the sequence, leading to easy parallelization and faster training times. Despite these successes, however, popular feed-forward sequence models like the Transformer fail to generalize in many simple tasks that recurrent models handle with ease, e.g. copying strings or even simple logical inference when the string or formula lengths exceed those observed at training time. We propose the Universal Transformer (UT), a parallel-in-time self-attentive recurrent sequence model which can be cast as a generalization of the Transformer model and which addresses these issues. UTs combine the parallelizability and global receptive field of feed-forward sequence models like the Transformer with the recurrent inductive bias of RNNs. We also add a dynamic per-position halting mechanism and find that it improves accuracy on several tasks. In contrast to the standard Transformer, under certain assumptions UTs can be shown to be Turing-complete. Our experiments show that UTs outperform standard Transformers on a wide range of algorithmic and language understanding tasks, including the challenging LAMBADA language modeling task where UTs achieve a new state of the art, and machine translation where UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De dataset. * Equal contribution, alphabetically by last name. \u2020 Work performed while at Google Brain.",
    "prev": "One solution is cross-layer parameter sharing, which reduces the memory needed to store parameters, which can also reduce the cost of communicating model updates in distributed training (Lan et al., 2020;Jaegle et al., 2021) and federated learning (Kone\u010dn\u00fd et al., 2016;McMahan et al., 2017), as the model is smaller, and can help avoid overfitting (Jaegle et al., 2021).",
    "curr": "However, prior work in parameter sharing (e.g., Dehghani et al., 2019;Savarese & Maire, 2019;Lan et al., 2020;Jaegle et al., 2021) has two significant limitations.",
    "next": "First, they rely on suboptimal hand-crafted techniques for deciding where and how sharing occurs.",
    "hard_negative": [
      14091969,
      3785155,
      2009318,
      14091946,
      2381275
    ],
    "easy_negative": [
      16210778,
      196180524,
      6023976
    ]
  },
  {
    "index": 604,
    "source_corpus_id": 247597138,
    "ref_id": "b0",
    "citation_corpus_id": 61153666,
    "start": 6808,
    "end": 6813,
    "title": "SECTOR: A Neural Model for Coherent Topic Segmentation and Classification",
    "abstract": "When searching for information, a human reader first glances over a document, spots relevant sections, and then focuses on a few sentences for resolving her intention. However, the high variance of document structure complicates the identification of the salient topic of a given section at a glance. To tackle this challenge, we present SECTOR, a model to support machine reading systems by segmenting documents into coherent sections and assigning topic labels to each section. Our deep neural network architecture learns a latent topic embedding over the course of a document. This can be leveraged to classify local topics from plain text and segment a document at topic shifts. In addition, we contribute WikiSection, a publicly available data set with 242k labeled sections in English and German from two distinct domains: diseases and cities. From our extensive evaluation of 20 architectures, we report a highest score of 71.6% F1 for the segmentation and classification of 30 topics from the English city domain, scored by our SECTOR long short-term memory model with Bloom filter embeddings and bidirectional segmentation. This is a significant improvement of 29.5 points F1 over state-of-the-art CNN classifiers with baseline segmentation. 1 Our source code is available under the Apache License 2.0 at https://github.com/sebastianarnold/ SECTOR.",
    "prev": "Forcing autoregressive models to generate longer texts exacerbates this incoherence because the models struggle to extrapolate beyond their expected text end point.",
    "curr": "Prior work has tried to address the problem of generating globally coherent text with planning-based approaches (Puduppully et al., 2019;Moryossef et al., 2019;Fan et al., 2019;Kiddon et al., 2016).",
    "next": "However, planning-based approaches rely on domain-specific heuristics for capturing text structure and dynamics.",
    "hard_negative": [
      2937095,
      6039192,
      5079983,
      1967279,
      2367414,
      8574660,
      4411469,
      9159503,
      15620570,
      9672033,
      7190753,
      13401571,
      1969767,
      10014954,
      8020075
    ],
    "easy_negative": [
      52922902,
      254044221,
      33898649
    ]
  },
  {
    "index": 605,
    "source_corpus_id": 252683988,
    "ref_id": "b44",
    "citation_corpus_id": 23892230,
    "start": 2156,
    "end": 2178,
    "title": "Challenges in Data-to-Document Generation",
    "abstract": "Recent neural models have shown significant progress on the problem of generating short descriptive texts conditioned on a small number of database records. In this work, we suggest a slightly more difficult data-to-text generation task, and investigate how effective current approaches are on this task. In particular, we introduce a new, large-scale corpus of data records paired with descriptive documents, propose a series of extractive evaluation methods for analyzing performance, and obtain baseline results using current neural generation methods. Experiments show that these models produce fluent text, but fail to convincingly approximate humangenerated documents. Moreover, even templated baselines exceed the performance of these neural models on some metrics, though copy-and reconstructionbased extensions lead to noticeable improvements.",
    "prev": "With SLiC, we exceed or match SOTA results on a wide range of generation tasks spanning abstractive summarization, question generation, abstractive question answering and data-to-text generation, even with modest-sized models.",
    "curr": "INTRODUCTION\n\nConditional language generation aims to generate natural language text based on input context, and includes many useful and hard tasks such as abstractive summarization (Mani, 2001;Nenkova and McKeown, 2011), generative question answering (Bajaj et al., 2016), question generation (Zhou et al., 2017) and data-to-text (Wiseman et al., 2017;Gardent et al., 2017) tasks.",
    "next": "Pretraining large Transformer encoder-decoder models and fine-tuning them on downstream tasks is the common paradigm to address these tasks (Raffel et al., 2020;Lewis et al., 2019;Tay et al., 2022;Zhang et al., 2019a).",
    "hard_negative": [
      10056961,
      546306,
      7218315,
      9197196,
      12873739,
      1238927,
      1589010,
      11336213,
      8174613,
      238873,
      2120088,
      472478,
      13402912,
      2488223,
      2580910,
      934325,
      748227,
      1998416,
      969555,
      215541211,
      1354459,
      9672033,
      11212020,
      13830525
    ],
    "easy_negative": [
      44855702,
      8772766,
      51744460
    ]
  },
  {
    "index": 606,
    "source_corpus_id": 263608698,
    "ref_id": "b8",
    "citation_corpus_id": 215717103,
    "start": 6356,
    "end": 6375,
    "title": "Collecting Highly Parallel Data for Paraphrase Evaluation",
    "abstract": "A lack of standard datasets and evaluation metrics has prevented the field of paraphrasing from making the kind of rapid progress enjoyed by the machine translation community over the last 15 years. We address both problems by presenting a novel data collection framework that produces highly parallel text data relatively inexpensively and on a large scale. The highly parallel nature of this data allows us to use simple n-gram comparisons to measure both the semantic adequacy and lexical dissimilarity of paraphrase candidates. In addition to being simple and efficient to compute, experiments show that these metrics correlate highly with human judgments.",
    "prev": "age), and AL (audio-language) data pairs.The videos of previous datasets are always truncated segments from long videos (Miech et al., 2019;Xue et al., 2022), resulting in fragmented semantics.To avoid this problem, we construct our video-text pairs from short videos with complete stories.To ensure the quality of the central language modality, we perform multi-view text generation and enhancement on VIDAL-10M.",
    "curr": "The proposed LanguageBind ensures that we can extend vision-language to multiple (N) modalities, and our dataset VIDAL-10M benefits more downstream tasks beyond VL tasks, including video retrieval (Luo et al., 2022), depth classification (Cao et al., 2017), infrared classification (Baffa & Lattari, 2018) and audio classification (Palanisamy et al., 2020).In text-to-video zero-shot retrieval based on CLIP-Large, LanguageBind achieves state-of-the-art (SOTA) performance on four datasets, surpassing InterVideo (Wang et al., 2022c) by 1.9% on MSR-VTT (Xu et al., 2016), 8.8% on MSVD (Chen & Dolan, 2011), 6.3% on DiDeMo (Anne Hendricks et al., 2017), and 4.4% on ActivityNet (Caba Heilbron et al., 2015).For zero-shot classification on depth and infrared data, LanguageBind achieves a substantial performance advantage over ImageBind.LanguageBind attains top-1 accuracy of 87.2% and 65.1% on LLVIP and NYU-D, respectively, outperforming Im-ageBind by 23.8% and 11.1%.For zero-shot audio classification tasks, LanguageBind outperforms ImageBind with a 22.9% higher top-1 accuracy on the ESC50 dataset.",
    "next": "We summarize our primary contributions as follows:\n\n\u2022 We propose LanguageBind, the langauge-based multi-modal pretraining approach.During the pretraining process, all modalities gradually align with the language modality through contrastive learning, and these modalities are unified within a shared embedding space.",
    "hard_negative": [
      837398,
      11652247,
      9842595,
      1963942,
      11728052,
      8431414,
      1302329,
      13043395,
      16019656,
      2755801,
      11888861,
      7489770,
      6387310,
      10181753
    ],
    "easy_negative": [
      252624677,
      559589,
      29931733
    ]
  },
  {
    "index": 608,
    "source_corpus_id": 247595075,
    "ref_id": "b21",
    "citation_corpus_id": 4606753,
    "start": 2916,
    "end": 2937,
    "title": "NEURAL-GUIDED DEDUCTIVE SEARCH FOR REAL- TIME PROGRAM SYNTHESIS FROM EXAMPLES",
    "abstract": "Synthesizing user-intended programs from a small number of input-output examples is a challenging problem with several important applications like spreadsheet manipulation, data wrangling and code refactoring. Existing synthesis systems either completely rely on deductive logic techniques that are extensively handengineered or on purely statistical models that need massive amounts of data, and in general fail to provide real-time synthesis on challenging benchmarks. In this work, we propose Neural Guided Deductive Search (NGDS), a hybrid synthesis technique that combines the best of both symbolic logic techniques and statistical models. Thus, it produces programs that satisfy the provided specifications by construction and generalize well on unseen examples, similar to data-driven systems. Our technique effectively utilizes the deductive search framework to reduce the learning problem of the neural component to a simple supervised learning setup. Further, this allows us to both train on sparingly available real-world data and still leverage powerful recurrent neural network encoders. We demonstrate the effectiveness of our method by evaluating on real-world customer scenarios by synthesizing accurate programs with up to 12\u00d7 speed-up compared to state-ofthe-art systems.",
    "prev": "First, learning to search works best when it exploits the symbolic scaffolding of existing search algorithms already proven useful for the problem domain.",
    "curr": "For example, AlphaGo exploits Monte Carlo Tree Search (Silver et al., 2016), while NGDS exploits top-down deductive search (Kalyan et al., 2018).",
    "next": "We engineer CROSSBEAM around bottom-up enumerative search (Udupa et al., 2013), a backbone of several successful recent program synthesis algorithms (Shi et al., 2020a;Odena et al., 2021;Barke et al., 2020).",
    "hard_negative": [
      7034786,
      6628106,
      1844940,
      2468625
    ],
    "easy_negative": [
      4039253,
      60629654,
      1623350
    ]
  },
  {
    "index": 615,
    "source_corpus_id": 209832425,
    "ref_id": "b8",
    "citation_corpus_id": 54443381,
    "start": 5528,
    "end": 5551,
    "title": "EFFICIENT LIFELONG LEARNING WITH A-GEM",
    "abstract": "In lifelong learning, the learner is presented with a sequence of tasks, incrementally building a data-driven prior which may be leveraged to speed up learning of a new task. In this work, we investigate the efficiency of current lifelong approaches, in terms of sample complexity, computational and memory cost. Towards this end, we first introduce a new and a more realistic evaluation protocol, whereby learners observe each example only once and hyper-parameter selection is done on a small and disjoint set of tasks, which is not used for the actual learning experience and evaluation. Second, we introduce a new metric measuring how quickly a learner acquires a new skill. Third, we propose an improved version of GEM (Lopez-Paz & Ranzato, 2017), dubbed Averaged GEM (A-GEM), which enjoys the same or even better performance as GEM, while being almost as computationally and memory efficient as EWC  and other regularizationbased methods. Finally, we show that all algorithms including A-GEM can learn even more quickly if they are provided with task descriptors specifying the classification tasks under consideration. Our experiments on several standard lifelong learning benchmarks demonstrate that A-GEM has the best trade-off between accuracy and efficiency. 1",
    "prev": "Regularization and replay approaches fix the model architecture before training and prevent catastrophic forgetting by regularizing the change of a specific set of weights or replaying previously learned data.",
    "curr": "Hybrids of replay and regularization also exist, such as Gradient Episodic Memory (GEM) (Lopez-Paz & Ranzato, 2017;Chaudhry et al., 2019a).",
    "next": "On the other hand, methods based on expansion add new network components to learn new data.",
    "hard_negative": [
      22014305,
      49667227
    ],
    "easy_negative": [
      44101758,
      15308391,
      7371343
    ]
  },
  {
    "index": 616,
    "source_corpus_id": 13019454,
    "ref_id": "b17",
    "citation_corpus_id": 629094,
    "start": 10109,
    "end": 10130,
    "title": "Word representations: A simple and general method for semi-supervised learning",
    "abstract": "If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize. com/projects/wordreprs/",
    "prev": "E x \u2208 R |V |\u00d7E is the embedding matrix, where |V | is the number of unique events (the vocabulary size) and E is the embedding dimension.",
    "curr": "The use of embedding provides a dense representation for an event that improves learning (Turian et al., 2010).",
    "next": "Through training, the embedding vector of an event encodes its meaning relative to other events.",
    "hard_negative": [
      12064136,
      160543,
      10986188,
      1916754,
      1850092
    ],
    "easy_negative": [
      9330555,
      235258291,
      250390746
    ]
  },
  {
    "index": 626,
    "source_corpus_id": 3292002,
    "ref_id": "b23",
    "citation_corpus_id": 3144218,
    "start": 5643,
    "end": 5664,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "(2016) proposed to approximate the filters by means of a Chebyshev expansion of the graph Laplacian, removing the need to compute the eigenvectors of the Laplacian and yielding spatially localized filters.",
    "curr": "Finally, Kipf & Welling (2017) simplified the previous method by restricting the filters to operate in a 1-step neighborhood around each node.",
    "next": "However, in all of the aforementioned spectral approaches, the learned filters depend on the Laplacian eigenbasis, which depends on the graph structure.",
    "hard_negative": [
      6628106,
      17682909
    ],
    "easy_negative": [
      237099266,
      2774468,
      236460326
    ]
  },
  {
    "index": 628,
    "source_corpus_id": 91175758,
    "ref_id": "b34",
    "citation_corpus_id": 13751870,
    "start": 23320,
    "end": 23332,
    "title": "A Call for Clarity in Reporting BLEU Scores",
    "abstract": "The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to \"the\" BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for usersupplied reference processing, and provide a new tool, SACREBLEU, 1 to facilitate this. . 2016. Google's neural machine translation system: Bridging the gap between human and machine translation. ArXiv eprints, abs/1609.08144.",
    "prev": "If implementation details can cause the scores produced by a metric to vary significantly, this conflates comparison of when different implementations are used to compare different methods.",
    "curr": "This has caused issues in benchmarking machine translation (Post, 2018) and music information retrieval (Raffel et al., 2014).",
    "next": "This problem is particularly pronounced for NNDs because they require implementing a neural network architecture and training scheme, and the use of different software frameworks or even driver versions can cause results to vary (Henderson et al., 2018;Oliver et al., 2018).",
    "hard_negative": [
      512833,
      384994,
      2863491,
      16794216,
      49742509,
      2531955,
      7647892,
      17643319,
      1245593,
      21675165,
      252796,
      905565
    ],
    "easy_negative": [
      2764924,
      3014359,
      222132852
    ]
  },
  {
    "index": 632,
    "source_corpus_id": 204905143,
    "ref_id": "b16",
    "citation_corpus_id": 3633127,
    "start": 1617,
    "end": 1639,
    "title": "Published as a conference paper at ICLR 2018 CGANS WITH PROJECTION DISCRIMINATOR",
    "abstract": "We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. This approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. With this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (Im-ageNet) 1000-class image dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. We were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. This new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_projection.",
    "prev": "Moreover, Our consistency regularized GAN (CR-GAN) improves stateof-the-art FID scores for conditional generation from 14.73 to 11.67 on CIFAR-10 and from 8.73 to 6.66 on ImageNet-2012.",
    "curr": "INTRODUCTION\n\nGenerative Adversarial Networks (GANs) (Goodfellow et al., 2014) have recently demonstrated impressive results on image-synthesis benchmarks Zhang et al., 2017;Miyato & Koyama, 2018;Zhang et al., 2018;Brock et al., 2018;Karras et al., 2019).",
    "next": "In the original setting, GANs are composed of two neural networks trained with competing goals: the generator is trained to synthesize realistic samples to fool the discriminator and the discriminator is trained to distinguish real samples from fake ones produced by the generator.",
    "hard_negative": [
      6104263,
      5687613
    ],
    "easy_negative": [
      12929928,
      247187477,
      232021554
    ]
  },
  {
    "index": 635,
    "source_corpus_id": 85449634,
    "ref_id": "b41",
    "citation_corpus_id": 5592690,
    "start": 1968,
    "end": 1988,
    "title": "MACHINE COMPREHENSION USING MATCH-LSTM AND ANSWER POINTER",
    "abstract": "Machine comprehension of text is an important problem in natural language processing. A recently released dataset, the Stanford Question Answering Dataset (SQuAD), offers a large number of real questions and their answers created by humans through crowdsourcing. SQuAD provides a challenging testbed for evaluating machine comprehension algorithms, partly because compared with previous datasets, in SQuAD the answers do not come from a small set of candidate answers and they have variable lengths. We propose an end-to-end neural architecture for the task. The architecture is based on match-LSTM, a model we proposed previously for textual entailment, and Pointer Net, a sequence-to-sequence model proposed byVinyals et al. (2015)to constrain the output tokens to be from the input sequences. We propose two ways of using Pointer Net for our task. Our experiments show that both of our two models substantially outperform the best results obtained byRajpurkar et al. (2016)using logistic regression and manually crafted features.",
    "prev": "A lot of effort has been put into designing sophisticated neural MRC architectures for reading short context (e.g.",
    "curr": "a single paragraph), with much success (Wang & Jiang, 2017;Seo et al., 2017;Xiong et al., 2017;Wang et al., 2018c;Yu et al., 2018, inter alia).",
    "next": "However, the performance of such systems degrades significantly when combined with a retriever in open domain settings.",
    "hard_negative": [
      711424,
      6360322,
      2926851,
      14915449,
      3178759,
      6628106,
      11022639,
      8174613,
      1957433,
      2100831
    ],
    "easy_negative": [
      248496160,
      2601442,
      1410714
    ]
  },
  {
    "index": 636,
    "source_corpus_id": 11324902,
    "ref_id": "b24",
    "citation_corpus_id": 14124313,
    "start": 22935,
    "end": 22962,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "All evaluations are repeated 10 times based on different shuffles of the data, and the mean accuracies and standard deviations are analyzed.",
    "curr": "Office: Since the office dataset is rather small with only 2817 images in its largest domain, we use the latent representations of the convolution neural network VGG16 of Simonyan & Zisserman (2014).",
    "next": "In particular we train a classifier with one hidden layer, 256 hidden nodes and sigmoid activation function on top of the output of the first dense layer in the network.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      8143282,
      252683122,
      249089172
    ]
  },
  {
    "index": 639,
    "source_corpus_id": 235368204,
    "ref_id": "b16",
    "citation_corpus_id": 4722462,
    "start": 2279,
    "end": 2296,
    "title": "EMERGENT TRANSLATION IN MULTI-AGENT COMMUNICATION",
    "abstract": "While most machine translation systems to date are trained on large parallel corpora, humans learn language in a different way: by being grounded in an environment and interacting with other humans. In this work, we propose a communication game where two agents, native speakers of their own respective languages, jointly learn to solve a visual referential task. We find that the ability to understand and translate a foreign language emerges as a means to achieve shared goals. The emergent translation is interactive and multimodal, and crucially does not require parallel corpora, but only monolingual, independent text and corresponding images. Our proposed translation model achieves this by grounding the source and target languages into a shared visual modality, and outperforms several baselines on both word-level and sentence-level translation tasks. Furthermore, we show that agents in a multilingual community learn to translate better and faster than in a bilingual communication setting.",
    "prev": "The success of deep learning (DL) models on complicated cognitive tasks (Krizhevsky et al., 2012;LeCun et al., 2015;Silver et al., 2016) then inspired researchers to apply DL-based models to language games to investigate the agents' ability to invent communication protocols without preset rules (e.g.",
    "curr": "Lee et al., 2018;Lazaridou et al., 2018).",
    "next": "In the existing works (e.g.",
    "hard_negative": [
      14307651,
      6881637,
      19396711,
      11336213,
      11212020,
      2428314
    ],
    "easy_negative": [
      211126537,
      248780079,
      207757258
    ]
  },
  {
    "index": 644,
    "source_corpus_id": 53215593,
    "ref_id": "b3",
    "citation_corpus_id": 11212020,
    "start": 12131,
    "end": 12154,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "(1) Our key intuition is that the inverse dynamics model should attend to the most relevant part of the observation, which is controllable by the agent, to be able to classify the actions.",
    "curr": "We determine whether each region in a H \u00d7 W grid is controllable, or in other words, useful for predicting the agent's action, by using a spatial attention mechanism (Bahdanau et al., 2015;Xu et al., 2015).",
    "next": "An overview of the model is shown in Figure 1.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      3675467,
      2154244,
      5646428
    ]
  },
  {
    "index": 645,
    "source_corpus_id": 220347587,
    "ref_id": "b36",
    "citation_corpus_id": 196178484,
    "start": 5174,
    "end": 5178,
    "title": "Self-Attentive, Multi-Context One-Class Classification for Unsupervised Anomaly Detection on Text",
    "abstract": "There exist few text-specific methods for unsupervised anomaly detection, and for those that do exist, none utilize pre-trained models for distributed vector representations of words. In this paper we introduce a new anomaly detection method-Context Vector Data Description (CVDD)-which builds upon word embedding models to learn multiple sentence representations that capture multiple semantic contexts via the self-attention mechanism. Modeling multiple contexts enables us to perform contextual anomaly detection of sentences and phrases with respect to the multiple themes and concepts present in an unlabeled text corpus. These contexts in combination with the self-attention weights make our method highly interpretable. We demonstrate the effectiveness of CVDD quantitatively as well as qualitatively on the wellknown Reuters, 20 Newsgroups, and IMDB Movie Reviews datasets.",
    "prev": "These methods attempt to separate nominal samples from anomalies in an unsupervised manner by concentrating nominal data in feature space while mapping anomalies to distant locations [36,6].",
    "curr": "In the domain of NLP, DSVDD [36] has been successfully applied to text, which yields a form of interpretation using attention mechanisms [37].",
    "next": "For images, Kauffmann et al.",
    "hard_negative": [
      2937095,
      990233,
      15280949,
      1957433,
      3626819,
      9672033,
      5882977,
      207556454
    ],
    "easy_negative": [
      257258161,
      259376563,
      21699225
    ]
  },
  {
    "index": 647,
    "source_corpus_id": 264128269,
    "ref_id": "b19",
    "citation_corpus_id": 21850704,
    "start": 2428,
    "end": 2449,
    "title": "A Deep Reinforced Model for Abstractive Summarization",
    "abstract": "Attentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences. However, for longer documents and summaries, these models often include repetitive and incoherent phrases. We introduce a neural network model with intra-attention and a new training method. This method combines standard supervised word prediction and reinforcement learning (RL). Models trained only with the former often exhibit \"exposure bias\" -they assume ground truth is provided at each step during training. However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable. We evaluate this model on the CNN/Daily Mail and New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, a 5.7 absolute points improvement over previous state-of-the-art models. It also performs well as the first abstractive model on the New York Times corpus. Human evaluation also shows that our model produces higher quality summaries.",
    "prev": "xplanation for why Goodhart's law occurs in Markov decision processes.We use these theoretical insights to propose an optimal early stopping method that provably avoids the aforementioned pitfall and derive theoretical regret bounds for this method.Moreover, we derive a training method that maximises worst-case reward, for the setting where there is uncertainty about the true reward function.Finally, we evaluate our early stopping method experimentally.Our results support a foundation for a theoretically-principled study of reinforcement learning under reward misspecification.",
    "curr": "INTRODUCTION\n\nTo solve a problem using Reinforcement Learning (RL), it is necessary first to formalise that problem using a reward function (Sutton & Barto, 2018).However, due to the complexity of many real-world tasks, it is exceedingly difficult to directly specify a reward function that fully captures the task in the intended way.However, misspecified reward functions will often lead to undesirable behaviour (Paulus et al., 2018;Ibarz et al., 2018;Knox et al., 2023;Pan et al., 2021).This makes designing good reward functions a major obstacle to using RL in practice, especially for safety-critical applications.",
    "next": "An increasingly popular solution is to learn reward functions from mechanisms such as human or automated feedback (e.g.Christiano et al., 2017;Ng & Russell, 2000).However, this approach comes with its own set of challenges: the right data can be difficult to collect (e.g.Paulus et al., 2018), and it is often challenging to interpret it correctly (e.g.Mindermann & Armstrong, 2018;Skalse & Abate, 2023).Moreover, optimising a policy against a learned reward model effectively constitutes a distributional shift (Gao et al., 2023); i.e., even if a reward function is accurate under the training distribution, it may fail to induce desirable behaviour from the RL agent.",
    "hard_negative": [
      14068874,
      1729177,
      3937849,
      1957433,
      964287,
      10151113,
      16992492,
      9751546
    ],
    "easy_negative": [
      256105158,
      9283125,
      7623747
    ]
  },
  {
    "index": 649,
    "source_corpus_id": 247476256,
    "ref_id": "b33",
    "citation_corpus_id": 15197911,
    "start": 3725,
    "end": 3741,
    "title": "PUSHING THE BOUNDARIES OF BOUNDARY DETEC- TION USING DEEP LEARNING",
    "abstract": "In this work we show that adapting Deep Convolutional Neural Network training to the task of boundary detection can result in substantial improvements over the current state-of-the-art in boundary detection. Our contributions consist firstly in combining a careful design of the loss for boundary detection training, a multi-resolution architecture and training with external data to improve the detection accuracy of the current state of the art. When measured on the standard Berkeley Segmentation Dataset, we improve theoptimal dataset scale F-measure from 0.780 to 0.808 -while human performance is at 0.803. We further improve performance to 0.813 by combining deep learning with grouping, integrating the Normalized Cuts technique within a deep network. We also examine the potential of our boundary detector in conjunction with the task of semantic segmentation and demonstrate clear improvements over state-ofthe-art systems. Our detector is fully integrated in the popular Caffe framework and processes a 320x420 image in less than a second.",
    "prev": "Such a strategy has been successful in other dense prediction tasks (Ronneberger et al., 2015) as well.",
    "curr": "Others propose different loss functions (Kokkinos, 2016;Kervadec et al., 2019) to address class imbalance.",
    "next": "Despite the improvements, we identify two issues regarding crisp boundary detection.",
    "hard_negative": [
      4071727,
      14612342,
      1996665
    ],
    "easy_negative": [
      29563946,
      8250983,
      244077682
    ]
  },
  {
    "index": 652,
    "source_corpus_id": 202712898,
    "ref_id": "b2",
    "citation_corpus_id": 14124313,
    "start": 1541,
    "end": 1568,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "Nonetheless, these architectures may not necessarily lead to better generalization performance compared with other candidate architectures in the same search space, and therefore further improvement is possible by revising existing NAS algorithms.",
    "curr": "INTRODUCTION\n\nVarious neural network architectures (Krizhevsky et al., 2012;Simonyan & Zisserman, 2015;He et al., 2016;Huang et al., 2017) have been devised over the past decades, achieving superhuman performance for a wide range of tasks.",
    "next": "Designing these neural networks typically takes substantial efforts from domain experts by trial and error.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      1678415,
      6771196,
      38898903
    ]
  },
  {
    "index": 654,
    "source_corpus_id": 13807351,
    "ref_id": "b45",
    "citation_corpus_id": 252796,
    "start": 5644,
    "end": 5665,
    "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
    "abstract": "There is a growing consensus that significant, rapid progress can be made in both text understanding and spoken language understanding by investigating those phenomena that occur most centrally in naturally occurring unconstrained materials and by attempting to automatically extract information about language from very large corpora. Such corpora are beginning to serve as important research tools for investigators in natural language processing, speech recognition, and integrated spoken language systems, as well as in theoretical linguistics. Annotated corpora promise to be valuable for enterprises as diverse as the automatic construction of statistical models for the grammar of the written and the colloquial spoken language, the development of explicit formal theories of the differing grammars of writing and speech, the investigation of prosodic phenomena in speech, and the evaluation and comparison of the adequacy of parsing models.In this paper, we review our experience with constructing one such large annotated corpus--the Penn Treebank, a corpus 1 consisting of over 4.5 million words of American English. During the first three-year phase of the Penn Treebank Project (1989)(1990)(1991)(1992), this corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure. These materials are available to members of the Linguistic Data Consortium; for details, see Section 5.1.The paper is organized as follows. Section 2 discusses the POS tagging task. After outlining the considerations that informed the design of our POS tagset and presenting the tagset itself, we describe our two-stage tagging process, in which text is first assigned POS tags automatically and then corrected by human annotators. Section 3 briefly presents the results of a comparison between entirely manual and semi-automated tagging, with the latter being shown to be superior on three counts: speed, consistency, and accuracy. In Section 4, we turn to the bracketing task. Just as with the tagging task, we have partially automated the bracketing task: the output of",
    "prev": "Actively biasing the optimization towards wide valleys in the energy landscape results in better generalization error.",
    "curr": "We present experimental results on fully-connected and convolutional neural networks (CNNs) on the MNIST and CIFAR-10 (Krizhevsky, 2009) datasets and recurrent neural networks (RNNs) on the Penn Tree Bank dataset (PTB) (Marcus et al., 1993) and character-level text prediction.",
    "next": "Our experiments show that Entropy-SGD scales to deep networks used in practice, obtains comparable generalization error as competitive baselines and also trains much more quickly than SGD (we get a 2x speed-up over SGD on RNNs).",
    "hard_negative": [
      696805,
      3166885,
      2369736,
      12951757,
      5153623,
      2769726
    ],
    "easy_negative": [
      7766064,
      12595119,
      235592929
    ]
  },
  {
    "index": 660,
    "source_corpus_id": 222125236,
    "ref_id": "b21",
    "citation_corpus_id": 207870430,
    "start": 1696,
    "end": 1721,
    "title": "Published as a conference paper at ICLR 2020 GENERALIZATION THROUGH MEMORIZATION: NEAREST NEIGHBOR LANGUAGE MODELS",
    "abstract": "We introduce kNN-LMs, which extend a pre-trained neural language model (LM) by linearly interpolating it with a k-nearest neighbors (kNN) model. The nearest neighbors are computed according to distance in the pre-trained LM embedding space, and can be drawn from any text collection, including the original LM training data. Applying this augmentation to a strong WIKITEXT-103 LM, with neighbors drawn from the original training set, our kNN-LM achieves a new stateof-the-art perplexity of 15.79 -a 2.9 point improvement with no additional training. We also show that this approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore, again without further training. Qualitatively, the model is particularly helpful in predicting rare patterns, such as factual knowledge. Together, these results strongly suggest that learning similarity between sequences of text is easier than predicting the next word, and that nearest neighbor search is an effective approach for language modeling in the long tail. . Pointer sentinel mixture models. ICLR, 2017. Tom\u00e1\u0161 Mikolov, Martin Karafi\u00e1t, Luk\u00e1\u0161 Burget, Jan\u010cernock\u1ef3, and Sanjeev Khudanpur. Recurrent neural network based language model. In Eleventh annual conference of the international speech communication association, 2010. A. Emin Orhan. A simple cache model for image recognition. In NeurIPS, 2018. Nicolas Papernot and Patrick McDaniel. Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning. arXiv preprint arXiv:1803.04765, 2018.Ofir Press and Lior Wolf. Using the output embedding to improve language models. In ICLR, 2017. machine translation of rare words with subword units. arXiv preprint arXiv:1508.07909, 2015. Catanzaro. Megatron-lm: Training multi-billion parameter language models using gpu model parallelism. arXiv preprint arXiv:1909.08053, 2019.",
    "prev": "rity search.This approach requires no additional training and scales to give the decoder direct access to billions of examples at test time, resulting in a highly expressive model that consistently improves performance across many settings.Simply adding nearest neighbor search improves a state-of-the-art German-English translation model by 1.5 BLEU.kNN-MT allows a single model to be adapted to diverse domains by using a domain-specific datastore, improving results by an average of 9.2 BLEU over zero-shot transfer, and achieving new state-of-the-art results-without training on these domains.A massively multilingual model can also be specialized for particular language pairs, with improvements of 3 BLEU for translating from English into German and Chinese.Qualitatively, kNN-MT is easily interpretable; it combines source and target context to retrieve highly relevant examples.",
    "curr": "INTRODUCTION\n\nNon-parametric methods have recently been successfully applied to tasks such as language modeling (Khandelwal et al., 2020) and question answering (Guu et al., 2020;Lewis et al., 2020).They allow models that are (1) expressive, because they can use an arbitrary amount of data at test time; (2) adaptable, because predictions can be controlled by changing the datastore, and (3) interpretable, because the data used to make the prediction can be directly inspected.We introduce kNN-MT, a simple non-parametric method for machine translation (MT) using nearest neighbor retrieval.kNN-MT can be added to any pre-trained neural translation model without further training, and significantly improves performance for in-domain, out-of-domain, and multi-lingual evaluations.",
    "next": "More specifically, kNN-MT interpolates the target-token softmax distribution from a neural MT model with a multinomial generated using nearest neighbor search over examples cached in a data store.The cache is over translation contexts (i.e.",
    "hard_negative": [
      52967399,
      505,
      12122362,
      52892477
    ],
    "easy_negative": [
      228063930,
      8037559,
      16351973
    ]
  },
  {
    "index": 661,
    "source_corpus_id": 85543148,
    "ref_id": "b37",
    "citation_corpus_id": 14124313,
    "start": 7304,
    "end": 7332,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "It is challenging due to the complexity of features in high-dimensional space (Krizhevsky et al., 2012), the large intra-class variation and inter-class similarity across categories in benchmarks (Deng et al., 2009;Tsung-Yi Lin, 2015).",
    "curr": "Thanks to the development of deep networks structure (Simonyan & Zisserman, 2015;He et al., 2016) and modern GPU hardware acceleration, this community has witnessed a great bloom in both performance and efficiency.",
    "next": "The detection of small objects is addressed in concurrent literature mainly through two manners.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      11849431,
      247619041,
      6152986
    ]
  },
  {
    "index": 663,
    "source_corpus_id": 251953412,
    "ref_id": "b39",
    "citation_corpus_id": 201646309,
    "start": 3249,
    "end": 3275,
    "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    "abstract": "BERT(Devlin et al., 2018)and RoBERTa (Liu  et al., 2019)  has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT.We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods. 1",
    "prev": "As there are millions to billions of documents in a collection, efficiency is the most fundamental prerequisite for large-scale retrieval.",
    "curr": "To this end, query-agnostic document representations (i.e., indexing the collection independently) and lightweight relevance metrics (e.g., cosine similarity, dot-product) have become the common practices to meet the prerequisite -usually achieved by a two-tower structure (Reimers & Gurevych, 2019), a.k.a., bi-encoder and dual-encoder, in representation learning literature.",
    "next": "Besides the prevalent 'dense-vector retrieval' paradigm that encodes both queries and documents in the same low-dimension, real-valued latent semantic space , another retrieval paradigm, 'lexicon-weighting retrieval', aims to leverage weighted sparse representation in vocabulary space (Formal et al., 2021a;.",
    "hard_negative": [
      388,
      2937095,
      28971531,
      5033484,
      10241043,
      990233,
      195345563,
      3432876,
      12549805,
      1957433,
      11650107,
      646594,
      18283203,
      3264224,
      5394019,
      4421747,
      10181753
    ],
    "easy_negative": [
      219303144,
      235790533,
      250140658
    ]
  },
  {
    "index": 666,
    "source_corpus_id": 3473900,
    "ref_id": "b16",
    "citation_corpus_id": 5959482,
    "start": 1479,
    "end": 1501,
    "title": "Efficient Estimation of Word Representations in Vector Space",
    "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities. arXiv:1301.3781v3 [cs.CL] 7 Sep 2013 1 The test set is available at www.fit.vutbr.cz/\u02dcimikolov/rnnlm/word-test.v1.txt 2",
    "prev": "INTRODUCTION\n\nLearning feature representations of natural data such as text and images has become increasingly important for understanding real-world concepts.",
    "curr": "These representations are useful for many tasks, ranging from semantic understanding of words and sentences (Mikolov et al., 2013;Kiros et al., 2015), image caption generation (Vinyals et al., 2015), textual entailment prediction (Rockt\u00e4schel et al., 2015), to language communication with robots (Bisk et al., 2016).",
    "next": "Meaningful representations of text and images capture visual-semantic information, such as hierarchical structure where certain entities are abstractions of others.",
    "hard_negative": [
      633992,
      5278106,
      1428702,
      629094
    ],
    "easy_negative": [
      251404193,
      7501494,
      330545
    ]
  },
  {
    "index": 674,
    "source_corpus_id": 263620583,
    "ref_id": "b38",
    "citation_corpus_id": 57825721,
    "start": 29466,
    "end": 29486,
    "title": "ON THE TURING COMPLETENESS OF MODERN NEURAL NETWORK ARCHITECTURES",
    "abstract": "Alternatives to recurrent neural networks, in particular, architectures based on attention or convolutions, have been gaining momentum for processing input sequences. In spite of their relevance, the computational properties of these alternatives have not yet been fully explored. We study the computational power of two of the most paradigmatic architectures exemplifying these mechanisms: the Transformer (Vaswani et al., 2017) and the Neural GPU (Kaiser & Sutskever, 2016). We show both models to be Turing complete exclusively based on their capacity to compute and access internal dense representations of the data. In particular, neither the Transformer nor the Neural GPU requires access to an external memory to become Turing complete. Our study also reveals some minimal sets of elements needed to obtain these completeness results.",
    "prev": "(2022) for a survey).Since it is infeasible to precisely define real-world data and tasks, several works have studied it in stylized well-defined settings (Chan et al., 2022;Hahn & Goyal, 2023;Xie et al., 2021).Garg et al.",
    "curr": "(2022) presented a meta-learning-like Transformers and Sequence Models.The analysis of the capabilities and limitations of recurrent architectures dates back to a few decades ago (Kolen & Kremer, 2001).Given the recent success of Transformers, several works have sought to investigate their theoretical expressiveness (P\u00e9rez et al., 2019;Merrill et al., 2022;Chiang & Cholak, 2022;Hahn, 2020;Yun et al., 2020;Liu et al., 2022) as well as their empirical capabilities (Bhattamishra et al., 2023;2020b;Ebrahimi et al., 2020) and limitations (Bhattamishra et al., 2020a;Chiang & Cholak, 2022).Del\u00e9tang et al.",
    "next": "( 2022) conduct a comprehensive study of the performance of various sequence models such as Transformers and RNNs on formal language tasks.While most of these prior works focus on classification or related tasks, our work complements these as we conduct a comprehensive study on in-context learning tasks.",
    "hard_negative": [
      3666178,
      2009318,
      5590763,
      3725815
    ],
    "easy_negative": [
      218973965,
      235293924,
      209387585
    ]
  },
  {
    "index": 680,
    "source_corpus_id": 51942590,
    "ref_id": "b14",
    "citation_corpus_id": 1428702,
    "start": 10417,
    "end": 10421,
    "title": "Learning Word Vectors for Sentiment Analysis",
    "abstract": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term-document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.",
    "prev": "It just sucks.",
    "curr": "( ) This sentence is contained in a movie review from the IMDB movie data set [15], and it is classified as negative sentiment by a machine learning model to be discussed in the sequel.",
    "next": "Now suppose we wish to quantify the importance of feature \"not\" in prediction.",
    "hard_negative": [
      1260035,
      388,
      2279432,
      10473638,
      7105713,
      2787775,
      218515777,
      3264224,
      629094,
      469886
    ],
    "easy_negative": [
      16894495,
      247618647,
      241583731
    ]
  },
  {
    "index": 681,
    "source_corpus_id": 212633677,
    "ref_id": "b27",
    "citation_corpus_id": 5959482,
    "start": 10709,
    "end": 10713,
    "title": "Efficient Estimation of Word Representations in Vector Space",
    "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities. arXiv:1301.3781v3 [cs.CL] 7 Sep 2013 1 The test set is available at www.fit.vutbr.cz/\u02dcimikolov/rnnlm/word-test.v1.txt 2",
    "prev": ", x n ) in one go.",
    "curr": "An embedding is a mapping from plain input, for example words or characters, to a high dimensional vector, for which learning algorithms and toolkits exists, e.g., word2vec [26].",
    "next": "Given the encoders output z = (z 0 , .",
    "hard_negative": [
      633992,
      5278106,
      1428702,
      629094
    ],
    "easy_negative": [
      235359192,
      248780509,
      10410491
    ]
  },
  {
    "index": 683,
    "source_corpus_id": 249375359,
    "ref_id": "b1",
    "citation_corpus_id": 52922363,
    "start": 2697,
    "end": 2717,
    "title": "A CONVERGENCE ANALYSIS OF GRADIENT DESCENT FOR DEEP LINEAR NEURAL NETWORKS",
    "abstract": "We analyze speed of convergence to global optimum for gradient descent training a deep linear neural network (parameterized as x \u2192 W N W N \u22121 \u00b7 \u00b7 \u00b7 W 1 x) by minimizing the 2 loss over whitened data. Convergence at a linear rate is guaranteed when the following hold: (i) dimensions of hidden layers are at least the minimum of the input and output dimensions; (ii) weight matrices at initialization are approximately balanced; and (iii) the initial loss is smaller than the loss of any rank-deficient solution. The assumptions on initialization (conditions (ii) and (iii)) are necessary, in the sense that violating any one of them may lead to convergence failure. Moreover, in the important case of output dimension 1, i.e. scalar regression, they are met, and thus convergence to global optimum holds, with constant probability under a random initialization scheme. Our results significantly extend previous analyses, e.g., of deep linear residual networks(Bartlett et al., 2018).",
    "prev": "From the theoretical perspective, understanding the roles of nonlinearity in deep neural networks is one critical part of understanding how modern deep models work.",
    "curr": "Currently, most works focus on linear variants of deep models (Jacot et al., 2018;Arora et al., 2019a;Kawaguchi, 2016;Jing et al., 2022;Tian et al., 2021;Wang et al., 2021).",
    "next": "When nonlinearity is involved, deep models are often treated as richer families of black-box functions than linear ones (Arora et al., 2019b;HaoChen et al., 2021).",
    "hard_negative": [
      30745030,
      3624410
    ],
    "easy_negative": [
      51868421,
      14021216,
      202670323
    ]
  },
  {
    "index": 684,
    "source_corpus_id": 257365130,
    "ref_id": "b13",
    "citation_corpus_id": 102350747,
    "start": 5336,
    "end": 5357,
    "title": "Unsupervised Latent Tree Induction with Deep Inside-Outside Recursive Autoencoders",
    "abstract": "We introduce deep inside-outside recursive autoencoders (DIORA), a fully-unsupervised method for discovering syntax that simultaneously learns representations for constituents within the induced tree. Our approach predicts each word in an input sentence conditioned on the rest of the sentence and uses inside-outside dynamic programming to consider all possible binary trees over the sentence. At test time the CKY algorithm extracts the highest scoring parse. DIORA achieves a new state-of-the-art F1 in unsupervised binary constituency parsing (unlabeled) in two benchmark datasets, WSJ and MultiNLI.",
    "prev": "PRELIMINARY\n\n\nESSENTIAL PROPERTIES OF STRUCTURED LANGUAGE MODELS\n\nStructured language models feature combining the powerful representation of neural networks with syntax structures.",
    "curr": "Though many attempts have been made about structured language models (Kim et al., 2019;Drozdov et al., 2019;Shen et al., 2021), three prerequisites need to be met before a model is selected as the backbone of our method.",
    "next": "Firstly, it should have the ability to learn reasonable syntax structure in an unsupervised manner.",
    "hard_negative": [
      8078153,
      312731
    ],
    "easy_negative": [
      11787536,
      1572802,
      16750579
    ]
  },
  {
    "index": 686,
    "source_corpus_id": 233033761,
    "ref_id": "b9",
    "citation_corpus_id": 54101493,
    "start": 3683,
    "end": 3705,
    "title": "IMAGENET-TRAINED CNNS ARE BIASED TOWARDS TEXTURE; INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS",
    "abstract": "Convolutional Neural Networks (CNNs) are commonly thought to recognise objects by learning increasingly complex representations of object shapes. Some recent studies suggest a more important role of image textures. We here put these conflicting hypotheses to a quantitative test by evaluating CNNs and human observers on images with a texture-shape cue conflict. We show that ImageNettrained CNNs are strongly biased towards recognising textures rather than shapes, which is in stark contrast to human behavioural evidence and reveals fundamentally different classification strategies. We then demonstrate that the same standard architecture (ResNet-50) that learns a texture-based representation on ImageNet is able to learn a shape-based representation instead when trained on 'Stylized-ImageNet', a stylized version of ImageNet. This provides a much better fit for human behavioural performance in our well-controlled psychophysical lab setting (nine experiments totalling 48,560 psychophysical trials across 97 observers) and comes with a number of unexpected emergent benefits such as improved object detection performance and previously unseen robustness towards a wide range of image distortions, highlighting advantages of a shape-based representation. de Beeck. Deep neural networks as a computational model for human shape sensitivity. DiCarlo. Performance-optimized hierarchical models predict neural responses in higher visual cortex.",
    "prev": "First, obtaining photorealistic appearance features at the micro-level, such as texture and illumination, is challenging due to the limits of simulation complexity and rendering granularity.",
    "curr": "Without special treatment, CNNs tend to be biased towards textures (Geirhos et al., 2019) and suffer from badly learned representations on synthetic data.",
    "next": "Second, the common lack of texture and shape variations on synthetic images often leads to collapsed and trivial representations without any diversity.",
    "hard_negative": [
      56657912,
      68222714
    ],
    "easy_negative": [
      15631314,
      17910711,
      11527572
    ]
  },
  {
    "index": 688,
    "source_corpus_id": 220514300,
    "ref_id": "b32",
    "citation_corpus_id": 990233,
    "start": 5556,
    "end": 5560,
    "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
    "prev": "Structured Convolutional Models\n\nWe address neural models designed to learn from (multi-)relational, structured data, while exploiting some form of parameter sharing, as \"structured convolutional models\" 1 .",
    "curr": "Examples of such models include Recursive Neural Networks [33,23], Graph Neural Networks [16,28], and various Relational Neural Networks [34,26,5,31], designed for regular trees, graphs, and general relational structures, respectively.",
    "next": "They all utilize the idea of convolution (templating), where the same parameterized pattern is carried over different subparts of the data (representation) with the same local structure.",
    "hard_negative": [
      5584134,
      2279432,
      3116311,
      7747235,
      15659560,
      1588782,
      806709,
      2678583,
      3264224,
      15616495,
      2091504
    ],
    "easy_negative": [
      12666306,
      235313922,
      15058350
    ]
  },
  {
    "index": 693,
    "source_corpus_id": 255749563,
    "ref_id": "b62",
    "citation_corpus_id": 239616181,
    "start": 3323,
    "end": 3343,
    "title": "ILLITERATE DALL-E LEARNS TO COMPOSE",
    "abstract": "Although DALL\u00b7E has shown an impressive ability of composition-based systematic generalization in image generation, it requires the dataset of text-image pairs and the compositionality is provided by the text. In contrast, object-centric representation models like the Slot Attention model learn composable representations without the text prompt. However, unlike DALL\u00b7E its ability to systematically generalize for zero-shot generation is significantly limited. In this paper, we propose a simple but novel slot-based autoencoding architecture, called SLATE 1 , for combining the best of both worlds: learning object-centric representations that allows systematic generalization in zero-shot image generation without text. As such, this model can also be seen as an illiterate DALL\u00b7E model. Unlike the pixel-mixture decoders of existing object-centric representation models, we propose to use the Image GPT decoder conditioned on the slots for capturing complex interactions among the slots and pixels. In experiments, we show that this simple and easy-to-implement architecture not requiring a text prompt achieves significant improvement in in-distribution and out-of-distribution (zero-shot) image generation and qualitatively comparable or better slot-attention structure than the models based on mixture decoders. https://sites.google.com/view/slate-autoencoder",
    "prev": "Yet it is quite elusive what should be the appropriate structure and granularity of these tokens to support systematic generalization and how to obtain them, particularly in the unsupervised setting where the model should learn this ability only by observing.",
    "curr": "In visual scenes, binding has recently been pursued by object-centric learning methods through the spatial binding approach (Locatello et al., 2020;Singh et al., 2022a).",
    "next": "Spatial binding aims to divide a scene spatially into smaller areas so that each area contains a meaningful entity like an object.",
    "hard_negative": [
      2428314,
      232269768
    ],
    "easy_negative": [
      8938695,
      259370629,
      219179830
    ]
  },
  {
    "index": 704,
    "source_corpus_id": 222272028,
    "ref_id": "b5",
    "citation_corpus_id": 54443381,
    "start": 7151,
    "end": 7174,
    "title": "EFFICIENT LIFELONG LEARNING WITH A-GEM",
    "abstract": "In lifelong learning, the learner is presented with a sequence of tasks, incrementally building a data-driven prior which may be leveraged to speed up learning of a new task. In this work, we investigate the efficiency of current lifelong approaches, in terms of sample complexity, computational and memory cost. Towards this end, we first introduce a new and a more realistic evaluation protocol, whereby learners observe each example only once and hyper-parameter selection is done on a small and disjoint set of tasks, which is not used for the actual learning experience and evaluation. Second, we introduce a new metric measuring how quickly a learner acquires a new skill. Third, we propose an improved version of GEM (Lopez-Paz & Ranzato, 2017), dubbed Averaged GEM (A-GEM), which enjoys the same or even better performance as GEM, while being almost as computationally and memory efficient as EWC  and other regularizationbased methods. Finally, we show that all algorithms including A-GEM can learn even more quickly if they are provided with task descriptors specifying the classification tasks under consideration. Our experiments on several standard lifelong learning benchmarks demonstrate that A-GEM has the best trade-off between accuracy and efficiency. 1",
    "prev": "With the trending popularity of deep learning, continual learning has gained a critical importance because the catastrophic forgetting problem imposes key challenges to deploy deep learning models in various applications (e.g Lange et al., 2019;.",
    "curr": "A growing body of research has attempted to tackle this problem in recent years (e.g Parisi et al., 2018;Toneva et al., 2018;Nguyen et al., 2019;Farajtabar et al., 2019;Hsu et al., 2018;Rusu et al., 2016;Kirkpatrick et al., 2017;Zenke et al., 2017;Shin et al., 2017;Rolnick et al., 2018;Lopez-Paz & Ranzato, 2017;Chaudhry et al., 2018b;Riemer et al., 2018;Wallingford et al., 2020).",
    "next": "Among these works, our proposed MC-SGD bares most similarities to rehearsal based methods such us (e.g.",
    "hard_negative": [
      22014305,
      49667227
    ],
    "easy_negative": [
      259376875,
      2608991,
      8241258
    ]
  },
  {
    "index": 705,
    "source_corpus_id": 252408526,
    "ref_id": "b35",
    "citation_corpus_id": 247628243,
    "start": 3094,
    "end": 3098,
    "title": "EVALUATING DISTRIBUTIONAL DISTORTION IN NEURAL LANGUAGE MODELING",
    "abstract": "A fundamental characteristic of natural language is the high rate at which speakers produce novel expressions. Because of this novelty, a heavy-tail of rare events accounts for a significant amount of the total probability mass of distributions in language(Baayen, 2001). Standard language modeling metrics such as perplexity quantify the performance of language models (LM) in aggregate. As a result, we have relatively little understanding of whether neural LMs accurately estimate the probability of sequences in this heavy-tail of rare events. To address this gap, we develop a controlled evaluation scheme which uses generative models trained on natural data as artificial languages from which we can exactly compute sequence probabilities. Training LMs on generations from these artificial languages, we compare the sequence-level probability estimates given by LMs to the true probabilities in the target language. Our experiments reveal that LSTM and Transformer language models (i) systematically underestimate the probability of sequences drawn from the target language, and (ii) do so more severely for lessprobable sequences. Investigating where this probability mass went, (iii) we find that LMs tend to overestimate the probability of ill-formed (perturbed) sequences. In addition, we find that this underestimation behaviour (iv) is weakened, but not eliminated by greater amounts of training data, and (v) is exacerbated for target distributions with lower entropy.",
    "prev": "Prior work has developed a rough taxonomy of data properties, or metadata which different examples might exhibit, including but not limited to: noisy [68,71,62,63], atypical [25,10,21,60], challenging [24,3,8,49,2], prototypical or core subset selection [49,55,56,27] and out-of-distribution This approach can bring to light biases, mislabelled examples, and other dataset issues.",
    "curr": "[36].",
    "next": "While important progress has been made on some of these metadata categories individually, these categories are typically addressed in isolation reflecting an overly strong assumption that only one, known issue is at play in a given dataset.",
    "hard_negative": [
      208117506,
      202539918,
      202539170,
      7478738,
      199551982
    ],
    "easy_negative": [
      237440414,
      197865,
      235075857
    ]
  },
  {
    "index": 709,
    "source_corpus_id": 249209577,
    "ref_id": "b2",
    "citation_corpus_id": 219558760,
    "start": 10125,
    "end": 10144,
    "title": "On the Bottleneck of Graph Neural Networks and its Practical Implications",
    "abstract": "Graph neural networks (GNNs) were shown to effectively learn from highly structured data containing elements (nodes) with relationships (edges) between them. GNN variants differ in how each node in the graph absorbs the information flowing from its neighbor nodes. In this paper, we highlight an inherent problem in GNNs: the mechanism of propagating information between neighbors creates a bottleneck when every node aggregates messages from its neighbors. This bottleneck causes the over-squashing of exponentially-growing information into fixed-size vectors. As a result, the graph fails to propagate messages flowing from distant nodes and performs poorly when the prediction task depends on long-range information. We demonstrate that the bottleneck hinders popular GNNs from fitting the training data. We show that GNNs that absorb incoming edges equally, like GCN and GIN, are more susceptible to over-squashing than other GNN types. We further show that existing, extensively-tuned, GNN-based models suffer from over-squashing and that breaking the bottleneck improves state-of-the-art results without any hyperparameter tuning or additional weights.Preprint. Under review.",
    "prev": "Modern approaches implement variations of this idea as differentiable neural architectures (Gori et al., 2005;Scarselli et al., 2008;Kipf & Welling, 2017;Gilmer et al., 2017).",
    "curr": "This allows to express more elaborate forms of propagation (Li et al., 2018;Alon & Yahav, 2021) and aggregation (Wu et al., 2019;Xu et al., 2019;Li et al., 2016), including attention-based mechanisms (Veli\u010dkovi\u0107 et al., 2018;Brody et al., 2022).",
    "next": "Nonetheless, a key result by Wu et al.",
    "hard_negative": [
      11336213,
      3144218,
      3495200,
      8393918,
      13697606,
      202888772,
      209439835,
      212859361,
      52895589
    ],
    "easy_negative": [
      219308374,
      253384392,
      220058122
    ]
  },
  {
    "index": 711,
    "source_corpus_id": 247292293,
    "ref_id": "b47",
    "citation_corpus_id": 3292002,
    "start": 25827,
    "end": 25852,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "3(c), we compare the test accuracy averaged on eight graphs when using different GNNs e.g.",
    "curr": "GCN, SGC (Wu et al., 2019) and GAT (Velickovic et al., 2018), for data generation (See Appendix G for more results).",
    "next": "The results verify that our approach achieves consistently superior performance in different cases.",
    "hard_negative": [
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      202783651,
      243865555,
      235352802
    ]
  },
  {
    "index": 719,
    "source_corpus_id": 208268589,
    "ref_id": "b26",
    "citation_corpus_id": 5037032,
    "start": 7227,
    "end": 7247,
    "title": "ZERO-SHOT VISUAL IMITATION",
    "abstract": "The current dominant paradigm for imitation learning relies on strong supervision of expert actions to learn both what and how to imitate.We pursue an alternative paradigm wherein an agent first explores the world without any expert supervision and then distills its experience into a goal-conditioned skill policy with a novel forward consistency loss.In our framework, the role of the expert is only to communicate the goals (i.e., what to imitate) during inference.The learned policy is then employed to mimic the expert (i.e., how to imitate) after seeing just a sequence of images demonstrating the desired task.Our method is \"zero-shot\" in the sense that the agent never has access to expert actions during training or for the task demonstration at inference.We evaluate our zero-shot imitator in two real-world settings: complex rope manipulation with a Baxter robot and navigation in previously unseen office environments with a TurtleBot.Through further experiments in VizDoom simulation, we provide evidence that better mechanisms for exploration lead to learning a more capable policy which in turn improves end task performance.Videos, models, and more details are available at https://pathak22.github.io/zeroshot-imitation/. * Denotes equal contribution.",
    "prev": "\u2022 Combine the local alignment and global alignment components into a reinforcement learning framework by a regularized policy update objective.",
    "curr": "RELATED WORK\n\nImitation learning is widely used in solving complicated tasks where pure reinforcement learning might suffer from high sample complexity, like robotics control (Le et al., 2017;Ye & Alterovitz, 2017;Pathak et al., 2018), autonomous vehicle (Fu et al.",
    "next": ";Pomerleau, 1989), and playing video game Pohlen et al., 2018;Aytar et al., 2018a).",
    "hard_negative": [
      6628106,
      14724343
    ],
    "easy_negative": [
      261341918,
      239009856,
      21710652
    ]
  },
  {
    "index": 720,
    "source_corpus_id": 252280667,
    "ref_id": "b1",
    "citation_corpus_id": 7167114,
    "start": 67362,
    "end": 67382,
    "title": "DEEP VARIATIONAL INFORMATION BOTTLENECK",
    "abstract": "We present a variational approximation to the information bottleneck ofTishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \"Deep Variational Information Bottleneck\", or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.",
    "prev": "GWAE (GMP), AUC=1.0000.",
    "curr": "Figure 3 :\n3The ROC curves of the OoD detection inMNIST (LeCun et al., 1998) against Omniglot (Lake et al., 2015\n\nFrom\nthe Information Bottleneck (IB)(Tishby et al., 1999)  point of view, the \u03b2-VAE objective is re-interpreted as the following optimization problem(Alemi et al., 2018;Achille & Soatto, 2018): maximize \u03b8,\u03c6 I \u03c6 (z; y)\n\n\nZhao et al., 2019)  is an extension of VAE to prevent posterior collapse by the retention of data information in the latent variables.",
    "next": "The InfoVAE objective is the sum of the ELBO and the inference model mutual information I \u03c6 in Eq.",
    "hard_negative": [
      6628106,
      1257772,
      604334,
      5922522,
      6706414
    ],
    "easy_negative": [
      13328594,
      233210350,
      901816
    ]
  },
  {
    "index": 724,
    "source_corpus_id": 2721941,
    "ref_id": "b0",
    "citation_corpus_id": 748227,
    "start": 2947,
    "end": 2968,
    "title": "Generating Sentences from a Continuous Space",
    "abstract": "The standard recurrent neural network language model (rnnlm) generates sentences one word at a time and does not work from an explicit global sentence representation. In this work, we introduce and study an rnn-based variational autoencoder generative model that incorporates distributed latent representations of entire sentences. This factorization allows it to explicitly model holistic properties of sentences such as style, topic, and high-level syntactic features. Samples from the prior over these sentence representations remarkably produce diverse and well-formed sentences through simple deterministic decoding. By examining paths through this latent space, we are able to generate coherent novel sentences that interpolate between known sentences. We present techniques for solving the difficult learning problem presented by this model, demonstrate its effectiveness in imputing missing words, explore many interesting properties of the model's latent sentence space, and present negative results on the use of the model in language modeling.",
    "prev": "We find particularly promising the opportunity to leverage deep generative models for search in high-dimensional discrete spaces (G\u00f3mez-Bombarelli et al., 2016b;Kusner et al., 2017).",
    "curr": "Discrete search is at the heart of problems in drug discovery (G\u00f3mez-Bombarelli et al., 2016a), natural language processing (Bowman et al., 2016;Guimaraes et al., 2017), and symbolic regression (Kusner et al., 2017).",
    "next": "The application of deep modeling to search involves 'lifting' the search from the discrete space to a continuous space, via an autoencoder (Rumelhart et al., 1985).",
    "hard_negative": [
      216848261,
      1988653,
      10181753,
      3509328,
      9672033,
      207468,
      11212020,
      252796
    ],
    "easy_negative": [
      53083728,
      226283672,
      12186066
    ]
  },
  {
    "index": 735,
    "source_corpus_id": 13298214,
    "ref_id": "b13",
    "citation_corpus_id": 8395799,
    "start": 12275,
    "end": 12299,
    "title": "Language Understanding for Text-based Games using Deep Reinforcement Learning",
    "abstract": "In this paper, we consider the task of learning control policies for text-based games. In these games, all interactions in the virtual world are through text and the underlying state is not observed. The resulting language barrier makes such environments challenging for automatic game players. We employ a deep reinforcement learning framework to jointly learn state representations and action policies using game rewards as feedback. This framework enables us to map text descriptions into vector representations that capture the semantics of the game states. We evaluate our approach on two game worlds, comparing against baselines using bag-ofwords and bag-of-bigrams for state representations. Our algorithm outperforms the baselines on both worlds demonstrating the importance of learning expressive representations. 1",
    "prev": "Recent work has developed on-policy RL methods such as advantage actor-critic that use asynchronous training of multiple agents in parallel (Mnih et al., 2016).",
    "curr": "Recurrent networks have also been successfully incorporated to enable state disambiguation in partially observable environments (Koutnik et al., 2013;Hausknecht & Stone, 2015;Mnih et al., 2016;Narasimhan et al., 2015).",
    "next": ", 1999)) to transfer between navigation tasks.",
    "hard_negative": [
      9963298,
      1174836,
      3033526,
      1957433,
      2215227,
      8781666
    ],
    "easy_negative": [
      182178553,
      9218427,
      236460308
    ]
  },
  {
    "index": 736,
    "source_corpus_id": 1257772,
    "ref_id": "b0",
    "citation_corpus_id": 11212020,
    "start": 1804,
    "end": 1826,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "We find that a large fraction of adversarial examples are classified incorrectly even when perceived through the camera.",
    "curr": "INTRODUCTION\n\nRecent advances in machine learning and deep neural networks enabled researchers to solve multiple important practical problems like image, video, text classification and others (Krizhevsky et al., 2012;Hinton et al., 2012;Bahdanau et al., 2015).",
    "next": "However, machine learning models are often vulnerable to adversarial manipulation of their input intended to cause incorrect classification (Dalvi et al., 2004).",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      11885859,
      1289925,
      259370802
    ]
  },
  {
    "index": 738,
    "source_corpus_id": 259274820,
    "ref_id": "b0",
    "citation_corpus_id": 235436185,
    "start": 25378,
    "end": 25381,
    "title": "BEIT: BERT Pre-Training of Image Transformers",
    "abstract": "We introduce a self-supervised vision representation model BEIT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT [DCLT19] developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16\u00d716 pixels), and visual tokens (i.e., discrete tokens). We first \"tokenize\" the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEIT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.",
    "prev": "is typically utilized for downstream initialization.",
    "curr": "Except for the common supervised pre-training [16,10,24], contrastive learning (CL) [4,14,6,12] and masked image modeling (MIM) [1,44,13] dominate the recent research.",
    "next": "The former is achieved by pulling close the features of two different augment views of the input image.",
    "hard_negative": [
      14307651,
      52055130,
      218581596,
      4009713
    ],
    "easy_negative": [
      5578635,
      6167074,
      208267772
    ]
  },
  {
    "index": 739,
    "source_corpus_id": 265037895,
    "ref_id": "b14",
    "citation_corpus_id": 3366315,
    "start": 2403,
    "end": 2423,
    "title": "Published as a conference paper at ICLR 2018 SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.Published as a conference paper at ICLR 2018\u2022 Lipschitz constant is the only hyper-parameter to be tuned, and the algorithm does not require intensive tuning of the only hyper-parameter for satisfactory performance. \u2022 Implementation is simple and the additional computational cost is small.",
    "prev": "The original GAN is, however, highly unstable and often suffers from mode collapse.",
    "curr": "Much of recent researches has focused on improving the stability of GANs (Radford et al., 2015;Heusel et al., 2017;Miyato et al., 2018;Karras et al., 2018).",
    "next": "On the theoretical aspect, Nagarajan & Kolter (2017) proved that gradient based training of the original GAN is locally stable.",
    "hard_negative": [
      6628106,
      5687613,
      18828233,
      3633127,
      14570343,
      11758569
    ],
    "easy_negative": [
      63695190,
      221738987,
      201626593
    ]
  },
  {
    "index": 740,
    "source_corpus_id": 56895453,
    "ref_id": "b33",
    "citation_corpus_id": 2705742,
    "start": 8430,
    "end": 8449,
    "title": "Learning Language Games through Interaction",
    "abstract": "We introduce a new language learning setting relevant to building adaptive natural language interfaces. It is inspired by Wittgenstein's language games: a human wishes to accomplish some task (e.g., achieving a certain configuration of blocks), but can only communicate with a computer, who performs the actual actions (e.g., removing all red blocks). The computer initially knows nothing about language and therefore must learn it from scratch through interaction, while the human adapts to the computer's capabilities. We created a game called SHRDLURN in a blocks world and collected interactions from 100 people playing it. First, we analyze the humans' strategies, showing that using compositionality and avoiding synonyms correlates positively with task performance. Second, we compare computer strategies, showing that modeling pragmatics on a semantic parsing model accelerates learning for more strategic players.",
    "prev": "However, they have non-symmetric addition of agents in communication channel and are restricted to only cooperative scenarios.",
    "curr": "In contrast, a lot of work has focused on understanding agents' communication content; mostly in discrete settings with two agents (Wang et al., 2016;Havrylov & Titov, 2017;Kottur et al., 2017;Lazaridou et al., 2016;.",
    "next": "Lazaridou et al.",
    "hard_negative": [
      6401679,
      12728987,
      9963298,
      9337134,
      9497011,
      7719615,
      6228816,
      9027681,
      340852,
      333563,
      5249151
    ],
    "easy_negative": [
      13873204,
      215548041,
      259376755
    ]
  },
  {
    "index": 741,
    "source_corpus_id": 252917667,
    "ref_id": "b6",
    "citation_corpus_id": 231698861,
    "start": 7500,
    "end": 7503,
    "title": "Published as a conference paper at ICLR 2021 LEARNING PARAMETRISED GRAPH SHIFT OPERATORS",
    "abstract": "In many domains data is currently represented as graphs and therefore, the graph representation of this data becomes increasingly important in machine learning. Network data is, implicitly or explicitly, always represented using a graph shift operator (GSO) with the most common choices being the adjacency, Laplacian matrices and their normalisations. In this paper, a novel parametrised GSO (PGSO) is proposed, where specific parameter values result in the most commonly used GSOs and message-passing operators in graph neural network (GNN) frameworks. The PGSO is suggested as a replacement of the standard GSOs that are used in state-of-the-art GNN architectures and the optimisation of the PGSO parameters is seamlessly included in the model training. It is proved that the PGSO has real eigenvalues and a set of real eigenvectors independent of the parameter values and spectral bounds on the PGSO are derived. PGSO parameters are shown to adapt to the sparsity of the graph structure in a study on stochastic blockmodel networks, where they are found to automatically replicate the GSO regularisation found in the literature. On several real-world datasets the accuracy of state-of-theart GNN architectures is improved by the inclusion of the PGSO in both nodeand graph-classification tasks. * Equal contribution.Published as a conference paper at ICLR 2021On different tasks and datasets, the choice between the different representations encoded by the different graph shift operator matrices has shown to be a consequential decision. Due to the past successful approaches that use different GSOs for different tasks and datasets, it is natural to assume that there is no single optimal representation for all scenarios. Finding an optimal representation of network data could contribute positively to a range of learning tasks such as node and graph classification or community detection. Fundamental to this search is an answer to Question 1. In addition, we pose the following second research question.Question 2: Can we learn such an optimal representation to encode graph structure in a numerically stable and computationally efficient way?The utilisation of a GSO as a topology representation is currently a hand-engineered choice of normalised variants of the adjacency matrix. Thus, the learnable representation of node interactions is transferred into either convolutional filters(Kipf & Welling, 2017;Hamilton et al., 2017a)or attention weights(Veli\u010dkovi\u0107 et al., 2018), keeping the used GSO constant. In this work, we suggest a parametrisation of the GSO. Specific parameter values in our proposed parametrised (and differentiable) GSO result in the most commonly used GSOs, namely the adjacency, unnormalised Laplacian and both normalised Laplacian matrices, and GNN aggregation functions, e.g., the averaging and summation message passing operations. The beauty of this innovation is that it can be seamlessly included in both message passing and convolutional GNN architectures. Optimising the operator parameters will allow us to find answers to our two research questions.",
    "prev": "Together with Dasoulas et al.",
    "curr": "[7] and Sahbi [33], our work can be listed as a theoretically grounded way to learn the GSO.",
    "next": "Justified by formulas grounded in Monte-Carlo analysis, we show how to compensate for the nonuniformity in the sampling when computing non-uniform geometric GSOs.",
    "hard_negative": [
      195833273,
      3292002,
      52895589,
      210843644
    ],
    "easy_negative": [
      8680,
      207917908,
      236999927
    ]
  },
  {
    "index": 749,
    "source_corpus_id": 239016655,
    "ref_id": "b2",
    "citation_corpus_id": 231648113,
    "start": 23035,
    "end": 23062,
    "title": "ZERO-COST PROXIES FOR LIGHTWEIGHT NAS",
    "abstract": "Neural Architecture Search (NAS) is quickly becoming the standard methodology to design neural network models. However, NAS is typically compute-intensive because multiple models need to be evaluated before choosing the best one. To reduce the computational power and time needed, a proxy task is often used for evaluating each model instead of full training. In this paper, we evaluate conventional reduced-training proxies and quantify how well they preserve ranking between multiple models during search when compared with the rankings produced by final trained accuracy. We propose a series of zero-cost proxies, based on recent pruning literature, that use just a single minibatch of training data to compute a model's score. Our zero-cost proxies use 3 orders of magnitude less computation but can match and even outperform conventional proxies. For example, Spearman's rank correlation coefficient between final validation accuracy and our best zero-cost proxy on NAS-Bench-201 is 0.82, compared to 0.61 for EcoNAS (a recently proposed reduced-training proxy). Finally, we use these zerocost proxies to enhance existing NAS search algorithms such as random search, reinforcement learning, evolutionary search and predictor-based search. For all search methodologies and across three different NAS datasets, we are able to significantly improve sample efficiency, and thereby decrease computation, by using our zero-cost proxies. For example on NAS-Bench-101, we achieved the same accuracy 4\u00d7 quicker than the best previous result.",
    "prev": "Experimental setup details are included in Appendix A.3.",
    "curr": "To align with the experimental setup of prior work (Abdelfattah et al., 2021b;Mellor et al., 2021), we use two criteria to evaluate the correlations between different metrics and test accuracies across approximately 20k networks:\n\nSpearman's \u03c1 (Daniel et al., 1990) characterizes the monotonic relationships between two variables.",
    "next": "The correlation score is restricted in range [-1, 1], where \u03c1 = 1 denotes a perfect positive monotonic relationship and \u03c1 = \u22121 denotes a perfect negative monotonic relationship.",
    "hard_negative": [
      52920837,
      49411844,
      209531937,
      211146532,
      53388625,
      12713052
    ],
    "easy_negative": [
      14171240,
      225066758,
      39485158
    ]
  },
  {
    "index": 752,
    "source_corpus_id": 232290577,
    "ref_id": "b43",
    "citation_corpus_id": 196183669,
    "start": 10921,
    "end": 10940,
    "title": "Generating Fluent Adversarial Examples for Natural Languages",
    "abstract": "Efficiently building an adversarial attacker for natural language processing (NLP) tasks is a real challenge. Firstly, as the sentence space is discrete, it is difficult to make small perturbations along the direction of gradients. Secondly, the fluency of the generated examples cannot be guaranteed. In this paper, we propose MHA, which addresses both problems by performing Metropolis-Hastings sampling, whose proposal is designed with the guidance of gradients. Experiments on IMDB and SNLI show that our proposed MHA outperforms the baseline model on attacking capability. Adversarial training with MHA also leads to better robustness and performance.",
    "prev": "Different from this work, MARS is built upon the general MCMC sampling framework, which allows further enhancement with adaptive proposal learning to edit molecular graphs efficiently.",
    "curr": "Actually, generating instances from a discrete space with MCMC sampling methods is previously employed in various other applications, e.g., generating natural language sentences under various constraints Zhang et al., 2019;.",
    "next": "PROPOSED MARS APPROACH\n\nIn this section, we present the MArkov moleculaR Sampling method (MARS) for multi-objective molecular design.",
    "hard_negative": [
      13886408,
      6247656,
      15652746,
      21698802,
      1428702,
      5076191
    ],
    "easy_negative": [
      2872204,
      247388380,
      7966916
    ]
  },
  {
    "index": 754,
    "source_corpus_id": 251765117,
    "ref_id": "b27",
    "citation_corpus_id": 218487034,
    "start": 3201,
    "end": 3222,
    "title": "On Faithfulness and Factuality in Abstractive Summarization",
    "abstract": "It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria.",
    "prev": "respects; for example, they are not able to retroactively modify or refine their own outputs.",
    "curr": "Beyond that, they are hard to control (Korbak et al., 2022) and verifying their outputs is challenging as they often hallucinate content (Maynez et al., 2020;Shuster et al., 2021;Nakano et al., 2021) and lack the ability to explain their intentions.",
    "next": "All of this makes it very difficult for humans to collaborate with such models for writing coherent, factual texts.",
    "hard_negative": [
      4940548,
      23892230,
      1046281,
      202734604,
      1238927,
      3510042,
      189762081,
      3608234,
      3432876,
      21850704,
      86611921,
      199551982,
      215768182,
      196181887
    ],
    "easy_negative": [
      235097303,
      236460246,
      243865565
    ]
  },
  {
    "index": 759,
    "source_corpus_id": 264289264,
    "ref_id": "b44",
    "citation_corpus_id": 247446904,
    "start": 9874,
    "end": 9893,
    "title": "Published as a conference paper at ICLR 2023 PROTEIN REPRESENTATION LEARNING BY GEOMETRIC STRUCTURE PRETRAINING",
    "abstract": "Learning effective protein representations is critical in a variety of tasks in biology such as predicting protein function or structure. Existing approaches usually pretrain protein language models on a large number of unlabeled amino acid sequences and then finetune the models with some labeled data in downstream tasks. Despite the effectiveness of sequence-based approaches, the power of pretraining on known protein structures, which are available in smaller numbers only, has not been explored for protein property prediction, though protein structures are known to be determinants of protein function. In this paper, we propose to pretrain protein representations according to their 3D structures. We first present a simple yet effective encoder to learn the geometric features of a protein. We pretrain the protein graph encoder by leveraging multiview contrastive learning and different self-prediction tasks. Experimental results on both function prediction and fold classification tasks show that our proposed pretraining methods outperform or are on par with the state-of-the-art sequence-based methods, while using much less pretraining data. Our implementation is available at https://github.com/ DeepGraphLearning/GearNet.",
    "prev": "mising methods in the realm of protein design, which encompasses protein diffusion (Yim et al., 2023) and inverse folding (Gao et al., 2022a;Jendrusch et al., 2021;Wu et al., 2021;Ovchinnikov & Huang, 2021;Dauparas et al., 2022;Ingraham et al., 2019;Hsu et al., 2022;Gao et al., 2023b;Derevyanko et al., 2018).Specifically, a protein diffusion model first generates the backbone structure of a protein, followed by an inverse folding network that designs the corresponding sequence for this backbone.The feasibility of both these steps has been experimentally validated through cryo-electron microscopy (Watson et al., 2023;Dauparas et al., 2022), marking a significant breakthrough in the field of protein design.However, while protein diffusion methods based on frame representation achieve significant success, in these methods, atom representation is absent, rendering previous general purpose encoders unusable.",
    "curr": "GENERAL PURPOSE ENCODER\n\nIn the past, numerous encoders (Hermosilla et al., 2020;Zhang et al., 2022;Hermosilla & Ropinski, 2022;Veli\u010dkovi\u0107 et al., 2017;Baldassarre et al., 2021;Li et al., 2022;Gao et al., 2022b;Shroff et al., 2019;Dumortier et al., 2022;McPartlon et al., 2022;Cao et al., 2021;Anishchenko et al., 2021;Karimi et al., 2020;Zhang et al., 2020;Wang et al., 2022b;Derevyanko et al., 2018) have been proposed for tasks such as model quality assessment (Townshend et al., 2021) and fold classification (Hou et al., 2018), where atomic information is available.However, these methods are not suitable for protein design tasks where atomic representations of proteins are unavailable.For instance, GVP (Jing et al., 2020) transforms input atomic coordinates into vector and scalars variables as the network input, facilitating the model's SE(3) invariance.Meanwhile, Wang et al.",
    "next": "(2022a); Jin et al.",
    "hard_negative": [
      3144218,
      211842237
    ],
    "easy_negative": [
      248811371,
      258947302,
      61294173
    ]
  },
  {
    "index": 764,
    "source_corpus_id": 108296236,
    "ref_id": "b42",
    "citation_corpus_id": 1957433,
    "start": 2187,
    "end": 2212,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "INTRODUCTION\n\nLearned embeddings form the basis for many state-of-the-art learning systems.",
    "curr": "Word embeddings like word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), fastText (Bojanowski et al., 2017), and ELMo (Peters et al., 2018) are ubiquitous in natural language processing, where they are used for tasks like machine translation (Neubig et al., 2018), while graph embeddings (Nickel et al., 2016) like node2vec (Grover & Leskovec, 2016) are used to represent knowledge graphs and pre-trained image models (Simon et al., 2016) appear in many computer vision pipelines.",
    "next": "An effective embedding should capture the semantic structure of the data with high fidelity, in a way that is amenable to downstream tasks.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      1104123
    ],
    "easy_negative": [
      246702343,
      7668783,
      15761339
    ]
  },
  {
    "index": 771,
    "source_corpus_id": 220265858,
    "ref_id": "b38",
    "citation_corpus_id": 6359641,
    "start": 40818,
    "end": 40822,
    "title": "Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism",
    "abstract": "We propose multi-way, multilingual neural machine translation. The proposed approach enables a single neural translation model to translate between multiple languages, with a number of parameters that grows only linearly with the number of languages. This is made possible by having a single attention mechanism that is shared across all language pairs. We train the proposed multiway, multilingual model on ten language pairs from WMT'15 simultaneously and observe clear performance improvements over models trained on only one language pair. In particular, we observe that the proposed model significantly improves the translation quality of low-resource language pairs.",
    "prev": "As a result, the run-time overhead is typically negligible, even for convolutional networks where masking and padding are heavily used.",
    "curr": "We chose multilingual neural machine translation (MT) [39,40,41] to validate our design for efficient training with GShard.",
    "next": "Multilingual MT, which is an inherently multi-task learning problem, aims at building a single neural network for the goal of translating multiple language pairs simultaneously.",
    "hard_negative": [
      6628106,
      1998416,
      11336213,
      359451
    ],
    "easy_negative": [
      8502808,
      248780023,
      250390934
    ]
  },
  {
    "index": 775,
    "source_corpus_id": 247778993,
    "ref_id": "b4",
    "citation_corpus_id": 54458698,
    "start": 1952,
    "end": 1978,
    "title": "Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning",
    "abstract": "Text-based adventure games provide a platform on which to explore reinforcement learning in the context of a combinatorial action space, such as natural language. We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration. This graph is used to prune the action space, enabling more efficient exploration. The question of which action to take can be reduced to a question-answering task, a form of transfer learning that pre-trains certain parts of our architecture. In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives. We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN.",
    "prev": "Our experiments show that the proposed approach consistently improves existing methods, obtains good out-of-distribution generalization, and achieves new state-of-the-art results on widely used environments.",
    "curr": "INTRODUCTION\n\nText-based games (TBGs) have emerged as key benchmarks for studying how reinforcement learning (RL) agents can tackle the challenges of grounded language understanding, partial observability, large action spaces, and out-of-distribution generalization Ammanabrolu & Riedl, 2019).",
    "next": "While we have indeed made some progress on these fronts in recent years Adhikari et al., 2020;Murugesan et al., 2021b;a), these agents are still very inefficient and suffer from insufficient generalization to novel environments.",
    "hard_negative": [
      6015236,
      3618568,
      2924682
    ],
    "easy_negative": [
      224803723,
      14285410,
      248721770
    ]
  },
  {
    "index": 779,
    "source_corpus_id": 14711954,
    "ref_id": "b2",
    "citation_corpus_id": 3130692,
    "start": 5513,
    "end": 5535,
    "title": "Learning to Compose Neural Networks for Question Answering",
    "abstract": "We describe a question answering model that applies to both images and structured knowledge bases. The model uses natural language strings to automatically assemble neural networks from a collection of composable modules. Parameters for these modules are learned jointly with network-assembly parameters via reinforcement learning, with only (world, question, answer) triples as supervision. Our approach, which we term a dynamic neural module network, achieves state-of-theart results on benchmark datasets in both visual and structured domains.",
    "prev": "We show that our approach substantially outperforms purely unsupervised methods that do not provide the learner with any task-specific guidance about how hierarchies should be deployed, and further that the specific use of sketches to parameterize modular subpolicies makes better use of sketches than conditioning on them directly.",
    "curr": "The present work may be viewed as an extension of recent approaches for learning compositional deep architectures from structured program descriptors (Andreas et al., 2016;Reed & de Freitas, 2016).",
    "next": "Here we focus on learning in interactive environments.",
    "hard_negative": [
      9027681,
      9337134,
      14687186
    ],
    "easy_negative": [
      9798738,
      7231965,
      253761978
    ]
  },
  {
    "index": 781,
    "source_corpus_id": 247849778,
    "ref_id": "b15",
    "citation_corpus_id": 236459945,
    "start": 2063,
    "end": 2081,
    "title": "Enhancing Content Preservation in Text Style Transfer Using Reverse Attention and Conditional Layer Normalization",
    "abstract": "Text style transfer aims to alter the style (e.g., sentiment) of a sentence while preserving its content. A common approach is to map a given sentence to content representation that is free of style, and the content representation is fed to a decoder with a target style. Previous methods in filtering style completely remove tokens with style at the token level, which incurs the loss of content information. In this paper, we propose to enhance content preservation by implicitly removing the style information of each token with reverse attention, and thereby retain the content. Furthermore, we fuse content information when building the target style representation, making it dynamic with respect to the content. Our method creates not only styleindependent content representation, but also content-dependent style representation in transferring style. Empirical results show that our method outperforms the state-of-the-art baselines by a large margin in terms of content preservation. In addition, it is also competitive in terms of style transfer accuracy and fluency.",
    "prev": "INTRODUCTION\n\nText style transfer (TST) models learn how to transfer the style of text from source to target while preserving the style-independent content (John et al., 2019;Fu et al., 2018).",
    "curr": "Existing TST methods perform well when transferring simple styles, such as sentiment; however, they tend to do a poor job on more abstract and subtle styles, such as formality and political stance (Lee et al., 2021;Fu et al., 2019b).",
    "next": "The lack of parallel datasets is one of the main bottlenecks for text style transfer tasks.",
    "hard_negative": [
      9672033,
      46889991,
      52967399,
      6628106,
      13959787,
      153313581,
      8313873,
      11212020,
      6857205,
      2428314,
      5687613
    ],
    "easy_negative": [
      53246621,
      438829,
      18053326
    ]
  },
  {
    "index": 783,
    "source_corpus_id": 12130431,
    "ref_id": "b18",
    "citation_corpus_id": 14124313,
    "start": 2824,
    "end": 2851,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "We believe that our method sheds new insights on how to make deep CNNs to be applicable on mobile or embedded devices.",
    "curr": "The code is available at https://github.com\n\nINTRODUCTION\n\nDeep convolutional neural networks (CNNs) have demonstrated record breaking results on a variety of computer vision tasks such as image classification (Krizhevsky et al., 2012;Simonyan & Zisserman, 2015), face recognition (Taigman et al., 2014;Sun et al., 2014), semantic segmentation (Long et al., 2015;Chen et al., 2015a) and object detection (Girshick, 2015;Ren et al., 2015).",
    "next": "Regardless of the availability of significantly improved training resources such as abundant annotated data, powerful computational platforms and diverse training frameworks, the promising results of deep CNNs are mainly attributed to the large number of learnable parameters, ranging from tens of millions to even hundreds of millions.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      14229502,
      53651435,
      237940293
    ]
  },
  {
    "index": 786,
    "source_corpus_id": 238419267,
    "ref_id": "b6",
    "citation_corpus_id": 11212020,
    "start": 8264,
    "end": 8287,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "THE PROBABILISTIC ATTENTION MECHANISM\n\nWe now give a high-level explanation of our results; the detailed formulations are in Section 2.",
    "curr": "Introduced in (Bahdanau et al., 2015) and later used to define the transformer architecture (Vaswani et al., 2017), in the NLP context, attention maps a matrix of queries Q, a matrix of keys K, and a matrix of values V to the quantity Softmax(QK )V , where the softmax function (defined below) is applied row-wise to QK .",
    "next": "Just as the authors of (Petersen & Voigtlaender, 2020;Zhou, 2020) focus on the simplified versions of practically implementable ConvNets in the study of approximation theory of deep ConvNets (e.g.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      29437576,
      11728465,
      6936671
    ]
  },
  {
    "index": 787,
    "source_corpus_id": 88517649,
    "ref_id": "b8",
    "citation_corpus_id": 52889459,
    "start": 2223,
    "end": 2226,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "By capturing the mechanisms behind the data generation process, one can reason about data probabilistically, access and traverse the low-dimensional manifold the data is assumed to live on, and ultimately generate new data.",
    "curr": "It is therefore not surprising that learning generative models has gained momentum in applications like chemistry [16,25], NLP [8,46] and computer vision [9,48].",
    "next": "Variational Autoencoders (VAEs) [27,38] allow for a principled probabilistic way to model high-dimensional distributions.",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      16285012,
      7751200,
      253156410
    ]
  },
  {
    "index": 794,
    "source_corpus_id": 238408158,
    "ref_id": "b39",
    "citation_corpus_id": 3587087,
    "start": 1885,
    "end": 1904,
    "title": "Collective Entity Disambiguation with Structured Gradient Tree Boosting",
    "abstract": "We present a gradient-tree-boosting-based structured learning model for jointly disambiguating named entities in a document. Gradient tree boosting is a widely used machine learning algorithm that underlies many topperforming natural language processing systems. Surprisingly, most works limit the use of gradient tree boosting as a tool for regular classification or regression problems, despite the structured nature of language. To the best of our knowledge, our work is the first one that employs the structured gradient tree boosting (SGTB) algorithm for collective entity disambiguation. By defining global features over previous disambiguation decisions and jointly modeling them with local features, our system is able to produce globally optimized entity assignments for mentions in a document. Exact inference is prohibitively expensive for our globally normalized model. To solve this problem, we propose Bidirectional Beam Search with Gold path (BiBSG), an approximate inference algorithm that is a variant of the standard beam search algorithm. BiBSG makes use of global information from both past and future to perform better local search. Experiments on standard benchmark datasets show that SGTB significantly improves upon published results. Specifically, SGTB outperforms the previous state-of-the-art neural system by near 1% absolute accuracy on the popular AIDA-CoNLL dataset. 1",
    "prev": "INTRODUCTION\n\nWe consider the most general form of entity linking (EL) in which a system, given a document, must both extract entity mentions and link the mentions to their corresponding entries in a knowledge base (KB).",
    "curr": "EL is a foundational building block in automatic text understanding with applications to question answering (QA) (Ferrucci, 2012), information retrieval (Xiong et al., 2017;Hasibi et al., 2016;Balog et al., 2013;Reinanda et al., 2015), and commercial recommendation systems (Yang et al., 2018;Slawski, 2015).",
    "next": "The output space in EL is intractably large.",
    "hard_negative": [
      18309765,
      6401679,
      5267356,
      18772898,
      2882092,
      17784265,
      5883983,
      2952144,
      17507793,
      1405777,
      6430811,
      10910955,
      3021306
    ],
    "easy_negative": [
      53081632,
      225103074,
      247188139
    ]
  },
  {
    "index": 795,
    "source_corpus_id": 254096162,
    "ref_id": "b18",
    "citation_corpus_id": 235313882,
    "start": 10712,
    "end": 10731,
    "title": "NODE-GAM: NEURAL GENERALIZED ADDITIVE MODEL FOR INTERPRETABLE DEEP LEARNING",
    "abstract": "Deployment of machine learning models in real high-risk settings (e.g. healthcare) often depends not only on the model's accuracy but also on its fairness, robustness, and interpretability. Generalized Additive Models (GAMs) are a class of interpretable models with a long history of use in these high-risk domains, but they lack desirable features of deep learning such as differentiability and scalability. In this work, we propose a neural GAM (NODE-GAM) and neural GA 2 M (NODE-GA 2 M) that scale well and perform better than other GAMs on large datasets, while remaining interpretable compared to other ensemble and deep learning models. We demonstrate that our models find interesting patterns in the data. Lastly, we show that we improve model accuracy via self-supervised pre-training, an improvement that is not possible for non-differentiable GAMs.",
    "prev": "By using neural networks to learn the transformations from raw feature values to effects, Neural Additive Models (NAMs) maintain the interpretability of GAMs with more expressive effects (Agarwal et al., 2021).",
    "curr": "Pairwise interactions between effects can be included for more complex models (Yang et al., 2021;Chang et al., 2022), though complications arise involving degeneracy and the number of effect terms to inspect grows rapidly.",
    "next": "Regularization can be used to encourage sparsity in the ML model so that fewer components-weights in the network (Ng, 2004) or even features (Lemhadri et al., 2021)-conspire to produce the final prediction.",
    "hard_negative": [
      153313159,
      53112107
    ],
    "easy_negative": [
      260866107,
      231918498,
      4895442
    ]
  },
  {
    "index": 802,
    "source_corpus_id": 221761540,
    "ref_id": "b26",
    "citation_corpus_id": 211146562,
    "start": 3602,
    "end": 3619,
    "title": "Published as a conference paper at ICLR 2020 DIVIDEMIX: LEARNING WITH NOISY LABELS AS SEMI-SUPERVISED LEARNING",
    "abstract": "Deep neural networks are known to be annotation-hungry. Numerous efforts have been devoted to reducing the annotation cost when learning with deep networks. Two prominent directions include learning with noisy labels and semi-supervised learning by exploiting unlabeled data. In this work, we propose DivideMix, a novel framework for learning with noisy labels by leveraging semi-supervised learning techniques. In particular, DivideMix models the per-sample loss distribution with a mixture model to dynamically divide the training data into a labeled set with clean samples and an unlabeled set with noisy samples, and trains the model on both the labeled and unlabeled data in a semi-supervised manner. To avoid confirmation bias, we simultaneously train two diverged networks where each network uses the dataset division from the other network. During the semi-supervised training phase, we improve the MixMatch strategy by performing label co-refinement and label co-guessing on labeled and unlabeled samples, respectively. Experiments on multiple benchmark datasets demonstrate substantial improvements over state-of-the-art methods. Code is available at",
    "prev": "While increasing the size of data does improve the model's robustness to noise, our method can substantially boost the representation learning performance by addressing noise.",
    "curr": "There exists a large body of literature on learning with label noise (Jiang et al., 2018;Han et al., 2018;Guo et al., 2018;Tanaka et al., 2018;Arazo et al., 2019;Li et al., 2020a).",
    "next": "However, existing methods have several limitations that make them less effective for webly-supervised representation learning.",
    "hard_negative": [
      13123084,
      9545399,
      3162051
    ],
    "easy_negative": [
      259376722,
      7992583,
      916523
    ]
  },
  {
    "index": 804,
    "source_corpus_id": 263909090,
    "ref_id": "b19",
    "citation_corpus_id": 253244266,
    "start": 11341,
    "end": 11358,
    "title": "A Systematic Investigation of Commonsense Knowledge in Large Language Models",
    "abstract": "Language models (LMs) trained on large amounts of data (e.g., Brown et al., 2020;Patwary et al., 2021)have shown impressive performance on many NLP tasks under the zeroshot and few-shot setup. Here we aim to better understand the extent to which such models learn commonsense knowledge -a critical component of many NLP applications. We conduct a systematic and rigorous zero-shot and few-shot commonsense evaluation of large pretrained LMs, where we: (i) carefully control for the LMs' ability to exploit potential surface cues and annotation artefacts, and (ii) account for variations in performance that arise from factors that are not related to commonsense knowledge. Our findings highlight the limitations of pre-trained LMs in acquiring commonsense knowledge without task-specific supervision; furthermore, using larger models or few-shot evaluation are insufficient to achieve human-level commonsense performance.",
    "prev": "Take the \"Take nap\" task as an example, the robot needs to understand that napping can be done on a bed, and the bed is typically located in a bedroom.",
    "curr": "Many works hold the belief that LLMs trained on large-scale data encode commonsense knowledge about the real-world (Davison et al., 2019;Li et al., 2022b;Bian et al., 2023).",
    "next": "Recently, several studies have investigated the integration of LLMs into task planning, which aims to address language ambiguities and provide robots with background knowledge Li et al., 2022a;Ahn et al., 2022).",
    "hard_negative": [
      189762527,
      216035815,
      202541043,
      221878771,
      235694265,
      1066490,
      202539551
    ],
    "easy_negative": [
      10106635,
      7747592,
      226225852
    ]
  },
  {
    "index": 806,
    "source_corpus_id": 256358781,
    "ref_id": "b28",
    "citation_corpus_id": 236170938,
    "start": 2281,
    "end": 2300,
    "title": "EFFICIENT NEURAL CAUSAL DISCOVERY WITHOUT ACYCLICITY CONSTRAINTS",
    "abstract": "Learning the structure of a causal graphical model using both observational and interventional data is a fundamental problem in many scientific fields. A promising direction is continuous optimization for score-based methods, which, however, require constrained optimization to enforce acyclicity or lack convergence guarantees. In this paper, we present ENCO, an efficient structure learning method for directed, acyclic causal graphs leveraging observational and interventional data. ENCO formulates the graph search as an optimization of independent edge likelihoods, with the edge orientation being modeled as a separate parameter. Consequently, we provide for ENCO convergence guarantees when interventions on all variables are available, without having to constrain the score function with respect to acyclicity. In experiments, we show that ENCO can efficiently recover graphs with hundreds of nodes, an order of magnitude larger than what was previously possible, while handling deterministic variables and discovering latent confounders. * Qualcomm AI Research is an initiative of Qualcomm Technologies, Inc.In this work, we address both problems. By modeling the orientation of an edge as a separate parameter, we can define the score function without any acyclicity constraints or regularizers. This allows for unbiased low-variance gradient estimators that scale learning to much larger graphs. Yet, if we are able to intervene on all variables, the proposed optimization is guaranteed to converge to the correct, acyclic graph. Importantly, since such interventions might not always be available, we show that our algorithm performs robustly even when intervening on fewer variables and having small sample sizes. We call our method ENCO for Efficient Neural Causal Discovery.We make the following four contributions. Firstly, we propose ENCO, a causal structure learning method for observational and interventional data using continuous optimization. Different from recent methods, ENCO models the edge orientation as a separate parameter. Secondly, we derive unbiased, low-variance gradient estimators, which is crucial for scaling up the model to large numbers of variables. Thirdly, we show that ENCO is guaranteed to converge to the correct causal graph if interventions on all variables are available, despite not having any acyclicity constraints. Yet, we show in practice that the algorithm works on partial intervention sets as well. Fourthly, we extend ENCO to detecting latent confounders. In various experimental settings, ENCO recovers graphs accurately, making less than one error on graphs with 1,000 variables in less than nine hours of computation.",
    "prev": "lems in protein-signaling and transcriptional network discovery, that our approach lies on the Pareto frontier of two key metrics, the SID and SHD.",
    "curr": "INTRODUCTION\n\nIn many domains, including cell biology (Sachs et al., 2005), finance (Sanford & Moosa, 2012), and genetics (Zhang et al., 2013), the data generating process is thought to be represented by an underlying directed acylic graph (DAG).Many models rely on DAG assumptions, e.g., causal modeling uses DAGs to model distribution shifts, ensure predictor fairness among subpopulations, or learn agents more sample-efficiently (Kaddour et al., 2022).A key question, with implications ranging from better modeling to causal discovery, is how to recover this unknown DAG from observed data alone.While there are methods for identifying the underlying DAG if given additional interventional data (Eberhardt, 2007;Hauser & B\u00fchlmann, 2014;Shanmugam et al., 2015;Kocaoglu et al., 2017;Brouillard et al., 2020;Addanki et al., 2020;Squires et al., 2020;Lippe et al., 2022), it is not always practical or ethical to obtain such data (e.g., if one aims to discover links between dietary choices and deadly diseases).",
    "next": "Learning DAGs from observational data alone is fundamentally difficult for two reasons.",
    "hard_negative": [
      59413789,
      184486852
    ],
    "easy_negative": [
      246431258,
      51872536,
      5272821
    ]
  },
  {
    "index": 808,
    "source_corpus_id": 52135921,
    "ref_id": "b26",
    "citation_corpus_id": 11217889,
    "start": 3258,
    "end": 3283,
    "title": "Under review as a conference paper at ICLR 2018 CERTIFIED DEFENSES AGAINST ADVERSARIAL EX- AMPLES",
    "abstract": "While neural networks have achieved high accuracy on standard image classification benchmarks, their accuracy drops to nearly zero in the presence of small adversarial perturbations to test inputs. Defenses based on regularization and adversarial training have been proposed, but often followed by new, stronger attacks that defeat these defenses. Can we somehow end this arms race? In this work, we study this problem for neural networks with one hidden layer. We first propose a method based on a semidefinite relaxation that outputs a certificate that for a given network and test input, no attack can force the error to exceed a certain value. Second, as this certificate is differentiable, we jointly optimize it with the network parameters, providing an adaptive regularizer that encourages robustness against all attacks. On MNIST, our approach produces a network and a certificate that no attack that perturbs each pixel by at most = 0.1 can cause more than 35% test error.",
    "prev": "It has been shown time and again ) that basically all defenses previously proposed did not increase model robustness but prevented existing attacks from finding minimal adversarial examples, the most common reason being masking of the gradients on which most attacks rely.",
    "curr": "The few verifiable defenses can only guarantee robustness within a small linear regime around the data points (Hein & Andriushchenko, 2017;Raghunathan et al., 2018).",
    "next": "The only defense currently considered effective  is a particular type of adversarial training .",
    "hard_negative": [
      604334,
      6706414
    ],
    "easy_negative": [
      52009917,
      250164143,
      259088773
    ]
  },
  {
    "index": 811,
    "source_corpus_id": 108296442,
    "ref_id": "b8",
    "citation_corpus_id": 13276568,
    "start": 2297,
    "end": 2319,
    "title": "Learning language through pictures",
    "abstract": "We propose IMAGINET, a model of learning visually grounded representations of language from coupled textual and visual input. The model consists of two Gated Recurrent Unit networks with shared word embeddings, and uses a multi-task objective by receiving a textual description of a scene and trying to concurrently predict its visual representation and the next word in the sentence. Mimicking an important aspect of human language learning, it acquires meaning representations for individual words from descriptions of visual scenes. Moreover, it learns to effectively use sequential structure in semantic interpretation of multi-word phrases.",
    "prev": "It also empowers applications including visual question answering and bidirectional image-text retrieval.",
    "curr": "INTRODUCTION\n\nHumans are capable of learning visual concepts by jointly understanding vision and language (Fazly et al., 2010;Chrupa\u0142a et al., 2015;Gauthier et al., 2018).",
    "next": "Consider the example shown in Figure 1-I.",
    "hard_negative": [
      8264070,
      5881871,
      11336213,
      3104920,
      6618571
    ],
    "easy_negative": [
      247570285,
      227905601,
      7671968
    ]
  },
  {
    "index": 812,
    "source_corpus_id": 54477714,
    "ref_id": "b13",
    "citation_corpus_id": 8495258,
    "start": 2224,
    "end": 2245,
    "title": "A Decomposable Attention Model for Natural Language Inference",
    "abstract": "We propose a simple neural architecture for natural language inference. Our approach uses attention to decompose the problem into subproblems that can be solved separately, thus making it trivially parallelizable. On the Stanford Natural Language Inference (SNLI) dataset, we obtain state-of-the-art results with almost an order of magnitude fewer parameters than previous work and without relying on any word-order information. Adding intra-sentence attention that takes a minimum amount of order into account yields further improvements.",
    "prev": "To generate a coherent piece, a model needs to reference elements that came before, sometimes in the distant past, repeating, varying, and further developing them to create contrast and surprise.",
    "curr": "Intuitively, self-attention (Parikh et al., 2016) appears to be a good match for this task.",
    "next": "Self-attention over its own previous outputs allows an autoregressive model to access any part of the previously generated output at every step of generation.",
    "hard_negative": [
      6506243,
      8893912,
      543369,
      52817936,
      1922162,
      11440692,
      1957433
    ],
    "easy_negative": [
      227231637,
      232021583,
      28489415
    ]
  },
  {
    "index": 818,
    "source_corpus_id": 2703040,
    "ref_id": "b19",
    "citation_corpus_id": 3144218,
    "start": 4782,
    "end": 4803,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "This process is then repeated multiple times like in classical CNNs to build a deep graph representation.",
    "curr": "Other notable works on graph neural networks include (Li et al., 2015;Sch\u00fctt et al., 2017;Battaglia et al., 2016;Kipf & Welling, 2017).",
    "next": "Very recently, (Gilmer et al., 2017) showed that many of these approaches can be seen to be specific instances of a general message passing formalism, and coined the term message passing neural networks (MPNNs) to refer to them collectively.",
    "hard_negative": [
      6628106,
      8393918
    ],
    "easy_negative": [
      528183,
      216034672,
      24263154
    ]
  },
  {
    "index": 820,
    "source_corpus_id": 246634143,
    "ref_id": "b38",
    "citation_corpus_id": 14124313,
    "start": 4373,
    "end": 4401,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "\u2022 Experimental results show that our efficient models outperform the previous efficient models and yield faster model speeds with further robustness ( \u00a75).",
    "curr": "INTRODUCTION\n\nImage classification has been advanced with deep convolutional neural networks (Simonyan & Zisserman, 2015;Huang et al., 2017;He et al., 2016b) with the common design paradigm of the network building blocks with trainable spatial convolutions inside.",
    "next": "Such trainable layers with learnable parameters effectively grasp attentive signals to distinguish input but are computationally heavy.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      17891711,
      986180,
      10627917
    ]
  },
  {
    "index": 821,
    "source_corpus_id": 252070677,
    "ref_id": "b37",
    "citation_corpus_id": 2131938,
    "start": 2278,
    "end": 2282,
    "title": "Information Extraction over Structured Data: Question Answering with Freebase",
    "abstract": "Answering natural language questions using the Freebase knowledge base has recently been explored as a platform for advancing the state of the art in open domain semantic parsing. Those efforts map questions to sophisticated meaning representations that are then attempted to be matched against viable answer candidates in the knowledge base. Here we show that relatively modest information extraction techniques, when paired with a webscale corpus, can outperform these sophisticated approaches by roughly 34% relative gain.",
    "prev": "INTRODUCTION\n\nKnowledge graphs (KGs) represent a large amount of entities and their relationships via a collection of factual triplets, (\u210e, , ), where each triplet expresses the relationship between a head entity \u210e and a tail entity .",
    "curr": "Large-scale KGs [1,19,26,32] can provide powerful knowledge inference capabilities for many intelligent applications, including question answering [38], web search [8] and recommendation systems [33].",
    "next": "As KGs are often built semiautomatically from unstructured data, it has become a well-known fact that most existing KGs are far from complete [6].",
    "hard_negative": [
      6401679,
      12728987,
      9337134,
      5219389,
      2493904,
      6228816,
      245587,
      8597719,
      8893912,
      298585,
      5633240,
      10318045,
      10824175,
      340852,
      16639862
    ],
    "easy_negative": [
      52012669,
      4324445,
      251395690
    ]
  },
  {
    "index": 822,
    "source_corpus_id": 54472058,
    "ref_id": "b1",
    "citation_corpus_id": 11212020,
    "start": 1821,
    "end": 1843,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "INTRODUCTION\n\nDue to the power law distribution of word frequencies, rare words are extremely common in any language (Zipf, 1935).",
    "curr": "Yet, the majority of language generation tasks-including machine translation (Sutskever et al., 2014;Bahdanau et al., 2014;Luong et al., 2015), summarization (Rush et al., 2015;See et al., 2017;Paulus et al., 2018), dialogue generation (Vinyals & Le, 2015), question answering (Yin et al., 2015), speech recognition (Graves et al., 2013;Xiong et al., 2017), and others-generate words by sampling from a multinomial distribution over a closed output vocabulary.",
    "next": "This is done by computing scores for each candidate word and normalizing them to probabilities using a softmax layer.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      219302945,
      1036150,
      14908610
    ]
  },
  {
    "index": 828,
    "source_corpus_id": 222291521,
    "ref_id": "b18",
    "citation_corpus_id": 3144218,
    "start": 3067,
    "end": 3071,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "For example, in drug discovery, when viewing molecules as graphs with atoms as nodes and chemical bonds as edges, biochemists are interested in identifying the subgraphs that mostly represent certain properties of the molecules, namely the functional groups [17,11].",
    "curr": "In graph representation learning, the predictive subgraph highlights the vital substructure for graph classification, and provides an alternative way for yielding graph representation besides mean/sum aggregation [19,30,32] and pooling aggregation [35,21,4].",
    "next": "In graph attack and defense, it is vital to purify a perturbed graph and mine the robust structures for classification [16].",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      11043495,
      245836975,
      243865304
    ]
  },
  {
    "index": 830,
    "source_corpus_id": 222208633,
    "ref_id": "b20",
    "citation_corpus_id": 3608234,
    "start": 5721,
    "end": 5740,
    "title": "Published as a conference paper at ICLR 2018 GENERATING WIKIPEDIA BY SUMMARIZING LONG SEQUENCES",
    "abstract": "We show that generating English Wikipedia articles can be approached as a multidocument summarization of source documents. We use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. For the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoderdecoder architectures used in sequence transduction. We show that this model can generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia articles. When given reference documents, we show it can extract relevant factual information as reflected in perplexity, ROUGE scores and human evaluations. * Joint first-authors. Ordered randomly. \u2020 Work done as a member of the Google Brain Residency (g.co/brainresidency)",
    "prev": "The most straightforward paradigm is restricting the attention pattern to be fixed local windows.",
    "curr": "Most works (Liu et al., 2018a;Parmar et al., 2018;Child et al., 2019;Huang et al., 2019;Ho et al., 2019;Hu et al., 2019;Parmar et al., 2019;Qiu et al., 2019;Beltagy et al., 2020;Zaheer et al., 2020) follow this paradigm.",
    "next": "Although restricting the attention pattern to a local neighborhood can decrease the complexity, it loses global information.",
    "hard_negative": [
      1238927,
      577937,
      1918428,
      964287
    ],
    "easy_negative": [
      218470415,
      18187461,
      183592
    ]
  },
  {
    "index": 837,
    "source_corpus_id": 235669672,
    "ref_id": "b23",
    "citation_corpus_id": 1487550,
    "start": 19543,
    "end": 19559,
    "title": "UNSUPERVISED WORD SENSE DISAMBIGUATION RIVALING SUPERVISED METHODS",
    "abstract": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints -that words tend to have one sense per discourse and one sense per collocation -exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%.",
    "prev": "We use 5 iterations, t 1 = 0.8, and t 2 = 1.2.",
    "curr": "\u2022 Self-training (Yarowsky, 1995;McClosky et al., 2006).",
    "next": "A classical semi-supervised method -each iteration, we train on pseudo-labeled data (initialized to be the original labeled dataset) and add highly confident predictions to the training set using the prediction as the label.",
    "hard_negative": [
      11329942,
      1693468,
      3166885,
      1580335,
      5458997,
      2946526,
      9537399
    ],
    "easy_negative": [
      7717053,
      256460896,
      252365088
    ]
  },
  {
    "index": 838,
    "source_corpus_id": 256697539,
    "ref_id": "b17",
    "citation_corpus_id": 238354201,
    "start": 24567,
    "end": 24592,
    "title": "MOBILEVIT: LIGHT-WEIGHT, GENERAL-PURPOSE, AND MOBILE-FRIENDLY VISION TRANSFORMER",
    "abstract": "Light-weight convolutional neural networks (CNNs) are the de-facto for mobile vision tasks. Their spatial inductive biases allow them to learn representations with fewer parameters across different vision tasks. However, these networks are spatially local. To learn global representations, self-attention-based vision transformers (ViTs) have been adopted. Unlike CNNs, ViTs are heavyweight. In this paper, we ask the following question: is it possible to combine the strengths of CNNs and ViTs to build a light-weight and low latency network for mobile vision tasks? Towards this end, we introduce MobileViT, a light-weight and general-purpose vision transformer for mobile devices. Mobile-ViT presents a different perspective for the global processing of information with transformers. Our results show that MobileViT significantly outperforms CNNand ViT-based networks across different tasks and datasets. On the ImageNet-1k dataset, MobileViT achieves top-1 accuracy of 78.4% with about 6 million parameters, which is 3.2% and 6.2% more accurate than MobileNetv3 (CNN-based) and DeIT (ViT-based) for a similar number of parameters. On the MS-COCO object detection task, MobileViT is 5.7% more accurate than MobileNetv3 for a similar number of parameters. Our source code is open-source and available at: https://github.com/apple/ml-cvnets.",
    "prev": "We tested the inference time and peak memory consumption on CPU (Intel(R) Xeon(R) Gold 6246R CPU with 3.40 GHz clock), GPU (Nvidia A100), and on CPU with XNNPACK optimization.",
    "curr": "For comparison, we also tested LSTM and MobileViT (Mehta & Rastegari, 2022) networks.",
    "next": "MODELS AND TRAINING PROCESS\n\nGhostNet Our classification network consist of 3 ghost bottlenecks and ends with a convolutional layer and average pooling.",
    "hard_negative": [
      225039882,
      17127188,
      3162051
    ],
    "easy_negative": [
      2443336,
      218974521,
      220280819
    ]
  },
  {
    "index": 856,
    "source_corpus_id": 244709059,
    "ref_id": "b28",
    "citation_corpus_id": 225094135,
    "start": 49901,
    "end": 49923,
    "title": "Published as a conference paper at ICLR 2021 LEARNING TO REPRESENT ACTION VALUES AS A HYPERGRAPH ON THE ACTION VERTICES",
    "abstract": "Action-value estimation is a critical component of many reinforcement learning (RL) methods whereby sample complexity relies heavily on how fast a good estimator for action value can be learned. By viewing this problem through the lens of representation learning, good representations of both state and action can facilitate action-value estimation. While advances in deep learning have seamlessly driven progress in learning state representations, given the specificity of the notion of agency to RL, little attention has been paid to learning action representations. We conjecture that leveraging the combinatorial structure of multi-dimensional action spaces is a key ingredient for learning good representations of action. To test this, we set forth the action hypergraph networks framework-a class of functions for learning action representations in multi-dimensional discrete action spaces with a structural inductive bias. Using this framework we realise an agent class based on a combination with deep Q-networks, which we dub hypergraph Q-networks. We show the effectiveness of our approach on a myriad of domains: illustrative prediction problems under minimal confounding effects, Atari 2600 games, and discretised physical control benchmarks.Published as a conference paper at ICLR 2021Our results advocate for the general usefulness of leveraging the combinatorial structure of multidimensional discrete action spaces, especially in problems with larger action spaces.",
    "prev": "This paradigm transforms the value decomposition to the structured prediction problem.",
    "curr": "A future work is integrating prior knowledge of the decomposition structure as many previous works for structured prediction (Chen et al., 2020;Tavakoli et al., 2021).",
    "next": "Figure 1 :\n1Learning curves on a suite of MuJoCo benchmark tasks with episodic rewards.",
    "hard_negative": [
      13022595,
      6628106,
      5176587,
      222133333,
      16326763
    ],
    "easy_negative": [
      253762019,
      220936168,
      211069144
    ]
  },
  {
    "index": 859,
    "source_corpus_id": 262824542,
    "ref_id": "b30",
    "citation_corpus_id": 3608234,
    "start": 6444,
    "end": 6448,
    "title": "Published as a conference paper at ICLR 2018 GENERATING WIKIPEDIA BY SUMMARIZING LONG SEQUENCES",
    "abstract": "We show that generating English Wikipedia articles can be approached as a multidocument summarization of source documents. We use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. For the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoderdecoder architectures used in sequence transduction. We show that this model can generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia articles. When given reference documents, we show it can extract relevant factual information as reflected in perplexity, ROUGE scores and human evaluations. * Joint first-authors. Ordered randomly. \u2020 Work done as a member of the Google Brain Residency (g.co/brainresidency)",
    "prev": "Experimental methodology\n\nThis section details our experimental set-up (Section 2.1) and useful tools employed by our analysis: (i) measuring the relationship between learning rate and loss across scales (Section 2.2) and (ii) examining scaling trends for model characteristics (Section 2.3).",
    "curr": "Experimental set-up\n\nWe train small Transformer models [45] with a similar experimental set-up as GPT-2 [38] implemented in Flax [20]: the models are decoder-only [31] and trained with an auto-regressive loss (refer to Section A for more infrastructure details).While we experimentally manipulate many of the following hyperparameters, this section provides their default values, which we use unless otherwise specified.",
    "next": "By default, we use AdamW [33] with \u03b2 1 = 0.9, \u03b2 2 = 0.95, \u03f5 = 1e-8, and gradient clipping at global norm 1.The default warmup is 5e3 steps, and the default number of total steps is 1e5.We use a linear schedule for warmup and and a cosine-decay [32] schedule for the remainder, with minimum learning rate 1e-5.We use an independent weight decay of 1e-4 and auxiliary z-loss [6] with coefficient 1e-4.Sections 3.2.2 and 3.1.2respectively provide additional information and ablations on decoupled weight decay and z-loss.",
    "hard_negative": [
      1238927,
      577937,
      1918428,
      964287
    ],
    "easy_negative": [
      10361075,
      86556588,
      1579047
    ]
  },
  {
    "index": 861,
    "source_corpus_id": 255186293,
    "ref_id": "b8",
    "citation_corpus_id": 218486942,
    "start": 28207,
    "end": 28229,
    "title": "GoEmotions: A Dataset of Fine-Grained Emotions",
    "abstract": "Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using large-scale datasets with a fine-grained typology, adaptable to multiple downstream tasks. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the annotations via Principal Preserved Component Analysis. We conduct transfer learning experiments with existing emotion benchmarks to show that our dataset generalizes well to other domains and different emotion taxonomies. Our BERTbased model achieves an average F1-score of .46 across our proposed taxonomy, leaving much room for improvement. 1",
    "prev": "CIFAR-100 is a single-label image recognition task, which we perform in the challenging zero-shot classification setting using CLIP (Radford et al., 2021).",
    "curr": "In addition, we conduct a natural language processing experiment using the Go Emotions (Demszky et al., 2020) dataset and a fine-tuned BERT model (Devlin et al., 2018), where the goal is to recognize emotion in text and a single instance may have multiple labels.",
    "next": "Finally, we evaluate the interaction between our method and subgroup fairness using the UCI Nursery dataset (Dua and Graff, 2017), where applicants are ranked for admissions to school.",
    "hard_negative": [
      1260035,
      4941467,
      155092004,
      15590323,
      3626819,
      44090948,
      53137220,
      52012769,
      51881697,
      53234404,
      52967399,
      28363891
    ],
    "easy_negative": [
      218977400,
      218974451,
      14701624
    ]
  },
  {
    "index": 863,
    "source_corpus_id": 227209335,
    "ref_id": "b14",
    "citation_corpus_id": 52908831,
    "start": 24092,
    "end": 24116,
    "title": "FFJORD: FREE-FORM CONTINUOUS DYNAMICS FOR SCALABLE REVERSIBLE GENERATIVE MODELS",
    "abstract": "A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network. Likelihood-based training of these models requires restricting their architectures to allow cheap computation of Jacobian determinants. Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson's trace estimator to give a scalable unbiased estimate of the log-density. The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density estimation, image generation, and variational inference, achieving the state-of-the-art among exact likelihood methods with efficient sampling. * Equal contribution. Order determined by coin toss.",
    "prev": "4).",
    "curr": "(Dinh et al., 2016) 3.49 -iResNet  3.45 -Glow (Kingma & Dhariwal, 2018) 3.35 -MintNet (Song et al., 2019b) 3.32 -Residual Flow  3.28 46.37 FFJORD (Grathwohl et al., 2018) 3  Exact likelihood computation Leveraging the connection to neural ODEs, we can compute the density defined by Eq.",
    "next": "(12) via the instantaneous change of variables formula .",
    "hard_negative": [
      3366315,
      8768364,
      13995862
    ],
    "easy_negative": [
      259370595,
      9174835,
      15494101
    ]
  },
  {
    "index": 874,
    "source_corpus_id": 263608822,
    "ref_id": "b43",
    "citation_corpus_id": 254877499,
    "start": 1940,
    "end": 1961,
    "title": "Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions",
    "abstract": "Prompting-based large language models (LLMs) are surprisingly powerful at generating natural language reasoning steps or Chains-of-Thoughts (CoT) for multi-step question answering (QA). They struggle, however, when the necessary knowledge is either unavailable to the LLM or not up-to-date within its parameters. While using the question to retrieve relevant text from an external knowledge source helps LLMs, we observe that this one-step retrieve-and-read approach is insufficient for multi-step QA. Here, what to retrieve depends on what has already been derived, which in turn may depend on what was previously retrieved. To address this, we propose IRCoT, a new approach for multi-step QA that interleaves retrieval with steps (sentences) in a CoT, guiding the retrieval with CoT and in turn using retrieved results to improve CoT. Using IRCoT with GPT3 substantially improves retrieval (up to 21 points) as well as downstream QA (up to 15 points) on four datasets: HotpotQA, 2WikiMultihopQA, MuSiQue, and IIRC. We observe similar substantial gains in out-ofdistribution (OOD) settings as well as with much smaller models such as Flan-T5-large without additional training. IRCoT reduces model hallucination, resulting in factually more accurate CoT reasoning. 1 .",
    "prev": "at retrieval augmentation can sometimes have a negative effect on performance.In this work, we present a thorough analysis on five open-domain question answering benchmarks, characterizing cases when retrieval reduces accuracy.We then propose two methods to mitigate this issue.First, a simple baseline that filters out retrieved passages that do not entail question-answer pairs according to a natural language inference (NLI) model.This is effective in preventing performance reduction, but at a cost of also discarding relevant passages.Thus, we propose a method for automatically generating data to fine-tune the language model to properly leverage retrieved passages, using a mix of relevant and irrelevant contexts at training time.We empirically show that even 1,000 examples suffice to train the model to be robust to irrelevant contexts while maintaining high performance on examples with relevant ones.",
    "curr": "INTRODUCTION\n\nLarge Language Models (LLMs) (Brown et al., 2020;Chowdhery et al., 2022;Touvron et al., 2023) are the foundation on top of which modern language systems are built.However, open-domain question answering (ODQA; Chen et al.",
    "next": "2017) and other knowledge-intensive tasks (Thorne et al., 2018;Petroni et al., 2021) require vast amounts of up-to-date factual knowledge about rare entities that even very large models cannot memorize (Roberts et al., 2020;Dhingra et al., 2022).A dominant approach for combating this issue has been Retrieval Augmented Language Models (RALMs), which incorporate a retrieval mechanism to reduce the need for storing information in the LLM parameters (Guu et al., 2020;Lewis et al., 2020b;Izacard et al., 2022;Rubin & Berant, 2023).Furthermore, RALMs have also been shown to improve ODQA performance in an in-context setting (without any training), simply by prepending retrieved sentences to the input question (Ram et al., 2023).Nevertheless, retrievers are not perfect and past work has shown that noisy retrieval can negatively affect LLM performance (Petroni et al.,",
    "hard_negative": [
      252408513,
      221970302
    ],
    "easy_negative": [
      15076761,
      13413603,
      221957644
    ]
  },
  {
    "index": 896,
    "source_corpus_id": 219965999,
    "ref_id": "b33",
    "citation_corpus_id": 211532691,
    "start": 5026,
    "end": 5030,
    "title": "RIDE: REWARDING IMPACT-DRIVEN EXPLORATION FOR PROCEDURALLY-GENERATED ENVIRONMENTS",
    "abstract": "Exploration in sparse reward environments remains one of the key challenges of model-free reinforcement learning. Instead of solely relying on extrinsic rewards provided by the environment, many state-of-the-art methods use intrinsic rewards to encourage exploration. However, we show that existing methods fall short in procedurally-generated environments where an agent is unlikely to visit a state more than once. We propose a novel type of intrinsic reward which encourages the agent to take actions that lead to significant changes in its learned state representation. We evaluate our method on multiple challenging procedurally-generated tasks in MiniGrid, as well as on tasks with high-dimensional observations used in prior work. Our experiments demonstrate that this approach is more sample efficient than existing exploration methods, particularly for procedurally-generated MiniGrid environments. Furthermore, we analyze the learned behavior as well as the intrinsic reward received by our agent. In contrast to previous approaches, our intrinsic reward does not diminish during the course of training and it rewards the agent substantially more for interacting with objects that it can control. * Work done during an internship at Facebook AI Research.",
    "prev": "We evaluate AMIGO on MiniGrid [6], a suite of fast-to-run procedurally-generated environments with a symbolic/discrete (expressed in terms of objects like walls, doors, keys, chests and balls) observation space which isolates the problem of exploration from that of visual perception.",
    "curr": "Furthermore, [34] found that MiniGrid presents a particular challenge for existing state-of-the-art intrinsic motivation approaches.",
    "next": "Here, AMIGO sets a new state-of-the-art on some of the hardest MiniGrid environments [6], being the only method based on intrinsic motivation capable of successfully obtaining extrinsic reward on some of them.",
    "hard_negative": [
      5176587,
      14717992,
      2918187,
      3521071,
      53215593,
      5273326
    ],
    "easy_negative": [
      2150529,
      235097334,
      258486909
    ]
  },
  {
    "index": 904,
    "source_corpus_id": 256615829,
    "ref_id": "b26",
    "citation_corpus_id": 221739314,
    "start": 2570,
    "end": 2586,
    "title": "Contextualized Perturbation for Textual Adversarial Attack",
    "abstract": "Adversarial examples expose the vulnerabilities of natural language processing (NLP) models, and can be used to evaluate and improve their robustness. Existing techniques of generating such examples are typically driven by local heuristic rules that are agnostic to the context, often resulting in unnatural and ungrammatical outputs. This paper presents CLARE, a ContextuaLized AdversaRial Example generation model that produces fluent and grammatical outputs through a mask-then-infill procedure. CLARE builds on a pre-trained masked language model and modifies the inputs in a contextaware manner. We propose three contextualized perturbations, Replace, Insert and Merge, that allow for generating outputs of varied lengths. CLARE can flexibly combine these perturbations and apply them at any position in the inputs, and is thus able to attack the victim model more effectively with fewer edits. Extensive experiments and human evaluation demonstrate that CLARE outperforms the baselines in terms of attack success rate, textual similarity, fluency and grammaticality. Young. 2016. Counter-fitting word vectors to linguistic constraints. In Proc. of NAACL.Daniel Naber et al. 2003. A rule-based style and grammar checker. Citeseer.",
    "prev": "INTRODUCTION\n\nDeep Neural Networks (DNNs) have obtained great progress in the field of natural language processing (NLP) but are vulnerable to adversarial attacks, leading to security and safety concerns, and research on defense algorithms against such attacks is urgently needed.",
    "curr": "Specifically, the most common attack for NLP is word-level attack (Wang et al., 2019b;Garg & Ramakrishnan, 2020;Zang et al., 2020;Li et al., 2021), which is usually implemented by adding, deleting or substituting words within a sentence.",
    "next": "Such an attack often brings catastrophic performance degradation to DNN-based models.",
    "hard_negative": [
      174802397,
      202537221,
      3513418,
      21698802,
      16639476,
      196183669,
      196210782
    ],
    "easy_negative": [
      15129940,
      3006421,
      3176359
    ]
  },
  {
    "index": 910,
    "source_corpus_id": 12200521,
    "ref_id": "b14",
    "citation_corpus_id": 252796,
    "start": 13724,
    "end": 13745,
    "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
    "abstract": "There is a growing consensus that significant, rapid progress can be made in both text understanding and spoken language understanding by investigating those phenomena that occur most centrally in naturally occurring unconstrained materials and by attempting to automatically extract information about language from very large corpora. Such corpora are beginning to serve as important research tools for investigators in natural language processing, speech recognition, and integrated spoken language systems, as well as in theoretical linguistics. Annotated corpora promise to be valuable for enterprises as diverse as the automatic construction of statistical models for the grammar of the written and the colloquial spoken language, the development of explicit formal theories of the differing grammars of writing and speech, the investigation of prosodic phenomena in speech, and the evaluation and comparison of the adequacy of parsing models.In this paper, we review our experience with constructing one such large annotated corpus--the Penn Treebank, a corpus 1 consisting of over 4.5 million words of American English. During the first three-year phase of the Penn Treebank Project (1989)(1990)(1991)(1992), this corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure. These materials are available to members of the Linguistic Data Consortium; for details, see Section 5.1.The paper is organized as follows. Section 2 discusses the POS tagging task. After outlining the considerations that informed the design of our POS tagset and presenting the tagset itself, we describe our two-stage tagging process, in which text is first assigned POS tags automatically and then corrected by human annotators. Section 3 briefly presents the results of a comparison between entirely manual and semi-automated tagging, with the latter being shown to be superior on three counts: speed, consistency, and accuracy. In Section 4, we turn to the bracketing task. Just as with the tagging task, we have partially automated the bracketing task: the output of",
    "prev": "Experiments and Discussion\n\nWe evaluate zoneout's performance on the following tasks:\n\n\u2022 Classification of hand-written digits on permuted sequential MNIST [Le et al., 2015].",
    "curr": "\u2022 Word-level language modeling on the Penn Treebank corpus [Marcus et al., 1993].",
    "next": "\u2022 Character-level language modeling on the Penn Treebank corpus\n\nWe first investigate zoneout with a shared zoneout mask on cells and hiddens on the above tasks and compare its performance with other regularizers.",
    "hard_negative": [
      696805,
      3166885,
      2369736,
      12951757,
      5153623,
      2769726
    ],
    "easy_negative": [
      30339746,
      252819443,
      4982725
    ]
  },
  {
    "index": 912,
    "source_corpus_id": 11480374,
    "ref_id": "b9",
    "citation_corpus_id": 7228830,
    "start": 5988,
    "end": 6007,
    "title": "Adversarial Examples for Evaluating Reading Comprehension Systems",
    "abstract": "Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear.To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of 75% F1 score to 36%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7%. We hope our insights will motivate the development of new models that understand language more precisely.",
    "prev": "The ensemble model achieves an exact match (EM) score of 78.8% and F1 score of 85.9%.",
    "curr": "Furthermore, we have tested FusionNet against adversarial SQuAD datasets (Jia & Liang, 2017).",
    "next": "Results show that FusionNet outperforms existing state-of-the-art architectures in both datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to 51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.",
    "hard_negative": [
      748227,
      14068874,
      7218315,
      6706414,
      17652653,
      11816014,
      604334,
      1957433,
      2381275
    ],
    "easy_negative": [
      237490295,
      59773669,
      238259850
    ]
  },
  {
    "index": 917,
    "source_corpus_id": 53576131,
    "ref_id": "b3",
    "citation_corpus_id": 38407095,
    "start": 5929,
    "end": 5942,
    "title": "Europarl: A Parallel Corpus for Statistical Machine Translation",
    "abstract": "We collected a corpus of parallel text in 11 languages from the proceedings of the European Parliament, which are published on the web 1 . This corpus has found widespread use in the NLP community. Here, we focus on its acquisition and its application as training data for statistical machine translation (SMT). We trained SMT systems for 110 language pairs, which reveal interesting clues into the challenges ahead.",
    "prev": "\u2022 We systematically analyze what information is captured by units in representation across multiple settings by varying network architectures, tasks, and datasets.",
    "curr": "We use VD- CNN (Conneau et al., 2017) for sentiment and topic classification tasks on Yelp Reviews, AG News (Zhang et al., 2015), and DBpedia ontology dataset (Lehmann et al., 2015) and ByteNet (Kalchbrenner et al., 2016) for translation tasks on Europarl (Koehn, 2005) and News Commentary (Tiedemann, 2012) datasets.",
    "next": "\u2022 We also analyze how aligned natural language concepts evolve as they get represented in deeper layers.",
    "hard_negative": [
      6204420,
      12928205
    ],
    "easy_negative": [
      235421599,
      10381786,
      5756443
    ]
  },
  {
    "index": 921,
    "source_corpus_id": 219636236,
    "ref_id": "b6",
    "citation_corpus_id": 52889459,
    "start": 27586,
    "end": 27590,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "CLUE's latent space optimization mechanism allows it to cope well with high dimensional data.",
    "curr": "Future work can leverage recent advances in scalable BNNs [37] and generative modeling [38] to explore using CLUE for more complex data, such as natural images and natural language.",
    "next": "Broader Impact\n\nAs machine learning models are deployed in high-stakes scenarios, there has been a call for algorithmic transparency into models' behavior.",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      1234342,
      60180900,
      9473711
    ]
  },
  {
    "index": 930,
    "source_corpus_id": 238856821,
    "ref_id": "b48",
    "citation_corpus_id": 227230646,
    "start": 2994,
    "end": 3011,
    "title": "Distill and Replay for Continual Language Learning",
    "abstract": "Accumulating knowledge to tackle new tasks without necessarily forgetting the old ones is a hallmark of human-like intelligence. But the current dominant paradigm of machine learning is still to train a model that works well on static datasets. When learning tasks in a stream where data distribution may fluctuate, fitting on new tasks often leads to forgetting on the previous ones. We propose a simple yet effective framework that continually learns natural language understanding tasks with one model. Our framework distills knowledge and replays experience from previous tasks when fitting on a new task, thus named DnR (distill and replay). The framework is based on language models and can be smoothly built with different language model architectures. Experimental results demonstrate that DnR outperfoms previous state-of-the-art models in continually learning tasks of the same type but from different domains, as well as tasks of radically different types. With the distillation method, we further show that it's possible for DnR to incrementally compress the model size while still outperforming most of the baselines. We hope that DnR could promote the empirical application of continual language learning, and contribute to building human-level language intelligence minimally bothered by catastrophic forgetting. This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/.",
    "prev": "More recent methods attempt to learn from different types of tasks.",
    "curr": "These include LAMOL (Sun et al., 2019) and its improvements (Chuang et al., 2020;Sun et al., 2020;Kanwatchara et al., 2021).",
    "next": "Despite the effectiveness of these methods in LLL, there are several limitations.",
    "hard_negative": [
      53082881,
      11816014,
      209475822,
      53079675
    ],
    "easy_negative": [
      3039570,
      6055237,
      1346130
    ]
  },
  {
    "index": 936,
    "source_corpus_id": 252967732,
    "ref_id": "b9",
    "citation_corpus_id": 67855286,
    "start": 9462,
    "end": 9481,
    "title": "ANTISYMMETRICRNN: A DYNAMICAL SYSTEM VIEW ON RECURRENT NEURAL NETWORKS",
    "abstract": "Recurrent neural networks have gained widespread use in modeling sequential data. Learning long-term dependencies using these models remains difficult though, due to exploding or vanishing gradients. In this paper, we draw connections between recurrent networks and ordinary differential equations. A special form of recurrent networks called the AntisymmetricRNN is proposed under this theoretical framework, which is able to capture long-term dependencies thanks to the stability property of its underlying differential equation. Existing approaches to improving RNN trainability often incur significant computation overhead. In comparison, AntisymmetricRNN achieves the same goal by design. We showcase the advantage of this new architecture through extensive simulations and experiments. AntisymmetricRNN exhibits much more predictable dynamics. It outperforms regular LSTM models on tasks requiring long-term memory and matches the performance on tasks where short-term dependencies dominate despite being much simpler. advocate going beyond initialization and forcing the weight matrices to be orthogonal throughout the entire learning process. However, some of these approaches come with significant computational overhead and reportedly hinder representation power of these models(Vorontsov et al., 2017). Moreover, orthogonal weight matrices alone do not prevent exploding and vanishing gradients, due to the nonlinear nature of deep neural networks as shown in(Pennington et al., 2017).Here we offer a new perspective on the trainability of RNNs from the dynamical system viewpoint. While exploding gradient is a manifestation of the instability of the underlying dynamical system, vanishing gradient results from a lossy system, properties that have been widely studied in the dynamical system literature(Haber & Ruthotto, 2017;Laurent & von Brecht, 2017). The main contributions of the work are:\u2022 We draw connections between RNNs and the ordinary differential equation theory and design new recurrent architectures by discretizing ODEs.",
    "prev": "In this way, the time variable is discretized and the ODE solution is computed by the successive application of an iterated map that operates on the discrete set of points between 0 and T , with a step size > 0.",
    "curr": "Crucially, as already observed for feed-forward and recurrent neural models (Haber & Ruthotto, 2017;Chang et al., 2019), each step of the ODE discretization process can be equated to one layer of a DGN network.",
    "next": "The whole neural architecture contains as many layers as the integration steps in the numerical method (i.e., L = T / ), and each layer = 1, ..., L computes nodes' states x u which approximates x u ( ).",
    "hard_negative": [
      3532296,
      3005102,
      5590763,
      35673326
    ],
    "easy_negative": [
      264038822,
      247476136,
      67855269
    ]
  },
  {
    "index": 943,
    "source_corpus_id": 14911774,
    "ref_id": "b14",
    "citation_corpus_id": 6308361,
    "start": 25501,
    "end": 25526,
    "title": "ReferItGame: Referring to Objects in Photographs of Natural Scenes",
    "abstract": "In this paper we introduce a new game to crowd-source natural language referring expressions. By designing a two player game, we can both collect and verify referring expressions directly within the game. To date, the game has produced a dataset containing 130,525 expressions, referring to 96,654 distinct objects, in 19,894 photographs of natural scenes. This dataset is larger and more varied than previous REG datasets and allows us to study referring expressions in real-world scenes. We provide an in depth analysis of the resulting dataset. Based on our findings, we design a new optimization based model for generating referring expressions and perform experimental evaluations on 3 test sets.",
    "prev": "However, a very interesting effect of supervision is that it improves the interpretability of the code even when agents must communicate about images that do not contain objects in the supervised category set.",
    "curr": "This emerged in a follow-up experiment in which, during training, the sender was again exposed (with equal probability) to the same supervised classification task as above, but now the agents played the referential game on a different dataset of images derived from ReferItGame (Kazemzadeh et al., 2014).",
    "next": "In its general format, the ReferItGame contains annotations of bounding boxes in real images with referring expressions produced by humans when playing the game.",
    "hard_negative": [
      256272,
      5223711,
      1847966,
      7983519,
      7825911,
      9682853,
      18650536,
      2970563,
      6034383,
      14687186,
      7198177,
      6176757
    ],
    "easy_negative": [
      37742236,
      5315990,
      248512457
    ]
  },
  {
    "index": 951,
    "source_corpus_id": 238857090,
    "ref_id": "b21",
    "citation_corpus_id": 204960716,
    "start": 37833,
    "end": 37852,
    "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    "abstract": "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new stateof-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance. 1",
    "prev": "For direct comparison with existing methods that do not take direct advantage of this assumption, we trained a new Language Processing module that does not make use of templates but makes use of the subtasks sequences annotations ALFRED provides.",
    "curr": "5 Fine-tuning a pre-trained BART (Lewis et al., 2020) model, we directly learned a mapping from a high-level instruction to a sequence of subtasks (e.g.",
    "next": "\"Drop a clean pan on the table\" \u2192 \"(PickupObject, Pan), (PutObject, Sink), ...\").",
    "hard_negative": [
      52967399,
      16639476,
      990233
    ],
    "easy_negative": [
      44156276,
      5210480,
      260203143
    ]
  },
  {
    "index": 967,
    "source_corpus_id": 263608898,
    "ref_id": "b19",
    "citation_corpus_id": 233296292,
    "start": 6518,
    "end": 6536,
    "title": "SimCSE: Simple Contrastive Learning of Sentence Embeddings",
    "abstract": "This paper presents SimCSE, a simple contrastive learning framework that greatly advances the state-of-the-art sentence embeddings. We first describe an unsupervised approach, which takes an input sentence and predicts itself in a contrastive objective, with only standard dropout used as noise. This simple method works surprisingly well, performing on par with previous supervised counterparts. We find that dropout acts as minimal data augmentation and removing it leads to a representation collapse. Then, we propose a supervised approach, which incorporates annotated pairs from natural language inference datasets into our contrastive learning framework, by using \"entailment\" pairs as positives and \"contradiction\" pairs as hard negatives. We evaluate SimCSE on standard semantic textual similarity (STS) tasks, and our unsupervised and supervised models using BERT base achieve an average of 76.3% and 81.6% Spearman's correlation respectively, a 4.2% and 2.2% improvement compared to previous best results. We also show-both theoretically and empirically-that contrastive learning objective regularizes pre-trained embeddings' anisotropic space to be more uniform, and it better aligns positive pairs when supervised signals are available. 1",
    "prev": "(2020); Kumar et al.",
    "curr": "(2022) for CL.In this paper, we use SimCLR (Chen et al., 2020) and SimSiam (Chen & He, 2021) for CIFAR10 dataset and SimCSE (Gao et al., 2021) for BIASBIOS dataset to learn CL representations.",
    "next": "Several works have theoretically studied the success of self-supervised learning (Arora et al., 2019;HaoChen et al., 2021;Lee et al., 2020;Tian et al., 2021;Tosh et al., 2021).Our theoretical analysis of CL loss is partly motivated by Fang et al.",
    "hard_negative": [
      3264224,
      208117506,
      18283203,
      201646309,
      235187266,
      3432876,
      207853396,
      3104920,
      1957433,
      990233,
      221948991
    ],
    "easy_negative": [
      25041690,
      235097198,
      6442284
    ]
  },
  {
    "index": 972,
    "source_corpus_id": 208006294,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 2671,
    "end": 2694,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": " and metrics evaluation on both LSTM models and BERT Transformer models on multiple datasets show that our algorithms outperform prior hierarchical explanation algorithms.Our algorithms apply to hierarchical visualization of compositional semantics, extraction of classification rules and improving human trust of models.",
    "curr": "Introduction\n\nRecent advances in deep neural networks have led to impressive results on a range of natural language processing (NLP) tasks, by learning latent, compositional vector representations of text data (Peters et al., 2018;Devlin et al., 2018;Liu et al., 2019b).However, interpretability of the predictions given by these complex, \"black box\" models has always been a limiting factor for use cases that require explanations of the features involved in modeling (e.g., words and phrases) (Guidotti et al., 2018;Ribeiro et al., 2016).Prior efforts on enhancing model interpretability have focused on either constructing models with intrinsically interpretable structures (Bahdanau et al., 2015;Liu et al., 2019a), or developing post-hoc explanation algorithms which can explain model predictions without elucidating the mechanisms by which model works (Mohseni et al., 2018;Guidotti et al., 2018).Among these work, post-hoc explanation has come to the fore as they can operate over a variety of trained models while not affecting predictive performance of models.",
    "next": "Towards post-hoc explanation, a major line of work, additive feature attribution methods (Lundberg and Lee, 2017;Ribeiro et al., 2016;Binder et al., 2016;Shrikumar et al., 2017), explain a model prediction by assigning importance scores to individual input variables.However, these methods may not work for explaining compositional semantics in natural language (e.g., phrases or clauses), as the importance of a phrase often is non-linear combination of the importance of the words in the phrase.Contextual decomposition (CD) (Murdoch et al., 2018) and its hierarchical extension (Singh et al., 2019) go beyond the additive assu",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      2307113,
      218758195,
      8130938
    ]
  },
  {
    "index": 973,
    "source_corpus_id": 251252927,
    "ref_id": "b17",
    "citation_corpus_id": 3144218,
    "start": 2452,
    "end": 2456,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "A variety of applications characterized by this type of graph-structured data include works in the areas of social analysis [5], recommendation systems [56], computer vision [42], study of the properties of chemical compounds [26,48], statistical physics [8,10], and financial forensics [51,57].",
    "curr": "The most popular learning models for relational data use graph convolutions [33], where the idea is to aggregate the attributes of the set of neighbours of a node instead of only utilizing its own attributes.",
    "next": "Despite several empirical studies of various GCN-type models [13,38] that demonstrate that graph convolutions can improve the performance of traditional classification methods, such as a multi-layer perceptron (MLP), there has been limited progress in the theoretical understanding of the benefits of graph convolutions in multi-layer networks in terms of improving node classification tasks.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      10082370,
      3871844,
      201687076
    ]
  },
  {
    "index": 977,
    "source_corpus_id": 249431433,
    "ref_id": "b13",
    "citation_corpus_id": 14124313,
    "start": 2098,
    "end": 2126,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "INTRODUCTION\n\nThe success of deep learning in computer vision is largely driven by Convolutional Neural Networks (CNNs).",
    "curr": "Starting from the milestone work AlexNet (Krizhevsky et al., 2012), CNNs keep pushing the frontier of computer vision (Simonyan & Zisserman, 2015;He et al., 2016;Tan & Le, 2019).",
    "next": "Interestingly, the recently emerged Vision Transformer (ViT) (Dosovitskiy et al., 2020) challenges the leading position of CNNs.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      9264341,
      251403409,
      252735195
    ]
  },
  {
    "index": 982,
    "source_corpus_id": 263829263,
    "ref_id": "b10",
    "citation_corpus_id": 189928186,
    "start": 2333,
    "end": 2337,
    "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models",
    "abstract": "Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.156",
    "prev": "it complexity class TC 0 , i.e., AC 0 -circuits extended by majority gates.We first show a negative result that there is an AC 0 -language that cannot be recognized by an UHAT encoder.On the positive side, we show that UHAT encoders can recognize a rich fragment of AC 0 -languages, namely, all languages definable in first-order logic with arbitrary unary numerical predicates.This logic, includes, for example, all regular languages from AC 0 .We then show that AHAT encoders can recognize all languages of our logic even when we enrich it with counting terms.We apply these results to derive new results on the expressive power of UHAT and AHAT up to permutation of letters (a.k.a.Parikh images).",
    "curr": "Introduction\n\nTransformers have revolutionized natural language processing by facilitating the efficient and effective modeling of intricate contextual relationships within text [19].This remarkable capability has sparked numerous investigations into the potential boundaries of transformers' power [11,22,17,21,12,6,5,7].One natural method for addressing this question is to explore the classes of formal languages that these architectures can recognize.This approach provides an insight into their strengths and limitations.The response to this question naturally relies on the specific features allowed within transformer encoders.These encompass the interplay between encoders and decoders, the kind of functions used for positional encodings and attention mechanisms, and considerations of fixed or unbounded precision, among other factors.",
    "next": "While the capacity of transformers that incorporate both encoders and decoders to recognize languages is well understood today (indeed, such architectures are Turing-complete and can thus recognize any computable language [17]), the expressive power of transformer encoders has not been fully elucidated to date.Unique Hard Attention Transformers (UHAT) are a class of transformer encoders that has been a subject of many recent papers.As was shown by [12]",
    "hard_negative": [
      6506243,
      53299978,
      58981389,
      8495258,
      162183964,
      53230878,
      52113185,
      155092004,
      14091946,
      49667762,
      44115640,
      57825721,
      3785155,
      53051208,
      21850704,
      192546007,
      184486746,
      13747425,
      52967399,
      174799346,
      173990523,
      4460159
    ],
    "easy_negative": [
      11905341,
      7589431,
      8699388
    ]
  },
  {
    "index": 990,
    "source_corpus_id": 4862861,
    "ref_id": "b1",
    "citation_corpus_id": 9963298,
    "start": 5135,
    "end": 5162,
    "title": "Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions",
    "abstract": "The context in which language is used provides a strong signal for learning to recover its meaning. In this paper, we show it can be used within a grounded CCG semantic parsing approach that learns a joint model of meaning and context for interpreting and executing natural language instructions, using various types of weak supervision. The joint nature provides crucial benefits by allowing situated cues, such as the set of visible objects, to directly influence learning. It also enables algorithms that learn while executing instructions, for example by trying to replicate human actions. Experiments on a benchmark navigational dataset demonstrate strong performance under differing forms of supervision, including correctly executing 60% more instruction sets relative to the previous state of the art.",
    "prev": "Static datasets such as visual question answering (Antol et al., 2015) provide grounding into images, but no possibility for language learning through interaction.",
    "curr": "Some works utilize a geographical environment such as a maze but still employ static datasets (Artzi & Zettlemoyer, 2013).",
    "next": "It has been argued that virtual embodiment of agents is a viable long-term strategy for artificial intelligence research and the learning of natural language semantics, particularly in the form of games which also contain human players (Kiela et al., 2016).",
    "hard_negative": [
      5667590,
      1140108,
      10576017,
      238873,
      9337134,
      5249151,
      16191296,
      6228816,
      15703800,
      245587,
      9111381,
      8597719,
      8701528,
      5633240,
      340852,
      333563
    ],
    "easy_negative": [
      258557844,
      14760845,
      15955042
    ]
  },
  {
    "index": 994,
    "source_corpus_id": 238744039,
    "ref_id": "b32",
    "citation_corpus_id": 44090489,
    "start": 5646,
    "end": 5671,
    "title": "On the Impact of Various Types of Noise on Neural Machine Translation",
    "abstract": "We examine how various types of noise in the parallel training data impact the quality of neural machine translation systems. We create five types of artificial noise and analyze how they degrade performance in neural and statistical machine translation. We find that neural models are generally more harmed by noise than statistical models. For one especially egregious type of noise they learn to just copy the input sentence.",
    "prev": "Although being highly effective in low-resource translation, backtranslation also has issues, as the model is trained on potentially invalid input-output pairs.",
    "curr": "Neural machine translation models being highly sensitive to input noise (Belinkov & Bisk, 2018;Khayrallah & Koehn, 2018), this can severely deteriorate the performance.",
    "next": "Fortunately, many programming languages come with relatively mature tools and technologies for automated test data generation.",
    "hard_negative": [
      216849409,
      8313873,
      7921428,
      8822680,
      29180066,
      14928935,
      11706155,
      1557806,
      2479536,
      38407095,
      12639289,
      15210695,
      13270994,
      765547,
      10766958,
      14547438,
      3510512
    ],
    "easy_negative": [
      962605,
      208332276,
      52154053
    ]
  },
  {
    "index": 997,
    "source_corpus_id": 219401642,
    "ref_id": "b7",
    "citation_corpus_id": 202749904,
    "start": 5510,
    "end": 5513,
    "title": "HIGH FIDELITY SPEECH SYNTHESIS WITH ADVERSARIAL NETWORKS",
    "abstract": "Generative adversarial networks have seen rapid development in recent years and have led to remarkable improvements in generative modelling of images. However, their application in the audio domain has received limited attention, and autoregressive models, such as WaveNet, remain the state of the art in generative modelling of audio signals such as human speech. To address this paucity, we introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech. Our architecture is composed of a conditional feed-forward generator producing raw speech audio, and an ensemble of discriminators which operate on random windows of different sizes. The discriminators analyse the audio both in terms of general realism, as well as how well the audio corresponds to the utterance that should be pronounced. To measure the performance of GAN-TTS, we employ both subjective human evaluation (MOS -Mean Opinion Score), as well as novel quantitative metrics (Fr\u00e9chet DeepSpeech Distance and Kernel DeepSpeech Distance), which we find to be well correlated with MOS. We show that GAN-TTS is capable of generating high-fidelity speech with naturalness comparable to the state-of-the-art models, and unlike autoregressive models, it is highly parallelisable thanks to an efficient feed-forward generator. Listen to GAN-TTS reading this abstract at https://storage.googleapis.com/ deepmind-media/research/abstract.wav.",
    "prev": "It is illustrated in Figure 1.",
    "curr": "The generator is inspired by GAN-TTS [8], a text-to-speech generative adversarial network operating on aligned linguistic features.",
    "next": "We employ the GAN-TTS generator as the decoder in our model, but instead of upsampling pre-computed linguistic features, its input comes from the aligner block.",
    "hard_negative": [
      17272965,
      6104263,
      3568073,
      84591,
      13890001,
      17127188,
      67856213
    ],
    "easy_negative": [
      7562727,
      474726,
      219307563
    ]
  },
  {
    "index": 1000,
    "source_corpus_id": 16299141,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 17150,
    "end": 17173,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "Other work has improved language modeling performance by modifying the RNN architecture to better handle increased recurrence depth (Zilly et al., 2016).",
    "curr": "In order to increase capacity and minimize the impact of vanishing gradients, some language and translation mod- WikiText-2  WikiText-103  Train  Valid  Test  Train  Valid  Test  Train  Valid  Test   Articles  ---600  60  60  28,475  60  60  Tokens  929,590 73,761 82, els have also added a soft attention or memory component (Bahdanau et al., 2015;Sukhbaatar et al., 2015;Cheng et al., 2016;Kumar et al., 2016;Xiong et al., 2016;Ahn et al., 2016).",
    "next": "These mechanisms allow for the retrieval and use of relevant previous hidden states.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      252818935,
      232765126,
      21699285
    ]
  },
  {
    "index": 1002,
    "source_corpus_id": 252595881,
    "ref_id": "b3",
    "citation_corpus_id": 46899514,
    "start": 2583,
    "end": 2610,
    "title": "Generative Code Modeling with Graphs",
    "abstract": "Generative models for source code are an interesting structured prediction problem, requiring to reason about both hard syntactic and semantic constraints as well as about natural, likely programs. We present a novel model for this problem that uses a graph to represent the intermediate state of the generated output. The generative procedure interleaves grammar-driven expansion steps with graph augmentation and neural message passing steps. An experimental evaluation shows that our new model can generate semantically meaningful expressions, outperforming a range of strong baselines.Preprint. Work in progress.",
    "prev": "Diffusion models have been used successfully in a variety of settings, outperforming all other methods on image and video (Dhariwal & Nichol, 2021;Ho et al., 2022).",
    "curr": "These successes raise hope for building powerful models for graph generation, a task with diverse applications such as molecule design (Liu et al., 2018), traffic modeling (Yu & Gu, 2019), and code completion (Brockschmidt et al., 2019).",
    "next": "However, generating graphs remains challenging due to their unordered nature and sparsity properties.",
    "hard_negative": [
      3495200,
      12718048,
      15904815,
      11336213,
      8393918
    ],
    "easy_negative": [
      1662839,
      219306865,
      245838347
    ]
  },
  {
    "index": 1008,
    "source_corpus_id": 257636846,
    "ref_id": "b24",
    "citation_corpus_id": 229923720,
    "start": 31899,
    "end": 31918,
    "title": "Transformer Feed-Forward Layers Are Key-Value Memories",
    "abstract": "Feed-forward layers constitute two-thirds of a transformer model's parameters, yet their role in the network remains under-explored. We show that feed-forward layers in transformerbased language models operate as key-value memories, where each key correlates with textual patterns in the training examples, and each value induces a distribution over the output vocabulary. Our experiments show that the learned patterns are human-interpretable, and that lower layers tend to capture shallow patterns, while upper layers learn more semantic ones. The values complement the keys' input patterns by inducing output distributions that concentrate probability mass on tokens likely to appear immediately after each pattern, particularly in the upper layers. Finally, we demonstrate that the output of a feed-forward layer is a composition of its memories, which is subsequently refined throughout the model's layers via residual connections to produce the final output distribution.",
    "prev": "Being able to write SDM as an MLP with minor modifications is interesting in light of SDM's connection to Transformer Attention (Bricken & Pehlevan, 2021).",
    "curr": "This link converges with work showing that Transformer MLP layers perform associative memory-like operations that approximate Top-K by showing up to 90% activation sparsity in later layers (Geva et al., 2020;Sukhbaatar et al., 2019;Nelson et al., 2022).",
    "next": "Viewing both Attention and MLPs through the lens of SDM presents their tradeoffs: Attention operates on patterns in the model's current receptive field.",
    "hard_negative": [
      16299141,
      218628619,
      52346770,
      162183964,
      195477534,
      155092004,
      52892477,
      3626819,
      184486746,
      184486755,
      52967399,
      199552244,
      207853045
    ],
    "easy_negative": [
      987509,
      41297504,
      201697132
    ]
  },
  {
    "index": 1009,
    "source_corpus_id": 235829401,
    "ref_id": "b5",
    "citation_corpus_id": 168169888,
    "start": 14293,
    "end": 14311,
    "title": "Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation",
    "abstract": "Advances in learning and representations have reinvigorated work that connects language to other modalities. A particularly exciting direction is Vision-and-Language Navigation (VLN), in which agents interpret natural language instructions and visual scenes to move through environments and reach goals. Despite recent progress, current research leaves unclear how much of a role language understanding plays in this task, especially because dominant evaluation metrics have focused on goal completion rather than the sequence of actions corresponding to the instructions. Here, we highlight shortcomings of current metrics for the Room-to-Room dataset(Anderson et al., 2018b)and propose a new metric, Coverage weighted by Length Score (CLS). We also show that the existing paths in the dataset are not ideal for evaluating instruction following because they are direct-to-goal shortest paths. We join existing short paths to form more challenging extended paths to create a new data set, Room-for-Room (R4R). Using R4R and CLS, we show that agents that receive rewards for instruction fidelity outperform agents that focus on goal completion.",
    "prev": "Again, CLIP-ViT-B variant leads to dramatically worse performance compared to other visual modules, that we will discuss in Section 5.",
    "curr": "Vision-and-Language Navigation\n\nVision-and-language navigation tests the agent's ability to take action according to human instructions, which recently gains popularity in embodied AI (Anderson et al., 2018b;Chen et al., 2019;Jain et al., 2019;Chen et al., 2019;Qi et al., 2020b;Krantz et al., 2020;Nguyen and Daum\u00e9 III, 2019;.",
    "next": "Specifically, the agent is put at a location in the environment (Chang et al., 2017) and asked to reach a target by following the language instructions.",
    "hard_negative": [
      1957433,
      173188813,
      51991118,
      52155604,
      53301865
    ],
    "easy_negative": [
      2329288,
      9525340,
      52145734
    ]
  },
  {
    "index": 1011,
    "source_corpus_id": 253264964,
    "ref_id": "b28",
    "citation_corpus_id": 1428702,
    "start": 21021,
    "end": 21040,
    "title": "Learning Word Vectors for Sentiment Analysis",
    "abstract": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term-document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.",
    "prev": "COMPARISON WITH BASELINES ON DIFFERENT BENCHMARKS\n\nSettings.",
    "curr": "In this section, we evaluate our MPCFormer framework with different approximations and compare it with baselines on the IMDb dataset and the GLUE benchmark (Maas et al., 2011;Wang et al., 2018).",
    "next": "For all experiments in this section, we use BERT BASE as the base model.",
    "hard_negative": [
      1260035,
      388,
      2279432,
      10473638,
      7105713,
      2787775,
      218515777,
      3264224,
      629094,
      469886
    ],
    "easy_negative": [
      236145029,
      254877175,
      232021578
    ]
  },
  {
    "index": 1013,
    "source_corpus_id": 254823652,
    "ref_id": "b48",
    "citation_corpus_id": 233306870,
    "start": 4363,
    "end": 4380,
    "title": "Gradient Matching for Domain Generalization",
    "abstract": "Machine learning systems typically assume that the distributions of training and test sets match closely. However, a critical requirement of such systems in the real world is their ability to generalize to unseen domains. Here, we propose an inter-domain gradient matching objective that targets domain generalization by maximizing the inner product between gradients from different domains. Since direct optimization of the gradient inner product can be computationally prohibitive -it requires computation of second-order derivatives --we derive a simpler first-order algorithm named Fish that approximates its optimization. We perform experiments on the WILDS benchmark, which captures distribution shift in the real world, as well as the DOMAINBED benchmark that focuses more on syntheticto-real transfer. Our method produces competitive results on both benchmarks, demonstrating its effectiveness across a wide range of domain generalization tasks.",
    "prev": "With increasing attention on this issue, researchers have been probing the generalisation performance of ML models by creating datasets that feature distribution shift tasks (Koh et al., 2021;Gulrajani and Lopez-Paz, 2020;Shah et al., 2020) and proposing algorithms that aim to improve generalisation performance under distribution shift (Ganin et al., 2016;Arjovsky et al., 2019;Sun and Saenko, 2016; Figure 1: Synthetic vs. realistic distribution shift: The distribution shift in synthetic datasets (left, MNIST-CIFAR and CdSprites) are usually extreme and controllable (adjusted via changing the correlation); for realistic datasets (right, WILDS-Camelyon17 and FMoW) distribution shift can be subtle, hard to identify and impossible to control.",
    "curr": "Sagawa et al., 2020;Shi et al., 2022).",
    "next": "In this work, we identify three specific problems with current approaches in distribution shift problems, in computer vision, and develop a suite of experiments to address them.",
    "hard_negative": [
      52967399,
      13997424,
      1066490
    ],
    "easy_negative": [
      235359141,
      160744178,
      18132219
    ]
  },
  {
    "index": 1016,
    "source_corpus_id": 246822636,
    "ref_id": "b23",
    "citation_corpus_id": 8394195,
    "start": 1895,
    "end": 1914,
    "title": "LOSSY IMAGE COMPRESSION WITH COMPRESSIVE AUTOENCODERS",
    "abstract": "We propose a new approach to the problem of optimizing autoencoders for lossy image compression. New media formats, changing hardware technology, as well as diverse requirements and content types create a need for compression algorithms which are more flexible than existing codecs. Autoencoders have the potential to address this need, but are difficult to optimize directly due to the inherent non-differentiabilty of the compression loss. We here show that minimal changes to the loss are sufficient to train deep autoencoders competitive with JPEG 2000 and outperforming recently proposed approaches based on RNNs. Our network is furthermore computationally efficient thanks to a sub-pixel architecture, which makes it suitable for high-resolution images. This is in contrast to previous work on autoencoders for compression using coarser approximations, shallower architectures, computationally expensive methods, or focusing on small images.",
    "prev": "With the development of deep learning, learned methods have led to several breakthroughs in this task.",
    "curr": "Currently, the state-of-the-art (SOTA) deep image compression models are built on the auto-encoder framework [Hinton and Salakhutdinov, 2006] with an entropy-constrained bottleneck [Theis et al., 2017, Ball\u00e9 et al., 2017, Ball\u00e9 et al., 2018, Mentzer et al., 2018, Minnen et al., 2018a, Lee et al., 2019, Guo et al., 2021].",
    "next": "An entropy model estimates the conditional probability distribution of latents for compression by standard entropy coding algorithms.",
    "hard_negative": [
      6628106,
      2187805
    ],
    "easy_negative": [
      202767450,
      10716231,
      261344688
    ]
  },
  {
    "index": 1017,
    "source_corpus_id": 246652106,
    "ref_id": "b16",
    "citation_corpus_id": 3144218,
    "start": 3286,
    "end": 3308,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "As shown in Figure 1 (b), a noise edge means the connection between two faces of different classes.",
    "curr": "Unlike common graph datasets such as Citeseer, Cora and Pubmed with explicit link relation as edges (Kipf & Welling, 2017), face images do not contain explicit structural information, but only deep features extracted from a trained CNN model.",
    "next": "Therefore, face images are treated as vertices, and the edges between face images are usually constructed based on the kNN (Cover & Hart, 1967) relations when building the graph: Each face serves as a probe to retrieve its k nearest neighbours by deep features (Wang et al., 2019b;Guo et al., 2020;Shen et al., 2021).",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      233004444,
      16483732,
      8459419
    ]
  },
  {
    "index": 1018,
    "source_corpus_id": 252596252,
    "ref_id": "b33",
    "citation_corpus_id": 227209335,
    "start": 1587,
    "end": 1607,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "INTRODUCTION\n\nDiffusion models learn the implicit prior of the underlying data distribution by matching the gradient of the log density (i.e.",
    "curr": "Stein score; \u2207 x log p(x)) (Song et al., 2021b).",
    "next": "The prior can be leveraged when solving inverse problems, which aim to recover x from the measurement y, related through the forward measurement operator A and the detector noise n. When we know such forward models, one can incorporate the gradient of the log likelihood (i.e.",
    "hard_negative": [
      52889459,
      52908831
    ],
    "easy_negative": [
      11872486,
      238857090,
      10198873
    ]
  },
  {
    "index": 1022,
    "source_corpus_id": 239049848,
    "ref_id": "b43",
    "citation_corpus_id": 3626819,
    "start": 67576,
    "end": 67596,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "Small weights final layer.Following Andrychowicz et al.",
    "curr": "(2020), we consider using smaller weights for the final layers of the actor and the critic.Specifically, we downscale these weights by a factor of 100 at initialization time.We refer to this strategy as scale down.Gradient clipping.Another stabilizing strategy is gradient clipping (Zhang et al., 2020).To avoid occasional exploding gradients, one simply clips the norm of gradients that are above some threshold.This strategy is popular in NLP (Gehring et al., 2017;Peters et al., 2018) and is sometimes used in RL (Raffin et al., 2019).We consider clipping the gradient when the norm, calculated independently for the actor, critic, and convolutional encoder, is larger than 1 or 10.We refer to these strategies as grad clip 1 and grad clip 10.",
    "next": "Results.",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      8535316,
      11336213,
      990233,
      9917468,
      20472740,
      34032948,
      10489017,
      1957433,
      1222212,
      12688069,
      15026764,
      11816014,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      216562627,
      233365362,
      11282692
    ]
  },
  {
    "index": 1023,
    "source_corpus_id": 263831010,
    "ref_id": "b31",
    "citation_corpus_id": 3144218,
    "start": 24639,
    "end": 24661,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "( 2022) is included in Graphium to reduce the cost of hyper-parameter tuning.More details are given in Appendix E.7.The library supports CPU, GPU and IPU [ \u00a7E.8] hardware to accelerate training.Further library optimisations are detailed in Appendix E.9.",
    "curr": "EXPERIMENTS ON BASELINE MODELS\n\nTo demonstrate the capabilities of the Graphium library in a multi-task setting with thousands of labels, a set of standard baselines were run with simple hyperparameter sweeps using 3 popular GNNs, namely GCN (Kipf & Welling, 2017), GIN (Xu et al., 2019), and GINE (Hu et al., 2020a).",
    "next": "A basic hyper-parameter sweep was conducted for each model and multiple random seeds used for initialisation to provide a performance baseline for future experiments to be evaluated against.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      151157,
      3772100,
      16722028
    ]
  },
  {
    "index": 1024,
    "source_corpus_id": 3609219,
    "ref_id": "b12",
    "citation_corpus_id": 11243593,
    "start": 7843,
    "end": 7864,
    "title": "TRACKING THE WORLD STATE WITH RECURRENT ENTITY NETWORKS",
    "abstract": "We introduce a new model, the Recurrent Entity Network (EntNet). It is equipped with a dynamic long-term memory which allows it to maintain and update a representation of the state of the world as it receives new data. For language understanding tasks, it can reason on-the-fly as it reads text, not just when it is required to answer a question or respond as is the case for a Memory Network(Sukhbaatar et al., 2015). Like a Neural Turing Machine or Differentiable Neural Computer(Graves et al., 2014;2016)it maintains a fixed size memory and can learn to perform location and content-based read and write operations. However, unlike those models it has a simple parallel architecture in which several memory locations can be updated simultaneously. The EntNet sets a new state-of-the-art on the bAbI tasks, and is the first method to solve all the tasks in the 10k training examples setting. We also demonstrate that it can solve a reasoning task which requires a large number of supporting facts, which other methods are not able to solve, and can generalize past its training horizon. It can also be practically used on large scale datasets such as Children's Book Test, where it obtains competitive performance, reading the story in a single pass.",
    "prev": "AMN does not use strong supervision but can solve tasks that require transitive logic by modeling sentence walks on the fly.",
    "curr": "EntNet constructs dynamic networks based on entities with tied weights for each entity (Henaff et al., 2017).",
    "next": "A key-value update system allows it to update relevant (learned) entities.",
    "hard_negative": [
      11336213,
      14915449
    ],
    "easy_negative": [
      6315014,
      2175426,
      236486141
    ]
  },
  {
    "index": 1026,
    "source_corpus_id": 259095535,
    "ref_id": "b14",
    "citation_corpus_id": 174799399,
    "start": 51070,
    "end": 51089,
    "title": "Learning Deep Transformer Models for Machine Translation",
    "abstract": "Transformer is the state-of-the-art model in recent machine translation evaluations. Two strands of research are promising to improve models of this kind: the first uses wide networks (a.k.a. Transformer-Big) and has been the de facto standard for the development of the Transformer system, and the other uses deeper language representation but faces the difficulty arising from learning deep networks. Here, we continue the line of research on the latter. We claim that a truly deep Transformer model can surpass the Transformer-Big counterpart by 1) proper use of layer normalization and 2) a novel way of passing the combination of previous layers to the next. On WMT'16 English-German, NIST OpenMT'12 Chinese-English and larger WMT'18 Chinese-English tasks, our deep system (30/25-layer encoder) outperforms the shallow Transformer-Big/Base baseline (6-layer encoder) by 0.4\u223c2.4 BLEU points. As another bonus, the deep model is 1.6X smaller in size and 3X faster in training than Transformer-Big 1 . * Corresponding author. 1  The source code is available at https://github. com/wangqiangneu/dlcl",
    "prev": "\u2022 Affine maps W len , W num : R \u2192 Rd and W node : R 2 \u2192 Rd.",
    "curr": "\u2022 A simple stack of five Transformer blocks with eight heads in the self-attention and layer normalization before the MHA and the FF (Wang et al., 2019).",
    "next": "The structure of a Transformer block is summarized in Figure 4.",
    "hard_negative": [
      22973057,
      52011544,
      16538528,
      9146682,
      3626819,
      44131019,
      1998416,
      51880415,
      35673326,
      3725815,
      53236219
    ],
    "easy_negative": [
      1045043,
      249605593,
      17182637
    ]
  },
  {
    "index": 1031,
    "source_corpus_id": 58006571,
    "ref_id": "b40",
    "citation_corpus_id": 21946795,
    "start": 4326,
    "end": 4346,
    "title": "ENSEMBLE ADVERSARIAL TRAINING: ATTACKS AND DEFENSES",
    "abstract": "Adversarial examples are perturbed inputs designed to fool machine learning models. Adversarial training injects such examples into training data to increase robustness. To scale this technique to large datasets, perturbations are crafted using fast single-step methods that maximize a linear approximation of the model's loss. We show that this form of adversarial training converges to a degenerate global minimum, wherein small curvature artifacts near the data points obfuscate a linear approximation of the loss. The model thus learns to generate weak perturbations, rather than defend against strong ones. As a result, we find that adversarial training remains vulnerable to black-box attacks, where we transfer perturbations computed on undefended models, as well as to a powerful novel single-step attack that escapes the non-smooth vicinity of the input data via a small random step. We further introduce Ensemble Adversarial Training, a technique that augments training data with perturbations transferred from other models. On ImageNet, Ensemble Adversarial Training yields models with stronger robustness to blackbox attacks. In particular, our most robust model won the first round of the NIPS 2017 competition on Defenses against Adversarial Attacks (Kurakin et al., 2017c). However, subsequent work found that more elaborate black-box attacks could significantly enhance transferability and reduce the accuracy of our models.",
    "prev": "For datasets that are relatively simple and have low intrinsic dimensions (MNIST, Fashion MNIST, etc), we can obtain enough training examples to make sure adversarial training covers most part of the data distribution.",
    "curr": "For high dimensional datasets (CIFAR, ImageNet), adversarial training have been shown difficult (Kurakin et al., 2016;Tram\u00e8r et al., 2018) and only limited success was obtained.",
    "next": "A recent attack proposed by  shows that adversarial training can be defeated when the input image is produced by a generative model (for example, a generative adversarial network) rather than selected directly from the test examples.",
    "hard_negative": [
      211126665,
      9059612,
      1257772,
      210164926,
      11217889,
      3526769
    ],
    "easy_negative": [
      219306865,
      15139384,
      8640400
    ]
  },
  {
    "index": 1033,
    "source_corpus_id": 254198961,
    "ref_id": "b5",
    "citation_corpus_id": 53115163,
    "start": 9077,
    "end": 9096,
    "title": "EXPLORATION BY RANDOM NETWORK DISTILLATION",
    "abstract": "We introduce an exploration bonus for deep reinforcement learning methods that is easy to implement and adds minimal overhead to the computation performed. The bonus is the error of a neural network predicting features of the observations given by a fixed randomly initialized neural network. We also introduce a method to flexibly combine intrinsic and extrinsic rewards. We find that the random network distillation (RND) bonus combined with this increased flexibility enables significant progress on several hard exploration Atari games. In particular we establish state of the art performance on Montezuma's Revenge, a game famously difficult for deep reinforcement learning methods. To the best of our knowledge, this is the first method that achieves better than average human performance on this game without using demonstrations or having access to the underlying state of the game, and occasionally completes the first level.",
    "prev": "This is motivated by applications in robotics and Embodied Intelligence where the state is not directly observable, but can be well-approximated through the combination: s = (x, q), where x denotes stacked RGB images observed by the agent's camera, and q denotes proprioceptive sensory information, e.g., the joint pose of a robot.",
    "curr": "Furthermore, shaped reward functions can be hard to script for real-world applications (Singh et al., 2019) or result in undesirable artifacts or behaviors (Amodei et al., 2016;Burda et al., 2019).",
    "next": "Thus, we desire to learn with simple sparse rewards that accurately capture task completion.",
    "hard_negative": [
      12256925,
      3461154
    ],
    "easy_negative": [
      27094656,
      9759915,
      227231312
    ]
  },
  {
    "index": 1035,
    "source_corpus_id": 67855499,
    "ref_id": "b11",
    "citation_corpus_id": 3529936,
    "start": 2439,
    "end": 2458,
    "title": "Gradient Estimators for Implicit Models",
    "abstract": "Implicit models, which allow for the generation of samples but not for point-wise evaluation of probabilities, are omnipresent in real world problems tackled by machine learning and a hot topic of current research. Some examples include data simulators that are widely used in engineering and scientific research, generative adversarial networks (GANs) for image synthesis, and hot-off-the-press approximate inference techniques relying on implicit distributions. The majority of existing approaches to learning implicit models rely on approximating the intractable distribution or optimisation objective for gradient-based optimisation, which is liable to produce inaccurate updates and thus poor models. This paper alleviates the need for such approximations by proposing the Stein gradient estimator, which directly estimates the score function of the implicitly defined distribution. The efficacy of the proposed estimator is empirically demonstrated by examples that include meta-learning for approximate inference, and entropy regularised GANs that provide improved sample diversities.",
    "prev": "Traditional VI methods approximate the true posterior with oversimplified distribution families like factorized Gaussians, which can severely limit the approximation quality and induce pathologies such as over-pruning (Trippe & Turner, 2018).",
    "curr": "These limitations have motivated the recent development of implicit VI methods (Li & Turner, 2018;Shi et al., 2018b), which allow the use of flexible approximate distributions without a tractable density.",
    "next": "However, most of the implicit inference methods require to learn a \"generator network\" that maps a simple distribution to approximate the target posterior.",
    "hard_negative": [
      6628106,
      11758569
    ],
    "easy_negative": [
      216868696,
      258463931,
      248863247
    ]
  },
  {
    "index": 1040,
    "source_corpus_id": 51559,
    "ref_id": "b27",
    "citation_corpus_id": 1952530,
    "start": 1928,
    "end": 1947,
    "title": "Predicting Polarities of Tweets by Composing Word Embeddings with Long Short-Term Memory",
    "abstract": "In this paper, we introduce Long Short-Term Memory (LSTM) recurrent network for twitter sentiment prediction. With the help of gates and constant error carousels in the memory block structure, the model could handle interactions between words through a flexible compositional function. Experiments on a public noisy labelled data show that our model outperforms several feature-engineering approaches, with the result comparable to the current best data-driven technique. According to the evaluation on a generated negation phrase test set, the proposed architecture doubles the performance of non-neural model based on bag-of-word features. Furthermore, words with special functions (such as negation and transition) are distinguished and the dissimilarities of words with opposite sentiment are magnified. An interesting case study on negation expression processing shows a promising potential of the architecture dealing with complex sentiment phrases.",
    "prev": "Recurrent layers can also be stacked, increasing network depth, representational power and often accuracy.",
    "curr": "RNN applications in the natural language domain range from sentence classification (Wang et al., 2015) to word-and character-level language modeling (Zaremba et al., 2014).",
    "next": "RNNs are also commonly the basic building block for more complex models for tasks such as machine translation (Bahdanau et al., 2015;Luong et al., 2015; or question answering (Kumar et al., 2016;.",
    "hard_negative": [
      9026691,
      7695235,
      9093385,
      16719115,
      886027,
      12964363,
      15720214,
      3116311,
      990233,
      7105713,
      16399303,
      1306065,
      1428702,
      629094
    ],
    "easy_negative": [
      227231496,
      6939619,
      218977391
    ]
  },
  {
    "index": 1042,
    "source_corpus_id": 245668925,
    "ref_id": "b18",
    "citation_corpus_id": 15986631,
    "start": 3620,
    "end": 3638,
    "title": "Deep Reinforcement Learning with a Natural Language Action Space",
    "abstract": "This paper introduces a novel architecture for reinforcement learning with deep neural networks designed to handle state and action spaces characterized by natural language, as found in text-based games. Termed a deep reinforcement relevance network (DRRN), the architecture represents action and state spaces with separate embedding vectors, which are combined with an interaction function to approximate the Q-function in reinforcement learning. We evaluate the DRRN on two popular text games, showing superior performance over other deep Qlearning architectures. Experiments with paraphrased action descriptions show that the model is extracting meaning rather than simply memorizing strings of text.",
    "prev": "On the other hand, since rewards are sparse, the agent only gets a few high-scoring trajectories to learn from, requiring vigorous exploitation in order to get back to the furthest point of the game and make progress thereon.",
    "curr": "Prior approaches to solving these games (He et al., 2016a;Guo et al., 2020) usually employ a single policy and action selection strategy, making it difficult to strike the right balance between exploration and exploitation.",
    "next": "In this paper, we propose eXploit-Then-eXplore (XTX), an algorithm for multi-stage control to explicitly decompose the exploitation and exploration phases within each episode.",
    "hard_negative": [
      8781666,
      16326763,
      1998416,
      5249151
    ],
    "easy_negative": [
      49745096,
      53609310,
      219309898
    ]
  },
  {
    "index": 1054,
    "source_corpus_id": 233306870,
    "ref_id": "b6",
    "citation_corpus_id": 68222714,
    "start": 3462,
    "end": 3475,
    "title": "APPROXIMATING CNNS WITH BAG-OF-LOCAL- FEATURES MODELS WORKS SURPRISINGLY WELL ON IMAGENET",
    "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 33 \u00d7 33 px features and Alexnet performance for 17 \u00d7 17 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.",
    "prev": "Consider, for example, a model that is built to distinguish between cows and camels using photos collected in nature under different climates.",
    "curr": "Since CNNs are known to have a bias towards texture (Geirhos et al., 2018, Brendel andBethge, 2019), if we simply try to minimize the average loss across different domains, the classifier is prone to spuriously correlate \"cow\" with grass and \"camels\" with desert, and predict the species using only the background.",
    "next": "Such a classifier can be rendered useless when the animals are placed indoors or in a zoo.",
    "hard_negative": [
      2103669,
      32654687
    ],
    "easy_negative": [
      7654859,
      218502322,
      235352644
    ]
  },
  {
    "index": 1055,
    "source_corpus_id": 252683303,
    "ref_id": "b16",
    "citation_corpus_id": 231632658,
    "start": 3133,
    "end": 3151,
    "title": "What Makes Good In-Context Examples for GPT-3?",
    "abstract": "GPT-3 has attracted lots of attention due to its superior performance across a wide range of NLP tasks, especially with its in-context learning abilities. Despite its success, we found that the empirical results of GPT-3 depend heavily on the choice of in-context examples. In this work, we investigate whether there are more effective strategies for judiciously selecting incontext examples (relative to random sampling) that better leverage GPT-3's in-context learning capabilities. Inspired by the recent success of leveraging a retrieval module to augment neural networks, we propose to retrieve examples that are semantically-similar to a test query sample to formulate its corresponding prompt. Intuitively, the examples selected with such a strategy may serve as more informative inputs to unleash GPT-3's power of text generation. We evaluate the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random selection baseline. Moreover, it is observed that the sentence encoders finetuned on task-related datasets yield even more helpful retrieval results. Notably, significant gains are observed on tasks such as table-totext generation (44.3% on the ToTTo dataset) and open-domain question answering (45.5% on the NQ dataset).",
    "prev": "This work studies example selection in chain-of-thoughts multi-step reasoning.",
    "curr": "Example selection is a central problem in the prompting literature (Liu et al., 2022;Rubin et al., 2022;Su et al., 2022;Lazaridou et al., 2022).",
    "next": "It asks what instances make the best prompts for solving the tasks of interest.",
    "hard_negative": [
      6401679,
      86611921,
      990233,
      15975226,
      216641852,
      1428702
    ],
    "easy_negative": [
      9686561,
      219300494,
      219303244
    ]
  },
  {
    "index": 1061,
    "source_corpus_id": 226221794,
    "ref_id": "b29",
    "citation_corpus_id": 221878944,
    "start": 9619,
    "end": 9636,
    "title": "How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks",
    "abstract": "We study how neural networks trained by gradient descent extrapolate, i.e., what they learn outside the support of training distribution. Previous works report mixed empirical results when extrapolating with neural networks: while multilayer perceptrons (MLPs) do not extrapolate well in simple tasks, Graph Neural Networks (GNNs), a structured network with MLP modules, have some success in more complex tasks. We provide a theoretical explanation and identify conditions under which MLPs and GNNs extrapolate well. We start by showing ReLU MLPs trained by gradient descent converge quickly to linear functions along any direction from the origin, which suggests ReLU MLPs cannot extrapolate well in most non-linear tasks. On the other hand, ReLU MLPs can provably converge to a linear target function when the training distribution is \"diverse\" enough. These observations lead to a hypothesis: GNNs can extrapolate well in dynamic programming (DP) tasks if we encode appropriate non-linearity in the architecture and input representation. We provide theoretical and empirical support for the hypothesis. Our theory explains previous extrapolation success and suggest their limitations: successful extrapolation relies on incorporating task-specific non-linearity, which often requires domain knowledge or extensive model search.",
    "prev": "Also, we consider a larger family of distribution shifts including covariate shifts.",
    "curr": "The above two categories are not exhaustivee.g., there are some recent works that characterize how some inductive biases favor extrapolation [Xu et al., 2021] and can be better for OOD generalization.",
    "next": "Sample Complexity of Invariant Risk Minimization\n\n\nInvariant Risk Minimization\n\nWe start with some background on IRM [Arjovsky et al., 2019].",
    "hard_negative": [
      13900194,
      208547770,
      3626819,
      213085920,
      52967399,
      52920808,
      6706414,
      85504763
    ],
    "easy_negative": [
      198904598,
      226283933,
      252819502
    ]
  },
  {
    "index": 1068,
    "source_corpus_id": 235614244,
    "ref_id": "b4",
    "citation_corpus_id": 11212020,
    "start": 23811,
    "end": 23834,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "ntic segmentation is a saturated task, and most contemporary published works have approximate performances, Hamburger shows considerable improvements over previous state-of-the-art attention modules.",
    "curr": "Method mIoU(%) PSPNet (Zhao et al., 2017) 82.6 DFN * (Yu et al., 2018) 82.7 EncNet  82.9 DANet * (Fu et al., 2019) 82.6 DMNet * (He et al., 2019a) 84.4 APCNet * (He et al., 2019b) 84.2 CFNet * (Zhang et al., 2019b) 84.2 SpyGR *  84.2 SANet * (Zhong et al., 2020) 83.2 OCR * (Yuan et al., 2020) 84.3 HamNet 85.9 Method mIoU(%) PSPNet (Zhao et al., 2017) 47.8 SGR * (Liang et al., 2018) 50.8 EncNet  51.7 DANet * (Fu et al., 2019) 52.6 EMANet * (Li et al., 2019a) 53.1 DMNet * (He et al., 2019a) 54.4 APCNet * (He et al., 2019b) 54.7 CFNet * (Zhang et al., 2019b) 54.0 SpyGR *  52.8 SANet * (Zhong et al., 2020) 53.0 OCR * (Yuan et al., 2020) 54.8 HamNet 55.2 \n\n\nIMAGE GENERATION\n\n\nRELATED WORK\n\nGeneral Survey for Attention The last five years have witnessed a roaring success of attention mechanisms (Bahdanau et al., 2015;Mnih et al., 2014;Xu et al., 2015;Luong et al., 2015) in deep learning.",
    "next": "Roughly speaking, the attention mechanism is a term of adaptively generating the targets' weights to be attended according to the requests.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      2696588,
      7692118,
      21726572
    ]
  },
  {
    "index": 1074,
    "source_corpus_id": 253080708,
    "ref_id": "b23",
    "citation_corpus_id": 3144218,
    "start": 2175,
    "end": 2199,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "GNNs broadly follow a message-passing framework, meaning that each layer of the GNN aggregates the representations of a node and its neighbors, and transforms these features into a new representation for that node.",
    "curr": "The aggregation function used by the GNN layer is taken to be locally permutationinvariant, since the ordering of the neighbors of a node is arbitrary, and its specific form is a key component of the GNN architecture; varying it gives rise to several common GNN variants (Kipf and Welling, 2017;Veli\u010dkovi\u0107 et al., 2018;Li et al., 2015;Hamilton et al., 2017;Xu et al., 2019).",
    "next": "The output of a GNN can be used for tasks such as graph classification or node classification.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      15734062,
      219306310,
      220446145
    ]
  },
  {
    "index": 1075,
    "source_corpus_id": 53113561,
    "ref_id": "b17",
    "citation_corpus_id": 1957433,
    "start": 6778,
    "end": 6802,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "BASIC DESIGN OF MACHINE COMPREHENSION MODELS\n\nFor single-turn MC, many top-performing models share a similar architecture, consisting of four major components: (1) question encoding, (2) context encoding, (3) reasoning, and finally (4) answer prediction.",
    "curr": "Initially the word embeddings (e.g., Pennington et al., 2014;Peters et al., 2018) of question tokens Q and context tokens C are taken as input and fed into contextual integration layers, such as LSTMs (Hochreiter & Schmidhuber, 1997) or self attentions (Yu et al., 2018), to encode the question and context.",
    "next": "Multiple integration layers provide contextualized representations of context, and are often inter-weaved with attention, which inject question information.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      250150633,
      7523960,
      229923177
    ]
  },
  {
    "index": 1077,
    "source_corpus_id": 229923128,
    "ref_id": "b18",
    "citation_corpus_id": 8822680,
    "start": 2025,
    "end": 2048,
    "title": "Six Challenges for Neural Machine Translation",
    "abstract": "We explore six challenges for neural machine translation: domain mismatch, amount of training data, rare words, long sentences, word alignment, and beam search. We show both deficiencies and improvements over the quality of phrasebased statistical machine translation.",
    "prev": "INTRODUCTION\n\nWhen translating a word, translation models need to spend a substantial amount of its capacity in disambiguating its sense in the source language and choose a lexeme in the target language which adequately express its meaning (Choi et al., 2017;Tamchyna, 2017).",
    "curr": "However, neural machine translation (NMT) has a severe problem on lexical choice, since it usually has mistranslation errors on low-frequency words (Koehn & Knowles, 2017;Nguyen & Chiang, 2018).",
    "next": "Table 1: All samples that contain the source word \"\u7ebd \u9a6c \u57fa\u7279\" in raw and distilled training corpora, which are different in target sides (RAW-TGT vs. KD-TGT).",
    "hard_negative": [
      216849409,
      2722451,
      11336213,
      1395225,
      1245593,
      1557806,
      1785399,
      930231,
      12639289,
      94792,
      13292366,
      14421595,
      905565,
      765547,
      11212020
    ],
    "easy_negative": [
      256460995,
      7207964,
      247450844
    ]
  },
  {
    "index": 1078,
    "source_corpus_id": 238856778,
    "ref_id": "b30",
    "citation_corpus_id": 1957433,
    "start": 19469,
    "end": 19494,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "(Even without having ever seen a white wolf, a typical English speaker can guess that a white wolf is more likely to resemble an arctic fox than a snorkel.)",
    "curr": "These kinds of relations are often captured by embeddings of class labels (or more detailed class descriptions) (Pennington et al., 2014).",
    "next": "When available, this kind of information about class semantics can be used to construct an improved subspace regularizer by encouraging new class representations to lie close to a convex combination of base classes weighted by their semantic similarity.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      261494431,
      253523033,
      10497905
    ]
  },
  {
    "index": 1081,
    "source_corpus_id": 260351224,
    "ref_id": "b4",
    "citation_corpus_id": 29153681,
    "start": 11096,
    "end": 11121,
    "title": "META-LEARNING WITH DIFFERENTIABLE CLOSED-FORM SOLVERS",
    "abstract": "Adapting deep networks to new concepts from a few examples is challenging, due to the high computational requirements of standard fine-tuning procedures.Most work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent. Nonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently. In this paper, we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning. The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression, as part of its own internal model, enabling it to quickly adapt to novel data. This requires back-propagating errors through the solver steps. While normally the cost of the matrix operations involved in such a process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage. We propose both closed-form and iterative solvers, based on ridge regression and logistic regression components. Our methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks.",
    "prev": "Bilevel optimization.",
    "curr": "Bilevel optimization is a powerful tool to study many machine learning applications such as hyperparameter optimization (Franceschi et al., 2018;Shaban et al., 2019), meta-learning (Bertinetto et al., 2018;Franceschi et al., 2018;Rajeswaran et al., 2019;Ji et al., 2020;, neural architecture search (Liu et al., 2018;Zhang et al., 2021a), etc.",
    "next": "Existing approaches are usually approximate implicit differentiation (AID) based (Domke, 2012;Pedregosa, 2016;Gould et al., 2016;Liao et al., 2018;Lorraine et al., 2020), or iterative differentiation (ITD) based (Domke, 2012;Maclaurin et al., 2015;Franceschi et al., 2017;Finn et al., 2017;Shaban et al., 2019;Rajeswaran et al., 2019;Liu et al., 2020).",
    "hard_negative": [
      3507990,
      3431470,
      12122362
    ],
    "easy_negative": [
      9171251,
      10813537,
      258378313
    ]
  },
  {
    "index": 1083,
    "source_corpus_id": 256663850,
    "ref_id": "b4",
    "citation_corpus_id": 229376913,
    "start": 8174,
    "end": 8191,
    "title": "RealFormer: Transformer Likes Residual Attention",
    "abstract": "Transformer is the backbone of modern NLP models. In this paper, we propose Real-Former, a simple and generic technique to create Residual Attention Layer Transformer networks that significantly outperform the canonical Transformer and its variants (BERT, ETC, etc.) on a wide spectrum of tasks including Masked Language Modeling, GLUE, SQuAD, Neural Machine Translation, WikiHop, HotpotQA, Natural Questions, and OpenKP. We also observe empirically that RealFormer stabilizes training and leads to models with sparser attention. Source code and pre-trained checkpoints for RealFormer can be found at https",
    "prev": "To distinguish it from our RLA, we rename the former as RLA g in the following.",
    "curr": "RealFormer (He et al., 2021) and EA-Transformer (Wang et al., 2021) both added attention scores in the previous layer to the current one, connecting the layers by residual attention.",
    "next": "Bapna et al.",
    "hard_negative": [
      59317031,
      174799399,
      201670412,
      9192723,
      221845203
    ],
    "easy_negative": [
      8241258,
      196192520,
      6630494
    ]
  },
  {
    "index": 1086,
    "source_corpus_id": 212414027,
    "ref_id": "b6",
    "citation_corpus_id": 53464644,
    "start": 24902,
    "end": 24925,
    "title": "LEARNING PROTEIN SEQUENCE EMBEDDINGS USING INFORMATION FROM STRUCTURE",
    "abstract": "Inferring the structural properties of a protein from its amino acid sequence is a challenging yet important problem in biology. Structures are not known for the vast majority of protein sequences, but structure is critical for understanding function. Existing approaches for detecting structural similarity between proteins from sequence are unable to recognize and exploit structural patterns when sequences have diverged too far, limiting our ability to transfer knowledge between structurally related proteins. We newly approach this problem through the lens of representation learning. We introduce a framework that maps any protein sequence to a sequence of vector embeddings -one per amino acid position -that encode structural information. We train bidirectional long short-term memory (LSTM) models on protein sequences with a two-part feedback mechanism that incorporates information from (i) global structural similarity between proteins and (ii) pairwise residue contact maps for individual proteins. To enable learning from structural similarity information, we define a novel similarity measure between arbitrarylength sequences of vector embeddings based on a soft symmetric alignment (SSA) between them. Our method is able to learn useful position-specific embeddings despite lacking direct observations of position-level correspondence between sequences. We show empirically that our multi-task framework outperforms other sequence-based methods and even a top-performing structure-based alignment method when predicting structural similarity, our goal. Finally, we demonstrate that our learned embeddings can be transferred to other protein sequence problems, improving the state-of-the-art in transmembrane domain prediction. 1 1 source code and datasets are available at Published as a conference paper at ICLR 2019 but the problem is challenging, because sequence similarity and structural similarity are only loosely related [1, 2, 3, 4], e.g. similar structural folds can be formed by diverse sequences. As a result, our ability to transfer knowledge between proteins with similar structures is limited.In this work, we address this problem by learning protein sequence embeddings using weak supervision from global structural similarity for the first time. Specifically, we aim to learn a bidirectional LSTM (biLSTM) embedding model, mapping sequences of amino acids to sequences of vector representations, such that residues occurring in similar structural contexts will be close in embedding space. This is difficult, because we have not observed position-level correspondences between sequences, only global sequence similarity. We solve this by defining a whole sequence similarity measure from sequences of vector embeddings. The measure decomposes into an alignment of the sequences and pairwise comparison of the aligned positions in embedding space. For the alignment, we propose a soft symmetric alignment (SSA) mechanism -a symmetrization of the directional alignment commonly used in attention mechanisms. Furthermore, in order to take advantage of information about local structural context within proteins, we extend this framework to include position-level supervision from contacts between residues in the individual protein structures. This multitask framework(Figure 1) allows us to newly leverage both global structural similarity between proteins and residue-residue contacts within proteins for training embedding models.",
    "prev": "In contrast to our work, these methods operate over small molecular graphs and were not applied to large macromolecules, like proteins.",
    "curr": "In parallel, recent work proposes that generative models pre-trained on protein sequences can transfer knowledge to downstream supervised tasks (Bepler & Berger, 2019;Alley et al., 2019;Yang et al., 2019;Rives et al., 2019).",
    "next": "These methods have also been explored for protein design (Wang et al., 2018).",
    "hard_negative": [
      28971531,
      8535316,
      16787742,
      11866664,
      11022639,
      3033526,
      3626819,
      8476273,
      11212020
    ],
    "easy_negative": [
      22155691,
      2058981,
      17588382
    ]
  },
  {
    "index": 1091,
    "source_corpus_id": 259138847,
    "ref_id": "b8",
    "citation_corpus_id": 247958465,
    "start": 5999,
    "end": 6002,
    "title": "MoEfication: Transformer Feed-forward Layers are Mixtures of Experts",
    "abstract": "Recent work has shown that feed-forward networks (FFNs) in pre-trained Transformers are a key component, storing various linguistic and factual knowledge.However, the computational patterns of FFNs are still unclear.In this work, we study the computational patterns of FFNs and observe that most inputs only activate a tiny ratio of neurons of FFNs.This phenomenon is similar to the sparsity of the human brain, which drives research on functional partitions of the human brain.To verify whether functional partitions also emerge in FFNs, we propose to convert a model into its MoE version with the same parameters, namely MoEfication.Specifically, MoEfication consists of two phases: (1) splitting the parameters of FFNs into multiple functional partitions as experts, and (2) building expert routers to decide which experts will be used for each input.Experimental results show that MoEfication can conditionally use 10% to 30% of FFN parameters while maintaining over 95% original performance for different models on various downstream tasks.Besides, MoEfication brings two advantages: (1) it significantly reduces the FLOPS of inference, i.e., 2x speedup with 25% of FFN parameters, and (2) it provides a fine-grained perspective to study the inner mechanism of FFNs.The source code of this paper can be obtained from https://github.com/thunlp/MoEfication.",
    "prev": "Moreover, unlike classical sparse methods where such a connection is established via explicit sparse regularization [8], the sparsity observed in Transformers is emergent without any explicit design.",
    "curr": "It is worth noting that the observation that Transformers produce sparse activations is previously reported in [9].",
    "next": "Our paper significantly extends upon results in [9] to demonstrate that sparsity emerges prevalently at all layers of Transformers, for both language and vision tasks, on both training and evaluation data, and for some architectures beyond Transformers.",
    "hard_negative": [
      220265858,
      16299141,
      229923720,
      221970445,
      990233,
      12462234,
      162183964,
      195477534,
      155092004,
      3432876,
      201670719,
      233289412,
      215238853,
      11816014,
      202712654,
      229923538,
      235097557,
      201645145,
      263266654,
      202719327,
      209315300,
      16639476
    ],
    "easy_negative": [
      257366019,
      241651270,
      15037844
    ]
  },
  {
    "index": 1092,
    "source_corpus_id": 236087421,
    "ref_id": "b34",
    "citation_corpus_id": 14124313,
    "start": 5101,
    "end": 5129,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "In the MLP-Mixer , the model obtains the global receptive field through matrix transposition and token-mixing projection such that the long-range dependencies are covered.",
    "curr": "However, this rarely makes full use of the local information, which is very important in CNN-like architecture (Simonyan & Zisserman, 2015;He et al., 2016) because not all pixels need long-range dependencies, and the Therefore, a more ideal way to introduce locality is to directly model the relationship between a feature point and its surrounding feature points at any position, without the need to set a fixed window (and window size) in advance.",
    "next": "To aggregate the features of different spatial positions in the same position and model their relationships, inspired by (Wu et al., 2018;Lin et al., 2019;Wang et al., 2020;Ho et al., 2019), we propose an axial shift strategy for MLP-based architecture, where we spatially shift features in both horizontal and vertical directions.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      21613313,
      31910266,
      250390517
    ]
  },
  {
    "index": 1096,
    "source_corpus_id": 250048824,
    "ref_id": "b6",
    "citation_corpus_id": 240354066,
    "start": 2154,
    "end": 2157,
    "title": "Efficiently Modeling Long Sequences with Structured State Spaces",
    "abstract": "A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies. Although conventional models including RNNs, CNNs, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of 10000 or more steps. A promising recent approach proposed modeling sequences by simulating the fundamental state space model, and showed that for appropriate choices of the state matrix A, this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning A with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel. S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91% accuracy on sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation 60\u00d7 faster (iii) SoTA on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors. 1",
    "prev": "* Equal contribution.",
    "curr": "Introduction\n\nThe Structured State Space model (S4) is a recent deep learning model based on continuous-time dynamical systems that has shown promise on a wide variety of sequence modeling tasks [7].",
    "next": "It is defined as a linear time-invariant (LTI) state space model (SSM), which give it multiple properties [6]: as an SSM, S4 can be simulated as a discrete-time recurrence for efficiency in online or autoregressive settings, and as a LTI model, S4 can be converted into a convolution for parallelizability and computational efficiency at training time.",
    "hard_negative": [
      239009958,
      52890982,
      59310641,
      219965819,
      222067132
    ],
    "easy_negative": [
      253223917,
      261341821,
      259370522
    ]
  },
  {
    "index": 1100,
    "source_corpus_id": 36483539,
    "ref_id": "b37",
    "citation_corpus_id": 12713052,
    "start": 2560,
    "end": 2577,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "(2017)) is a class of approaches to reduce the size of Deep Neural Networks (DNNs) and accelerate inference.",
    "curr": "Meanwhile, Structure Learning (Zoph & Le (2017), Philipp & Carbonell (2017), Cortes et al.",
    "next": "(2017)) becomes an active research area for DNN structure exploration, which can potentially replace human labor with machine automation for design space exploration.",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      233356271,
      8729131,
      5121472
    ]
  },
  {
    "index": 1101,
    "source_corpus_id": 256662499,
    "ref_id": "b55",
    "citation_corpus_id": 13751870,
    "start": 2617,
    "end": 2629,
    "title": "A Call for Clarity in Reporting BLEU Scores",
    "abstract": "The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to \"the\" BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for usersupplied reference processing, and provide a new tool, SACREBLEU, 1 to facilitate this. . 2016. Google's neural machine translation system: Bridging the gap between human and machine translation. ArXiv eprints, abs/1609.08144.",
    "prev": "INTRODUCTION\n\nTraining of deep learning models utilizes randomness to improve generalization and training efficiency, thus causing an inherent nondeterminism that hampers the reliability of machine learning evaluation -the consistency of the measurement of evaluation scores across replicated training runs.Gundersen et al.",
    "curr": "(2022) list several sources of nondeterminism, e.g., implementation-level nondeterminism such as random ordering in floating-point accumulation in parallel GPU threads (Pham et al., 2021), algorithmic factors such as variations in meta-parameters and model architecture (Lucic et al., 2018;Henderson et al., 2018;D'Amour et al., 2020), or data-level factors such as variations in pre-processing and evaluation metrics (Post, 2018;Chen et al., 2022) or varying characteristics of data in different splits (Gorman & Bedrick, 2019;S\u00f8gaard et al., 2021).Zhuang et al.",
    "next": "(2022) show that implementation-level nondeterminism is partly irreducible, leading to variability in evaluation scores even for training runs on identical data, algorithmic settings and infrastructure.Furthermore, they point out strong effects of certain types of algorithm-level nondeterminism on certain subsets of the data.",
    "hard_negative": [
      384994,
      2863491,
      16794216,
      49742509,
      2531955,
      7647892,
      17643319,
      1245593,
      21675165,
      252796,
      905565
    ],
    "easy_negative": [
      14250345,
      202540591,
      15646981
    ]
  },
  {
    "index": 1102,
    "source_corpus_id": 263333942,
    "ref_id": "b10",
    "citation_corpus_id": 13046179,
    "start": 2171,
    "end": 2197,
    "title": "A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS",
    "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.Published as a conference paper at ICLR 2017 one method which outperforms the baseline on some (but not all) tasks. This new method evaluates the quality of a neural network's input reconstruction to determine if an example is abnormal.",
    "prev": "INTRODUCTION\n\nIn deep neural networks, out-of-distribution (OOD) detection distinguishes samples which deviate from the training distribution.Standard OOD detection concerns semantic shifts (Yang et al., 2022;Zhang et al., 2023), where OOD data is defined as test samples from semantic categories unseen during training.Ideally, the neural network should be able to reject such samples as being OOD, while still maintaining strong performance on in-distribution (ID) test samples belonging to seen training categories.",
    "curr": "Methods for detecting OOD samples work by scoring network outputs such as logits or softmax values (Hendrycks & Gimpel, 2017;Hendrycks et al., 2022), post-hoc network adjustment during inference to improve OOD scoring (Sun & Li, 2022;Sun et al., 2021;Djurisic et al., 2023), or by adjusting model training (Wei et al., 2022;Ming et al., 2023;DeVries & Taylor, 2018).These approaches can be used either independently or in conjunction with one another.Typically, post-hoc adjustments together with OOD scoring is the preferred combination since it is highly effective at discerning OOD samples with minimal ID drop and can also be applied directly to already-trained models off-the-shelf.Examples include ReAct (Sun et al., 2021), DICE (Sun & Li, 2022) and more recently, ASH (Djurisic et al., 2023).",
    "next": "On the surface, each method takes different and sometimes even contradictory approaches.ReAct rectifies penultimate activations which exceed a threshold; ASH, on the other hand, prunes penultimate activations that are too low while amplifying remaining activations.While ASH currently achieves state-of-the-art performance,",
    "hard_negative": [
      6628106,
      7105713,
      2879445,
      1428702,
      6706414
    ],
    "easy_negative": [
      17489603,
      2817406,
      14509235
    ]
  },
  {
    "index": 1104,
    "source_corpus_id": 67749672,
    "ref_id": "b46",
    "citation_corpus_id": 14687186,
    "start": 3842,
    "end": 3863,
    "title": "Parsing with Compositional Vector Grammars",
    "abstract": "Natural language parsing has typically been done with small sets of discrete categories such as NP and VP, but this representation does not capture the full syntactic nor semantic richness of linguistic phrases, and attempts to improve on this by lexicalizing phrases or splitting categories only partly address the problem at the cost of huge feature spaces and sparseness. Instead, we introduce a Compositional Vector Grammar (CVG), which combines PCFGs with a syntactically untied recursive neural network that learns syntactico-semantic, compositional vector representations. The CVG improves the PCFG of the Stanford Parser by 3.8% to obtain an F1 score of 90.4%. It is fast to train and implemented approximately as an efficient reranker it is about 20% faster than the current Stanford factored parser. The CVG learns a soft notion of head words and improves performance on the types of ambiguities that require semantic information such as PP attachments.",
    "prev": "One feature shared by many humandesigned representation systems is compositionality: the capacity to represent complex concepts (from objects to procedures to beliefs) by combining simple parts (Fodor & Lepore, 2002).",
    "curr": "While many machine learning approaches make use of human-designed compositional analyses for representation and prediction (Socher et al., 2013;Dong & Lapata, 2016), it is also natural to ask whether (and how) compositionality arises in learning problems where compositional structure has not been built in from the start.",
    "next": "Consider the example in Figure 1, which shows a hypothetical character-based encoding scheme learned for a simple communication task (similar to the one studied by Lazaridou et al., 2016).",
    "hard_negative": [
      11691908,
      1123594,
      6684426,
      806709,
      1588411,
      1345,
      5968454,
      7901127,
      10986188,
      7478738,
      2755801,
      6693851,
      7645153,
      2388321,
      2847717,
      628455,
      11599080
    ],
    "easy_negative": [
      218973710,
      227231606,
      219306526
    ]
  },
  {
    "index": 1109,
    "source_corpus_id": 232307426,
    "ref_id": "b19",
    "citation_corpus_id": 52877454,
    "start": 1868,
    "end": 1893,
    "title": "DEEP GRAPH INFOMAX",
    "abstract": "We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs-both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. In contrast to most prior approaches to unsupervised learning with GCNs, DGI does not rely on random walk objectives, and is readily applicable to both transductive and inductive learning setups. We demonstrate competitive performance on a variety of node classification benchmarks, which at times even exceeds the performance of supervised learning.",
    "prev": "Self-supervised learning, a subset of unsupervised learning, learns representations by allowing the data to provide supervision (Devlin et al., 2018).",
    "curr": "Among its mainstream strategies, self-supervised contrastive learning has been successful in visual object recognition (He et al., 2020;Tian et al., 2019;Chen et al., 2020c), speech recognition (Oord et al., 2018;Rivi\u00e8re et al., 2020), language modeling (Kong et al., 2019), graph representation learning (Velickovic et al., 2019) and reinforcement learning (Kipf et al., 2019).",
    "next": "The idea of self-supervised contrastive learning is to learn latent representations such that related instances (e.g., patches from the same image; defined as positive pairs) will have representations within close distance, while unrelated instances (e.g., patches from two different images; defined as negative pairs) will have distant representations (Arora et al., 2019).",
    "hard_negative": [
      4630420,
      1957433
    ],
    "easy_negative": [
      236486249,
      248572047,
      219301287
    ]
  },
  {
    "index": 1110,
    "source_corpus_id": 244908617,
    "ref_id": "b12",
    "citation_corpus_id": 56657912,
    "start": 25448,
    "end": 25478,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "First, we learn pixel classifiers on the clean images using the DDPM, SwAV and MAE representations on the Bedroom-28 and Horse-21 datasets.",
    "curr": "Then, 18 diverse corruption types, adopted from (Hendrycks & Dietterich, 2019), are applied to test images.",
    "next": "Each corruption has five levels of severity.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      52155625,
      11053025,
      8058109
    ]
  },
  {
    "index": 1113,
    "source_corpus_id": 263830433,
    "ref_id": "b15",
    "citation_corpus_id": 233296808,
    "start": 4926,
    "end": 4947,
    "title": "The Power of Scale for Parameter-Efficient Prompt Tuning",
    "abstract": "In this work, we explore \"prompt tuning,\" a simple yet effective mechanism for learning \"soft prompts\" to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3's few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method \"closes the gap\" and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed \"prefix tuning\" of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient \"prompt ensembling.\" We release code and model checkpoints to reproduce our experiments. 1ReferencesRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,  Danilo Giampiccolo, Bernardo Magnini, and Idan  Szpektor. 2006. The second PASCAL recognising textual entailment challenge. In Proceedings of the second PASCAL challenges workshop on recognising textual entailment, volume 6, pages 6-4. Venice. . 2019a. SuperGLUE: A stickier benchmark for general-purpose language understanding systems. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.",
    "prev": "ext descriptions of the desired tasks that are often significantly easier to obtain compared to full model weights or even a generic linear classifier over the last layer.The versatility and performance of prompting Table 1: Comparison with existing state-of-the-art generalization bounds for test error on different datasets.We report both data-independent and data-dependent bounds (\u22c6 indicates data-dependent prior and \u2212 indicates that the bounds are not available).Note that different works use different architectures and analytic tools so direct comparison can be more nuanced.Nonetheless, our bounds on prompt engineering are significantly tighter than the existing PAC-Bayes bounds in the literature, often within a few percent of the actual test error.",
    "curr": "Dataset\n\nZhou pretrained models have led to the rise of prompt engineering, an emergent paradigm in machine learning where practitioners carefully design the task specification in text or even learn the prompts in a data-driven fashion (Lester et al., 2021).For example, to obtain a two-class image classifier, one would write two sentences that describe the classes (e.g., \"This is a dog\" and \"This is a cat\"), and the two sentences are turned into text embeddings which can be used to classify image embeddings.Despite its empirical success, little is understood of how and why prompting these pretrained models work and, in particular, why the method seems to suffer little from overfitting: manually tuning or even greedily optimizing prompts on a given training set often performs nearly as well on the corresponding test set.",
    "next": "In this paper, we demonstrate that rather simple analysis tools capture this behavior surprisingly well (under some assumptions).In particular, we show that classical PAC-Bayes bounds (McAllester, 1999), when applied to the discrete hypothesis class defined by prompts (and specifically with a prior given by a large language model), are often remarkably tight, even for large domains: for example, we achieve a generalizati",
    "hard_negative": [
      155091369,
      3626819,
      204960716,
      11816014,
      233231453,
      40100965,
      218470133
    ],
    "easy_negative": [
      256390348,
      216641953,
      258841548
    ]
  },
  {
    "index": 1116,
    "source_corpus_id": 252693131,
    "ref_id": "b22",
    "citation_corpus_id": 209439843,
    "start": 2844,
    "end": 2866,
    "title": "MEASURING COMPOSITIONAL GENERALIZATION: A COMPREHENSIVE METHOD ON REALISTIC DATA",
    "abstract": "State-of-the-art machine learning methods exhibit limited compositional generalization. At the same time, there is a lack of realistic benchmarks that comprehensively measure this ability, which makes it challenging to find and evaluate improvements. We introduce a novel method to systematically construct such benchmarks by maximizing compound divergence while guaranteeing a small atom divergence between train and test sets, and we quantitatively compare this method to other approaches for creating compositional generalization benchmarks. We present a large and realistic natural language question answering dataset that is constructed according to this method, and we use it to analyze the compositional generalization ability of three machine learning architectures. We find that they fail to generalize compositionally and that there is a surprisingly strong negative correlation between compound divergence and accuracy. We also demonstrate how our method can be used to create new compositionality benchmarks on top of the existing SCAN dataset, which confirms these findings. Radev. Improving text-to-SQL evaluation methodology. In ACL, 2018. URL http://aclweb.org/anthology/P18-1033.Jerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical analysis. Cognition, 28(1-2):3-71, 1988. URL https://pdfs.semanticscholar.org/d806/ 76034bfabfea59f35698af0f715a555fcf50.pdf.",
    "prev": "This type of compositionality is central to the human ability to generalize from limited data to novel combinations (Lake et al., 2017).",
    "curr": "Recently, several datasets have been proposed to test systematic generalization of machine learning models-SCAN (Lake & Baroni, 2018), PCFG (Hupkes et al., 2020), CFQ (Keysers et al., 2020), and HINT (Li et al., 2021), to name a few.",
    "next": "While conventional neural networks fail dramatically on these datasets, certain inductive biases have been explored to improve systematic generalization.",
    "hard_negative": [
      969059,
      3728944,
      348944,
      108296442,
      3986974,
      2711679
    ],
    "easy_negative": [
      9016696,
      199379469,
      238857129
    ]
  },
  {
    "index": 1121,
    "source_corpus_id": 221818900,
    "ref_id": "b24",
    "citation_corpus_id": 49882757,
    "start": 1897,
    "end": 1915,
    "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech",
    "abstract": "In this work, we propose an alternative solution for parallel wave generation by WaveNet. In contrast to parallel WaveNet (Oord et al., 2018), we distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet by minimizing a novel regularized KL divergence between their highly-peaked output distributions. Our method computes the KL divergence in closed-form, which simplifies the training algorithm and provides very efficient distillation. In addition, we propose the first text-to-wave neural architecture for speech synthesis, which is fully convolutional and enables fast end-to-end training from scratch. It significantly outperforms the previous pipeline that connects a text-to-spectrogram model to a separately trained WaveNet (Ping et al., 2018). We also successfully distill a parallel waveform synthesizer conditioned on the hidden representation in this end-to-end model. 2 * These authors contributed equally to this work. Correspondence to <weiping.thu@gmail.com>. Our method is named after the musical instrument clarinet, whose sound resembles human voice.2 Audio samples are in https://clarinet-demo.github.io/ arXiv:1807.07281v2 [cs.CL] 30 Jul 2018",
    "prev": "In previous work, likelihood-based models, including autoregressive models (van den Oord et al., 2016;Kalchbrenner et al., 2018; and flow-based models Prenger et al., 2019;, have predominated in audio synthesis because of the simple training objective and superior ability of modeling the fine details of waveform in real data.",
    "curr": "There are other waveform models, which often require auxiliary losses for training, such as flow-based models trained by distillation Ping et al., 2019), variational auto-encoder (VAE) based model , and generative adversarial network (GAN) based models Yamamoto et al., 2020).",
    "next": "Most of previous waveform models focus on audio synthesis with informative local conditioner (e.g., mel spectrogram or aligned linguistic features), with only a few exceptions in unconditional generation .",
    "hard_negative": [
      8451212,
      8768364,
      11212020,
      3480671
    ],
    "easy_negative": [
      1918428,
      1399957,
      18780774
    ]
  },
  {
    "index": 1124,
    "source_corpus_id": 247996510,
    "ref_id": "b4",
    "citation_corpus_id": 235368289,
    "start": 4765,
    "end": 4786,
    "title": "Measuring and Improving BERT's Mathematical Abilities by Predicting the Order of Reasoning",
    "abstract": "Imagine you are in a supermarket. You have two bananas in your basket and want to buy four apples. How many fruits do you have in total? This seemingly straightforward question can be challenging for data-driven language models, even if trained at scale. However, we would expect such generic language models to possess some mathematical abilities in addition to typical linguistic competence. Towards this goal, we investigate if a commonly used language model, BERT, possesses such mathematical abilities and, if so, to what degree. For that, we fine-tune BERT on a popular dataset for word math problems, AQuA-RAT, and conduct several tests to understand learned representations better. Since we teach models trained on natural language to do formal mathematics, we hypothesize that such models would benefit from training on semi-formal steps that explain how math results are derived. To better accommodate such training, we also propose new pretext tasks for learning mathematical rules. We call them (Neighbor) Reasoning Order Prediction (ROP or NROP). With this new model, we achieve significantly better outcomes than data-driven baselines and even on-par with more tailored models. We also show how to reduce positional bias in such models.",
    "prev": "(2020) showed that SATNet (Wang et al., 2019) could not solve visual Sudoku without using intermediate labels to identify individual Sudoku digit images.",
    "curr": "Similar limitations were observed in language related compounded tasks, including commonsense reasoning (Liu et al., 2022;Wei et al., 2022;Zelikman et al., 2022), math word problems (Pi\u0119kos et al., 2021;Wei et al., 2022), and programs execution (Nye et al., 2022).",
    "next": "The go-to architectures in this domain are powerful language models, which are trained as sequence-to-sequence models over text.",
    "hard_negative": [
      215548225,
      173188048,
      15717845,
      184486746,
      52967399
    ],
    "easy_negative": [
      53245252,
      15946286,
      18682524
    ]
  },
  {
    "index": 1130,
    "source_corpus_id": 239769065,
    "ref_id": "b30",
    "citation_corpus_id": 3687922,
    "start": 2541,
    "end": 2544,
    "title": "SEMI-PARAMETRIC TOPOLOGICAL MEMORY FOR NAVIGATION",
    "abstract": "We introduce a new memory architecture for navigation in previously unseen environments, inspired by landmark-based navigation in animals. The proposed semiparametric topological memory (SPTM) consists of a (non-parametric) graph with nodes corresponding to locations in the environment and a (parametric) deep network capable of retrieving nodes from the graph based on observations. The graph stores no metric information, only connectivity of locations corresponding to the nodes. We use SPTM as a planning module in a navigation system. Given only 5 minutes of footage of a previously unseen maze, an SPTM-based navigation agent can build a topological map of the environment and use it to confidently navigate towards goals. The average success rate of the SPTM agent in goal-directed navigation across test environments is higher than the best-performing baseline by a factor of three.",
    "prev": "Some prior methods approach this problem by performing search or optimization over subgoals at test time.",
    "curr": "However, these test-time planning methods either rely on graph search [7,31], which scales poorly with dimensionality [14], or continuous optimization over subgoals [26], which is expensive and can result in model exploitation.",
    "next": "In this paper, we take a different tack and instead use search at training time to automatically generate a curriculum.",
    "hard_negative": [
      6628106,
      534043,
      13298214,
      16134629
    ],
    "easy_negative": [
      3146900,
      258741298,
      2926996
    ]
  },
  {
    "index": 1131,
    "source_corpus_id": 248810913,
    "ref_id": "b30",
    "citation_corpus_id": 108300988,
    "start": 2602,
    "end": 2624,
    "title": "WHAT DO YOU LEARN FROM CONTEXT? PROBING FOR SENTENCE STRUCTURE IN CONTEXTUALIZED WORD REPRESENTATIONS",
    "abstract": "Contextualized representation models such as ELMo(Peters et al., 2018a)andBERT (Devlin et al., 2018)have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.",
    "prev": "A large number of studies have been devoted towards interpreting DNNs.",
    "curr": "A major line of research work has focused on DNNs in interpreting deep Natural Language Processing (NLP) models and their ability to learn various pre-defined linguistic concepts (Tenney et al., 2019b;Liu et al., 2019a).",
    "next": "More specifically, they rely on pre-defined linguistic concepts such as: parts-of-speech tags and semantic tags, and probe whether the specific linguistic knowledge is learned in various parts of the network.",
    "hard_negative": [
      49363457,
      6628106,
      28971531,
      5112203,
      44152851,
      24461982,
      52113185,
      436023,
      1957433,
      11162815,
      3626819,
      1222212,
      5034059,
      52123220,
      7645153,
      40100965,
      4891749,
      13888490,
      19206893,
      3994096,
      21663989,
      6771196,
      4460159
    ],
    "easy_negative": [
      248779866,
      5155512,
      36005974
    ]
  },
  {
    "index": 1133,
    "source_corpus_id": 1091965,
    "ref_id": "b22",
    "citation_corpus_id": 14124313,
    "start": 2130,
    "end": 2158,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "(2012) developed AlexNet, an ImageNet-winning CNN with more than 1.1 \u00d7 10 9 multiplies.",
    "curr": "In 2014, ImageNetwinning and runner up CNNs increased the number of multiplies to 1.4 \u00d7 10 9 (Szegedy et al., 2015) and 1.6 \u00d7 10 10 (Simonyan & Zisserman, 2015) respectively.",
    "next": "Despite the powerful representational ability of large scale CNNs, their computational workload prohibits deployment on mobile devices.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      15513499,
      260453789,
      259187538
    ]
  },
  {
    "index": 1140,
    "source_corpus_id": 210932183,
    "ref_id": "b31",
    "citation_corpus_id": 12713052,
    "start": 1608,
    "end": 1625,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "To showcase the framework, we compare several state-of-the-art one-shot NAS methods, examine how sensitive they are to their hyperparameters and how they can be improved by tuning their hyperparameters, and compare their performance to that of blackbox optimizers for NAS-Bench-101.",
    "curr": "INTRODUCTION\n\nWhile neural architecture search (NAS) has attracted a lot of attention due to the effectiveness in automatically designing state-of-the-art neural networks (Zoph & Le, 2017;Real et al., 2017;, the focus has recently shifted to making the search process more efficient (Pham et al., 2018;Elsken et al., 2019;Xie et al., 2019;Cai et al., 2019;Casale et al., 2019).",
    "next": "The most crucial concept which led to a reduction in search costs to the order of a single function evaluation is certainly the weight-sharing paradigm: Training only a single large architecture (the one-shot model) subsuming all the possible architectures in the search space (Brock et al., 2018;Pham et al., 2018).",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      18358623,
      1986773,
      37653771
    ]
  },
  {
    "index": 1142,
    "source_corpus_id": 219792972,
    "ref_id": "b24",
    "citation_corpus_id": 3568073,
    "start": 7236,
    "end": 7240,
    "title": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024 2 . We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.",
    "prev": "MSGAN (aka Miss-GAN) (23) aims to solve the missing mode problem of conditional GANs through a regularization term that maximizes the distance between the generated images with respect to the distance between their corresponding input latent codes.",
    "curr": "Progressive GANs (24) are growing both the generator and discriminator progressively, and approach resembling the layer-wise training of autoencoders.",
    "next": "Method\n\n\nPreliminaries\n\nWe define an N -way, K (tr) -shot supervised classification task, T , as a set D (tr) T composed of i \u2208 {1, .",
    "hard_negative": [
      18828233,
      6628106
    ],
    "easy_negative": [
      127987872,
      219649,
      16598300
    ]
  },
  {
    "index": 1153,
    "source_corpus_id": 235390683,
    "ref_id": "b27",
    "citation_corpus_id": 3292002,
    "start": 2577,
    "end": 2601,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "Due to their prevalence and rich descriptive capacity, pattern mining and discovery on graph data is a prominent research area with powerful implications.",
    "curr": "As the generalization of deep neural networks on graph data, graph neural networks (GNNs) have proved to be powerful in learning representations for graphs and associated entities (nodes, edges, subgraphs), and they have been employed in various applications such as node classification (Kipf & Welling, 2016a;Veli\u010dkovi\u0107 et al., 2018), node clustering (Pan et al., 2018), recommender systems (Ying et al., 2018) and drug discovery (Duvenaud et al., 2015).",
    "next": "In recent years, the explosive interest in self-supervised learning (SSL) has suggested its great potential in empowering stronger neural networks in an unsupervised manner Kolesnikov et al., 2019;Doersch et al., 2015).",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      16731231,
      585845,
      233480312
    ]
  },
  {
    "index": 1160,
    "source_corpus_id": 3290366,
    "ref_id": "b1",
    "citation_corpus_id": 3495200,
    "start": 3105,
    "end": 3108,
    "title": "LEARNING TO REPRESENT PROGRAMS WITH GRAPHS",
    "abstract": "Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures. In this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VARNAMING, in which a network attempts to predict the name of a variable given its usage, and VARMISUSE, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VARMISUSE task in many cases. Additionally, our testing showed that VARMISUSE identifies a number of bugs in mature open-source projects.",
    "prev": "Examples include prediction of properties of chemical molecules [9], answering questions about knowledge graphs [25], natural language processing with parsestructured inputs (trees or richer structures like Abstract Meaning Representations) [4], predicting properties of data structures or source code in programming * Work done partially while author was at Microsoft Research.",
    "curr": "languages [2,22], and making predictions from scene graphs [39].",
    "next": "Sequence data can be seen as a special case of a simple chain-structured graph.",
    "hard_negative": [
      11336213,
      1957433,
      8393918
    ],
    "easy_negative": [
      252682995,
      15749064,
      53604363
    ]
  },
  {
    "index": 1164,
    "source_corpus_id": 247922261,
    "ref_id": "b18",
    "citation_corpus_id": 8348149,
    "start": 2513,
    "end": 2534,
    "title": "Learning Effective and Interpretable Semantic Models using Non-Negative Sparse Embedding",
    "abstract": "In this paper, we introduce an application of matrix factorization to produce corpus-derived, distributional models of semantics that demonstrate cognitive plausibility. We find that word representations learned by Non-Negative Sparse Embedding (NNSE), a variant of matrix factorization, are sparse, effective, and highly interpretable. To the best of our knowledge, this is the first approach which yields semantic representation of words satisfying these three desirable properties. Though extensive experimental evaluations on multiple real-world tasks and datasets, we demonstrate the superiority of semantic models learned by NNSE over other state-of-the-art baselines.",
    "prev": "For this we draw inspiration from overcomplete representations: representations of an input that are nonunique combinations of a number of basis vectors greater than the input's dimensionality (Lewicki & Sejnowski, 2000).",
    "curr": "Mostly studied in the context of the sparse coding literature (Gregor & LeCun, 2010;Goodfellow et al., 2012;Olshausen, 2013), sparse overcomplete representations have been shown to increase stability in the presence of noise (Donoho et al., 2006), have applications in neuroscience (Olshausen & Field, 1996;Lee et al., 2007), and lead to more interpretable representations (Murphy et al., 2012;Fyshe et al., 2015;Faruqui et al., 2015).",
    "next": "However, the choice of basis vectors is generally assumed to be learned using traditional methods such as ICA (Teh et al., 2003) or fitting linear models (Lewicki & Sejnowski, 2000), limiting the expressive power of the encoding function.",
    "hard_negative": [
      5584134,
      7747235,
      380201,
      9460276,
      15698938,
      629094
    ],
    "easy_negative": [
      5294513,
      226262310,
      245877546
    ]
  },
  {
    "index": 1165,
    "source_corpus_id": 222133257,
    "ref_id": "b4",
    "citation_corpus_id": 5590763,
    "start": 6162,
    "end": 6165,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "By unrolling this algorithm, the authors demonstrate superior recovery over ALISTA for a specific setting of M, N and s.\n\nIn a related approach [20] identify undershooting, meaning that reconstructed components are smaller than target components, as a shortcoming of LISTA and propose Gated-LISTA to address these issues.",
    "curr": "The authors introduce gain and overshoot gates to LISTA, which can amplify the reconstruction after each iteration before and after thresholding, yielding an architecture resembling GRU cells [5].",
    "next": "The authors demonstrate better sparse reconstruction than previous LISTA-variants and also show that adding their proposed gates to ALISTA, named AGLISTA, it is possible to improve its performance in the same setting of M, N and s as ALISTA-AT.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      6780550,
      6745820,
      253018433
    ]
  },
  {
    "index": 1166,
    "source_corpus_id": 231698498,
    "ref_id": "b58",
    "citation_corpus_id": 202888885,
    "start": 2681,
    "end": 2700,
    "title": "Published as a conference paper at ICLR 2020 DRAWING EARLY-BIRD TICKETS: TOWARDS MORE EF- FICIENT TRAINING OF DEEP NETWORKS",
    "abstract": "Frankle & Carbin, 2019)shows that there exist winning tickets (small but critical subnetworks) for dense, randomly initialized networks, that can be trained alone to achieve a comparable accuracy to the latter in a similar number of iterations. However, the identification of these winning tickets still requires the costly train-prune-retrain process, limiting their practical benefits. In this paper, we discover for the first time that the winning tickets can be identified at a very early training stage, which we term as Early-Bird (EB) tickets, via lowcost training schemes (e.g., early stopping and low-precision training) at large learning rates. Our finding on the existence of EB tickets is consistent with recently reported observations that the key connectivity patterns of neural networks emerge early. Furthermore, we propose a mask distance metric that can be used to identify EB tickets with a low computational overhead, without needing to know the true winning tickets that emerge after the full training. Finally, we leverage the existence of EB tickets and the proposed mask distance to develop efficient training methods, which are achieved by first identifying EB tickets via low-cost schemes, and then continuing to train merely the EB tickets towards the target accuracy. Experiments based on various deep networks and datasets validate: 1) the existence of EB tickets and the effectiveness of mask distance in efficiently identifying them; and 2) that the proposed efficient training via EB tickets can achieve up to 5.8\u00d7 \u223c 10.7\u00d7 energy savings while maintaining comparable or even better accuracy as compared to the most competitive state-ofthe-art training methods, demonstrating a promising and easily adopted method for tackling the often cost-prohibitive deep network training.",
    "prev": "INTRODUCTION\n\nThe record-breaking performance of modern deep neural networks (DNNs) comes at a prohibitive training cost due to the required massive training data and parameters, limiting the development of the highly demanded DNN-powered intelligent solutions for numerous applications Wu et al., 2018).",
    "curr": "As an illustration, training ResNet-50 involves 10 18 FLOPs (floating-point operations) and can take 14 days on one state-of-the-art (SOTA) GPU (You et al., 2020b).",
    "next": "Meanwhile, the large DNN training costs have raised increasing financial and environmental concerns.",
    "hard_negative": [
      52920837,
      211259030,
      212415013,
      3603886,
      53388625,
      12713052,
      14089312
    ],
    "easy_negative": [
      33641106,
      1529891,
      252377998
    ]
  },
  {
    "index": 1168,
    "source_corpus_id": 259298217,
    "ref_id": "b42",
    "citation_corpus_id": 246652474,
    "start": 34913,
    "end": 34929,
    "title": "GRAPH-RELATIONAL DOMAIN ADAPTATION",
    "abstract": "Existing domain adaptation methods tend to treat every domain equally and align them all perfectly. Such uniform alignment ignores topological structures among different domains; therefore it may be beneficial for nearby domains, but not necessarily for distant domains. In this work, we relax such uniform alignment by using a domain graph to encode domain adjacency, e.g., a graph of states in the US with each state as a domain and each edge indicating adjacency, thereby allowing domains to align flexibly based on the graph structure. We generalize the existing adversarial learning framework with a novel graph discriminator using encodingconditioned graph embeddings. Theoretical analysis shows that at equilibrium, our method recovers classic domain adaptation when the graph is a clique, and achieves non-trivial alignment for other types of graphs. Empirical results show that our approach successfully generalizes uniform alignment, naturally incorporates domain information represented by graphs, and improves upon existing domain adaptation methods on both synthetic and real-world datasets 1 . * Work conducted during internship at AWS AI Labs. 1 Code will soon be available at https://github.com/Wang-ML-Lab/GRDA arXiv:2202.03628v2 [cs.LG] 21 Apr 2023Published as a conference paper at ICLR 2022One na\u00efve DA method for such graph-relational domains is to perform DA for each pair of neighboring domains separately. Unfortunately, due to the strict alignment between each domain pair, this method will still lead to uniform alignment so long as the graph is connected. To generalize DA to the graphrelational domains, we argue that an ideal method should (1) only enforce uniform alignment when the domain graph is a clique (i.e., every two domains are adjacent), and (2) more importantly, relax uniform alignment to adapt more flexibly across domains according to any non-clique domain graph, thereby naturally incorporating information on the domain adjacency. In this paper, we generalize adversarial DA methods and replace the traditional binary (or multi-class) discriminator with a novel graph discriminator: instead of distinguishing among different domains, our graph discriminator takes as input the encodings of data to reconstruct the domain graph. We show that our method enjoys the following theoretical guarantees: it recovers classic DA when the the domain graph is a clique, and realizes intuitive alignments for other types of graphs such as chains and stars (seeFig. 4). We summarize our contributions as follows:\u2022 We propose to use a graph to characterize domain relations and develop graph-relational domain adaptation (GRDA) as the first general adversarial DA method to adapt across domains living on a graph. \u2022 We provide theoretical analysis showing that at equilibrium, our method can retain the capability of uniform alignment when the domain graph is a clique, and achieve non-trivial alignment for other types of graphs. \u2022 Empirical results on both synthetic and real-world datasets demonstrate the superiority of our method over the state-of-the-art DA methods. Eric Granger. Unsupervised multi-target domain adaptation through knowledge distillation. In . Sentry: Selective entropy optimization via committee consistency for unsupervised domain adaptation. In Bridging theory and algorithm for domain adaptation. arXiv preprint arXiv:1904.05801, 2019.",
    "prev": "CLASSIFICATION\n\nDatasets.",
    "curr": "DG-15 (Xu et al., 2022) is a synthetic binary classification dataset with 15 groups.",
    "next": "Each group contains 100 data points.",
    "hard_negative": [
      46890017,
      6628106
    ],
    "easy_negative": [
      226283759,
      5291877,
      7454685
    ]
  },
  {
    "index": 1186,
    "source_corpus_id": 232013402,
    "ref_id": "b21",
    "citation_corpus_id": 3144218,
    "start": 2403,
    "end": 2425,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "INTRODUCTION\n\nGraph neural networks (GNNs) (Zhou et al., 2018;Wu et al., 2019), which work with graph structured data, have recently attracted considerable attention, as they can learn expressive representations for various graph-related tasks such as node classification, link prediction, and graph classification.",
    "curr": "While the majority of the existing works on GNNs focus on the message passing strategies for neighborhood aggregation (Kipf & Welling, 2017;Hamilton et al., 2017), which aims to encode the nodes in a graph accurately, graph pooling Ying et al., 2018) that maps the set of nodes into a compact representation is crucial in capturing a meaningful structure of an entire graph.",
    "next": "As a simplest approach for graph pooling, we can average or sum all node features in the given graph (Atwood & Towsley, 2016;Xu et al., 2019) (Figure 1 (B)).",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      900850,
      14321437,
      227257938
    ]
  },
  {
    "index": 1187,
    "source_corpus_id": 264288929,
    "ref_id": "b2",
    "citation_corpus_id": 53115163,
    "start": 5411,
    "end": 5430,
    "title": "EXPLORATION BY RANDOM NETWORK DISTILLATION",
    "abstract": "We introduce an exploration bonus for deep reinforcement learning methods that is easy to implement and adds minimal overhead to the computation performed. The bonus is the error of a neural network predicting features of the observations given by a fixed randomly initialized neural network. We also introduce a method to flexibly combine intrinsic and extrinsic rewards. We find that the random network distillation (RND) bonus combined with this increased flexibility enables significant progress on several hard exploration Atari games. In particular we establish state of the art performance on Montezuma's Revenge, a game famously difficult for deep reinforcement learning methods. To the best of our knowledge, this is the first method that achieves better than average human performance on this game without using demonstrations or having access to the underlying state of the game, and occasionally completes the first level.",
    "prev": "23b]'s K 6 /7 regret through a computationally efficient algorithm.Still, there remain significant gaps between the current upper bounds and the \u221a K lower bound.In this work, we push the frontiers both on the information theoretical limits and the achievable bounds under computational constraints: 1) we present the first (computationally inefficient) algorithm that provably obtains O( \u221a K) regret, showing that this is the minimax K dependence (Section 3); 2) we obtain O(K 3 /4 ) regret with a polynomial-time algorithm (Section 4).Below, we briefly describe the elements in our approaches.",
    "curr": "Inefficient\n\n\u221a K algorithm.We convert the linear MDP problem to a linear bandit problem by mapping each policy to a single dH-dimensional feature vector, where d is the ambient dimension of the linear MDP and H K 3 /4 in this paper.Beyond theoretical advancement, exploration in policy optimization has also showcased its potential in addressing real-world challenges, as evidenced by empirical studies [Burda et al., 2018, Pan et al., 2019].",
    "next": "Preliminaries\n\nNo-Regret Learning in MDPs.An (episodic) MDP is specified by a tuple M = (S, A, P ) where S is the state space (possibly infinite), A is the action space (assumed to be finite with size A = |A|), P : S \u00d7 A \u2192 \u2206(S) is the transition kernal.The state space is assumed to be layered, i.e., S = S 1 \u222a S 2 \u222a \u2022 \u2022 \u2022 \u222a S H where S h \u2229 S h \u2032 = \u2205 for any 1 \u2264 h < h \u2032 \u2264 H, and transition is only possible from one layer to the next, that is, P (s \u2032 | s, a) = 0 only when s \u2208 S h and s \u2032 \u2208 S h+1 .Without loss of generality, we assume S 1 = {s 1 }.",
    "hard_negative": [
      12256925,
      3461154
    ],
    "easy_negative": [
      226281476,
      244119701,
      250391057
    ]
  },
  {
    "index": 1195,
    "source_corpus_id": 258557287,
    "ref_id": "b22",
    "citation_corpus_id": 227209335,
    "start": 11292,
    "end": 11311,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "BACKGROUND\n\nIn this section, we first review diffusion models in Section 3.1 and we discuss how they are used for solving inverse problems in Section 3.2.",
    "curr": "DENOISING DIFFUSION MODELS\n\nDiffusion models (Sohl-Dickstein et al., 2015;Ho et al., 2020;Song et al., 2021b) consist of two processes: a forward process that gradually adds noise to input images and a reverse process that learns to generate images by iterative denoising.",
    "next": "Formally the forward process can be expressed by the variance preserving stochastic differential equation (VP-SDE) (Song et al., 2021b) dx \" 1 2 \u03b2ptqxdt`a\u03b2ptqdw for t P r0, T s where \u03b2ptq :\" \u03b2 min`p \u03b2 max\u00b4\u03b2min q t T rescales the time variable, and dw is the standard Wiener process.",
    "hard_negative": [
      52908831,
      52889459
    ],
    "easy_negative": [
      233296793,
      12776014,
      259360547
    ]
  },
  {
    "index": 1196,
    "source_corpus_id": 3463660,
    "ref_id": "b6",
    "citation_corpus_id": 5590763,
    "start": 23522,
    "end": 23540,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "We then employ a meta controller called interpreter in an iterative manner.",
    "curr": "For the ith interpretation step, the interpreter computes the word attention as:\n\u03c4\u02da$ ' ' ' ' ' & ' ' ' ' ' % Word attention: o i l 9 exp \" S cos pp i\u00b41 , w l q \u2030 Attended context: w i \" \u00ff l o i l w l Attended word: s i \" \u00ff l o i l w l Interpreter state: p i \" GRUpp i\u00b41 , w i q(6)\nwhere S cos is cosine similarity and GRU is the gated recurrent unit (Cho et al., 2014).",
    "next": "Here we use \u03c4\u02dato represent an approximation of \u03c4 via soft word attention.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      232124787,
      11051461,
      1442816
    ]
  },
  {
    "index": 1197,
    "source_corpus_id": 211296452,
    "ref_id": "b20",
    "citation_corpus_id": 6018348,
    "start": 2313,
    "end": 2331,
    "title": "Distant Supervision for Relation Extraction with an Incomplete Knowledge Base",
    "abstract": "Distant supervision, heuristically labeling a corpus using a knowledge base, has emerged as a popular choice for training relation extractors. In this paper, we show that a significant number of \"negative\" examples generated by the labeling process are false negatives because the knowledge base is incomplete. Therefore the heuristic for generating negative examples has a serious flaw. Building on a state-of-the-art distantly-supervised extraction algorithm, we proposed an algorithm that learns from only positive and unlabeled labels at the pair-of-entity level. Experimental results demonstrate its advantage over existing algorithms.",
    "prev": "\", one can identify the entity Grateful Dead and the path of relations LeadSinger, BirthDate to efficiently extract the answer-provided that this information is present in the KB.",
    "curr": "Unfortunately, KBs are often incomplete (Min et al., 2013).",
    "next": "While relation extraction methods can be used to populate KBs, this process is inherently error-prone, expensive and slow.",
    "hard_negative": [
      3179848,
      10910955,
      17069935,
      12995507,
      16483125,
      5869747,
      8945340,
      11494526
    ],
    "easy_negative": [
      9546207,
      2874200,
      29060920
    ]
  },
  {
    "index": 1201,
    "source_corpus_id": 53216170,
    "ref_id": "b19",
    "citation_corpus_id": 7228830,
    "start": 2122,
    "end": 2141,
    "title": "Adversarial Examples for Evaluating Reading Comprehension Systems",
    "abstract": "Standard accuracy metrics indicate that reading comprehension systems are making rapid progress, but the extent to which these systems truly understand language remains unclear.To reward systems with real language understanding abilities, we propose an adversarial evaluation scheme for the Stanford Question Answering Dataset (SQuAD). Our method tests whether systems can answer questions about paragraphs that contain adversarially inserted sentences, which are automatically generated to distract computer systems without changing the correct answer or misleading humans. In this adversarial setting, the accuracy of sixteen published models drops from an average of 75% F1 score to 36%; when the adversary is allowed to add ungrammatical sequences of words, average accuracy on four models decreases further to 7%. We hope our insights will motivate the development of new models that understand language more precisely.",
    "prev": "However, while standard encoders (e.g.",
    "curr": "bidirectional LSTMs) theoretically have the ability to handle arbitrary long-distance relationships, in practice they often fail to correctly handle long texts and are easily distracted by simple noise (Jia & Liang, 2017).",
    "next": "In this work, we focus on an improvement of sequence encoders that is compatible with a wide range of decoder choices.",
    "hard_negative": [
      748227,
      7218315,
      6706414,
      17652653,
      11816014,
      604334,
      1957433,
      2381275
    ],
    "easy_negative": [
      253481411,
      4075637,
      204848200
    ]
  },
  {
    "index": 1204,
    "source_corpus_id": 260704206,
    "ref_id": "b30",
    "citation_corpus_id": 259262608,
    "start": 4302,
    "end": 4319,
    "title": "Understanding In-Context Learning via Supportive Pretraining Data",
    "abstract": "In-context learning (ICL) improves language models' performance on a variety of NLP tasks by simply demonstrating a handful of examples at inference time. It is not well understood why ICL ability emerges, as the model has never been specifically trained on such demonstrations. Unlike prior work that explores implicit mechanisms behind ICL, we study ICL via investigating the pretraining data. Specifically, we first adapt an iterative, gradient-based approach to find a small subset of pretraining data that supports ICL. We observe that a continued pretraining on this small subset significantly improves the model's ICL ability, by up to 18%. We then compare the supportive subset constrastively with random subsets of pretraining data and discover: (1) The supportive pretraining data to ICL do not have a higher domain relevance to downstream tasks. (2) The supportive pretraining data have a higher mass of rarely occurring, long-tail tokens. (3) The supportive pretraining data are challenging examples where the information gain from long-range context is below average, indicating learning to incorporate difficult long-range context encourages ICL. Our work takes a first step towards understanding ICL via analyzing instance-level pretraining data. Our insights have a potential to enhance the ICL ability of language models by actively guiding the construction of pretraining data in the future.ReferencesEkin Aky\u00fcrek, Dale Schuurmans, Jacob Andreas, Tengyu Ma, and Denny Zhou. 2022. What learning algorithm is in-context learning? investigations with linear models. arXiv preprint arXiv:2211.15661.Tiago A Almeida, Jos\u00e9 Mar\u00eda G Hidalgo, and Akebo Yamakami. 2011. Contributions to the study of sms spam filtering: new collection and results. In Proceedings of the 11th ACM symposium on Document engineering, pages 259-262. . 2022. Why can gpt learn in-context? language models secretly perform gradient descent as meta optimizers. arXiv preprint arXiv:2212.10559.",
    "prev": "These new capabilities enable better alignment of the model with various data-use regulations, e.g., the fair use doctrine in the United States (Henderson et al., 2023) and the GDPR in the European Union , as detailed in \u00a72.",
    "curr": "This is in contrast to parametric models, where removing high-risk data is infeasible after training (Bourtoule et al., 2020; and data attribution at scale is difficult (Zhang et al., 2021;Han et al., 2023).",
    "next": "We introduce SILO, a new nonparametric language model that follows our proposal ( \u00a74).",
    "hard_negative": [
      241035330,
      13746570,
      210838924,
      990233,
      247155069,
      202539551
    ],
    "easy_negative": [
      11250697,
      244527086,
      17727105
    ]
  },
  {
    "index": 1210,
    "source_corpus_id": 209475822,
    "ref_id": "b5",
    "citation_corpus_id": 7586460,
    "start": 2422,
    "end": 2442,
    "title": "Lifelong Learning for Sentiment Classification",
    "abstract": "This paper proposes a novel lifelong learning (LL) approach to sentiment classification. LL mimics the human continuous learning process, i.e., retaining the knowledge learned from past tasks and use it to help future learning. In this paper, we first discuss LL in general and then LL for sentiment classification in particular. The proposed LL approach adopts a Bayesian optimization framework based on stochastic gradient descent. Our experimental results show that the proposed method outperforms baseline methods significantly, which demonstrates that lifelong learning is a promising research direction.",
    "prev": "In this paper, we focus on lifelong language learning, where a machine achieves lifelong learning on a stream of natural language processing (NLP) tasks.",
    "curr": "To the best of our knowledge, lifelong language learning has been studied in only a few instances; for sentiment analysis (Chen et al., 2015b;Xia et al., 2017), conversational agents (Lee, 2017), word representation learning (Xu et al., 2018), sentence representation learning (Liu et al., 2019), text classification, and question answering (d'Autume et al., 2019).",
    "next": "However, in all previous work, the tasks in the stream are essentially the same task but in different domains.",
    "hard_negative": [
      6732044,
      15652752,
      8326937,
      14473519,
      7105713,
      1728741,
      16707689,
      2461673
    ],
    "easy_negative": [
      10203451,
      252819208,
      237532582
    ]
  },
  {
    "index": 1214,
    "source_corpus_id": 3323727,
    "ref_id": "b17",
    "citation_corpus_id": 38407095,
    "start": 29641,
    "end": 29654,
    "title": "Europarl: A Parallel Corpus for Statistical Machine Translation",
    "abstract": "We collected a corpus of parallel text in 11 languages from the proceedings of the European Parliament, which are published on the web 1 . This corpus has found widespread use in the NLP community. Here, we focus on its acquisition and its application as training data for statistical machine translation (SMT). We trained SMT systems for 110 language pairs, which reveal interesting clues into the challenges ahead.",
    "prev": "LARGER DATASETS\n\nWMT13 Experiments.",
    "curr": "We run a similar LSTM architecture as above for the WMT13 dataset (Koehn, 2005) (1.7M sentences train, 190K sentences test) and we provide additional experiments for quantized distillation technique, see Table 6.",
    "next": "We note that, on this large dataset, PM quantization does not perform well, even with bucketing.",
    "hard_negative": [
      6204420,
      12928205
    ],
    "easy_negative": [
      8168250,
      29181427,
      16832577
    ]
  },
  {
    "index": 1216,
    "source_corpus_id": 219721263,
    "ref_id": "b10",
    "citation_corpus_id": 213085920,
    "start": 2983,
    "end": 2987,
    "title": "Published as a conference paper at ICLR 2020 STRATEGIES FOR PRE-TRAINING GRAPH NEURAL NETWORKS",
    "abstract": "Many applications of machine learning require a model to make accurate predictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that na\u00efve strategies, which pre-train GNNs at the level of either entire graphs or individual nodes, give limited improvement and can even lead to negative transfer on many downstream tasks. In contrast, our strategy avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction. * Equal contribution. Project website, data and code: Attribute Masking Supervised Attribute Prediction Structural Similarity Prediction Structure prediction Context Prediction (b) Categorization of our pre-training methods Graph space Node space Graph embeddings Node embeddings Linear classifier Figure 1: (a.i) When only node-level pre-training is used, nodes of different shapes (semantically different nodes) can be well separated, however, node embeddings are not composable, and thus resulting graph embeddings (denoted by their classes, + and \u2212) that are created by pooling node-level embeddings are not separable. (a.ii) With graph-level pre-training only, graph embeddings are well separated, however the embeddings of individual nodes do not necessarily capture their domainspecific semantics. (a.iii) High-quality node embeddings are such that nodes of different types are well separated, while at the same time, the embedding space is also composable. This allows for accurate and robust representations of entire graphs and enables robust transfer of pre-trained models to a variety of downstream tasks. (b) Categorization of pre-training methods for GNNs. Crucially, our methods, i.e., Context Prediction, Attribute Masking, and graph-level supervised pre-training (Supervised Attribute Prediction) enable both node-level and graph-level pre-training.matter of increasing the number of labeled pre-training datasets that are from the same domain as the downstream task. Instead, it requires substantial domain expertise to carefully select examples and target labels that are correlated with the downstream task of interest. Otherwise, the transfer of knowledge from related pre-training tasks to a new downstream task can harm generalization, which is known as negative transfer(Rosenstein et al., 2005)and significantly limits the applicability and reliability of pre-trained models.Present work. Here, we focus on pre-training as an approach to transfer learning in Graph Neural Networks (GNNs)(Kipf & Welling, 2017;Hamilton et al., 2017a;Ying et al., 2018b;Xu et al., 2019;2018)for graph-level property prediction. Our work presents two key contributions.(1) We conduct the first systematic large-scale investigation of strategies for pre-training GNNs. For that, we build two large new pre-training datasets, which we share with the community: a chemistry dataset with 2 million graphs and a biology dataset with 395K graphs. We also show that large domain-specific datasets are crucial to investigate pre-training and that existing downstream benchmark datasets are too small to evaluate models in a statistically reliable way.(2) We develop an effective pretraining strategy for GNNs and demonstrate its effectiveness and its ability for out-of-distribution generalization on hard transfer-learning problems.",
    "prev": "[9]).",
    "curr": "To learn graph representations, GNN-based frameworks make use of three generic modules, which provide i) feature aggregation, ii) graph pooling (i.e., readout), and iii) classification [10].",
    "next": "The feature aggregator provides a vector representation for each node of the graph, referred to as a node embedding.",
    "hard_negative": [
      6628106,
      52877454,
      3144218,
      3626819,
      3292002,
      52967399
    ],
    "easy_negative": [
      16218122,
      9191554,
      1228554
    ]
  },
  {
    "index": 1225,
    "source_corpus_id": 236635379,
    "ref_id": "b12",
    "citation_corpus_id": 1957433,
    "start": 9589,
    "end": 9613,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "As hardware grew more powerful, neural nets led to breakthroughs in image understanding (Krizhevsky et al., 2012;Zeiler & Fergus, 2014;Szegedy et al., 2015) and interest intensified: autoregressive models that could process and complete samples of handwriting were developed (Graves, 2013), and new convolutional network designs led to good results in structured output spaces like semantic segmentation (Farabet et al., 2012;Long et al., 2015;Ronneberger et al., 2015), pose estimation (Toshev & Szegedy, 2014), detection (Sermanet et al., 2014), captioning (You et al., 2016), and optical flow (Fischer et al., 2015).",
    "curr": "At the same time, natural language applications research has made extensive progressive in capturing the structured nature of language, typically via autoregressive models (Collobert et al., 2011;Sutskever et al., 2014;Vaswani et al., 2017;Radford et al., 2019;Brown et al., 2020) or context prediction (Mikolov et al., 2013;Pennington et al., 2014;Devlin et al., 2019).",
    "next": "Similar to our work, several groups have proposed to solve tasks in multiple domains (e.g.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      226284015,
      15547235,
      14864476
    ]
  },
  {
    "index": 1227,
    "source_corpus_id": 3526391,
    "ref_id": "b3",
    "citation_corpus_id": 5590763,
    "start": 3087,
    "end": 3104,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "2015.",
    "curr": "INTRODUCTION\n\nModern neural networks are known to generalize well when the training and testing data are sampled from the same distribution (Krizhevsky et al., 2012;Simonyan & Zisserman, 2015;He et al., 2016;Cho et al., 2014;Zhang et al., 2017).",
    "next": "However, when deploying neural networks in real-world applications, there is often very little control over the testing data distribution.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      16369019,
      1157837,
      14664868
    ]
  },
  {
    "index": 1229,
    "source_corpus_id": 264172668,
    "ref_id": "b46",
    "citation_corpus_id": 3626819,
    "start": 2006,
    "end": 2027,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "We release code and data at\n\nINTRODUCTION\n\nDriven by the advancements of Large Language Models (LLMs) (Brown et al., 2020;Chowdhery et al., 2022;OpenAI, 2023;Touvron et al., 2023a), a transformative wave has reshaped the landscape in multiple areas of Artificial Intelligence, elevating performance across diverse tasks.",
    "curr": "From a parametric perspective, the objective of pre-training is to encode substantial amounts of knowledge into model parameters through language modeling on extensive corpora (Peters et al., 2018;Radford et al.",
    "next": ";Devlin et al., 2019;Del\u00e9tang et al., 2023).",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      8535316,
      11336213,
      990233,
      9917468,
      20472740,
      34032948,
      10489017,
      1957433,
      1222212,
      12688069,
      15026764,
      11816014,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      8385533,
      17082127,
      13861819
    ]
  },
  {
    "index": 1230,
    "source_corpus_id": 258418258,
    "ref_id": "b5",
    "citation_corpus_id": 13807351,
    "start": 3365,
    "end": 3388,
    "title": "ENTROPY-SGD: BIASING GRADIENT DESCENT INTO WIDE VALLEYS",
    "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under certain assumptions. Our experiments on convolutional and recurrent neural networks demonstrate that Entropy-SGD compares favorably to state-of-the-art techniques in terms of generalization error and training time.",
    "prev": "The training loss landscape is complex and nonconvex with many local minima of different generalization abilities.",
    "curr": "Many studies have investigated the relationship between the loss surface's geometry and generalization performance (Hochreiter & Schmidhuber, 1994;McAllester, 1999;Keskar et al., 2017;Neyshabur et al., 2017;Jiang et al., 2020), and found that flatter minima generalize better than sharper minima (Dziugaite & Roy, 2017;Petzka et al., 2021;Chaudhari et al., 2017;Keskar et al., 2017;Jiang et al., 2020).",
    "next": "Sharpness-aware minimization (SAM) (Foret et al., 2021) is the current state-of-the-art to seek flat minima by solving a min-max optimization problem.",
    "hard_negative": [
      17272965,
      16209268,
      252796
    ],
    "easy_negative": [
      247518591,
      12084801,
      248779920
    ]
  },
  {
    "index": 1231,
    "source_corpus_id": 86840468,
    "ref_id": "b38",
    "citation_corpus_id": 26873455,
    "start": 2472,
    "end": 2492,
    "title": "Adversarial Training for Unsupervised Bilingual Lexicon Induction",
    "abstract": "Word embeddings are well known to capture linguistic regularities of the language on which they are trained. Researchers also observe that these regularities can transfer across languages. However, previous endeavors to connect separate monolingual word embeddings typically require cross-lingual signals as supervision, either in the form of parallel corpus or seed lexicon. In this work, we show that such cross-lingual connection can actually be established without any form of supervision. We achieve this end by formulating the problem as a natural adversarial game, and investigating techniques that are crucial to successful training. We carry out evaluation on the unsupervised bilingual lexicon induction task. Even though this task appears intrinsically cross-lingual, we are able to demonstrate encouraging performance without any cross-lingual clues.",
    "prev": "We present convincing results in a few visual domains, such as no-glasses to glasses, adding facial hair based on a reference image, etc.",
    "curr": "INTRODUCTION\n\nIn the problem of unsupervised domain translation, the algorithm receives two sets of samples, one from each domain, and learns a function that maps between a sample in one domain to the analogous sample in the other domain Yi et al., 2017;Benaim & Wolf, 2017;Liu & Tuzel, 2016;Liu et al., 2017;Choi et al., 2017;Conneau et al., 2017;Zhang et al., 2017a;b;Lample et al., 2018).",
    "next": "The term unsupervised means, in this context, that the two sets are unpaired.",
    "hard_negative": [
      1513472,
      17515652,
      5757459,
      1395225,
      586137,
      7185434,
      11740443,
      13603998,
      272933,
      12479653,
      16730027,
      1040556,
      874413,
      39590706,
      14656950,
      17910711,
      13888952,
      158652,
      5357629,
      18828233,
      13805769,
      5727182,
      11591887,
      12959203,
      16470894,
      931054,
      12187767,
      3084029,
      14183678,
      459519
    ],
    "easy_negative": [
      52013268,
      6947186,
      15806146
    ]
  },
  {
    "index": 1235,
    "source_corpus_id": 250089240,
    "ref_id": "b27",
    "citation_corpus_id": 213085920,
    "start": 2415,
    "end": 2419,
    "title": "Published as a conference paper at ICLR 2020 STRATEGIES FOR PRE-TRAINING GRAPH NEURAL NETWORKS",
    "abstract": "Many applications of machine learning require a model to make accurate predictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that na\u00efve strategies, which pre-train GNNs at the level of either entire graphs or individual nodes, give limited improvement and can even lead to negative transfer on many downstream tasks. In contrast, our strategy avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction. * Equal contribution. Project website, data and code: Attribute Masking Supervised Attribute Prediction Structural Similarity Prediction Structure prediction Context Prediction (b) Categorization of our pre-training methods Graph space Node space Graph embeddings Node embeddings Linear classifier Figure 1: (a.i) When only node-level pre-training is used, nodes of different shapes (semantically different nodes) can be well separated, however, node embeddings are not composable, and thus resulting graph embeddings (denoted by their classes, + and \u2212) that are created by pooling node-level embeddings are not separable. (a.ii) With graph-level pre-training only, graph embeddings are well separated, however the embeddings of individual nodes do not necessarily capture their domainspecific semantics. (a.iii) High-quality node embeddings are such that nodes of different types are well separated, while at the same time, the embedding space is also composable. This allows for accurate and robust representations of entire graphs and enables robust transfer of pre-trained models to a variety of downstream tasks. (b) Categorization of pre-training methods for GNNs. Crucially, our methods, i.e., Context Prediction, Attribute Masking, and graph-level supervised pre-training (Supervised Attribute Prediction) enable both node-level and graph-level pre-training.matter of increasing the number of labeled pre-training datasets that are from the same domain as the downstream task. Instead, it requires substantial domain expertise to carefully select examples and target labels that are correlated with the downstream task of interest. Otherwise, the transfer of knowledge from related pre-training tasks to a new downstream task can harm generalization, which is known as negative transfer(Rosenstein et al., 2005)and significantly limits the applicability and reliability of pre-trained models.Present work. Here, we focus on pre-training as an approach to transfer learning in Graph Neural Networks (GNNs)(Kipf & Welling, 2017;Hamilton et al., 2017a;Ying et al., 2018b;Xu et al., 2019;2018)for graph-level property prediction. Our work presents two key contributions.(1) We conduct the first systematic large-scale investigation of strategies for pre-training GNNs. For that, we build two large new pre-training datasets, which we share with the community: a chemistry dataset with 2 million graphs and a biology dataset with 395K graphs. We also show that large domain-specific datasets are crucial to investigate pre-training and that existing downstream benchmark datasets are too small to evaluate models in a statistically reliable way.(2) We develop an effective pretraining strategy for GNNs and demonstrate its effectiveness and its ability for out-of-distribution generalization on hard transfer-learning problems.",
    "prev": "However, the problem remains challenging due to the limited number of labeled molecules as it is in general expensive and time-consuming to label molecules, which usually requires expensive physics simulations or wet-lab experiments.",
    "curr": "As a result, recently, there has been growing interest in developing pretraining or self-supervised learning methods for learning molecular representations by leveraging the huge amount of unlabeled molecule data [28,35,63,75].",
    "next": "These methods have shown superior performance on many tasks, especially when the number of labeled molecules is insufficient.",
    "hard_negative": [
      6628106,
      52877454,
      3144218,
      3626819,
      3292002,
      52895589,
      52967399
    ],
    "easy_negative": [
      204788606,
      225075866,
      37254668
    ]
  },
  {
    "index": 1241,
    "source_corpus_id": 222291282,
    "ref_id": "b5",
    "citation_corpus_id": 1463401,
    "start": 2327,
    "end": 2346,
    "title": "HIERARCHICAL MULTISCALE RECURRENT NEURAL NETWORKS",
    "abstract": "Learning both hierarchical and temporal representation has been among the longstanding challenges of recurrent neural networks. Multiscale recurrent neural networks have been considered as a promising approach to resolve this issue, yet there has been a lack of empirical evidence showing that this type of models can actually capture the temporal dependencies by discovering the latent hierarchical structure of the sequence. In this paper, we propose a novel multiscale approach, called the hierarchical multiscale recurrent neural network, that can capture the latent hierarchical structure in the sequence by encoding the temporal dependencies with different timescales using a novel update mechanism. We show some evidence that the proposed model can discover underlying hierarchical structure in the sequences without using explicit boundary information. We evaluate our proposed model on character-level language modelling and handwriting sequence generation. * Yoshua Bengio is CIFAR Senior Fellow.",
    "prev": "The majority of these models are trained to minimize an expected loss using gradient-based optimization, so the problem of gradient estimation for discrete latent variable models has received considerable attention over recent years.",
    "curr": "Existing estimation techniques can be broadly categorized into two groups, based on whether they require one loss evaluation (Glynn, 1990;Williams, 1992;Bengio et al., 2013;Mnih & Gregor, 2014;Chung et al., 2017;Jang et al., 2017;Grathwohl et al., 2018) or multiple loss evaluations (Gu et al., 2016;Mnih & Rezende, 2016;Tucker et al., 2017) per estimate.",
    "next": "These estimators reduce variance by introducing bias or increasing the computational cost with the overall goal being to reduce the total mean squared error.",
    "hard_negative": [
      5590763,
      252796
    ],
    "easy_negative": [
      261494545,
      7636847,
      259205
    ]
  },
  {
    "index": 1249,
    "source_corpus_id": 250144478,
    "ref_id": "b32",
    "citation_corpus_id": 231632854,
    "start": 9873,
    "end": 9892,
    "title": "IN DEFENSE OF PSEUDO-LABELING: AN UNCERTAINTY-AWARE PSEUDO-LABEL SELEC- TION FRAMEWORK FOR SEMI-SUPERVISED LEARNING",
    "abstract": "The recent research in semi-supervised learning (SSL) is mostly dominated by consistency regularization based methods which achieve strong performance. However, they heavily rely on domain-specific data augmentations, which are not easy to generate for all data modalities. Pseudo-labeling (PL) is a general SSL approach that does not have this constraint but performs relatively poorly in its original formulation. We argue that PL underperforms due to the erroneous high confidence predictions from poorly calibrated models; these predictions generate many incorrect pseudo-labels, leading to noisy training. We propose an uncertainty-aware pseudo-label selection (UPS) framework which improves pseudo labeling accuracy by drastically reducing the amount of noise encountered in the training process. Furthermore, UPS generalizes the pseudo-labeling process, allowing for the creation of negative pseudo-labels; these negative pseudo-labels can be used for multi-label classification as well as negative learning to improve the single-label classification. We achieve strong performance when compared to recent SSL methods on the CIFAR-10 and CIFAR-100 datasets. Also, we demonstrate the versatility of our method on the video dataset UCF-101 and the multi-label dataset Pascal VOC.",
    "prev": "Prevailing SSL methods (Sohn et al., 2020;Berthelot et al., 2019b;a) share a similar strategy: training a model with the labeled data and generating pseudo-labels for unlabeled data based on the model predictions.",
    "curr": "Pseudo-labeling methods (Lee, 2013;Xie et al., 2020;Rizve et al., 2021) predict pseudo-labels for unlabeled data and add them to the training data for re-training.",
    "next": "Consistency-regularization methods (Sajjadi et al., 2016;Laine & Aila, 2016;Berthelot et al., 2019b) apply a random perturbation to an unlabeled image and then use the prediction as the pseudo-label of the same image under a different augmentation.",
    "hard_negative": [
      1487550,
      3162051,
      208617304,
      628455
    ],
    "easy_negative": [
      226239157,
      253258526,
      1106388
    ]
  },
  {
    "index": 1256,
    "source_corpus_id": 54462139,
    "ref_id": "b3",
    "citation_corpus_id": 53221030,
    "start": 2235,
    "end": 2251,
    "title": "JANOSSY POOLING: LEARNING DEEP PERMUTATION- INVARIANT FUNCTIONS FOR VARIABLE-SIZE INPUTS",
    "abstract": "We consider a simple and overarching representation for permutation-invariant functions of sequences (or set functions). Our approach, which we call Janossy pooling, expresses a permutation-invariant function as the average of a permutation-sensitive function applied to all reorderings of the input sequence. This allows us to leverage the rich and mature literature on permutation-sensitive functions to construct novel and flexible permutation-invariant functions. If carried out naively, Janossy pooling can be computationally prohibitive. To allow computational tractability, we consider three kinds of approximations: canonical orderings of sequences, functions with k-order interactions, and stochastic optimization algorithms with random permutations. Our framework unifies a variety of existing work in the literature, and suggests possible modeling and algorithmic extensions. We explore a few in our experiments, which demonstrate improved performance over current state-of-the-art methods.",
    "prev": "The typical approach is to compose elementwise operations with permutation-invariant reduction operations, such as summing (Zaheer et al., 2017) or taking the maximum (Qi et al., 2017) over the whole set.",
    "curr": "Since the reduction operator compresses a set of any size down to a single descriptor, this can be a significant bottleneck in what information about the set can be represented efficiently (Qi et al., 2017;Le & Duan, 2018;Anonymous, 2019).",
    "next": "We take an alternative approach based on an idea explored in Vinyals et al.",
    "hard_negative": [
      6628106,
      22191393,
      5590763
    ],
    "easy_negative": [
      250150685,
      61492637,
      220057358
    ]
  },
  {
    "index": 1258,
    "source_corpus_id": 249062882,
    "ref_id": "b56",
    "citation_corpus_id": 3432876,
    "start": 5189,
    "end": 5211,
    "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    "abstract": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",
    "prev": "In order to explore how barriers in the loss surface expose a model's generalization strategy, we will consider a variety of text classification tasks.",
    "curr": "We focus on Natural Language Inference (NLI; Williams et al., 2018;Consortium et al., 1996), as well as paraphrase and grammatical acceptability 2 IDENTIFYING GENERALIZATION STRATEGIES Finetuning on standard GLUE  datasets often leads to models that perform similarly on in-domain (ID) test sets (Sellam et al., 2021).",
    "next": "In this paper, to evaluate the functional differences between these models, we will measure generalization to OOD domains.",
    "hard_negative": [
      10202504,
      14429450,
      5555594,
      28495499,
      6628106,
      3104920,
      8495258,
      11866664,
      11262376,
      34032948,
      5471801,
      1957433,
      15978939,
      30758763,
      252796
    ],
    "easy_negative": [
      9865708,
      248006483,
      9821042
    ]
  },
  {
    "index": 1259,
    "source_corpus_id": 257834100,
    "ref_id": "b50",
    "citation_corpus_id": 57761150,
    "start": 4582,
    "end": 4602,
    "title": "REVEALING INTERPRETABLE OBJECT REPRESENTA- TIONS FROM HUMAN BEHAVIOR",
    "abstract": "To study how mental object representations are related to behavior, we estimated sparse, non-negative representations of objects using human behavioral judgments on images representative of 1,854 object categories. These representations predicted a latent similarity structure between objects, which captured most of the explainable variance in human behavioral judgments. Individual dimensions in the low-dimensional embedding were found to be highly reproducible and interpretable as conveying degrees of taxonomic membership, functionality, and perceptual attributes. We further demonstrated the predictive power of the embeddings for explaining other forms of human behavior, including categorization, typicality judgments, and feature ratings, suggesting that the dimensions reflect human conceptual representations of objects beyond the specific task.",
    "prev": "Our embedding space, induced under a novel conditional framework, not only enables the accurate prediction of face similarity, but also Psychological embeddings.",
    "curr": "Multidimensional scaling (MDS) is often used to learn psychological embeddings from human similarity judgments (Zheng et al., 2019;Roads & Love, 2021;Dima et al., 2022;Josephs et al., 2021).",
    "next": "As MDS approaches cannot embed images outside of the training set, researchers have used pretrained models as feature extractors (Sanders & Nosofsky, 2020;Peterson et al., 2018;Attarian et al., 2020), which can introduce unwanted implicit biases (Krishnakumar et al., 2021;Steed & Caliskan, 2021).",
    "hard_negative": [
      1671874,
      16173223,
      6628106,
      8348149
    ],
    "easy_negative": [
      8934190,
      15702681,
      16038645
    ]
  },
  {
    "index": 1261,
    "source_corpus_id": 229348988,
    "ref_id": "b36",
    "citation_corpus_id": 7147309,
    "start": 2309,
    "end": 2331,
    "title": "SEQUENCE LEVEL TRAINING WITH RECURRENT NEURAL NETWORKS",
    "abstract": "Many natural language processing applications use language models to generate text. These models are typically trained to predict the next word in a sequence, given the previous words and some context such as an image. However, at test time the model is expected to generate the entire sequence from scratch. This discrepancy makes generation brittle, as errors may accumulate along the way. We address this issue by proposing a novel sequence level training algorithm that directly optimizes the metric used at test time, such as BLEU or ROUGE. On three different tasks, our approach outperforms several strong baselines for greedy generation. The method is also competitive when these baselines employ beam search, while being several times faster.",
    "prev": "For instance, we may want to avoid toxic content; prevent certain demographic biases; or steer generations towards a certain topic or style.",
    "curr": "Prior work, taking inspiration from Reinforcement Learning (RL), has aimed at inducing autoregressive models to optimize global objectives using task specific rewards such as BLEU and ROUGE for Machine Translation and Summarization (Ranzato et al., 2016;Bahdanau et al., 2017), or hand crafted rewards (Li et al., 2016b;Tambwekar et al., 2019) to improve certain a priori desirable features.",
    "next": "However, such an optimization process is not infallible; Liu et al.",
    "hard_negative": [
      1391785,
      5467830,
      1318875,
      1918428,
      11212020
    ],
    "easy_negative": [
      52124316,
      64669232,
      8945340
    ]
  },
  {
    "index": 1263,
    "source_corpus_id": 211010532,
    "ref_id": "b36",
    "citation_corpus_id": 3347806,
    "start": 2681,
    "end": 2701,
    "title": "Under review as a conference paper NEURAL LANGUAGE MODELING BY JOINTLY LEARNING SYNTAX AND LEXICON",
    "abstract": "We propose a neural language model capable of unsupervised syntactic structure induction. The model leverages the structure information to form better semantic representations and better language modeling. Standard recurrent neural networks are limited by their structure and fail to efficiently use syntactic information. On the other hand, tree-structured recursive networks usually require additional structural supervision at the cost of human expert annotation. In this paper, We propose a novel neural language model, called the Parsing-Reading-Predict Networks (PRPN), that can simultaneously induce the syntactic structure from unannotated sentences and leverage the inferred structure to learn a better language model. In our model, the gradient can be directly back-propagated from the language model loss into the neural parsing network. Experiments show that the proposed model can discover the underlying syntactic structure and achieve state-of-the-art performance on word/character-level language model tasks.",
    "prev": "INTRODUCTION\n\nGrammar induction, which is closely related to unsupervised parsing and latent tree learning, allows one to associate syntactic trees, i.e., constituency and dependency trees, with sentences.",
    "curr": "As grammar induction essentially assumes no supervision from gold-standard syntactic trees, the existing approaches for this task mainly rely on unsupervised objectives, such as language modeling (Shen et al., 2018b;Kim et al., 2019a;b) and cloze-style word prediction (Drozdov et al., 2019) to train their task-oriented models.",
    "next": "On the other hand, there is a trend in the natural language processing (NLP) community of leveraging pre-trained language models (LMs), e.g., ELMo (Peters et al., 2018) and BERT (Devlin et al., 2019), as a means of acquiring contextualized word representations.",
    "hard_negative": [
      9833924,
      990233
    ],
    "easy_negative": [
      237568724,
      12224437,
      222290927
    ]
  },
  {
    "index": 1266,
    "source_corpus_id": 17611960,
    "ref_id": "b25",
    "citation_corpus_id": 14124313,
    "start": 1836,
    "end": 1863,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "1: Shattered gradients in a PL-function.",
    "curr": "& Fergus, 2014;Simonyan & Zisserman, 2015;Szegedy et al., 2015;He et al., 2015).",
    "next": "Even in convex settings, convergence for nonsmooth functions is lower-bounded by 1/ \u221a N (Bubeck, 2015).",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      226283863,
      237155090,
      235196067
    ]
  },
  {
    "index": 1267,
    "source_corpus_id": 264128411,
    "ref_id": "b26",
    "citation_corpus_id": 14091946,
    "start": 5558,
    "end": 5581,
    "title": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies",
    "abstract": "The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture's grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1% errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.",
    "prev": "COMPA BENCHMARK\n\nBackground.CompA-order evaluates an ALMs' capability to understand the order of occurrence between multiple acoustic events.CompA-attribute evaluates attribute-binding for acoustic events.The task is to choose (or retrieve) the right caption given the audio and vice-versa.More examples are in Table 4.",
    "curr": "(Levesque et al., 2012), has been earlier used for a variety of language-related tasks (Rudinger et al., 2018;Sakaguchi et al., 2021;Zhao et al., 2018).We are particularly inspired by the Winoground dataset proposed by Thrush et al.",
    "next": "(2022) built for evaluating visio-linguistic compositional reasoning.Each instance in each benchmark has two (or three) audio-caption pairs, where each audio has the same acoustic events but with a different composition (i.e., for example, different order of occurrence of the events in the audio), and each caption has the same words but with minute differences.The task of an ALM is to match the right caption with the right audio and vice-versa.",
    "hard_negative": [
      6628106,
      14099741,
      17352617,
      3925937,
      10915381,
      13313501,
      5590763,
      11212020,
      1195002
    ],
    "easy_negative": [
      18816757,
      254823156,
      67332552
    ]
  },
  {
    "index": 1271,
    "source_corpus_id": 261582259,
    "ref_id": "b16",
    "citation_corpus_id": 3568073,
    "start": 20621,
    "end": 20642,
    "title": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024 2 . We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.",
    "prev": "We use CelebA-HQ and ImageNet in our experiments.",
    "curr": "CelebA-HQ (Karras et al., 2018) is a high-quality subset of CelebA (Liu et al., 2015) which consists of 30,000 images of faces from human celebrities.",
    "next": "ImageNet (Deng et al., 2009) contains 1,281,167 images spanning 1000 different classes and is a widely-used dataset for generation and vision tasks.",
    "hard_negative": [
      18828233,
      6628106
    ],
    "easy_negative": [
      222272007,
      237563010,
      236134371
    ]
  },
  {
    "index": 1272,
    "source_corpus_id": 201657791,
    "ref_id": "b4",
    "citation_corpus_id": 62823235,
    "start": 21356,
    "end": 21359,
    "title": "Universal Stagewise Learning for Non-Convex Problems with Convergence on Averaged Solutions",
    "abstract": "Although stochastic gradient descent (SGD) method and its variants (e.g., stochastic momentum methods, ADAGRAD) are the choice of algorithms for solving nonconvex problems (especially deep learning), there still remain big gaps between the theory and the practice with many questions unresolved. For example, there is still a lack of theories of convergence for SGD and its variants that use stagewise step size and return an averaged solution in practice. In addition, theoretical insights of why adaptive step size of ADAGRAD could improve non-adaptive step size of SGD is still missing for non-convex optimization. This paper aims to address these questions and fill the gap between theory and practice. We propose a universal stagewise optimization framework for a broad family of non-smooth non-convex (namely weakly convex) problems with the following key features: (i) at each stage any suitable stochastic convex optimization algorithms (e.g., SGD or ADAGRAD) that return an averaged solution can be employed for minimizing a regularized convex problem; (ii) the step size is decreased in a stagewise manner; (iii) an averaged solution is returned as the final solution that is selected from all stagewise averaged solutions with sampling probabilities increasing as the stage number. Our theoretical results of stagewise ADAGRAD exhibit its adaptive convergence, therefore shed insights on its faster convergence for problems with sparse stochastic gradients than stagewise SGD. To the best of our knowledge, these new results are the first of their kind for addressing the unresolved issues of existing theories mentioned earlier.",
    "prev": "We aim to achieve an adaptive convergence by using PPD-AdaGrad.",
    "curr": "The analysis of PPD-AdaGrad is inspired by the analysis of AdaGrad for non-convex minimization problems [5].",
    "next": "The key difference is that we have to carefully deal with the primal-dual updates for the non-convex min-max problem.",
    "hard_negative": [
      65455367,
      6628106
    ],
    "easy_negative": [
      259370609,
      18637783,
      256461083
    ]
  },
  {
    "index": 1275,
    "source_corpus_id": 260519400,
    "ref_id": "b38",
    "citation_corpus_id": 53116133,
    "start": 3315,
    "end": 3318,
    "title": "POINCAR\u00c9 GLOVE: HYPERBOLIC WORD EMBEDDINGS",
    "abstract": "Words are not created equal. In fact, they form an aristocratic graph with a latent hierarchical structure that the next generation of unsupervised learned word embeddings should reveal. In this paper, justified by the notion of delta-hyperbolicity or tree-likeliness of a space, we propose to embed words in a Cartesian product of hyperbolic spaces which we theoretically connect to the Gaussian word embeddings and their Fisher geometry. This connection allows us to introduce a novel principled hypernymy score for word embeddings. Moreover, we adapt the well-known Glove algorithm to learn unsupervised word embeddings in this type of Riemannian manifolds. We further explain how to solve the analogy task using the Riemannian parallel transport that generalizes vector arithmetics to this new type of geometry. Empirically, based on extensive experiments, we prove that our embeddings, trained unsupervised, are the first to simultaneously outperform strong and popular baselines on the tasks of similarity, analogy and hypernymy detection. In particular, for word hypernymy, we obtain new state-of-the-art on fully unsupervised WBLESS classification accuracy. * All authors contributed equally.",
    "prev": "Compared to a flat Euclidean geometry, a hyperbolic space shows a higher embedding accuracy under fewer dimensions in such cases.",
    "curr": "Because a wide variety of real-world data encompasses some type of latent hierarchical structures [14,28,22,16], it has been empirically proven that a hyperbolic space is able to capture such intrinsic features thorough representation learning [16,8,29,39,19,2,11].",
    "next": "Motivated by such expressive characteristics, various machine learning methods, including support vector machines [7] and neural networks [9,12,25,27,6] have derived the analogous benefits from the introduction of a hyperbolic space, with an aim to improve the performance on advanced tasks beyond just representing data.",
    "hard_negative": [
      3328394,
      1957433,
      8198608,
      11730392,
      12730203,
      48360418,
      4966757,
      20269438
    ],
    "easy_negative": [
      2652169,
      17106591,
      219307644
    ]
  },
  {
    "index": 1276,
    "source_corpus_id": 264590778,
    "ref_id": "b13",
    "citation_corpus_id": 221878771,
    "start": 2185,
    "end": 2206,
    "title": "REALTOXICITYPROMPTS: Evaluating Neural Toxic Degeneration in Language Models",
    "abstract": "Pretrained neural language models (LMs) are prone to generating racist, sexist, or otherwise toxic language which hinders their safe deployment. We investigate the extent to which pretrained LMs can be prompted to generate toxic language, and the effectiveness of controllable text generation algorithms at preventing such toxic degeneration. We create and release RE-ALTOXICITYPROMPTS, a dataset of 100K naturally occurring, sentence-level prompts derived from a large corpus of English web text, paired with toxicity scores from a widelyused toxicity classifier. Using REALTOXICI-TYPROMPTS, we find that pretrained LMs can degenerate into toxic text even from seemingly innocuous prompts. We empirically assess several controllable generation methods, and find that while data-or compute-intensive methods (e.g., adaptive pretraining on non-toxic data) are more effective at steering away from toxicity than simpler solutions (e.g., banning \"bad\" words), no current method is failsafe against neural toxic degeneration. To pinpoint the potential cause of such persistent toxic degeneration, we analyze two web text corpora used to pretrain several LMs (including GPT-2;Radford et al., 2019), and find a significant amount of offensive, factually unreliable, and otherwise toxic content. Our work provides a test bed for evaluating toxic generations by LMs and stresses the need for better data selection processes for pretraining.",
    "prev": "INTRODUCTION\n\n\"We want AI agents that can discover like we can, not which contain what we have discovered.\"",
    "curr": "--Prof.Richard Sutton, The Bitter Lesson, 2019\n\nBy virtue of their ability to \"predict the next token(s)\", contemporary pre-trained language models (LMs) have shown remarkable proficiency in memorizing extensive corpora, thereby enabling the generation of text indistinguishable from human-produced content (Brown et al., 2020).However, successful memorization of human knowledge does not assure a model's propensity to perform as per societal expectations.Recent research has exposed behavioral anomalies in these LMs (Weidinger et al., 2022), which include the generation of harmful content (Gehman et al., 2020;Bommasani et al., 2021), the reinforcement of bias (Venkit et al., 2022;Liu et al., 2022), and the dissemination of disinformation (Tamkin et al., 2021;Lin et al., 2022).This process of enhancing desirable societal behaviors and inhibiting undesirable ones is commonly referred to as \"social alignment\" (Gabriel, 2020;Taylor et al., 2016).",
    "next": "Supervised Fine-Tuning (SFT) presents a straightforward method for achieving alignment by training LMs using socially aligned data (Figure 1 [a]).However, this method often yields models susceptible to adversarial attacks, like \"jailbreaking prompting\" (Subhash, 2023;Xu et al., 2021), due to limited exposure to misaligned data during training (Amodei et al., 2016).To address this, a more advanced technique, \"reward modeling\" has been proposed (Leike et al., 2018;Christiano et al., 2017).This involves training a reward model as a surrogate for human judgment to guide the optimization of the LM (e.g., OpenAI's RLHF, Figure 1 [b]).However, it is crucial",
    "hard_negative": [
      201682311,
      21731209,
      225075985,
      218487466,
      218971825,
      201666620,
      687037,
      52917952,
      102352962,
      202895301,
      52255687,
      11054023,
      202235596,
      202778702,
      202537041,
      201698258,
      121125604,
      52967399,
      190000105,
      207853290,
      1066490
    ],
    "easy_negative": [
      259223256,
      14681834,
      1263312
    ]
  },
  {
    "index": 1277,
    "source_corpus_id": 240288910,
    "ref_id": "b15",
    "citation_corpus_id": 227209335,
    "start": 2190,
    "end": 2208,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "Introduction\n\nModern unsupervised representation learning techniques can generate images of our world with intricate detail (e.g.",
    "curr": "Karras et al., 2019;Song et al., 2020;Razavi et al., 2019), and yet, the latent representations from which these images are generated remain entangled and challenging to interpret (Sch\u00f6lkopf et al., 2021;Locatello et al., 2019).",
    "next": "At the same time, the success of pre-trained of transformers (Devlin et al., 2018;Brown et al., 2020) shows that advances in our ability to disentangle the underlying generative factors can lead to dramatic improvements in the sample complexity of downstream supervised tasks (Bengio & LeCun, 2007;Bengio et al., 2013).",
    "hard_negative": [
      52908831,
      52889459
    ],
    "easy_negative": [
      245123905,
      6329764,
      198185049
    ]
  },
  {
    "index": 1293,
    "source_corpus_id": 252992725,
    "ref_id": "b13",
    "citation_corpus_id": 237347130,
    "start": 32925,
    "end": 32945,
    "title": "Published as a conference paper at ICLR 2022 TRAIN SHORT, TEST LONG: ATTENTION WITH LINEAR BIASES ENABLES INPUT LENGTH EXTRAPOLATION",
    "abstract": "Since the introduction of the transformer model byVaswani et al. (2017), a fundamental question has yet to be answered: how does a model achieve extrapolation at inference time for sequences that are longer than it saw during training? We first show that extrapolation can be enabled by simply changing the position representation method, though we find that current methods do not allow for efficient extrapolation. We therefore introduce a simpler and more efficient position method, Attention with Linear Biases (ALiBi). ALiBi does not add positional embeddings to word embeddings; instead, it biases query-key attention scores with a penalty that is proportional to their distance. We show that this method trains a 1.3 billion parameter model on input sequences of length 1024 that extrapolates to input sequences of length 2048, achieving the same perplexity as a sinusoidal position embedding model trained on inputs of length 2048 but training 11% faster and using 11% less memory. ALiBi's inductive bias towards recency also leads it to outperform multiple strong position methods on the WikiText-103 benchmark. 1 1 Code & models: https://github.com/ofirpress/attention_with_linear_biases 2Figure 7in the appendix plots training speed, in words per second, against L.",
    "prev": "Using a combination of scratchpad (a.k.a.",
    "curr": "\"chain-of-thought\") (Nye et al., 2021, Wei et al., 2022 and recency bias (Press et al., 2022), we demonstrate that Transformers can be guided towards learning recurrent (depth-T ) solutions, which generalize outof-distribution and to longer sequence lengths (Figure 7, yellow curves).",
    "next": "Details are deferred to Section B.2.3.",
    "hard_negative": [
      207930593,
      7443908,
      211483460,
      207870430,
      52967399,
      207853045,
      3725815,
      207880568,
      229924221
    ],
    "easy_negative": [
      1440142,
      7739417,
      218973989
    ]
  },
  {
    "index": 1297,
    "source_corpus_id": 251564473,
    "ref_id": "b29",
    "citation_corpus_id": 215238853,
    "start": 3593,
    "end": 3610,
    "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices",
    "abstract": "Natural Language Processing (NLP) has recently achieved great success by using huge pre-trained models with hundreds of millions of parameters. However, these models suffer from heavy model sizes and high latency such that they cannot be deployed to resourcelimited mobile devices. In this paper, we propose MobileBERT for compressing and accelerating the popular BERT model. Like the original BERT, MobileBERT is task-agnostic, that is, it can be generically applied to various downstream NLP tasks via simple fine-tuning. Basically, MobileBERT is a thin version of BERT LARGE , while equipped with bottleneck structures and a carefully designed balance between self-attentions and feed-forward networks. To train MobileBERT, we first train a specially designed teacher model, an invertedbottleneck incorporated BERT LARGE model. Then, we conduct knowledge transfer from this teacher to MobileBERT. Empirical studies show that MobileBERT is 4.3\u00d7 smaller and 5.5\u00d7 faster than BERT BASE while achieving competitive results on well-known benchmarks. On the natural language inference tasks of GLUE, MobileBERT achieves a GLUE score of 77.7 (0.6 lower than BERT BASE ), and 62 ms latency on a Pixel 4 phone. On the SQuAD v1.1/v2.0 question answering task, MobileBERT achieves a dev F1 score of 90.0/79.2 (1.5/2.1 higher than BERT BASE ).",
    "prev": "This ignores potentially useful internal representations which can also be levered for knowledge transfer.",
    "curr": "Various extensions have been proposed in the literature along these lines (see, e.g., [Sun et al., 2020, Aguilar et al., 2020, Li et al., 2019, Sun et al., 2019 and references therein).",
    "next": "However, despite their success, most use the teacher model in a black-box manner, and do not fully utilize the domain understanding it contains [Cho andHariharan, 2019, Stanton et al., 2021].",
    "hard_negative": [
      16639476,
      990233,
      195477534
    ],
    "easy_negative": [
      235446427,
      233365106,
      1963942
    ]
  },
  {
    "index": 1299,
    "source_corpus_id": 220127956,
    "ref_id": "b28",
    "citation_corpus_id": 14124313,
    "start": 23613,
    "end": 23617,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "In particular, we desire to understand, if the insights gained from experiments on smaller networks can be generalized to more complex networks and datasets.",
    "curr": "Understanding Influence Functions in Deep Architectures\n\nSetup: In this section, we evaluate the accuracy of influence estimates using MNIST [21] and CIFAR-10 [22] datasets across different network architectures including small CNN [3], LeNet [27], ResNet-18, ResNet-50 [28], VGG-13 and VGG-14 [29] 4 .",
    "next": "To compute influence estimates, we choose two test points for each architecture: a) the test-point with the highest loss, and b) the test-point at the 50 th percentile of the losses of all test points.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      12338312,
      216804955,
      17711681
    ]
  },
  {
    "index": 1301,
    "source_corpus_id": 108300988,
    "ref_id": "b32",
    "citation_corpus_id": 1957433,
    "start": 1415,
    "end": 1439,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.",
    "curr": "INTRODUCTION 1\n\nPretrained word embeddings (Mikolov et al., 2013;Pennington et al., 2014) are a staple tool for NLP.",
    "next": "These models provide continuous representations for word types, typically learned from cooccurrence statistics on unlabeled data, and improve generalization of downstream models across many domains.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      252624648,
      253762046,
      237453540
    ]
  },
  {
    "index": 1307,
    "source_corpus_id": 237581512,
    "ref_id": "b15",
    "citation_corpus_id": 3292002,
    "start": 35221,
    "end": 35246,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "In GCN, AGGREGATE is implemented as weighted average with respect to the inverse of square root of node degrees:\nh k i = \u03c3 W k j\u2208N (i)\u222a{i} \u03b1 ij h k\u22121 j ,(6)\nwhere W k is a learnable matrix, \u03b1 ij = 1/ |N (i)| \u00b7 |N (j)|, and \u03c3 is activation function.",
    "curr": "Graph Attention Networks (GAT) (Veli\u010dkovi\u0107 et al., 2018).",
    "next": "In GAT, AGGREGATE is implemented as multi-head self-attention:\nh k i = S s=1 \u03c3 W k,s j\u2208N (i)\u222a{i} SOFTMAX \u03b1 k,s ij h k\u22121 j ,(7)\nwhere \u03b1 k,s ij = LeakyReLU w k,s W k,s h k i W k,s h k j is (unnormalized) attention weight, w is a learnable vector, denotes concatenate operation, and S is the number of attention heads.",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      16406435,
      27191574,
      16060349
    ]
  },
  {
    "index": 1312,
    "source_corpus_id": 53327717,
    "ref_id": "b25",
    "citation_corpus_id": 14124313,
    "start": 2784,
    "end": 2811,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "However, there is no analogous result of practical interest for the non-convex optimization problem of a deep neural network.",
    "curr": "An illustration of this issue is the diversity of learning rate schedules used to train deep convolutional networks with SGD: Simonyan & Zisserman (2015) and He et al.",
    "next": "(2016) adapt the learning rate according to the validation performance, while Szegedy et al.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      13053999,
      199379619,
      44144456
    ]
  },
  {
    "index": 1315,
    "source_corpus_id": 249191952,
    "ref_id": "b83",
    "citation_corpus_id": 236477395,
    "start": 2139,
    "end": 2142,
    "title": "Unsupervised Energy-based Adversarial Domain Adaptation for Cross-domain Text Classification",
    "abstract": "Transferring knowledge from a label-rich domain (source domain) to a label-scarce domain (target domain) for pervasive cross-domain Text Classification (TC) is a non-trivial task. To overcome this issue, we propose EADA, a novel unsupervised energy-based adversarial domain adaptation framework. First, a deep pre-trained language model (e.g. RoBERTa) is leveraged as a shared feature extractor that maps the text sequences from both source and target domains to a feature space. Since the source features maintain good feature discriminability because of the full supervised training, we design a method that encourages target features towards the source ones via adversarial learning. An autoencoder is designed as an energy function that focuses on reconstructing source feature embeddings, while the feature extractor aims to generate source-like target feature embeddings to deceive the autoencoder. In this manner, the target feature embeddings become domain-invariant and inherit great discriminability. Extensive experiments on multidomain sentiment classification (Amazon review dataset) and Yes/No question-answering classification (BoolQ and MARCO dataset) are conducted. The experimental results validate that EADA largely alleviates the domain discrepancy while maintaining excellent discriminability and achieves state-of-the-art cross-domain TC performance.",
    "prev": "Extensive experiments demonstrate BETA outperforms existing methods on all DABP benchmarks, and is even comparable with the standard domain adaptation methods that use the source-domain data.",
    "curr": "Introduction\n\nUnsupervised domain adaptation (UDA) [19,47,59,85] aims to transfer knowledge from a labeled source domain to an unlabeled target domain and has wide applications [66,26,84,81].",
    "next": "However, UDA methods require to access the source-domain data, thus raising concerns about data privacy and portability issues.",
    "hard_negative": [
      52178689,
      3282953,
      51879969,
      204800552,
      5034059,
      9387600,
      201666897,
      165163607,
      15876696,
      52967399,
      52176498
    ],
    "easy_negative": [
      248780111,
      16092889,
      8467680
    ]
  },
  {
    "index": 1318,
    "source_corpus_id": 249712407,
    "ref_id": "b2",
    "citation_corpus_id": 239050418,
    "start": 2555,
    "end": 2558,
    "title": "A FINE-GRAINED ANALYSIS ON DISTRIBUTION SHIFT",
    "abstract": "Robustness to distribution shifts is critical for deploying machine learning models in the real world. Despite this necessity, there has been little work in defining the underlying mechanisms that cause these shifts and evaluating the robustness of algorithms across multiple, different distribution shifts. To this end, we introduce a framework that enables fine-grained analysis of various distribution shifts. We provide a holistic analysis of current state-of-the-art methods by evaluating 19 distinct methods grouped into five categories across both synthetic and real-world datasets. Overall, we train more than 85K models. Our experimental framework can be easily extended to include new methods, shifts, and datasets. We find, unlike previous work (Gulrajani & Lopez-Paz, 2021), that progress has been made over a standard ERM baseline; in particular, pretraining and augmentations (learned or heuristic) offer large gains in many cases. However, the best methods are not consistent over different datasets and shifts. . Model-agnostic meta-learning for fast adaptation of deep networks. In . Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness. In Achieving robustness in the wild via adversarial mixing with disentangled representations. In",
    "prev": "Given data from multiple domains that share a common optimal predictor, the domain generalization (DG) task [1,2] encapsulates this challenge by evaluating accuracy on an unseen domain.",
    "curr": "Recent empirical studies of DG algorithms [3,4] have characterized different kinds of distribution shifts across domains.",
    "next": "Using MNIST as an example, a diversity shift is when domains are created either by adding new values of a spurious attribute like rotation (e.g., Rotated-MNIST dataset [5,6]) whereas a correlation shift is when domains exhibit different values of correlation between the class label and a spurious attribute like color (e.g., Colored-MNIST [7]).",
    "hard_negative": [
      236087592,
      208193111
    ],
    "easy_negative": [
      14855303,
      1278819,
      2689789
    ]
  },
  {
    "index": 1324,
    "source_corpus_id": 248811614,
    "ref_id": "b19",
    "citation_corpus_id": 13123084,
    "start": 2790,
    "end": 2810,
    "title": "Published as a conference paper at ICLR 2017 TEMPORAL ENSEMBLING FOR SEMI-SUPERVISED LEARNING",
    "abstract": "In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels.",
    "prev": "To alleviate such reliance, semi-supervised learning (SSL) (Zhu, 2005;Zhu & Goldberg, 2009;Sohn et al., 2020;Rosenberg et al., 2005;Gong et al., 2016;Kervadec et al., 2019;Dai et al., 2017) is developed to improve the model's generalization performance by exploiting a large volume of unlabeled data.",
    "curr": "Pseudo labeling (Lee et al., 2013;Xie et al., 2020b;McLachlan, 1975;Rizve et al., 2020) and consistency regularization (Bachman et al., 2014;Samuli & Timo, 2017;Sajjadi et al., 2016) are two popular paradigms designed for modern SSL.",
    "next": "Recently, their combinations have shown promising results (Xie et al., 2020a;Sohn et al., 2020;Pham et al., 2021;Xu et al., 2021;Zhang et al., 2021).",
    "hard_negative": [
      1965764,
      2780493,
      6230637,
      9398766,
      1487550
    ],
    "easy_negative": [
      259095910,
      237385483,
      815719
    ]
  },
  {
    "index": 1338,
    "source_corpus_id": 221878944,
    "ref_id": "b34",
    "citation_corpus_id": 208547770,
    "start": 3802,
    "end": 3828,
    "title": "DEEP LEARNING FOR SYMBOLIC MATHEMATICS",
    "abstract": "Neural networks have a reputation for being better at solving statistical or approximate problems than at performing calculations or working with symbolic data. In this paper, we show that they can be surprisingly good at more elaborated tasks in mathematics, such as symbolic integration and solving differential equations. We propose a syntax for representing mathematical problems, and methods for generating large datasets that can be used to train sequence-to-sequence models. We achieve results that outperform commercial Computer Algebra Systems such as Matlab or Mathematica. * Equal contribution.",
    "prev": "multilayer perceptrons (MLPs), fail to extrapolate well when learning simple polynomial functions [Haley andSoloway, 1992, Barnard andWessels, 1992].",
    "curr": "However, recent works show Graph Neural Networks (GNNs) [Scarselli et al., 2009], a class of structured networks with MLP building blocks, can be successful in more challenging tasks, such as predicting the time evolution of physical systems [Battaglia et al., 2016], solving mathematical equations [Lample and Charton, 2020], and learning graph algorithms [Velickovic et al., 2020].",
    "next": "In these tasks, GNNs can generalize to graphs larger than those in the training set.",
    "hard_negative": [
      14298291,
      3033526,
      11212020,
      14519034
    ],
    "easy_negative": [
      208547755,
      24355028,
      231839865
    ]
  },
  {
    "index": 1352,
    "source_corpus_id": 258865613,
    "ref_id": "b25",
    "citation_corpus_id": 5378837,
    "start": 2060,
    "end": 2086,
    "title": "Observed versus latent features for knowledge base and text inference",
    "abstract": "In this paper we show the surprising effectiveness of a simple observed features model in comparison to latent feature models on two benchmark knowledge base completion datasets, FB15K and WN18. We also compare latent and observed feature models on a more challenging dataset derived from FB15K, and additionally coupled with textual mentions from a web-scale corpus. We show that the observed features model is most effective at capturing the information present for entity pairs with textual relations, and a combination of the two combines the strengths of both model types.",
    "prev": "of queries investigated previously and precisely identifying the gap between its formulation and its goal, as well as providing complexity analysis for the currently investigated queries.Moreover, we develop a new dataset containing ten new types of queries with features that have never been considered and therefore can provide a thorough investigation of complex queries.Finally, we propose a new neural-symbolic method, Fuzzy Inference with Truth value (FIT), where we equip the neural link predictors with fuzzy logic theory to support end-to-end learning using complex queries with provable reasoning capability.Empirical results show that our method outperforms previous methods significantly in the new dataset and also surpasses previous methods in the existing dataset at the same time.",
    "curr": "Introduction\n\nKnowledge graph (KG) is a mighty knowledge base that encodes relational knowledge into a graph representation.However, due to the fact that modern knowledge graphs are often autogenerated [Toutanova and Chen, 2015] or constructed by crowd-sourcing [Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014], they are considered noisy and incomplete, which is also known as the Open World Assumption (OWA) [Libkin and Sirangelo, 2009].Complex query answering (CQA) on knowledge graphs is a practical task that can support many applications [Ren et al., 2023a, Wang et al., 2022].The CQA task requires answering the existential first order logic formula, which is one family of the logical formula involving logical operators, conjunction (\u2227), disjunction (\u2228), and negation (\u00ac), as well as the existential quantifier \u2203.In particular, as CQA is based on KGs that are with OWA, it should perform reasoning, which utilizes available knowledge to produce the prediction of the missing one where traditional traversal methods are doomed to fail [Ren et al., 2020].",
    "next": "To tackle this challenge, the query embedding method has been proposed [Hamilton et al., 2018], which aims to represent a set of entities by a low dimensional embedding.In addition to",
    "hard_negative": [
      1619841,
      2768038,
      1077128,
      3814153,
      5679499,
      577805,
      2687019
    ],
    "easy_negative": [
      259841016,
      18768582,
      252199965
    ]
  },
  {
    "index": 1360,
    "source_corpus_id": 58004637,
    "ref_id": "b10",
    "citation_corpus_id": 2863491,
    "start": 4116,
    "end": 4134,
    "title": "On Using Very Large Target Vocabulary for Neural Machine Translation",
    "abstract": "Neural machine translation, a recently proposed approach to machine translation based purely on neural networks, has shown promising results compared to the existing approaches such as phrasebased statistical machine translation. Despite its recent success, neural machine translation has its limitation in handling a larger vocabulary, as training complexity as well as decoding complexity increase proportionally to the number of target words. In this paper, we propose a method based on importance sampling that allows us to use a very large target vocabulary without increasing training complexity. We show that decoding can be efficiently done even with the model having a very large target vocabulary by selecting only a small subset of the whole target vocabulary. The models trained by the proposed approach are empirically found to match, and in some cases outperform, the baseline models with a small vocabulary as well as the LSTM-based neural machine translation models. Furthermore, when we use an ensemble of a few models with very large target vocabularies, we achieve performance comparable to the state of the art (measured by BLEU) on both the English\u2192German and English\u2192French translation tasks of WMT'14.",
    "prev": "Still, these algorithms suffer from high learning variance and poor sample complexity.",
    "curr": "INTRODUCTION\n\nEnd-to-end supervised learning with deep neural networks (DNNs) has taken the stage in the past few years, achieving state-of-the-art performance in multiple domains including computer vision (Szegedy et al., 2017), natural language processing (Sutskever et al., 2014;Jean et al., 2015), and speech recognition (Xiong et al., 2016).",
    "next": "Many of the tasks addressed by DNNs can be naturally decomposed to a series of functions.",
    "hard_negative": [
      9709731,
      5590763,
      8884845,
      8476273,
      6605459,
      11336213,
      12639289,
      5959482,
      13559036
    ],
    "easy_negative": [
      204788776,
      252365096,
      681862
    ]
  },
  {
    "index": 1362,
    "source_corpus_id": 246823327,
    "ref_id": "b7",
    "citation_corpus_id": 207852415,
    "start": 2669,
    "end": 2694,
    "title": "Published as a conference paper at ICLR 2020 ON THE RELATIONSHIP BETWEEN SELF-ATTENTION AND CONVOLUTIONAL LAYERS",
    "abstract": "Recent trends of incorporating attention mechanisms in vision have led researchers to reconsider the supremacy of convolutional layers as a primary building block. Beyond helping CNNs to handle long-range dependencies,Ramachandran et al. (2019)showed that attention can completely replace convolution and achieve state-of-the-art performance on vision tasks. This raises the question: do learned attention layers operate similarly to convolutional layers? This work provides evidence that attention layers can perform convolution and, indeed, they often learn to do so in practice. Specifically, we prove that a multi-head self-attention layer with sufficient number of heads is at least as expressive as any convolutional layer. Our numerical experiments then show that self-attention layers attend to pixel-grid patterns similarly to CNN layers, corroborating our analysis. Our code is publicly available 1 .Published as a conference paper at ICLR 2020Contributions. In this work, we put forth theoretical and empirical evidence that self-attention layers can (and do) learn to behave similar to convolutional layers: I. From a theoretical perspective, we provide a constructive proof showing that self-attention layers can express any convolutional layers. Specifically, we show that a single multi-head self-attention layer using relative positional encoding can be re-parametrized to express any convolutional layer.II. Our experiments show that the first few layers of attention-only architectures (Ramachandran et al., 2019) do learn to attend on grid-like pattern around each query pixel, similar to our theoretical construction.Strikingly, this behavior is confirmed both for our quadratic encoding, but also for relative encoding that is learned. Our results seem to suggest that localized convolution is the right inductive bias for the first few layers of an image classifying network. We provide an interactive website 2 to explore how self-attention exploits localized position-based attention in lower layers and contentbased attention in deeper layers. For reproducibility purposes, our code is publicly available.",
    "prev": "From the perspective of convolutional neural networks (CNNs), MSAs are a transformation of all feature map points with large-sized and data-specific kernels.",
    "curr": "Therefore, MSAs are at least as expressive as convolutional layers (Convs) (Cordonnier et al., 2020), although this does not guarantee that MSAs will behave like Convs.",
    "next": "Is the weak inductive bias of MSA, such as modeling long-range dependencies, beneficial for the predictive performance?",
    "hard_negative": [
      9672033,
      11212020,
      3433237
    ],
    "easy_negative": [
      174797795,
      233289793,
      226262388
    ]
  },
  {
    "index": 1363,
    "source_corpus_id": 248496446,
    "ref_id": "b10",
    "citation_corpus_id": 232417873,
    "start": 10241,
    "end": 10257,
    "title": "GROUNDING PHYSICAL CONCEPTS OF OBJECTS AND EVENTS THROUGH DYNAMIC VISUAL REASONING",
    "abstract": "We study the problem of dynamic visual reasoning on raw videos. This is a challenging problem; currently, state-of-the-art models often require dense supervision on physical object properties and events from simulation, which are impractical to obtain in real life. In this paper, we present the Dynamic Concept Learner (DCL), a unified framework that grounds physical objects and events from dynamic scenes and language. DCL first adopts a trajectory extractor to track each object over time and to represent it as a latent, object-centric feature vector. Building upon this object-centric representation, DCL learns to approximate the dynamic interaction among objects using graph networks. DCL further incorporates a semantic parser to parse question into semantic programs and, finally, a program executor to run the program to answer the question, levering the learned dynamics model. After training, DCL can detect and associate objects across the frames, ground visual properties and physical events, understand the causal relationship between events, make future and counterfactual predictions, and leverage these extracted presentations for answering queries. DCL achieves state-of-the-art performance on CLEVRER, a challenging causal video reasoning dataset, even without using ground-truth attributes and collision labels from simulations for training. We further test DCL on a newly proposed video-retrieval and event localization dataset derived from CLEVRER, showing its strong generalization capacity.",
    "prev": "Our work is also related to answering questions about visual content.",
    "curr": "Various benchmarks have been proposed to handle the tasks of cross-modal learning (Lei et al., 2018;Chen et al., 2019;Li et al., 2020;Wu et al., 2021;Hong et al., 2022).",
    "next": "However, they mainly focus on understanding human actions and activities rather than learning physical events and properties, which is essential for robot planning and control.",
    "hard_negative": [
      3728944,
      108296442
    ],
    "easy_negative": [
      226283897,
      2171449,
      17084584
    ]
  },
  {
    "index": 1370,
    "source_corpus_id": 53841789,
    "ref_id": "b18",
    "citation_corpus_id": 3463260,
    "start": 1386,
    "end": 1407,
    "title": "Published as a conference paper at ICLR 2018 DISTRIBUTED PRIORITIZED EXPERIENCE REPLAY",
    "abstract": "We propose a distributed architecture for deep reinforcement learning at scale, that enables agents to learn effectively from orders of magnitude more data than previously possible. The algorithm decouples acting from learning: the actors interact with their own instances of the environment by selecting actions according to a shared neural network, and accumulate the resulting experience in a shared experience replay memory; the learner replays samples of experience and updates the neural network. The architecture relies on prioritized experience replay to focus only on the most significant data generated by the actors. Our architecture substantially improves the state of the art on the Arcade Learning Environment, achieving better final performance in a fraction of the wall-clock training time.",
    "prev": "We demonstrate the efficacy of our agent to learn, in an unsupervised manner, to reach a diverse set of goals on three domains -Atari, the DeepMind Control Suite and DeepMind Lab.",
    "curr": "INTRODUCTION\n\nCurrently, the best performing methods on many reinforcement learning benchmark problems combine model-free reinforcement learning methods with policies represented using deep neural networks (Horgan et al., 2018;Espeholt et al., 2018).",
    "next": "Despite reaching or surpassing human-level performance on many challenging tasks, deep model-free reinforcement learning methods that learn purely from the reward signal learn in a way that differs greatly from the manner in which humans learn.",
    "hard_negative": [
      1163588,
      14717992
    ],
    "easy_negative": [
      51929842,
      10697066,
      5961171
    ]
  },
  {
    "index": 1384,
    "source_corpus_id": 52979229,
    "ref_id": "b31",
    "citation_corpus_id": 14124313,
    "start": 1621,
    "end": 1648,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "* These authors contributed equally.",
    "curr": "Introduction\n\nState-of-the-art vision and image-based tasks such as image classification (Krizhevsky et al., 2012;Simonyan & Zisserman, 2015;He et al., 2016), object detection (Ren et al., 2017; and segmentation (Long et al., 2015) are all built upon deep convolutional neural networks (CNNs).",
    "next": "While CNN architectures have evolved to become more efficient, the general trend has been to use larger models with greater memory and compute requirements to achieve higher accuracy.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      233429872,
      16882050,
      13525347
    ]
  },
  {
    "index": 1392,
    "source_corpus_id": 258823075,
    "ref_id": "b69",
    "citation_corpus_id": 227209335,
    "start": 2675,
    "end": 2678,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "e.For the implementations we approximate the gradient of the sliced MMD by using only a finite number P of slices.We show that the resulting error has complexity O( d/P ), where d is the data dimension.These results enable us to train generative models by approximating MMD gradient flows by neural networks even for image applications.We demonstrate the efficiency of our model by image generation on MNIST, FashionMNIST and CIFAR10.",
    "curr": "Introduction\n\nWith the rise of generative models, the field of gradient flows in measure spaces received increasing attention.Based on classical Markov chain Monte Carlo methods, Welling and Teh [80] proposed to apply the Langevin dynamics for inferring samples from a known probability density function.This corresponds to simulating a Wasserstein gradient flow with respect to the Kullback-Leibler divergence, see [38].Closely related to this approach are current state-of-the-art image generation methods like score-based models [68,69] or diffusion models [36,70], which significantly outperform classical generative models like GANs [27] or VAEs [41].A general aim of such algorithms [5,36,81] is to establish a path between input and target distribution, where \"unseen\" data points are established via the randomness of the input distribution.",
    "next": "For approximating gradient flows with respect to other functionals than the KL divergence, the authors of [1,2,15,23,55] proposed the use of suitable forward and backward discretizations.To   reduce the computational effort of evaluating distance measures on high-dimensional probability distributions, the sliced Wasserstein metric was introduced in [65].The main idea of the sliced Wasserstein distance is to compare one-dimensional projections of the corresponding probability distributions instead of the distributions themselves.This approach can be generalized to more general probability metrics [44] and was applied in the context of Wasserstein gradient flows in [13,52].",
    "hard_negative": [
      52889459,
      52908831
    ],
    "easy_negative": [
      233231453,
      2910396,
      44232537
    ]
  },
  {
    "index": 1393,
    "source_corpus_id": 256390009,
    "ref_id": "b3",
    "citation_corpus_id": 52889459,
    "start": 25351,
    "end": 25371,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "Since there has been lack of studies that explored the minority-focused generation in the unconditional setting as ours (see related work in Section 1 for details), we consider three generic frameworks that are widely adopted in literature.",
    "curr": "The first two baselines are GAN-based frameworks, BigGAN (Brock et al., 2019) and StyleGAN .",
    "next": "The third baseline, which is our main interest for comparison, is a diffusion-based generative model, DDPM (Ho et al., 2020) with the standard sampler (3).",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      252735240,
      219299723,
      102350787
    ]
  },
  {
    "index": 1396,
    "source_corpus_id": 257636556,
    "ref_id": "b16",
    "citation_corpus_id": 231979542,
    "start": 7024,
    "end": 7027,
    "title": "Published as a conference paper at ICLR 2021 EFFECTIVE AND EFFICIENT VOTE ATTACK ON CAP- SULE NETWORKS",
    "abstract": "Standard Convolutional Neural Networks (CNNs) can be easily fooled by images with small quasi-imperceptible artificial perturbations. As alternatives to CNNs, the recently proposed Capsule Networks (CapsNets) are shown to be more robust to white-box attack than CNNs under popular attack protocols. Besides, the class-conditional reconstruction part of CapsNets is also used to detect adversarial examples. In this work, we investigate the adversarial robustness of CapsNets, especially how the inner workings of CapsNets change when the output capsules are attacked. The first observation is that adversarial examples misled CapsNets by manipulating the votes from primary capsules. Another observation is the high computational cost, when we directly apply multi-step attack methods designed for CNNs to attack CapsNets, due to the computationally expensive routing mechanism. Motivated by these two observations, we propose a novel vote attack where we attack votes of CapsNets directly. Our vote attack is not only effective but also efficient by circumventing the routing process. Furthermore, we integrate our vote attack into the detection-aware attack paradigm, which can successfully bypass the class-conditional reconstruction based detection method. Extensive experiments demonstrate the superior attack performance of our vote attack on CapsNets.",
    "prev": "The previous works of attack on semantic segmentation models have been focused on the adversarial attack [64,14,25,2,19].",
    "curr": "The works [51,17,61] have demonstrated that various deep neural networks (DNNs) can be misled by adversarial examples with small imperceptible perturbations.",
    "next": "The works [14,64] extended adversarial examples to semantic segmentation.",
    "hard_negative": [
      211082896,
      14124313,
      1257772,
      3488815,
      208193111,
      195820512,
      6706414
    ],
    "easy_negative": [
      18657858,
      52012819,
      247447305
    ]
  },
  {
    "index": 1402,
    "source_corpus_id": 243756979,
    "ref_id": "b42",
    "citation_corpus_id": 212859361,
    "start": 2753,
    "end": 2772,
    "title": "DROPEDGE: TOWARDS DEEP GRAPH CONVOLU- TIONAL NETWORKS ON NODE CLASSIFICATION",
    "abstract": "Over-fitting and over-smoothing are two main obstacles of developing deep Graph Convolutional Networks (GCNs) for node classification. In particular, over-fitting weakens the generalization ability on small dataset, while over-smoothing impedes model training by isolating output representations from the input features with the increase in network depth. This paper proposes DropEdge, a novel and flexible technique to alleviate both issues. At its core, DropEdge randomly removes a certain number of edges from the input graph at each training epoch, acting like a data augmenter and also a message passing reducer. Furthermore, we theoretically demonstrate that DropEdge either reduces the convergence speed of over-smoothing or relieves the information loss caused by it. More importantly, our DropEdge is a general skill that can be equipped with many other backbone models (e.g. GCN, ResGCN, GraphSAGE, and JKNet) for enhanced performance. Extensive experiments on several benchmarks verify that DropEdge consistently improves the performance on a variety of both shallow and deep GCNs. The effect of DropEdge on preventing over-smoothing is empirically visualized and validated as well. Codes are released on https://github.com/DropEdge/DropEdge.",
    "prev": "INTRODUCTION\n\nGraphs provide a powerful abstraction for complex datasets that arise in a variety of applications such as social networks, transportation networks, and biological sciences (Hamilton et al., 2017;Derrow-Pinion et al., 2021;Zitnik & Leskovec, 2017;Chanussot et al., 2021).",
    "curr": "Despite recent advances in graph neural networks (GNNs), when trained with supervised data alone, these networks can easily overfit and may fail to generalize (Rong et al., 2019).",
    "next": "Thus, finding ways to form simplified representations of graph-structured data without labels is an important yet unsolved challenge.",
    "hard_negative": [
      22191393,
      17682909
    ],
    "easy_negative": [
      247362946,
      8352285,
      236486240
    ]
  },
  {
    "index": 1406,
    "source_corpus_id": 252846202,
    "ref_id": "b7",
    "citation_corpus_id": 212945787,
    "start": 2811,
    "end": 2830,
    "title": "RESIDUAL ENERGY-BASED MODELS FOR TEXT GENERATION",
    "abstract": "Text generation is ubiquitous in many NLP tasks, from summarization, to dialogue and machine translation. The dominant parametric approach is based on locally normalized models which predict one word at a time. While these work remarkably well, they are plagued by exposure bias due to the greedy nature of the generation process. In this work, we investigate un-normalized energy-based models (EBMs) which operate not at the token but at the sequence level. In order to make training tractable, we first work in the residual of a pretrained locally normalized language model and second we train using noise contrastive estimation. Furthermore, since the EBM works at the sequence level, we can leverage pretrained bi-directional contextual representations, such as BERT and RoBERTa. Our experiments on two large language modeling datasets show that residual EBMs yield lower perplexity compared to locally normalized baselines. Moreover, generation via importance sampling is very efficient and of higher quality than the baseline models according to human evaluation.Published as a conference paper at ICLR 2020 perturbations of the ground truth would be efficient but hardly useful for generation purposes, when at test time the model needs to generate from scratch.",
    "prev": "In practice, given different data types, we can parameterize the energy function with different neural networks as needed, such as multi-layer perceptrons (MLPs), convolutional neural networks (CNNs) (LeCun et al., 1998), and graph neural networks (GNNs) (Gori et al., 2005;Scarselli et al., 2008).",
    "curr": "Recently, EBMs have been drawing increasing attention and are demonstrated to be effective in various domains, including images (Ngiam et al., 2011;Xie et al., 2016;Du & Mordatch, 2019), videos (Xie et al., 2017), texts (Deng et al., 2020), 3D objects (Xie et al., 2018), molecules (Liu et al., 2021;Hataya et al., 2021), and proteins (Du et al., 2020b).",
    "next": "Nonetheless, learning (a.k.a., training) EBMs is known to be challenging since we cannot compute the exact likelihood due to the intractable normalization constant.",
    "hard_negative": [
      202577673,
      7147309,
      748227,
      3718988,
      750809
    ],
    "easy_negative": [
      245144733,
      219309594,
      1527867
    ]
  },
  {
    "index": 1408,
    "source_corpus_id": 4564356,
    "ref_id": "b0",
    "citation_corpus_id": 11212020,
    "start": 5756,
    "end": 5779,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "RNN is broadly used given its capability in capturing long-range dependency through recurrent computation.",
    "curr": "It has been applied to various NLP tasks, e.g., question answering (Wang et al., 2017), neural machine translation (Bahdanau et al., 2015), sentiment analysis , natural language inference (Liu et al., 2016), etc.",
    "next": "However, training the basic RNN encounters the gradient dispersion problem, and is difficult to parallelize.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      232185104,
      219303632,
      2038851
    ]
  },
  {
    "index": 1411,
    "source_corpus_id": 244478674,
    "ref_id": "b66",
    "citation_corpus_id": 59523594,
    "start": 2091,
    "end": 2110,
    "title": "Multi-Task Deep Neural Networks for Natural Language Understanding",
    "abstract": "In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. MT-DNN extends the model proposed inLiu et al. (2015)by incorporating a pre-trained bidirectional transformer language model, known as BERT(Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.2% (1.8% absolute improvement). We also demonstrate using the SNLI and Sc-iTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. Our code and pre-trained models will be made publicly available.",
    "prev": "While self-supervised pre-training has been shown to be highly effective at exploiting large amounts of unlabeled data without relying on human annotation, there is still much to explore regarding transfer learning in a multi-task co-training setup.",
    "curr": "Prior seminal works like T5  and MT-DNN (Liu et al., 2019a) have demonstrated a degree of promise in the paradigm of multi-task co-training (Caruana, 1997).",
    "next": "However, the challenge of catastrophic forgetting remains.",
    "hard_negative": [
      11754890,
      30758763
    ],
    "easy_negative": [
      218974112,
      35250137,
      9520585
    ]
  },
  {
    "index": 1413,
    "source_corpus_id": 221112385,
    "ref_id": "b15",
    "citation_corpus_id": 56657912,
    "start": 4989,
    "end": 4992,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "In this paper, we experiment with three types of augmentations: rotation, color jittering, and texture randomization, as visualized in Figure 1.",
    "curr": "We evaluate our approach across a variety of diverse tasks including large-scale classification [5], fine-grained classification [34,33], few-shot classification [23], and classification on corrupted data [2,16].",
    "next": "Our representation shows consistent performance gains with increasing number of augmentations.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      25437880,
      259376563,
      15005998
    ]
  },
  {
    "index": 1415,
    "source_corpus_id": 10635893,
    "ref_id": "b32",
    "citation_corpus_id": 8888540,
    "start": 4796,
    "end": 4815,
    "title": "Feature Noising for Log-linear Structured Prediction",
    "abstract": "NLP models have many and sparse features, and regularization is key for balancing model overfitting versus underfitting. A recently repopularized form of regularization is to generate fake training data by repeatedly adding noise to real data. We reinterpret this noising as an explicit regularizer, and approximate it with a second-order formula that can be used during training without actually generating fake data. We show how to apply this method to structured prediction using multinomial logistic regression and linear-chain CRFs. We tackle the key challenge of developing a dynamic program to compute the gradient of the regularizer efficiently. The regularizer is a sum over inputs, so we can estimate it more accurately via a semi-supervised or transductive extension. Applied to text classification and NER, our method provides a >1% absolute performance gain over use of standard L 2 regularization.",
    "prev": "These methods, however, all consider weights and hidden units instead of the input data, and are motivated by the vanishing and exploding gradient problem.",
    "curr": "Feature noising has been demonstrated to be effective for structured prediction tasks, and has been interpreted as an explicit regularizer (Wang et al., 2013).",
    "next": "Additionally, Wager et al.",
    "hard_negative": [
      2433417,
      10977241
    ],
    "easy_negative": [
      6005907,
      250164143,
      18130401
    ]
  },
  {
    "index": 1418,
    "source_corpus_id": 252596302,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 4687,
    "end": 4710,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "Most graph models (Dauparas et al., 2022;Ingraham et al., 2019;Jing et al., 2020;Hsu et al., 2022;Hsu et al., 2022) adopt the autoregressive decoding scheme to generate amino acids, dramatically slowing down the inference process.",
    "curr": "Interestingly, few studies have attempted to improve the model efficiency, perhaps because the efficiency gain requires sacrificing some accuracy (Bahdanau et al., 2015;Vaswani et al., 2017;Ghazvininejad et al., 2019;Geng et al., 2021;Wang et al., 2019;Gu et al., 2018), while the latter is more important than efficiency in protein design.",
    "next": "To address this dilemma, AlphaDesign  proposes a parallel self-correcting module to speed up inference while almost maintaining the recovery.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      43510904,
      5880140,
      13630061
    ]
  },
  {
    "index": 1419,
    "source_corpus_id": 195218755,
    "ref_id": "b23",
    "citation_corpus_id": 3693334,
    "start": 4685,
    "end": 4688,
    "title": "Visualizing the Loss Landscape of Neural Nets",
    "abstract": "Neural network training relies on our ability to find \"good\" minimizers of highly non-convex loss functions. It is well-known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and wellchosen training parameters (batch size, learning rate, optimizer) produce minimizers that generalize better. However, the reasons for these differences, and their effects on the underlying loss landscape, are not well understood. In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple \"filter normalization\" method that helps us visualize loss function curvature and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture affects the loss landscape, and how training parameters affect the shape of minimizers.",
    "prev": "On the one hand, we are inspired by the success of AlphaGo [35,36], where a policy network is used to generate proposals for the Monte-Carlo tree search.",
    "curr": "On the other hand, we are inspired by the recent research into understanding deep neural networks [30,24,37].",
    "next": "Deep neural networks, frequently observed in practices, is much less likely to get stuck in sub-optimal points.",
    "hard_negative": [
      14124313,
      4429876,
      16138044,
      17786716,
      16209268
    ],
    "easy_negative": [
      231985467,
      226284006,
      1822902
    ]
  },
  {
    "index": 1420,
    "source_corpus_id": 244488409,
    "ref_id": "b11",
    "citation_corpus_id": 219965949,
    "start": 29195,
    "end": 29212,
    "title": "IDF++: Analyzing and Improving Integer Discrete Flows for Lossless Compression",
    "abstract": "In this paper we analyse and improve integer discrete flows for lossless compression. Integer discrete flows are a recently proposed class of models that learn invertible transformations for integer-valued random variables. Due to its discrete nature, they can be combined in a straightforward manner with entropy coding schemes for lossless compression without the need for bits-back coding. We discuss the potential difference in flexibility between invertible flows for discrete random variables and flows for continuous random variables and show that (integer) discrete flows are more flexible than previously claimed. We furthermore investigate the influence of quantization operators on optimization and gradient bias in integer discrete flows. Finally, we introduce modifications to the architecture to improve the performance of this model class for lossless compression.",
    "prev": "Results are shown in Table 4.",
    "curr": "First, compared to 4 baselines (i.e., IDF, IDF++ (van den Berg et al., 2020), Glow (Kingma & Dhariwal, 2018), and RealNVP (Dinh et al., 2016), PC+IDF achieved the best bpd on ImageNet32 and ImageNet64.",
    "next": "Next, PC+IDF improved over its base model IDF by 0.04, 0.16, and 0.19 bpd on three datasets, respectively.",
    "hard_negative": [
      3693334,
      2428314,
      14307651
    ],
    "easy_negative": [
      219307489,
      253762054,
      243865616
    ]
  },
  {
    "index": 1432,
    "source_corpus_id": 247595263,
    "ref_id": "b17",
    "citation_corpus_id": 560565,
    "start": 12284,
    "end": 12302,
    "title": "Solving General Arithmetic Word Problems",
    "abstract": "This paper presents a novel approach to automatically solving arithmetic word problems. This is the first algorithmic approach that can handle arithmetic problems with multiple steps and operations, without depending on additional annotations or predefined templates. We develop a theory for expression trees that can be used to represent and evaluate the target arithmetic expressions; we use it to uniquely decompose the target arithmetic problem to multiple classification problems; we then compose an expression tree, combining these with world knowledge through a constrained inference framework. Our classifiers gain from the use of quantity schemas that supports better extraction of features. Experimental results show that our method outperforms existing systems, achieving state of the art performance on benchmark datasets of arithmetic word problems.",
    "prev": "3\n\n\u2022 Arithmetic reasoning.",
    "curr": "For these tasks, we used the Math Word Problem Repository (Koncel-Kedziorski et al., 2016), including AddSub (Hosseini et al., 2014, MultiArith (Roy & Roth, 2015), and ASDiv (Miao et al., 2020).",
    "next": "We also included AQUA- RAT (Ling et al., 2017), a recently published benchmark of grade-school-math problems (GSM8K; Cobbe et al., 2021), and a challenge dataset over math word problems (SVAMP; Patel et al., 2021).",
    "hard_negative": [
      428579,
      10312772,
      8471750,
      12451537,
      17364624,
      3146611,
      12585594,
      10048734,
      11162815
    ],
    "easy_negative": [
      1677923,
      53248322,
      237453543
    ]
  },
  {
    "index": 1435,
    "source_corpus_id": 264406064,
    "ref_id": "b46",
    "citation_corpus_id": 990233,
    "start": 2454,
    "end": 2475,
    "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
    "prev": "character, word, and sentence levels, respectively.Besides, we use a fidelity filter to ensure that PromptAttack maintains the original semantic meanings of the adversarial examples.Further, we enhance the attack power of PromptAttack by ensembling adversarial examples at different perturbation levels.Comprehensive empirical results using Llama2 and GPT-3.5 validate that PromptAttack consistently yields a much higher attack success rate compared to AdvGLUE and AdvGLUE++.Interesting findings include that a simple emoji can easily mislead GPT-3.5 to make wrong predictions.Our project page is available at PromptAttack.",
    "curr": "Introduction\n\nLarge language models (LLMs) that are pre-trained on massive text corpora can be foundation models (Bommasani et al., 2021) to power various downstream applications.In particular, LLMs (Garg et al., 2022;Liu et al., 2023a;Wei et al., 2022) can yield superior performance in various natural language processing (NLP) downstream tasks, such as sentiment analysis (Socher et al., 2013) and logical reasoning (Miao et al., 2023;Liu et al., 2023a).However, in some critical areas such as medicine (Singhal et al., 2023) and industrial control (Song et al., 2023), LLM's reliability is of equal importance.This paper studies one key aspect of LLM's reliability-adversarial robustness.",
    "next": "Existing research evaluates adversarial robustness of LLMs on the GLUE dataset (Wang et al., 2018), in which an LLM is required to solve a classification task according to a prompt containing both a task description and an original sample (as shown in Figure 2).In particular, Zhu et al.",
    "hard_negative": [
      5584134,
      2279432,
      3116311,
      7747235,
      15659560,
      1588782,
      806709,
      2678583,
      3264224,
      15616495,
      2091504
    ],
    "easy_negative": [
      251712737,
      1895032,
      225063037
    ]
  },
  {
    "index": 1438,
    "source_corpus_id": 67856605,
    "ref_id": "b8",
    "citation_corpus_id": 3568073,
    "start": 3239,
    "end": 3260,
    "title": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024 2 . We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.",
    "prev": "The generator is trained adversarially by optimizing a minimax objective together with a discriminator.",
    "curr": "In practice, GANs have been shown to be very successful in a range of applications including generating photorealistic images (Karras et al., 2018).",
    "next": "Other than generating samples, many downstream tasks require a good generative model, such as image inpainting (Pathak et al., 2016;Yeh et al., 2017).",
    "hard_negative": [
      18828233,
      6628106
    ],
    "easy_negative": [
      218974472,
      135465591,
      21698258
    ]
  },
  {
    "index": 1439,
    "source_corpus_id": 253265114,
    "ref_id": "b4",
    "citation_corpus_id": 243865348,
    "start": 3134,
    "end": 3155,
    "title": "Shortcutted Commonsense: Data Spuriousness in Deep Learning of Commonsense Reasoning",
    "abstract": "Question: What is something someone driving a car needs even to begin?",
    "prev": "Still, given LMs' black-box nature, it is unclear whether this knowledge is being used properly (Doshi-Velez & Kim, 2017;Lipton, 2018).",
    "curr": "Previous studies have shown that LMs often learn spurious correlations from artifacts in downstream training data, thus limiting their generalizability (Branco et al., 2021;Geirhos et al., 2020;D'Amour et al., 2020).",
    "next": "With this in mind, a number of prior works aim to make LMs' reasoning processes more explicit by generating free-text rationales, which use LMs' internal knowledge to describe a reasoning process in natural language (Narang et al., 2020;Wei et al., 2022b;Marasovi\u0107 et al., 2022;Zelikman et al., 2022).",
    "hard_negative": [
      52011616,
      216641956,
      40100965,
      59523594,
      204960716,
      47018994,
      196181887,
      211205183
    ],
    "easy_negative": [
      15890923,
      36789753,
      15480579
    ]
  },
  {
    "index": 1443,
    "source_corpus_id": 263310960,
    "ref_id": "b14",
    "citation_corpus_id": 257280243,
    "start": 7755,
    "end": 7759,
    "title": "PARETO INVARIANT RISK MINIMIZATION: TOWARDS MITIGATING THE OPTIMIZATION DILEMMA IN OUT- OF-DISTRIBUTION GENERALIZATION",
    "abstract": "Recently, there has been a growing surge of interest in enabling machine learning systems to generalize well to Out-of-Distribution (OOD) data. Most efforts are devoted to advancing optimization objectives that regularize models to capture the underlying invariance; however, there often are compromises in the optimization process of these OOD objectives: i) Many OOD objectives have to be relaxed as penalty terms of Empirical Risk Minimization (ERM) for the ease of optimization, while the relaxed forms can weaken the robustness of the original objective; ii) The penalty terms also require careful tuning of the penalty weights due to the intrinsic conflicts between ERM and OOD objectives. Consequently, these compromises could easily lead to suboptimal performance of either the ERM or OOD objective. To address these issues, we introduce a multi-objective optimization (MOO) perspective to understand the OOD optimization process, and propose a new optimization scheme called PAreto Invariant Risk Minimization (PAIR). PAIR improves the robustness of OOD objectives by cooperatively optimizing with other OOD objectives, thereby bridging the gaps caused by the relaxations. Then PAIR approaches a Pareto optimal solution that trades off the ERM and OOD objectives properly. Extensive experiments on challenging benchmarks, WILDS, show that PAIR alleviates the compromises and yields top OOD performances. 1 * Work done during an internship at Tencent AI Lab. 1 Code is available at https://github.com/LFhase/PAIR.Published as a conference paper at ICLR 2023To address these issues, we propose a new optimization scheme for OOD generalization, called PAreto Invariant Risk Minimization (PAIR), which includes a new optimizer (PAIR-o) and a new model selection criteria (PAIR-s). Owing to the MOO formulation, PAIR-o allows for cooperative optimization with other OOD objectives to improve the robustness of practical OOD objectives. Despite the huge gaps between IRMv1 and IRM, we show that incorporating VREx (Krueger et al.,  2021)  into IRMv1 provably recovers the causal invariance (Arjovsky et al., 2019) for some group of problem instances (Sec. 3.2). When given robust OOD objectives, PAIR-o finds a descent path with adaptive penalty weights, which leads to a Pareto optimal solution that trades off ERM and OOD performance properly (Sec. 4). In addition, the MOO analysis also motivates PAIR-s, which facilitates the OOD model selection by considering the trade-offs between ERM and OOD objectives.We conducted extensive experiments on challenging OOD benchmarks. Empirical results show that PAIR-o successfully alleviates the objective conflicts and empowers IRMv1 to achieve high perfor-",
    "prev": "Recall that there has been a significant effort in OOD community to learn invariant features and discard spurious features [5].",
    "curr": "However, these approaches have not shown satisfactory performance when applied to real-world datasets [27], which may be due to the fact that invariant learning requires numerous domains [51], strong regularization [67], and faces additional difficulties induced by non-linearity [51], overparameterization [35], and optimization challenges [15].",
    "next": "In contrast, our findings offer a new perspective that spurious features diversification actually improves OOD performance, which can be easily implemented as shown in ensemble-based models and has achieved remarkable empirical success.",
    "hard_negative": [
      226221794,
      246867402
    ],
    "easy_negative": [
      14510744,
      256461094,
      250390933
    ]
  },
  {
    "index": 1448,
    "source_corpus_id": 224803601,
    "ref_id": "b27",
    "citation_corpus_id": 9027681,
    "start": 4672,
    "end": 4695,
    "title": "Compositional Semantic Parsing on Semi-Structured Tables",
    "abstract": "Two important aspects of semantic parsing for question answering are the breadth of the knowledge source and the depth of logical compositionality. While existing work trades off one aspect for another, this paper simultaneously makes progress on both fronts through a new task: answering complex questions on semi-structured tables using question-answer pairs as supervision. The central challenge arises from two compounding factors: the broader domain results in an open-ended set of relations, and the deeper compositionality results in a combinatorial explosion in the space of logical forms. We propose a logical-form driven parsing algorithm guided by strong typing constraints and show that it obtains significant improvements over natural baselines. For evaluation, we created a new dataset of 22,033 complex questions on Wikipedia tables, which is made publicly available.",
    "prev": "OTT-QA is distinguished from the existing QA datasets in two aspects.",
    "curr": "Existing table-based QA datasets (Pasupat & Liang, 2015;Yu et al., 2018; operates in the closed setting without requiring any retrieval, whereas most existing open QA datasets (Joshi et al., 2017;Yang et al., 2018) require only text retrieval, not table retrieval.",
    "next": "One dataset, Natural Questions (Kwiatkowski et al., 2019) includes some tabular information in its corpus, but the tables are nearly always of a restricted type (infobox tables with only a single row).",
    "hard_negative": [
      15324422,
      6401679,
      12728987,
      1336493,
      9337134,
      74065,
      8597719,
      10250712,
      8893912
    ],
    "easy_negative": [
      9789287,
      231741340,
      13418407
    ]
  },
  {
    "index": 1450,
    "source_corpus_id": 262084051,
    "ref_id": "b17",
    "citation_corpus_id": 252683303,
    "start": 3409,
    "end": 3413,
    "title": "COMPLEXITY-BASED PROMPTING FOR MULTI-STEP REASONING",
    "abstract": "We study the task of prompting large-scale language models to perform multistep reasoning. Existing work shows that when prompted with a chain of thoughts (CoT), sequences of short sentences describing intermediate reasoning steps towards a final answer, large language models can generate new reasoning chains and predict answers for new inputs. A central question is which reasoning examples make the most effective prompts. In this work, we propose complexitybased prompting, a simple and effective example selection scheme for multi-step reasoning. We show that prompts with higher reasoning complexity, i.e., chains with more reasoning steps, achieve substantially better performance on multistep reasoning tasks over strong baselines. We further extend our complexitybased criteria from prompting (selecting inputs) to decoding (selecting outputs), where we sample multiple reasoning chains from the model, then choose the majority of generated answers from complex reasoning chains (over simple chains). When used to prompt GPT-3 and Codex, our approach substantially improves multi-step reasoning accuracy and achieves new state-of-the-art (SOTA) performance on three math benchmarks (GSM8K, MultiArith, and MathQA) and two BigBenchHard tasks (Date Understanding and Penguins), with an average +5.3 and up to +18 accuracy improvements. Compared with existing example selection schemes like manual tuning or retrieval-based selection, selection based on reasoning complexity is intuitive, easy to implement, and annotation-efficient. Further results demonstrate the robustness of performance gains from complex prompts under format perturbation and distribution shift.",
    "prev": "e language models (LLMs) which emerge as the favored approach for various applications and demonstrate multi-dimensional abilities, including instruction following [6,49,59], coding assistance [7,32,39,45], and mathematical problem-solving [13,26,38,69].Among various tasks, solving mathematical problems is more challenging as they often require highly complex and symbolic multi-step reasoning capabilities.Although some close-sourced models, e.g., GPT-3.5-Turbo[46], GPT-4 [48] and PaLM-2 [62], have demonstrated promising performance on some mathematical problem-solving benchmarks, it is still a mystery how these models are trained and what data these models use.Therefore, how to equip open-source LLMs (e.g., LLaMA [61,62]) with good mathematical problem-solving skills remains an open challenge.",
    "curr": "To tackle this challenge, two popular lines of research to improve the mathematical problem-solving abilities of LLMs are: prompt-based methods and finetuning-based methods.Prompt-based methods [18,18,66,66,67,74] aim to activate the potential capacities of LLMs by choosing suitable prompting inputs without modifying the model parameters.Finetuning-based methods update the open-source LLMs (e.g., LLaMA) under the guidance of some other powerful closed-source LLMs (e.g., , GPT-4 [48]).While prompt-based methods are model-dependent and sensitive to many factors, finetuning-based methods, despite being simple and model-agnostic, heavily rely on effective training data on downstream mathematical questions.Our work aims to improve finetuning-based methods with a novel method to bootstrap available mathematical questions in the training set.Specifically, we propose to bootstrap the questions in both forward and backward reasoning directions.For the forward direction, we have the original and LLM-rephrased questions.",
    "next": "For the backward direction, we have the self-verification question [68] and FOBAR question [28].",
    "hard_negative": [
      245218561,
      231632658,
      230433941,
      9226412,
      49325612,
      560565,
      241035330,
      173188048,
      201698258,
      21673814,
      201646309,
      233296494,
      52113519
    ],
    "easy_negative": [
      239890006,
      19170988,
      573345
    ]
  },
  {
    "index": 1451,
    "source_corpus_id": 249209899,
    "ref_id": "b18",
    "citation_corpus_id": 218502350,
    "start": 3292,
    "end": 3313,
    "title": "Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?",
    "abstract": "Algorithmic approaches to interpreting machine learning models have proliferated in recent years. We carry out human subject tests that are the first of their kind to isolate the effect of algorithmic explanations on a key aspect of model interpretability, simulatability, while avoiding important confounding experimental factors. A model is simulatable when a person can predict its behavior on new inputs. Through two kinds of simulation tests involving text and tabular data, we evaluate five explanations methods: (1) LIME, (2) Anchor, (3) Decision Boundary, (4) a Prototype model, and (5) a Composite approach that combines explanations from each method. Clear evidence of method effectiveness is found in very few cases: LIME improves simulatability in tabular classification, and our Prototype method is effective in counterfactual simulation tests. We also collect subjective ratings of explanations, but we do not find that ratings are predictive of how helpful explanations are. Our results provide the first reliable and comprehensive estimates of how explanations influence simulatability across a variety of explanation methods and data domains. We show that (1) we need to be careful about the metrics we use to evaluate explanation methods, and (2) there is significant room for improvement in current methods. 1",
    "prev": "What makes ProtoPNets appealing is that, despite performing comparably to more opaque predictors, they explain their own predictions in terms of relevant part-prototypes and of examples that these are sourced from.",
    "curr": "These explanations are -by design -more faithful than those extracted by post-hoc approaches (Dombrowski et al., 2019;Teso, 2019;Lakkaraju & Bastani, 2020;Sixt et al., 2020) and can effectively help stakeholders to simulate and anticipate the model's reasoning (Hase & Bansal, 2020).",
    "next": "Despite all these advantages, ProtoPNets are prone -like regular neural networks -to picking up confounders from the training data (e.g., class-correlated watermarks), thus suffering from compromised generalization and out-of-distribution performance (Lapuschkin et al., 2019;Geirhos et al., 2020).",
    "hard_negative": [
      207847663,
      7105713,
      14099741
    ],
    "easy_negative": [
      16345611,
      250390866,
      15413755
    ]
  },
  {
    "index": 1455,
    "source_corpus_id": 208547770,
    "ref_id": "b0",
    "citation_corpus_id": 14298291,
    "start": 1636,
    "end": 1659,
    "title": "Learning Continuous Semantic Representations of Symbolic Expressions",
    "abstract": "Combining abstract, symbolic reasoning with continuous neural reasoning is a grand challenge of representation learning. As a step in this direction, we propose a new architecture, called neural equivalence networks, for the problem of learning continuous semantic representations of algebraic and logical expressions. These networks are trained to represent semantic equivalence, even of expressions that are syntactically very different. The challenge is that semantic representations must be computed in a syntax-directed manner, because semantics is compositional, but at the same time, small changes in syntax can lead to very large changes in semantics, which can be difficult for continuous neural architectures. We perform an exhaustive evaluation on the task of checking equivalence on a highly diverse class of symbolic algebraic and boolean expression types, showing that our model significantly outperforms existing architectures.",
    "prev": "However, the success of neural networks in symbolic computation is still extremely limited: combining symbolic reasoning with continuous representations is now one of the challenges of machine learning.",
    "curr": "Only a few studies investigated the capacity of neural network to deal with mathematical objects, and apart from a small number of exceptions Loos et al., 2017;Allamanis et al., 2017;Arabshahi et al., 2018b), the majority of these works focus on arithmetic tasks like integer addition and multiplication (Zaremba & Sutskever, 2014;Trask et al., 2018).",
    "next": "On these tasks, neural approaches tend to perform poorly, and require the introduction of components biased towards the task at hand Trask et al., 2018).",
    "hard_negative": [
      2009318,
      6715185,
      806709,
      990233,
      3116311,
      6278207
    ],
    "easy_negative": [
      250390556,
      15423144,
      252819279
    ]
  },
  {
    "index": 1460,
    "source_corpus_id": 49882757,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 5790,
    "end": 5813,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "Deep Voice 1 & 2 retain the traditional TTS pipeline, which has separate grapheme-to-phoneme, phoneme duration, frequency, and waveform synthesis models.",
    "curr": "In contrast, Tacotron, Deep Voice 3, and Char2Wav employ the attention based sequence-to-sequence models (Bahdanau et al., 2015), yielding more compact architectures.",
    "next": "In the literature, these models are usually referred to as \"endto-end\" speech synthesis.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      237491060,
      211126477,
      5653948
    ]
  },
  {
    "index": 1467,
    "source_corpus_id": 251223792,
    "ref_id": "b21",
    "citation_corpus_id": 964287,
    "start": 1741,
    "end": 1752,
    "title": "ROUGE: A Package for Automatic Evaluation of Summaries",
    "abstract": "ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It includes measures to automatically determine the quality of a summary by comparing it to other (ideal) summaries created by humans. The measures count the number of overlapping units such as n-gram, word sequences, and word pairs between the computer-generated summary to be evaluated and the ideal summaries created by humans. This paper introduces four different ROUGE measures: ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S included in the ROUGE summarization evaluation package and their evaluatio ns. Three of them have been used in the Document Understanding Conference (DUC) 2004, a large-scale summarization evaluation sponsored by NIST.",
    "prev": "is automatic evaluation.",
    "curr": "Traditionally, automatic metrics that rely on discrete token-level matching such as ROUGE (Lin, 2004) and BLEU (Papineni et al., 2002) have been utilized to check whether system outputs are of high quality across four dimensions (Kryscinski et al., 2019;Yuan et al., 2021): coherence, factuality, fluency, and informativeness.",
    "next": "These metrics do not correlate well with human judgments on all four dimensions of text quality (Fabbri et al., 2021).",
    "hard_negative": [
      1842,
      19265207
    ],
    "easy_negative": [
      7525432,
      202788853,
      222341385
    ]
  },
  {
    "index": 1469,
    "source_corpus_id": 252917984,
    "ref_id": "b23",
    "citation_corpus_id": 174797767,
    "start": 3826,
    "end": 3844,
    "title": "Disentangling neural mechanisms for perceptual grouping",
    "abstract": "Forming perceptual groups and individuating objects in visual scenes is an essential step towards visual intelligence. This ability is thought to arise in the brain from computations implemented by bottom-up, horizontal, and top-down connections between neurons. However, the relative contributions of these connections to perceptual grouping are poorly understood. We address this question by systematically evaluating neural network architectures featuring combinations of these connections on two synthetic visual tasks, which stress low-level \"gestalt\" vs. high-level object cues for perceptual grouping. We show that increasing the difficulty of either task strains learning for networks that rely solely on bottom-up processing. Horizontal connections resolve this limitation on tasks with gestalt cues by supporting incremental spatial propagation of activities, whereas top-down connections rescue learning on tasks featuring object cues by propagating coarse predictions about the position of the target object. Our findings disassociate the computational roles of bottom-up, horizontal and top-down connectivity, and demonstrate how a model featuring all of these interactions can more flexibly learn to form perceptual groups.Extant theory suggests that there are two distinct types of feedback strategies: A low-level strategy of grouping visual features with neighboring features according to Gestalt laws including similarity, good continuation, etc.[13][14][15][16][17][18][19]. In contrast, an object-based strategy is mediated by expectations \u2020 These authors contributed equally to this work.",
    "prev": "The exact implementation of the S4 model can be viewed as a (depthwise) global convolutional model with an involved computation global convolution kernel.",
    "curr": "Thanks to the global receptive field of the convolution kernel, S4 is able to handle tasks that require LRD, such as Pathfinder [Tay et al., 2020b], where classic local CNNs fail [Linsley et al., 2018, Kim et al., 2019.",
    "next": "Also, the use of Fast Fourier Transform (FFT) and techniques from numerical linear algebra make the computational complexity of S4 tractable compared to the quadratic complexity of attention.",
    "hard_negative": [
      1793573,
      1107124,
      5590763
    ],
    "easy_negative": [
      5980888,
      219179830,
      6282257
    ]
  },
  {
    "index": 1471,
    "source_corpus_id": 263608308,
    "ref_id": "b51",
    "citation_corpus_id": 3144218,
    "start": 2519,
    "end": 2541,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "o add relevant edges while omitting less beneficial ones.For the first time, our theoretical analysis explores how PR-MPNNs enhance expressive power, and we identify precise conditions under which they outperform purely randomized approaches.Empirically, we demonstrate that our approach effectively mitigates issues like over-squashing and under-reaching.In addition, on established realworld datasets, our method exhibits competitive or superior predictive performance compared to traditional MPNN models and recent graph transformer architectures.",
    "curr": "INTRODUCTION\n\nGraph-structured data is prevalent across various application domains, including fields like chemoand bioinformatics (Barabasi & Oltvai, 2004;Jumper et al., 2021;Reiser et al., 2022), combinatorial optimization (Cappart et al., 2023), and social-network analysis (Easley et al., 2012), highlighting the need for machine learning techniques designed explicitly for graphs.In recent years, message-passing graph neural networks (MPNNs) (Kipf & Welling, 2017;Gilmer et al., 2017;Scarselli et al., 2008b;Veli\u010dkovi\u0107 et al., 2018) have become the dominant approach in this area, showing promising performance in tasks such as predicting molecular properties (Klicpera et al., 2020;Jumper et al., 2021) or enhancing combinatorial solvers (Cappart et al., 2023).",
    "next": "However, MPNNs have a limitation due to their local aggregation mechanism.They focus on encoding local structures, severely limiting their expressive power (Morris et al., 2019;Xu et al., 2019;Morris et al., 2021).In addition, MPNNs struggle to capture global or long-range information, possibly leading Figure 1: Overview of the probabilistically rewired MPNN framework.PR-MPNNs use an upstream model to learn priors \u03b8 for candidate edges, parameterizing a probability mass function conditioned on exactly-k constraints.Subsequently, we sample multiple k-edge adjacency matrices (here: k = 1) from this distribution, aggregate these matrices (here: subtraction), and use the resulting adjacency matr",
    "hard_negative": [
      8393918,
      17682909
    ],
    "easy_negative": [
      35343653,
      14767290,
      217699834
    ]
  },
  {
    "index": 1473,
    "source_corpus_id": 252545164,
    "ref_id": "b19",
    "citation_corpus_id": 219965819,
    "start": 3474,
    "end": 3497,
    "title": "LIPSCHITZ RECURRENT NEURAL NETWORKS",
    "abstract": "Differential equations are a natural choice for modeling recurrent neural networks because they can be viewed as dynamical systems with a driving input. In this work, we propose a recurrent unit that describes the hidden state's evolution with two parts: a well-understood linear component plus a Lipschitz nonlinearity. This particular functional form simplifies stability analysis, which enables us to provide an asymptotic stability guarantee. Further, we demonstrate that Lipschitz recurrent units are more robust with respect to perturbations. We evaluate our approach on a range of benchmark tasks, and we show it outperforms existing recurrent units.",
    "prev": "Their complexity, however, is bottlenecked by their differential equation numerical solver that limits their scalability to longer-term sequences.",
    "curr": "How can we take advantage of LTC's generalization and causality capabilities and scale them to competitively learn long-range sequences without gradient issues, compared to advanced recurrent neural networks (RNNs) (Erichson et al., 2021;Gu et al., 2020a;Rusch and Mishra, 2021), convolutional neural networks (CNNs) (Cheng et al., 2022;Lea et al., 2016;Romero et al., 2021b), and attention-based models (Vaswani et al., 2017)?",
    "next": "In this work, we set out to leverage the elegant formulation of structural state-space models (S4) (Gu et al., 2022a) to obtain linear liquid network instances that possess the approximation capabilities of both S4 and LTCs.",
    "hard_negative": [
      58981389,
      3331622,
      604334,
      67855286
    ],
    "easy_negative": [
      1219111,
      258833682,
      46926791
    ]
  },
  {
    "index": 1479,
    "source_corpus_id": 4722462,
    "ref_id": "b0",
    "citation_corpus_id": 11212020,
    "start": 1941,
    "end": 1964,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "INTRODUCTION\n\nBuilding intelligent machines that can converse with humans is a longstanding challenge in artificial intelligence.",
    "curr": "Remarkable successes have been achieved in natural language processing (NLP) via the use of supervised learning approaches on large-scale datasets (Bahdanau et al., 2015;Wu et al., 2016;Gehring et al., 2017;.",
    "next": "Machine translation is no exception: most translation systems are trained to derive statistical patterns from huge parallel corpora.",
    "hard_negative": [
      1274371,
      13805769,
      5590763,
      8884845,
      10766958,
      1870512,
      8608051,
      12639289
    ],
    "easy_negative": [
      224817876,
      4994434,
      250179916
    ]
  },
  {
    "index": 1480,
    "source_corpus_id": 49881601,
    "ref_id": "b15",
    "citation_corpus_id": 5959482,
    "start": 2572,
    "end": 2593,
    "title": "Efficient Estimation of Word Representations in Vector Space",
    "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities. arXiv:1301.3781v3 [cs.CL] 7 Sep 2013 1 The test set is available at www.fit.vutbr.cz/\u02dcimikolov/rnnlm/word-test.v1.txt 2",
    "prev": "Many problems can be cast in this form: In a natural language processing setting, x represents a context (e.g.",
    "curr": "a bag of words), y represents a candidate word, and the target similarity measures the likelihood to observe y in context x [Mikolov et al., 2013, Pennington et al., 2014, Levy and Goldberg, 2014.",
    "next": "In recommender systems, x represents a user query (the user id and any available contextual information), y represents a candidate item to recommend, and the target similarity is a measure of relevance of item y to query x, e.g.",
    "hard_negative": [
      633992,
      5278106,
      1428702,
      629094
    ],
    "easy_negative": [
      11953528,
      263306080,
      218487295
    ]
  },
  {
    "index": 1482,
    "source_corpus_id": 246652474,
    "ref_id": "b1",
    "citation_corpus_id": 46890017,
    "start": 7968,
    "end": 7987,
    "title": "Domain Adaptation with Adversarial Training and Graph Embeddings",
    "abstract": "The success of deep neural networks (DNNs) is heavily dependent on the availability of labeled data. However, obtaining labeled data is a big challenge in many real-world problems. In such scenarios, a DNN model can leverage labeled and unlabeled data from a related domain, but it has to deal with the shift in data distributions between the source and the target domains. In this paper, we study the problem of classifying social media posts during a crisis event (e.g., Earthquake). For that, we use labeled and unlabeled data from past similar events (e.g., Flood) and unlabeled data for the current event. We propose a novel model that performs adversarial learning based domain adaptation to deal with distribution drifts and graph based semi-supervised learning to leverage unlabeled data within a single unified deep learning framework. Our experiments with two real-world crisis datasets collected from Twitter demonstrate significant improvements over several baselines.",
    "prev": "Usually they focus on adaptation between two domains where data points themselves are graphs.",
    "curr": "For example, (Pilanc\u0131 & Vural, 2019;Pilanci & Vural, 2020) use frequency analysis to align the data graphs between the source domain and the target domains, and (Alam et al., 2018;Ding et al., 2018) perform label propagation on the data graph.",
    "next": "In contrast, GRDA considers a setting completely different from the above references.",
    "hard_negative": [
      1957433,
      5959482,
      15978939,
      7255786
    ],
    "easy_negative": [
      8985261,
      224709477,
      8607756
    ]
  },
  {
    "index": 1483,
    "source_corpus_id": 259075246,
    "ref_id": "b17",
    "citation_corpus_id": 247315559,
    "start": 2212,
    "end": 2215,
    "title": "UniXcoder: Unified Cross-Modal Pre-training for Code Representation",
    "abstract": "Pre-trained models for programming languages have recently demonstrated great success on code intelligence. To support both code-related understanding and generation tasks, recent works attempt to pre-train unified encoder-decoder models. However, such encoder-decoder framework is sub-optimal for auto-regressive tasks, especially code completion that requires a decoder-only manner for efficient inference. In this paper, we present UniXcoder, a unified cross-modal pre-trained model for programming language. The model utilizes mask attention matrices with prefix adapters to control the behavior of the model and leverages cross-modal contents like AST and code comment to enhance code representation. To encode AST that is represented as a tree in parallel, we propose a one-to-one mapping method to transform AST in a sequence structure that retains all structural information from the tree. Furthermore, we propose to utilize multi-modal contents to learn representation of code fragment with contrastive learning, and then align representations among programming languages using a cross-modal generation task. We evaluate UniXcoder on five code-related tasks over nine datasets. To further evaluate the performance of code fragment representation, we also construct a dataset for a new task, called zero-shot code-to-code search. Results show that our model achieves state-of-the-art performance on most tasks and analysis reveals that comment and AST can both enhance UniXcoder.",
    "prev": "Introduction\n\nLarge language models (LLMs) [8,10,39,28] have been instrumental in paving new avenues for innovative applications across diverse domains, with programming being a notably attractive and promising domain [9,41,4,43].In particular, the rise and application of code auto-completion systems like GitHub's Copilot 1 , driven by OpenAI's Codex [9], have the potential to substantially changed the manner in which we interact with code.These changes facilitate coding for beginners and improve efficiency of the coding process for experienced developers.",
    "curr": "A variety of code auto-completion models [9,18,15,27,23,2] have emerged in recent years, each boasting unique capabilities and performance characteristics.This emergence of models emphasizes the increasing importance of AI in the realm of programming, leading to a more diversified and competitive landscape.However, current evaluation datasets and benchmarks [26,34,3] predominantly focus on completion tasks within the scope of a single file.This focus fails to reflect the complexity and intricacies of real-world programming scenarios, where developers frequently work on multi-file projects, often navigating through and understanding code spanning several repositories.",
    "next": "Recognizing the need for a more comprehensive evaluation, we introduce RepoBench, a new benchmark for evaluating the effectiveness of repository-level code auto-completion systems.Specifically, RepoBench offers three distinct evaluation sub-tasks, each emphasizing a unique aspect of a fully functioning code auto-completion system: (1) The Retrieval Task (RepoBench-R),",
    "hard_negative": [
      52125417,
      232185260,
      221761146
    ],
    "easy_negative": [
      5714733,
      8692813,
      202782807
    ]
  },
  {
    "index": 1484,
    "source_corpus_id": 247996981,
    "ref_id": "b71",
    "citation_corpus_id": 202888885,
    "start": 7970,
    "end": 7973,
    "title": "Published as a conference paper at ICLR 2020 DRAWING EARLY-BIRD TICKETS: TOWARDS MORE EF- FICIENT TRAINING OF DEEP NETWORKS",
    "abstract": "Frankle & Carbin, 2019)shows that there exist winning tickets (small but critical subnetworks) for dense, randomly initialized networks, that can be trained alone to achieve a comparable accuracy to the latter in a similar number of iterations. However, the identification of these winning tickets still requires the costly train-prune-retrain process, limiting their practical benefits. In this paper, we discover for the first time that the winning tickets can be identified at a very early training stage, which we term as Early-Bird (EB) tickets, via lowcost training schemes (e.g., early stopping and low-precision training) at large learning rates. Our finding on the existence of EB tickets is consistent with recently reported observations that the key connectivity patterns of neural networks emerge early. Furthermore, we propose a mask distance metric that can be used to identify EB tickets with a low computational overhead, without needing to know the true winning tickets that emerge after the full training. Finally, we leverage the existence of EB tickets and the proposed mask distance to develop efficient training methods, which are achieved by first identifying EB tickets via low-cost schemes, and then continuing to train merely the EB tickets towards the target accuracy. Experiments based on various deep networks and datasets validate: 1) the existence of EB tickets and the effectiveness of mask distance in efficiently identifying them; and 2) that the proposed efficient training via EB tickets can achieve up to 5.8\u00d7 \u223c 10.7\u00d7 energy savings while maintaining comparable or even better accuracy as compared to the most competitive state-ofthe-art training methods, demonstrating a promising and easily adopted method for tackling the often cost-prohibitive deep network training.",
    "prev": "Even though these methods surpass the trivial baseline of random network pruning at initialization, [19] suggests that accuracy of these methods on standard classification benchmarks remains below the dense network obtained after training.",
    "curr": "Pruning after training introduced by the Lottery Ticket Hypothesis [16], adapted by various works [3,5,6,12,17,18,20,47,49,72,75], prune the neural network weights based on the magnitude after the network is trained.",
    "next": "Typically the dense network is reset to the initial weights after pruning and retrained from scratch.",
    "hard_negative": [
      52920837,
      211259030,
      212415013,
      3603886,
      53388625,
      12713052,
      14089312
    ],
    "easy_negative": [
      8619716,
      18679773,
      248780075
    ]
  },
  {
    "index": 1485,
    "source_corpus_id": 222272074,
    "ref_id": "b21",
    "citation_corpus_id": 3626819,
    "start": 2468,
    "end": 2488,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "Open code for reproducing and extending our results is provided.",
    "curr": "* equal contribution arXiv:2010.04290v1 [cs.LG]\n\nINTRODUCTION AND MOTIVATION\n\nDeep Learning revolutionized Machine Learning by improving the accuracy by dozens of percents for fundamental tasks in Natural Language Processing (NLP) through learning representations of a natural language via a deep neural network (Mikolov et al., 2013;Radford et al., 2018;Le and Mikolov, 2014;Peters et al., 2018;Radford et al., 2019).",
    "next": "Lately, it was shown that there is no need to train those networks from scratch each time we receive a new task/data, but to fine-tune a full pre-trained model on the specific task (Dai and Le, 2015;Radford et al., 2018;Devlin et al., 2019).",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      8535316,
      11336213,
      990233,
      9917468,
      20472740,
      34032948,
      10489017,
      1957433,
      1222212,
      12688069,
      15026764,
      11816014,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      12873285,
      9115773,
      215745282
    ]
  },
  {
    "index": 1487,
    "source_corpus_id": 264439160,
    "ref_id": "b9",
    "citation_corpus_id": 247084324,
    "start": 2098,
    "end": 2121,
    "title": "Overcoming a Theoretical Limitation of Self-Attention",
    "abstract": "Although transformers are remarkably effective for many tasks, there are some surprisingly easy-looking regular languages that they struggle with. Hahn shows that for languages where acceptance depends on a single input symbol, a transformer's classification decisions become less and less confident (that is, with crossentropy approaching 1 bit per string) as input strings get longer and longer. We examine this limitation using two languages: PAR-ITY, the language of bit strings with an odd number of 1s, and FIRST, the language of bit strings starting with a 1. We demonstrate three ways of overcoming the limitation suggested by Hahn's lemma. First, we settle an open question by constructing a transformer that recognizes PARITY with perfect accuracy, and similarly for FIRST. Second, we use layer normalization to bring the cross-entropy of both models arbitrarily close to zero. Third, when transformers need to focus on a single position, as for FIRST, we find that they can fail to generalize to longer strings; we offer a simple remedy to this problem that also improves length generalization in machine translation.",
    "prev": "(2023)does not correctly predict Transformers' out-of-distribution behavior, but our conjecture does.Overall, our work provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers.",
    "curr": "Introduction\n\nLarge language models (LLMs) have shown impressive abilities in natural language generation, reading comprehension, code-synthesis, instruction-following, commonsense reasoning, and many other tasks (Brown et al., 2020;Chen et al., 2021;Chowdhery et al., 2022;Lewkowycz et al., 2022b;Gunasekar et al., 2023;Touvron et al., 2023).However, when evaluated in controlled studies, Transformers often struggle with out-of-distribution generalization (Nogueira et al., 2021;Onta\u00f1\u00f3n et al., 2022;Dziri et al., 2023;Wu et al., 2023;Saparov et al., 2023).It is thus not clear how to reconcile Transformers' seemingly-impressive performance in some settings with their fragility in others.",
    "next": "In this work, we aim to understand when standard decoder-only Transformers can generalize systematically beyond their training distribution.We adopt the approach of recent studies and focus on length generalization on algorithmic tasks as a measure of how well language models can learn to reason (Nogueira et al., 2021;Kim et al., 2021;Anil et al., 2022;Lee et al., 2023;Dziri et al., 2023;Welleck et al., 2022;Liu et al., 2023).Length generalization evaluates the model on problems that Figure 1: a A selection of tasks studied in this paper partitioned by whether they can be s",
    "hard_negative": [
      174799399,
      52967399,
      6628106,
      204512247,
      219708219
    ],
    "easy_negative": [
      13123084,
      227230275,
      8198620
    ]
  },
  {
    "index": 1489,
    "source_corpus_id": 3515219,
    "ref_id": "b16",
    "citation_corpus_id": 8822680,
    "start": 2635,
    "end": 2658,
    "title": "Six Challenges for Neural Machine Translation",
    "abstract": "We explore six challenges for neural machine translation: domain mismatch, amount of training data, rare words, long sentences, word alignment, and beam search. We show both deficiencies and improvements over the quality of phrasebased statistical machine translation.",
    "prev": "Thanks to this, NMT has been reported to significantly improve over SMT both in automatic metrics and human evaluation (Wu et al., 2016).",
    "curr": "Nevertheless, for the same reasons described above, NMT requires a large parallel corpus to be effective, and is known to fail when the training data is not big enough (Koehn & Knowles, 2017).",
    "next": "Unfortunately, the lack of large parallel corpora is a practical problem for the vast majority of language pairs, including low-resource languages (e.g.",
    "hard_negative": [
      216849409,
      10086161,
      2722451,
      11336213,
      1395225,
      1245593,
      146843,
      1557806,
      1785399,
      930231,
      12639289,
      94792,
      13292366,
      14421595,
      905565,
      765547,
      8476273
    ],
    "easy_negative": [
      18508557,
      14945992,
      17078428
    ]
  },
  {
    "index": 1490,
    "source_corpus_id": 227343966,
    "ref_id": "b29",
    "citation_corpus_id": 85498775,
    "start": 2157,
    "end": 2180,
    "title": "Competence-based Curriculum Learning for Neural Machine Translation",
    "abstract": "Current state-of-the-art NMT systems use large neural networks that are not only slow to train, but also often require many heuristics and optimization tricks, such as specialized learning rate schedules and large batch sizes. This is undesirable as it requires extensive hyperparameter tuning. In this paper, we propose a curriculum learning framework for NMT that reduces training time, reduces the need for specialized heuristics or large batch sizes, and results in overall better performance. Our framework consists of a principled way of deciding which training samples are shown to the model at different times during training, based on the estimated difficulty of a sample and the current competence of the model. Filtering training samples in this manner prevents the model from getting stuck in bad local optima, making it converge faster and reach a better solution than the common approach of uniformly sampling training examples. Furthermore, the proposed method can be easily applied to existing NMT models by simply modifying their input data pipelines. We show that our framework can help improve the training time and the performance of both recurrent neural network models and Transformers, achieving up to a 70% decrease in training time, while at the same time obtaining accuracy improvements of up to 2.2 BLEU.",
    "prev": "introduction\n\nInspired by the importance of properly ordering information when teaching humans (Avrahami et al., 1997), curriculum learning (CL) proposes training models by presenting easier examples earlier during training (Elman, 1993;Sanger, 1994;Bengio et al., 2009).",
    "curr": "Previous empirical studies have shown instances where curriculum learning can improve convergence speed and/or generalization in domains such as natural language processing (Cirik et al., 2016;Platanios et al., 2019), computer vision (Pentina et al., 2015;Sarafianos et al., 2017;Guo et al., 2018;, and neural evolutionary computing (Zaremba & Sutskever, 2014).",
    "next": "In contrast to curriculum learning, anti-curriculum learning selects the most difficult examples first and gradually exposes the model to easier ones.",
    "hard_negative": [
      65455367,
      52100117,
      4410027,
      1302329,
      12639289,
      13747425,
      931054,
      9460719,
      8197231,
      11212020,
      2383221,
      26468344
    ],
    "easy_negative": [
      218973946,
      243865423,
      233295981
    ]
  },
  {
    "index": 1492,
    "source_corpus_id": 252992876,
    "ref_id": "b10",
    "citation_corpus_id": 231592390,
    "start": 3465,
    "end": 3485,
    "title": "Published as a conference paper at ICLR 2021 UNLEARNABLE EXAMPLES: MAKING PERSONAL DATA UNEXPLOITABLE",
    "abstract": "The volume of \"free\" data on the internet has been key to the current success of deep learning. However, it also raises privacy concerns about the unauthorized exploitation of personal data for training commercial models. It is thus crucial to develop methods to prevent unauthorized data exploitation. This paper raises the question: can data be made unlearnable for deep learning models? We present a type of error-minimizing noise that can indeed make training examples unlearnable. Error-minimizing noise is intentionally generated to reduce the error of one or more of the training example(s) close to zero, which can trick the model into believing there is \"nothing\" to learn from these example(s). The noise is restricted to be imperceptible to human eyes, and thus does not affect normal data utility. We empirically verify the effectiveness of error-minimizing noise in both samplewise and class-wise forms. We also demonstrate its flexibility under extensive experimental settings and practicability in a case study of face recognition. Our work establishes an important first step towards making personal data unexploitable to deep learning models.The development of unlearnable examples should take full advantage of the unique characteristics, and more importantly, the weaknesses of DNNs. One well-studied characteristic of DNNs is that they tend to capture more of the high-frequency components of the data . Surprisingly, \u2020 Correspondence to: Xingjun Ma Learned-Miller. Labeled faces in the wild: A database forstudying face recognition in unconstrained environments. 2008.",
    "prev": "However, they also have the potential risk of privacy leakage.",
    "curr": "Thus, growing efforts (Huang et al., 2020;Fowl et al., 2021) have been made on protecting data from unauthorized usage by making the data samples unlearnable (Huang et al., 2020;Fowl et al., 2021;He et al., 2022).",
    "next": "In these methods, they generate the unlearnable examples by injecting imperceptible \"shortcut\" perturbation.",
    "hard_negative": [
      211126665,
      6628106,
      1248661,
      3162051,
      14337532
    ],
    "easy_negative": [
      261175933,
      3012890,
      10164978
    ]
  },
  {
    "index": 1495,
    "source_corpus_id": 247570285,
    "ref_id": "b5",
    "citation_corpus_id": 1066490,
    "start": 2307,
    "end": 2330,
    "title": "Demographic Dialectal Variation in Social Media: A Case Study of African-American English",
    "abstract": "Though dialectal language is increasingly abundant on social media, few resources exist for developing NLP tools to handle such language. We conduct a case study of dialectal language in online conversational text by investigating African-American English (AAE) on Twitter. We propose a distantly supervised model to identify AAE-like language from demographics associated with geo-located messages, and we verify that this language follows well-known AAE linguistic phenomena. In addition, we analyze the quality of existing language identification and dependency parsing tools on AAE-like text, demonstrating that they perform poorly on such text compared to text associated with white speakers. We also provide an ensemble classifier for language identification which eliminates this disparity and release a new corpus of tweets containing AAE-like language.Data and software resources are available at:, it calculates a unigram language model that sums to one across the vocabulary. This hints at a more complete modeling approach ( \u00a72.3). 6  To build the vocabulary, we select all words used by at least 20 different users, resulting in 191,873 unique words; other words are mapped to an out-of-vocabulary symbol.",
    "prev": "1\n\nINTRODUCTION\n\nIt is well acknowledged that modern neural network based machine learning models tend to underperform when they are evaluated on data distributions that differ from the one they were trained on.",
    "curr": "For example, machine learning model performance has been observed to degrade under train-test mismatch in topics (Gururangan et al., 2020), demographics (Blodgett et al., 2016;Amodei et al., 2016;Hovy & S\u00f8gaard, 2015;Grother et al., 2019), geographic regions , and even data collection processes (Beery et al., 2018;Zech et al., 2018;Michel & Neubig, 2018).",
    "next": "In particular, these models often perform poorly when evaluated on subpopulations, domains that are present but underrepresented in their training data , and they can latch on to spurious correlations (McCoy et al., 2019).",
    "hard_negative": [
      10914266,
      995282,
      17640698
    ],
    "easy_negative": [
      5543346,
      219792208,
      249062609
    ]
  },
  {
    "index": 1497,
    "source_corpus_id": 258332176,
    "ref_id": "b20",
    "citation_corpus_id": 211842237,
    "start": 8400,
    "end": 8404,
    "title": "Published as a conference paper at ICLR 2020 DIRECTIONAL MESSAGE PASSING FOR MOLECULAR GRAPHS",
    "abstract": "Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes). They do not, however, consider the spatial direction from one atom to another, despite directional information playing a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions and spherical harmonics to construct theoretically well-founded, orthogonal representations that achieve better performance than the currently prevalent Gaussian radial basis representations while using fewer than 1 /4 of the parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 76 % on MD17 and by 31 % on QM9. Our implementation is available online. 1 1 https://www.daml.in.tum.de/dimenet arXiv:2003.03123v2 [cs.LG] 5 Apr 2022Published as a conference paper at ICLR 2020 embeddings are equivariant with respect to the above transformations since the directions move with the molecule. Hence, they preserve the relative directional information between neighboring atoms. We propose to let message embeddings interact based on the distance between atoms and the angle between directions. Both distances and angles are invariant to translation, rotation, and inversion of the molecule, as required. Additionally, we show that the distance and angle can be jointly represented in a principled and effective manner by using spherical Bessel functions and spherical harmonics. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet can learn both molecular properties and atomic forces. It is twice continuously differentiable and solely based on the atom types and coordinates, which are essential properties for performing molecular dynamics simulations. DimeNet outperforms previous GNNs on average by 76 % on MD17 and by 31 % on QM9. Our paper's main contributions are:",
    "prev": "Recent advances of this category [4,16,3] introduced higher-order spherical harmonic tensors and significantly improved the performance.",
    "curr": "Another major type of EGNNs adopted equivariance or invariance by scalarizing vectorial features, which was first introduced by SchNet [43] and later developed to DimeNet [21], SphereNet [37] and GemNet [20], with increasingly comprehensive geometric information encoded with spherical harmonics.",
    "next": "Moreover, PaiNN [41] and TorchMD-NET [45] focused on iteratively updating scalar and vector features, and recently proposed ViSNet [49] further extended the idea of PaiNN by including the runtime geometric computation (RGC) and the corresponding vector-scalar interactive message passing (ViS-MP) to form a complete representation of molecule structures with lower computational cost.",
    "hard_negative": [
      65455367,
      3144218,
      85457862,
      21731691,
      7060599
    ],
    "easy_negative": [
      259370875,
      86840468,
      259376763
    ]
  },
  {
    "index": 1498,
    "source_corpus_id": 84591,
    "ref_id": "b1",
    "citation_corpus_id": 11212020,
    "start": 1754,
    "end": 1757,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "After training these models on a massive database of image-label pairs like ImageNet [26], the network easily adapts to a variety of similar visual tasks, achieving impressive results on image classification [5,25,32] or localization [9,21] tasks.",
    "curr": "In other perceptual domains such as natural language processing or speech recognition, deep networks have proven highly effective as well [2,12,28,30].",
    "next": "However, all of these recent results rely on a supervisory signal from large-scale databases of hand-labeled data, ignoring much of the useful information present in the structure of the data itself.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      252357948,
      219303746,
      222177426
    ]
  },
  {
    "index": 1499,
    "source_corpus_id": 226278023,
    "ref_id": "b11",
    "citation_corpus_id": 108296442,
    "start": 5119,
    "end": 5137,
    "title": "THE NEURO-SYMBOLIC CONCEPT LEARNER: INTERPRETING SCENES, WORDS, AND SENTENCES FROM NATURAL SUPERVISION",
    "abstract": "We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and reading paired questions and answers. Our model builds an object-based scene representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neuro-symbolic reasoning module that executes these programs on the latent scene representation. Analogical to human concept learning, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use curriculum learning to guide the searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval.",
    "prev": "We test D3DP-Nets in few-shot concept learning, visual question answering (VQA) and scene generation.",
    "curr": "We train concept classifiers for object shapes, object colors/materials, and spatial relationships on our inferred disentangled feature spaces, and show they outperform current stateof-the-art (Mao et al., 2019;Hu et al., 2016), which use 2D representations.",
    "next": "We show that a VQA modular network that incorporates our concept classifiers shows improved generalization over the state-of-the-art (Mao et al., 2019) with dramatically fewer examples.",
    "hard_negative": [
      3130692,
      5590763,
      13276568,
      15412473
    ],
    "easy_negative": [
      16987118,
      2593326,
      231662233
    ]
  },
  {
    "index": 1506,
    "source_corpus_id": 49299039,
    "ref_id": "b9",
    "citation_corpus_id": 3568073,
    "start": 3397,
    "end": 3418,
    "title": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024 2 . We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.",
    "prev": "(Yeh et al., 2017) showed how a latent model trained with GAN can be used to perform inpainting of tightly-cropped 64 \u00d7 64 face images.",
    "curr": "Below, we show that such models trained with GANs cannot generalize to higher resolution (eventhough GAN-based systems are now able to obtain high-quality samples at high resolutions (Karras et al., 2018)).",
    "next": "We argue that it is the limited dimensionality of the latent space in GANs and other existing latent models that precludes them from spanning the space of high-resolution natural images.",
    "hard_negative": [
      18828233,
      6628106
    ],
    "easy_negative": [
      18472030,
      16724841,
      14329203
    ]
  },
  {
    "index": 1507,
    "source_corpus_id": 58006691,
    "ref_id": "b28",
    "citation_corpus_id": 10565222,
    "start": 1854,
    "end": 1871,
    "title": "A Network-based End-to-End Trainable Task-oriented Dialogue System",
    "abstract": "Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing taskoriented dialogue systems requires creating multiple components and typically this involves either a large amount of handcrafting, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we introduce a neural network-based text-in, textout end-to-end trainable goal-oriented dialogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue systems easily and without making too many assumptions about the task at hand. The results show that the model can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain.",
    "prev": "INTRODUCTION\n\nTask-oriented dialogue systems aim to achieve specific user goals such as restaurant reservation or navigation inquiry within a limited dialogue turns via natural language.",
    "curr": "Traditional pipeline solutions are composed of natural language understanding, dialogue management and natural language generation (Young et al., 2013;Wen et al., 2017), where each module is designed separately and expensively.",
    "next": "In order to reduce human effort and scale up between domains, end-to-end dialogue systems, which input plain text and directly output system responses, have shown promising results based on recurrent neural networks (Zhao et al., 2017;Lei et al., 2018) and memory networks (Sukhbaatar et al., 2015).",
    "hard_negative": [
      7356547,
      6401679,
      14434979,
      1139492,
      7597872,
      8443958,
      6508854,
      1306065,
      7287895,
      9672033,
      5590763,
      739696
    ],
    "easy_negative": [
      254926545,
      65059243,
      229365664
    ]
  },
  {
    "index": 1515,
    "source_corpus_id": 252735209,
    "ref_id": "b20",
    "citation_corpus_id": 236635379,
    "start": 23986,
    "end": 24007,
    "title": "PERCEIVER IO: A GENERAL ARCHITECTURE FOR STRUCTURED INPUTS & OUTPUTS",
    "abstract": "A central goal of machine learning is the development of systems that can solve many problems in as many data domains as possible. Current architectures, however, cannot be applied beyond a small set of stereotyped settings, as they bake in domain & task assumptions or scale poorly to large inputs or outputs. In this work, we propose Perceiver IO, a general-purpose architecture that handles data from arbitrary settings while scaling linearly with the size of inputs and outputs. Our model augments the Perceiver with a flexible querying mechanism that enables outputs of various sizes and semantics, doing away with the need for task-specific architecture engineering. The same architecture achieves strong results on tasks spanning natural language and visual understanding, multi-task and multi-modal reasoning, and StarCraft II. As highlights, Perceiver IO outperforms a Transformer-based BERT baseline on the GLUE language benchmark despite removing input tokenization and achieves state-of-the-art performance on Sintel optical flow estimation with no explicit mechanisms for multiscale correspondence.Is the development of problem-specific models for each new set of inputs and outputs unavoidable? Life would be drastically simpler if a single neural network architecture could handle a wide variety of both input modalities and output tasks. In this work, we propose such an architecture, with the ultimate goal of building a network that can easily integrate and transform arbitrary information for arbitrary tasks. Our starting point is the Perceiver(Jaegle et al., 2021), an architecture which has demonstrated a remarkable ability to handle data from many modalities with no changes to the network architecture. The Perceiver uses attention to map inputs of a wide range of modalities to a fixed-size latent space that is further processed by a deep, fully attentional network. This process decouples the bulk of the network's processing from the size and modality-specific details of the input, allowing it to scale to large and multimodal data.But the Perceiver can only handle simple output spaces like classification. Much of the complexity of real-world tasks comes from the variety, size, and structure of their outputs, and in this regard i arXiv:2107.14795v3 [cs.LG] Gong. VATT: Transformers for multimodal self-supervised learning from raw video, audio and text.. A naturalistic open source movie for optical flow evaluation. . CANINE: pre-training an efficient tokenization-free encoder for language representation. Transactions of the Association for Computational Linguistics, 10:73-91, 2022.Ronan Collobert and Jason Weston. A unified architecture for natural language processing: Deep neural networks with multitask learning. . Sim2real transfer learning for 3D human pose estimation: motion to the rescue. . Learning to estimate hidden motions with global motion aggregation. . Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020.Iasonas Kokkinos. Ubernet: Training a universal convolutional neural network for low-, mid-, and high-level vision using diverse datasets and limited memory.",
    "prev": "F t consists of L slots {l 0 , l 1 , ..l L\u22121 }, each of dimension d l so that F t \u2208 R L\u00d7d l .",
    "curr": "The messages in M \u2032 t compete with each other to write into each KS's state slot via a cross-attention mechanism.The query, in this case, is a linear projection of the F t , i.e., Q = F t W q , whereas the keys and values are linear projections of the messages M \u2032 t .KS state is updated as:\nF t \u2190 softmax Q(M \u2032 t W e ) T \u221a de M \u2032 t W v\nAfter this, self-attention is applied to the KS using a transformer encoder tower constituting a Perceiver-IO architecture (Jaegle et al., 2022).",
    "next": "Step 3: Reading from the Knowledge Source.The KS makes the updated state available to the agents should they deem to use it.We again utilize cross attention to perform the reading operation.",
    "hard_negative": [
      235624202,
      6954272,
      1957433,
      5034059,
      14337532
    ],
    "easy_negative": [
      7478643,
      15401237,
      256461226
    ]
  },
  {
    "index": 1517,
    "source_corpus_id": 211069110,
    "ref_id": "b33",
    "citation_corpus_id": 11591887,
    "start": 2045,
    "end": 2064,
    "title": "OFFLINE BILINGUAL WORD VECTORS, ORTHOGONAL TRANSFORMATIONS AND THE INVERTED SOFTMAX",
    "abstract": "Usually bilingual word vectors are trained \"online\".Mikolov et al. (2013a)showed they can also be found \"offline\"; whereby two pre-trained embeddings are aligned with a linear transformation, using dictionaries compiled from expert knowledge. In this work, we prove that the linear transformation between two spaces should be orthogonal. This transformation can be obtained using the singular value decomposition. We introduce a novel \"inverted softmax\" for identifying translation pairs, with which we improve the precision @1 of Mikolov's original mapping from 34% to 43%, when translating a test set composed of both common and rare English words into Italian. Orthogonal transformations are more robust to noise, enabling us to learn the transformation without expert bilingual signal by constructing a \"pseudo-dictionary\" from the identical character strings which appear in both languages, achieving 40% precision on the same test set. Finally, we extend our method to retrieve the true translations of English sentences from a corpus of 200k Italian sentences with a precision @1 of 68%.",
    "prev": "Embedding alignment was originally studied for word vectors with the goal of enabling cross-lingual transfer, where the embeddings for two languages are in alignment if word translations, e.g.",
    "curr": "cat and Katze, have similar representations (Mikolov et al., 2013a;Smith et al., 2017).",
    "next": "Recently, large pretrained models have largely subsumed word vectors based on their accuracy on downstream tasks, partly due to the fact that their word representations are context-dependent, allowing them to more richly capture the meaning of a word (Peters et al., 2018;Howard & Ruder, 2018;Radford et al., 2018;Devlin et al., 2018).",
    "hard_negative": [
      874413,
      931054,
      7185434
    ],
    "easy_negative": [
      12295680,
      7259581,
      14596755
    ]
  },
  {
    "index": 1518,
    "source_corpus_id": 264439306,
    "ref_id": "b25",
    "citation_corpus_id": 3144218,
    "start": 47282,
    "end": 47304,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "., p}, where r is the perturbation rate and |E| is the number of edges.Detailed choices of p for each dataset in attacking group/individual fairness are summarized in Table 4.",
    "curr": "Training the victim model.We use a fixed list of random seed ([0, 1, 2, 42, 100]) to train each victim model 5 times and report the mean and standard deviation.Regarding the victim models in group fairness attacks, we train a 2-layer GCN (Kipf & Welling, 2017) for 400 epochs and a 2-layer FairGNN (Dai & Wang, 2021) for 2000 epochs to evaluate the efficacy of fairness attacks.The hidden dimension, learning rate, weight decay and dropout rate of GCN and FairGNN are set to 128, 1e \u2212 3, 1e \u2212 5 and 0.5, respectively.The regularization parameters in FairGNN, namely \u03b1 and \u03b2, are set to 100 and 1 for all datasets, respectively.Regarding the victim models in individual fairness attacks, we train a 2-layer GCN (Kipf & Welling, 2017) and 2-layer InFoRM-GNN (Kang et al., 2020;Dong et al., 2021) for 400 epochs.The hidden dimension, learning rate, weight decay and dropout rate of GCN and InFoRM-GNN are set to 128, 1e \u2212 3, 1e \u2212 5 and 0.5, respectively.The regularization parameter in InFoRM-GNN is set to 0.1 for all datasets.",
    "next": "E ADDITIONAL EXPERIMENTAL RESULTS: ATTACKING STATISTICAL PARITY ON GRAPH NEURAL NETWORKS\n\nA -FATE with FairGNN as the victim model.Here, we study how robust FairGNN is in fairness attacks against statistical parity with linear GCN a",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      2991926,
      920580,
      5039661
    ]
  },
  {
    "index": 1519,
    "source_corpus_id": 235266159,
    "ref_id": "b69",
    "citation_corpus_id": 231632202,
    "start": 1959,
    "end": 1962,
    "title": "Published as a conference paper at ICLR 2021 FREE LUNCH FOR FEW-SHOT LEARNING: DISTRIBUTION CALIBRATION",
    "abstract": "Learning from a limited number of samples is challenging since the learned model can easily become overfitted based on the biased distribution formed by only a few training examples. In this paper, we calibrate the distribution of these fewsample classes by transferring statistics from the classes with sufficient examples. Then an adequate number of examples can be sampled from the calibrated distribution to expand the inputs to the classifier. We assume every dimension in the feature representation follows a Gaussian distribution so that the mean and the variance of the distribution can borrow from that of similar classes whose statistics are better estimated with an adequate number of samples. Our method can be built on top of off-the-shelf pretrained feature extractors and classification models without extra parameters. We show that a simple logistic regression classifier trained using the features sampled from our calibrated distribution can outperform the state-of-the-art accuracy on three datasets (5% improvement on miniImageNet compared to the next best). The visualization of these generated features demonstrates that our calibrated distribution is an accurate estimation.",
    "prev": "Experiments demonstrate that the proposed method is superior to baselines and robust to a broad range of label noise types.",
    "curr": "Introduction\n\nLearning with noisy labels is one of the most challenging problems in weakly-supervised learning, since noisy labels are ubiquitous in the real world [40,74,45,1,70].",
    "next": "For instance, both crowdsourcing and web crawling yield large numbers of noisy labels everyday [15].",
    "hard_negative": [
      3507990,
      49868626
    ],
    "easy_negative": [
      10123739,
      11674476,
      202577934
    ]
  },
  {
    "index": 1526,
    "source_corpus_id": 250243971,
    "ref_id": "b19",
    "citation_corpus_id": 11816014,
    "start": 2256,
    "end": 2280,
    "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
    "abstract": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com.",
    "prev": "Moreover, the evaluation of compressing an already compact model shows our method can further reduce 9% to 30% parameters with an insignificant impact on task accuracy.",
    "curr": "INTRODUCTION\n\nLanguage models built with transformers (Devlin et al., 2018) have attained extensive success in natural language tasks such as language modeling (Radford et al., 2018), text classification (Wang et al., 2018), question answering (Rajpurkar et al., 2016), and summarization (Liu, 2019).",
    "next": "The success is achieved by fine-tuning a big transformer model pre-trained with a large corpus.",
    "hard_negative": [
      6360322,
      2337034,
      15425307,
      9846946,
      428579,
      8764466,
      14071482,
      1199934,
      8471750,
      1373518,
      12451537,
      2100831,
      15197674,
      5541486,
      226541,
      14915449,
      252796
    ],
    "easy_negative": [
      680537,
      219310262,
      239890020
    ]
  },
  {
    "index": 1527,
    "source_corpus_id": 264426355,
    "ref_id": "b5",
    "citation_corpus_id": 248986755,
    "start": 4284,
    "end": 4306,
    "title": "Instruction Induction: From Few Examples to Natural Language Task Descriptions",
    "abstract": "Large language models are able to perform a task by conditioning on a few input-output demonstrations -a paradigm known as incontext learning. We show that language models can explicitly infer an underlying task from a few demonstrations by prompting them to generate a natural language instruction that fits the examples. To explore this ability, we introduce the instruction induction challenge, compile a dataset consisting of 24 tasks, and define a novel evaluation metric based on executing the generated instruction. We discover that, to a large extent, the ability to generate instructions does indeed emerge when using a model that is both large enough and aligned to follow instructions; InstructGPT achieves 65.7% of human performance in our execution-based metric, while the original GPT-3 model reaches only 9.8% of human performance. This surprising result suggests that instruction induction might be a viable learning paradigm in and of itself, where instead of fitting a set of latent continuous parameters to the data, one searches for the best description in the natural language hypothesis space. 1",
    "prev": "hodologies exhibit significant drawbacks.Many prompting methods are ad hoc because of their human-in-the-loop development paradigm.In such a process, given a target task, we first draft an initial prompt.Then, we refine the prompt using techniques such as chain-of-thought, few-shot demonstrations, and coding-style problem descriptions (Wei et al., 2022c,a;Gao et al., 2023) based on the model's performance on the target task.We note that in practice, a hand-crafted prompt optimized for one task rarely translates to satisfactory performance in another task (Zhang et al., 2023).Therefore, each task becomes a new expedition, with its own set of trials, errors, and validations.Such an ad hoc human-in-the-loop development procedure introduces extensive human labor requirements, which significantly hinder the applicability of LLMs in real-world applications.",
    "curr": "Existing works develop algorithms to automatically generate prompts instead of relying on ad hoc human optimization (Shin et al., 2020;Honovich et al., 2022;Zhou et al., 2022).However, these methods often lack feedback loops, such that the refinement procedure essentially performs a random search.For example, in each refinement iteration, Zhou et al.",
    "next": "(2022) simply rephrases the prompt into multiple candidates, and then select the candidate that yields the best performance as the refined prompt.Note that such a procedure fails to learn from past successes and failures, such that refined prompt does not enrich the original prompt with additional context.",
    "hard_negative": [
      2924682,
      5034059,
      4421747,
      990233
    ],
    "easy_negative": [
      503164,
      232021938,
      13840496
    ]
  },
  {
    "index": 1528,
    "source_corpus_id": 259341801,
    "ref_id": "b10",
    "citation_corpus_id": 252715594,
    "start": 3168,
    "end": 3172,
    "title": "PHENAKI: VARIABLE LENGTH VIDEO GENERATION FROM OPEN DOMAIN TEXTUAL DESCRIPTIONS",
    "abstract": "We present Phenaki, a model capable of realistic video synthesis, given a sequence of textual prompts. Generating videos from text is particularly challenging due to the computational cost, limited quantities of high quality text-video data and variable length of videos. To address these issues, we introduce a new model for learning video representation which compresses the video to a small representation of discrete tokens. This tokenizer uses causal attention in time, which allows it to work with variable-length videos. To generate video tokens from text we are using a bidirectional masked transformer conditioned on pre-computed text tokens. The generated video tokens are subsequently de-tokenized to create the actual video. To address data issues, we demonstrate how joint training on a large corpus of image-text pairs as well as a smaller number of video-text examples can result in generalization beyond what is available in the video datasets. Compared to the previous video generation methods, Phenaki can generate arbitrary long videos conditioned on a sequence of prompts (i.e. time variable text or a story) in open domain. To the best of our knowledge, this is the first time a paper studies generating videos from time variable prompts. In addition, compared to the perframe baselines, the proposed video encoder-decoder computes fewer tokens per video but results in better spatio-temporal consistency. \u2021 Equal contribution.",
    "prev": "Additional samples are provided Appendices C and D.\n\n1 Introduction 1.1 Generative models are training on synthetic data from generative models Due to rapid advances in generative artificial intelligence (AI), synthetic data of all kinds is rapidly proliferating.",
    "curr": "Publicly available generative models have not only revolutionized the image, audio, and text domains [2][3][4][5][6][7][8][9], but they are also starting to impact the creation of videos, 3D models, graphs, tables, software, and even websites [10][11][12][13][14][15].",
    "next": "Companies like Google, Microsoft, and Shutterstock are incorporating generative models into their consumer services, and the output from these services and popular generative models like Stable Diffusion [2] (for images) and ChatGPT [16] (for text) tend to end up on the Internet.",
    "hard_negative": [
      6628106,
      174802916,
      238582653
    ],
    "easy_negative": [
      5603500,
      254069490,
      52154441
    ]
  },
  {
    "index": 1531,
    "source_corpus_id": 263909329,
    "ref_id": "b51",
    "citation_corpus_id": 252815378,
    "start": 9646,
    "end": 9668,
    "title": "Fine-tuned Language Models are Continual Learners",
    "abstract": "Recent work on large language models relies on the intuition that most natural language processing tasks can be described via natural language instructions and that models trained on these instructions show strong zero-shot performance on several standard datasets. However, these models even though impressive still perform poorly on a wide range of tasks outside of their respective training and evaluation sets. To address this limitation, we argue that a model should be able to keep extending its knowledge and abilities, without forgetting previous skills. In spite of the limited success of Continual Learning we show that Fine-tuned Language Models can be continual learners. We empirically investigate the reason for this success and conclude that Continual Learning emerges from self-supervision pre-training. Our resulting model Continual-T0 (CT0) is able to learn 8 new diverse language generation tasks, while still maintaining good performance on previous tasks, spanning in total 70 datasets. Finally, we show that CT0 is able to combine instructions in ways it was never trained for, demonstrating some level of instruction compositionality.",
    "prev": "ation methods for neural networks, primarily focusing on regulating the norm of network parameters (Glorot & Bengio, 2010;He et al., 2015).Theoretical works try to study these methods through dynamical isometry (Saxe et al., 2013) or mean field theory (Poole et al., 2016).Orthogonal initialization, which supports layer-wise dynamical isometry in fully-connected layers, has been extended to CNNs via Delta orthogonal initialization (Xiao et al., 2018).However, there has been limited research on initialization methods specifically for Transformers.Most of these works focus on theoretical approaches to train Transformers without skip connections or normalization layers (Noci et al., 2022;He et al., 2023).Mimetic initialization (Trockman & Kolter, 2023) seeks to initialize attention based on the principles of pre-trained Transformers.",
    "curr": "Continual pre-training.Recent research explores adapting pre-trained networks for new or improved datasets.While some target datasets from different domains (Scialom et al., 2022;Ke et al., 2022;Gupta et al., 2023;Qin et al., 2022), others focus on datasets that evolve over time (Han et al., 2020;Jang et al., 2021;Loureiro et al., 2022).Model expansion is similar to continual pre-training, with the distinction being a change in the model size rather than the data distribution.",
    "next": "PRELIMINARIES\n\nModel expansion aims to initialize a large model with the weights from its smaller pre-trained counterparts.Concretely, suppose we have pre-trained weights \u03b8 S in a source network f S (\u2022; \u03b8 trained\n\n\nS\n\n), our goal is to design a mapping \u03b8 expanded An example for model expansion is to use a pre-trained ResNet-18 (He et al., 2016) or BERT-Small (f S ) to facilitate the training of ResNet-50 or BERT-Base (f T ), respectively.Instead of training the larger models from scratch, the idea is to initialize them with the weights of their smaller pre-trained counterparts, i.e., ResNet-18 or BERT-Small, respectively.",
    "hard_negative": [
      221749248,
      237416585,
      229924005,
      195069365,
      964287,
      235097666,
      207847382,
      218470237,
      227231454,
      248512744,
      209475822,
      196170479,
      250164478,
      225067135
    ],
    "easy_negative": [
      672106,
      2408119,
      249204420
    ]
  },
  {
    "index": 1532,
    "source_corpus_id": 264487385,
    "ref_id": "b48",
    "citation_corpus_id": 219531522,
    "start": 1858,
    "end": 1875,
    "title": "FASTSPEECH 2: FAST AND HIGH-QUALITY END-TO- END TEXT TO SPEECH",
    "abstract": "Non-autoregressive text to speech (TTS) models such as FastSpeech(Ren et al., 2019)can synthesize speech significantly faster than previous autoregressive models with comparable quality. The training of FastSpeech model relies on an autoregressive teacher model for duration prediction (to provide more information as input) and knowledge distillation (to simplify the data distribution in output), which can ease the one-to-many mapping problem (i.e., multiple speech variations correspond to the same text) in TTS. However, FastSpeech has several disadvantages: 1) the teacher-student distillation pipeline is complicated and time-consuming, 2) the duration extracted from the teacher model is not accurate enough, and the target mel-spectrograms distilled from teacher model suffer from information loss due to data simplification, both of which limit the voice quality. In this paper, we propose FastSpeech 2, which addresses the issues in FastSpeech and better solves the one-to-many mapping problem in TTS by 1) directly training the model with ground-truth target instead of the simplified output from teacher, and 2) introducing more variation information of speech (e.g., pitch, energy and more accurate duration) as conditional inputs. Specifically, we extract duration, pitch and energy from speech waveform and directly take them as conditional inputs in training and use predicted values in inference. We further design FastSpeech 2s, which is the first attempt to directly generate speech waveform from text in parallel, enjoying the benefit of fully end-to-end inference. Experimental results show that 1) FastSpeech 2 achieves a 3x training speed-up over FastSpeech, and FastSpeech 2s enjoys even faster inference speed; 2) FastSpeech 2 and 2s outperform FastSpeech in voice quality, and Fast-Speech 2 can even surpass autoregressive models. Audio samples are available at https://speechresearch.github.io/fastspeech2/. * Authors contribute equally to this work. \u2020 Corresponding author arXiv:2006.04558v8 [eess.AS] 8 Aug 2022 2019). They usually suffer from slow inference speed and robustness (word skipping and repeating) issues(Ren et al., 2019;Chen et al., 2020). In recent years, non-autoregressive TTS models(Ren et al., 2019;\u0141a\u0144cucki, 2020;Lim et al., 2020;Miao et al., 2020;are designed to address these issues, which generate mel-spectrograms with extremely fast speed and avoid robustness issues, while achieving comparable voice quality with previous autoregressive models.Among those non-autoregressive TTS methods, FastSpeech (Ren et al., 2019) is one of the most successful models. FastSpeech designs two ways to alleviate the one-to-many mapping problem: 1) Reducing data variance in the target side by using the generated mel-spectrogram from an autoregressive teacher model as the training target (i.e., knowledge distillation). 2) Introducing the duration information (extracted from the attention map of the teacher model) to expand the text sequence to match the length of the mel-spectrogram sequence. While these designs in FastSpeech ease the learning of the one-to-many mapping problem (see Section 2.1) in TTS, they also bring several disadvantages: 1) The two-stage teacher-student training pipeline makes the training process complicated.2) The target mel-spectrograms generated from the teacher model have some information loss 1 compared with the ground-truth ones, since the quality of the audio synthesized from the generated mel-spectrograms is usually worse than that from the ground-truth ones.3) The duration extracted from the attention map of teacher model is not accurate enough.",
    "prev": "odel can be adapted to different downstream tasks with strong performance.Specifically, we pre-trained a generative model, named SpeechFlow, on 60k hours of untranscribed speech with Flow Matching and masked conditions.Experiment results show the pre-trained generative model can be fine-tuned with task-specific data to match or surpass existing expert models on speech enhancement, separation, and synthesis.Our work suggested a foundational model for generation tasks in speech can be built with generative pre-training.",
    "curr": "INTRODUCTION\n\nDiscriminative models have long been the mainstream in speech applications since the deep learning era.These models are applied to different types of tasks such as speech recognition (Graves et al., 2006), enhancement, and separation (Luo & Mesgarani, 2019).Interestingly, even for applications that can be naturally formulated as generative modeling problems, such as text-to-speech (TTS), we see most popular models remained discriminative (Shen et al., 2018;Ren et al., 2021).Consequentially, pre-trained foundation models (Baevski et al., 2020;Hsu et al., 2021) that served as the upstream of speech applications focused more on learning useful representation for discriminative tasks rather than modeling the data distribution p(speech).In this paper, we seek to answer whether generative models can serve as foundation models for speech applications or not.",
    "next": "Unlike discriminative models, generative models enable sampling of the data distribution.For example, generative TTS models (Habib et al., 2019) allow different emotions to be sampled given a fixed text as discriminative models produce a fixed output.Up to the present, generative models in speech are usually designed for a given purpose via task-specific conditioning or distribution mapping.Perhaps the most well-known examples of task-specific conditional generative models are neural vocoders (Kong et al., 2020;Chen et al., 2020).These models learn to map simple priors (e.g., normal distribution) to wavefo",
    "hard_negative": [
      49882757,
      26100519,
      232075892
    ],
    "easy_negative": [
      174799871,
      23504342,
      16693857
    ]
  },
  {
    "index": 1538,
    "source_corpus_id": 252716013,
    "ref_id": "b41",
    "citation_corpus_id": 165163607,
    "start": 25909,
    "end": 25935,
    "title": "BoolQ: Exploring the Surprising Difficulty of Natural Yes/No Questions",
    "abstract": "In this paper we study yes/no questions that are naturally occurring -meaning that they are generated in unprompted and unconstrained settings. We build a reading comprehension dataset, BoolQ, of such questions, and show that they are unexpectedly challenging. They often query for complex, non-factoid information, and require difficult entailment-like inference to solve. We also explore the effectiveness of a range of transfer learning baselines. We find that transferring from entailment data is more effective than transferring from paraphrase or extractive QA data, and that it, surprisingly, continues to be very beneficial even when starting from massive pre-trained language models such as BERT. Our best method trains BERT on MultiNLI and then re-trains it on our train set. It achieves 80.4% accuracy compared to 90% accuracy of human annotators (and 62% majority-baseline), leaving a significant gap for future work.",
    "prev": "We aim to validate whether AMA provides consistent lift across diverse tasks (Section 5.1), works across model families (Section 5.2), and reliably aggregates the predictions across prompts (Section 5.3).",
    "curr": "Experimental details We use a diverse set of tasks: SuperGLUE [Wang et al., 2019], NLI [Mostafazadeh et al., 2017, Nie et al., 2020, classification [Zhang et al., 2015, Socher et al., 2013, He and McAuley, 2016, and QA tasks [Kasai et al., 2022, Kwiatkowski et al., 2019, Berant et al., 2013, Dua et al., 2019.",
    "next": "For all tasks, we compare to published results of the OpenAI few-shot-prompted GPT3-175B parameter model using the numbers reported in  and, for classification tasks, Zhao et al.",
    "hard_negative": [
      3178759,
      9192723,
      8535316,
      8495258,
      52055325,
      7228830,
      52019251,
      34032948,
      3626819,
      52183757,
      11816014,
      52123220,
      52165754
    ],
    "easy_negative": [
      204748627,
      7467486,
      16837656
    ]
  },
  {
    "index": 1539,
    "source_corpus_id": 3861760,
    "ref_id": "b16",
    "citation_corpus_id": 252796,
    "start": 23601,
    "end": 23622,
    "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
    "abstract": "There is a growing consensus that significant, rapid progress can be made in both text understanding and spoken language understanding by investigating those phenomena that occur most centrally in naturally occurring unconstrained materials and by attempting to automatically extract information about language from very large corpora. Such corpora are beginning to serve as important research tools for investigators in natural language processing, speech recognition, and integrated spoken language systems, as well as in theoretical linguistics. Annotated corpora promise to be valuable for enterprises as diverse as the automatic construction of statistical models for the grammar of the written and the colloquial spoken language, the development of explicit formal theories of the differing grammars of writing and speech, the investigation of prosodic phenomena in speech, and the evaluation and comparison of the adequacy of parsing models.In this paper, we review our experience with constructing one such large annotated corpus--the Penn Treebank, a corpus 1 consisting of over 4.5 million words of American English. During the first three-year phase of the Penn Treebank Project (1989)(1990)(1991)(1992), this corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure. These materials are available to members of the Linguistic Data Consortium; for details, see Section 5.1.The paper is organized as follows. Section 2 discusses the POS tagging task. After outlining the considerations that informed the design of our POS tagset and presenting the tagset itself, we describe our two-stage tagging process, in which text is first assigned POS tags automatically and then corrected by human annotators. Section 3 briefly presents the results of a comparison between entirely manual and semi-automated tagging, with the latter being shown to be superior on three counts: speed, consistency, and accuracy. In Section 4, we turn to the bracketing task. Just as with the tagging task, we have partially automated the bracketing task: the output of",
    "prev": "However, flipout is applicable to a wider variety of architectures, including convolutional nets and RNNs.",
    "curr": "REGULARIZATION FOR LANGUAGE MODELING\n\nWe evaluated the regularization effect of flipout on the character-level and word-level language modeling tasks with the Penn Treebank corpus (PTB) (Marcus et al., 1993).",
    "next": "We compared flipout to several other methods for regularizing RNNs: na\u00efve dropout (Zaremba et al., 2014), variational dropout (Gal & Ghahramani, 2016), recurrent dropout (Semeniuta et al., 2016), zoneout (Krueger et al., 2016), and DropConnect (Merity et al., 2017).",
    "hard_negative": [
      696805,
      3166885,
      2369736,
      12951757,
      5153623,
      2769726
    ],
    "easy_negative": [
      253708049,
      35059437,
      53502621
    ]
  },
  {
    "index": 1541,
    "source_corpus_id": 212945787,
    "ref_id": "b28",
    "citation_corpus_id": 7147309,
    "start": 2536,
    "end": 2558,
    "title": "SEQUENCE LEVEL TRAINING WITH RECURRENT NEURAL NETWORKS",
    "abstract": "Many natural language processing applications use language models to generate text. These models are typically trained to predict the next word in a sequence, given the previous words and some context such as an image. However, at test time the model is expected to generate the entire sequence from scratch. This discrepancy makes generation brittle, as errors may accumulate along the way. We address this issue by proposing a novel sequence level training algorithm that directly optimizes the metric used at test time, such as BLEU or ROUGE. On three different tasks, our approach outperforms several strong baselines for greedy generation. The method is also competitive when these baselines employ beam search, while being several times faster.",
    "prev": "First, the designer of the model needs to specify the order in which tokens are generated.",
    "curr": "Second, at training time the model is conditioned on ground truth context while at test time it is conditioned on its own generations, a discrepancy referred to as exposure bias (Ranzato et al., 2016).",
    "next": "Finally, while heuristics like beam search somewhat help rescore at the sequence level, generation generally lacks long-range coherency because it is produced by the greedy selection of one token at a time without lookahead.",
    "hard_negative": [
      1391785,
      5467830,
      1318875,
      1918428,
      11212020
    ],
    "easy_negative": [
      11226147,
      8687826,
      13986668
    ]
  },
  {
    "index": 1542,
    "source_corpus_id": 252734952,
    "ref_id": "b42",
    "citation_corpus_id": 12718048,
    "start": 2540,
    "end": 2561,
    "title": "A Syntactic Neural Model for General-Purpose Code Generation",
    "abstract": "We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing datadriven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches.",
    "prev": "NL\u2192code models facilitate programming for both professional and inexperienced programmers, by allowing programmers to write code by only expressing their higher-level intent.",
    "curr": "Many existing code generation models either learn directly from input-output pairs provided as training data (Allamanis et al., 2015;Yin and Neubig, 2017;Iyer et al., 2018;Brockschmidt et al., 2019;Xu et al., 2020;Alon et al., 2020;, or learn the mapping between input and output implicitly from naturally occurring corpora of intertwined natural language and code (Austin et al., 2021;Nijkamp et al., 2022).",
    "next": "Nevertheless, all these works assume that all libraries and function calls were seen in the training data; and that at test time, the trained model will need to generate only seen libraries and function calls.",
    "hard_negative": [
      18309765,
      5667590,
      7771402,
      7218315,
      6401679,
      8174613,
      1245593,
      12847003,
      8820379,
      9963298,
      14434979,
      6715185,
      2916543,
      16911296,
      1772097,
      11334348,
      9027681,
      258794,
      340852,
      12401528,
      15412473
    ],
    "easy_negative": [
      16147979,
      247011095,
      259376563
    ]
  },
  {
    "index": 1543,
    "source_corpus_id": 258866127,
    "ref_id": "b7",
    "citation_corpus_id": 247292203,
    "start": 5957,
    "end": 5960,
    "title": "Deep Reinforcement Learning for Entity Alignment",
    "abstract": "Embedding-based methods have attracted increasing attention in recent entity alignment (EA) studies. Although great promise they can offer, there are still several limitations. The most notable is that they identify the aligned entities based on cosine similarity, ignoring the semantics underlying the embeddings themselves. Furthermore, these methods are shortsighted, heuristically selecting the closest entity as the target and allowing multiple entities to match the same candidate. To address these limitations, we model entity alignment as a sequential decision-making task, in which an agent sequentially decides whether two entities are matched or mismatched based on their representation vectors. The proposed reinforcement learning (RL)-based entity alignment framework can be flexibly adapted to most embedding-based EA methods. The experimental results demonstrate that it consistently advances the performance of several state-of-the-art methods, with a maximum improvement of 31.1% on Hits@1.",
    "prev": "To formally prove this idea, we dissect the ELBO in Equation (4) as follows:\nE p \u03b8 (y|x) log p(x, y) p \u03b8 (y|x) = E p \u03b8 (y|x) log p \u03b8 (x|y) \u2212 D KL (p \u03b8 (y|x) \u2225 p(y))(7)\nThe complete derivation can be found in Appendix A.",
    "curr": "Therefore, we have:\nlog p(x) = E p \u03b8 (y|x) log p \u03b8 (x|y) reconstruction term \u2212 D KL (p \u03b8 (y|x) \u2225 p(y)) distribution matching term + D KL (p \u03b8 (y|x) \u2225 p(y|x))\nprediction matching term (8) The first term aims to reconstruct the original embedding x based on y generated from x, which has not been studied by the existing EEA works.",
    "next": "The second term imposes the distribution y conditioned on x to match the prior distribution of y, which has been investigated by the GAN-based EEA methods [9][10][11].",
    "hard_negative": [
      13206339,
      3292002,
      16326763
    ],
    "easy_negative": [
      253762052,
      6225155,
      2302492
    ]
  },
  {
    "index": 1546,
    "source_corpus_id": 248965495,
    "ref_id": "b7",
    "citation_corpus_id": 239049858,
    "start": 12989,
    "end": 13009,
    "title": "SCALABLE ONE-PASS OPTIMISATION OF HIGH-DIMENSIONAL WEIGHT-UPDATE HYPERPARAMETERS BY IMPLICIT DIFFERENTIATION",
    "abstract": "Machine learning training methods depend plentifully and intricately on hyperparameters, motivating automated strategies for their optimisation. Many existing algorithms restart training for each new hyperparameter choice, at considerable computational cost. Some hypergradient-based one-pass methods exist, but these either cannot be applied to arbitrary optimiser hyperparameters (such as learning rates and momenta) or take several times longer to train than their base models. We extend these existing methods to develop an approximate hypergradient-based hyperparameter optimiser which is applicable to any continuous hyperparameter appearing in a differentiable model weight update, yet requires only one training episode, with no restarts. We also provide a motivating argument for convergence to the true hypergradient, and perform tractable gradient-based optimisation of independent learning rates for each model parameter. Our method performs competitively from varied random hyperparameter initialisations on several UCI datasets and Fashion-MNIST (using a one-layer MLP), Penn Treebank (using an LSTM) and CIFAR-10 (using a ResNet-18), in time only 2-3x greater than vanilla training. : A novel banditbased approach to hyperparameter optimization.",
    "prev": "This computation can be done exactly if |A \u03a8adapt | is small, which is the case considered in this paper (as will be discussed in Section 3.4).",
    "curr": "Otherwise, an approximation to the inverse Hessian (e.g., Neumann approximation (Lorraine et al., 2020;Clarke et al., 2022)) could be used, which reduces both the memory and computational complexities to O(|A \u03a8 |).",
    "next": "Combining Equations (4) and (5), we have a recipe for computing the hypergradient d L V /d \u03c8 meta exactly for a single task, as summarized in Algorithm 1.",
    "hard_negative": [
      3508234,
      59551640
    ],
    "easy_negative": [
      237365058,
      237490811,
      113877276
    ]
  },
  {
    "index": 1563,
    "source_corpus_id": 208637449,
    "ref_id": "b30",
    "citation_corpus_id": 3536221,
    "start": 9501,
    "end": 9523,
    "title": "MODEL-ENSEMBLE TRUST-REGION POLICY OPTI- MIZATION",
    "abstract": "Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning. However, they tend to suffer from high sample complexity which hinders their use in real-world domains. Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and, to date, it has succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and we show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks 1 2 .Published as a conference paper at ICLR 2018 assumption in this approach, henceforth termed vanilla model-based RL, is that with enough data, the learned model will be accurate enough, such that a policy optimized on it will also perform well in the real environment.Although vanilla model-based RL can work well on low-dimensional tasks with relatively simple dynamics, we find that on more challenging continuous control tasks, performance was highly unstable. The reason is that the policy optimization tends to exploit regions where insufficient data is available to train the model, leading to catastrophic failures. Previous work has pointed out this issue as model biasWhile this issue can be regarded as a form of overfitting, we emphasize that standard countermeasures from the supervised learning literature, such as regularization or cross validation, are not sufficient here -supervised learning can guarantee generalization to states from the same distribution as the data, but the policy optimization stage steers the optimization exactly towards areas where data is scarce and the model is inaccurate. This problem is severely aggravated when expressive models such as deep neural networks are employed.",
    "prev": "Most famously, the Dyna algorithm (Sutton, 1990) proposes using real experience to learn a model and then using the model to train a model-free policy.",
    "curr": "A number of more recent works have explored how to incorporate this idea into deep architectures (Kalweit & Boedecker, 2017;Feinberg et al., 2018;Buckman et al., 2018;Serban et al., 2018;Kurutach et al., 2018;Kaiser et al., 2019), with an emphasis on dealing with the errors that are introduced by approximate models.",
    "next": "In these approaches, the policy or value function is typically trained using on-policy rollouts from the model without using additional planning.",
    "hard_negative": [
      5176587,
      3075448
    ],
    "easy_negative": [
      12054082,
      156798,
      44153950
    ]
  },
  {
    "index": 1564,
    "source_corpus_id": 259836930,
    "ref_id": "b14",
    "citation_corpus_id": 213085920,
    "start": 2700,
    "end": 2717,
    "title": "Published as a conference paper at ICLR 2020 STRATEGIES FOR PRE-TRAINING GRAPH NEURAL NETWORKS",
    "abstract": "Many applications of machine learning require a model to make accurate predictions on test examples that are distributionally different from training ones, while task-specific labels are scarce during training. An effective approach to this challenge is to pre-train a model on related tasks where data is abundant, and then fine-tune it on a downstream task of interest. While pre-training has been effective in many language and vision domains, it remains an open question how to effectively use pre-training on graph datasets. In this paper, we develop a new strategy and self-supervised methods for pre-training Graph Neural Networks (GNNs). The key to the success of our strategy is to pre-train an expressive GNN at the level of individual nodes as well as entire graphs so that the GNN can learn useful local and global representations simultaneously. We systematically study pre-training on multiple graph classification datasets. We find that na\u00efve strategies, which pre-train GNNs at the level of either entire graphs or individual nodes, give limited improvement and can even lead to negative transfer on many downstream tasks. In contrast, our strategy avoids negative transfer and improves generalization significantly across downstream tasks, leading up to 9.4% absolute improvements in ROC-AUC over non-pre-trained models and achieving state-of-the-art performance for molecular property prediction and protein function prediction. * Equal contribution. Project website, data and code: Attribute Masking Supervised Attribute Prediction Structural Similarity Prediction Structure prediction Context Prediction (b) Categorization of our pre-training methods Graph space Node space Graph embeddings Node embeddings Linear classifier Figure 1: (a.i) When only node-level pre-training is used, nodes of different shapes (semantically different nodes) can be well separated, however, node embeddings are not composable, and thus resulting graph embeddings (denoted by their classes, + and \u2212) that are created by pooling node-level embeddings are not separable. (a.ii) With graph-level pre-training only, graph embeddings are well separated, however the embeddings of individual nodes do not necessarily capture their domainspecific semantics. (a.iii) High-quality node embeddings are such that nodes of different types are well separated, while at the same time, the embedding space is also composable. This allows for accurate and robust representations of entire graphs and enables robust transfer of pre-trained models to a variety of downstream tasks. (b) Categorization of pre-training methods for GNNs. Crucially, our methods, i.e., Context Prediction, Attribute Masking, and graph-level supervised pre-training (Supervised Attribute Prediction) enable both node-level and graph-level pre-training.matter of increasing the number of labeled pre-training datasets that are from the same domain as the downstream task. Instead, it requires substantial domain expertise to carefully select examples and target labels that are correlated with the downstream task of interest. Otherwise, the transfer of knowledge from related pre-training tasks to a new downstream task can harm generalization, which is known as negative transfer(Rosenstein et al., 2005)and significantly limits the applicability and reliability of pre-trained models.Present work. Here, we focus on pre-training as an approach to transfer learning in Graph Neural Networks (GNNs)(Kipf & Welling, 2017;Hamilton et al., 2017a;Ying et al., 2018b;Xu et al., 2019;2018)for graph-level property prediction. Our work presents two key contributions.(1) We conduct the first systematic large-scale investigation of strategies for pre-training GNNs. For that, we build two large new pre-training datasets, which we share with the community: a chemistry dataset with 2 million graphs and a biology dataset with 395K graphs. We also show that large domain-specific datasets are crucial to investigate pre-training and that existing downstream benchmark datasets are too small to evaluate models in a statistically reliable way.(2) We develop an effective pretraining strategy for GNNs and demonstrate its effectiveness and its ability for out-of-distribution generalization on hard transfer-learning problems.",
    "prev": "gns and integrates visually dissimilar 2D and 3D modalities of the same molecule at fine-grained atomic level, painting a more comprehensive depiction of each molecule.Extensive experiments show that MOLEBLEND achieves state-of-the-art performance across major 2D/3D molecular benchmarks.We further provide theoretical insights from the perspective of mutual-information maximization, demonstrating that our method unifies contrastive, generative (cross-modality prediction) and mask-then-predict (single-modality prediction) objectives into one single cohesive framework.",
    "curr": "INTRODUCTION\n\nSelf-supervised learning has been successfully applied to molecular representation learning (Xia et al., 2023;Chithrananda et al., 2020), where meaningful representations are extracted from a large amount of unlabeled molecules.The learned representation can then be finetuned to support diverse downstream molecular tasks.Early works design learning objectives based on a single modality (2D topological graphs (Hu et al., 2020;Rong et al., 2020;You et al., 2020), or 3D spatial structures (Zaidi et al., 2022;Liu et al., 2022a;Zhou et al., 2023)).Recently, multimodal molecular pretraining that exploits both 2D and 3D modalities in a single framework (Liu et al., 2022b;St\u00e4rk et al., 2022;Liu et al., 2023;Luo et al., 2022;Zhu et al., 2022) has emerged as an alternative solution.",
    "next": "Multimodal pretraining aims to align representations from different modalities.Most existing methods naturally adopt two models (Figure 1(a)) to encode 2D and 3D information separately (Liu et al., 2022b;St\u00e4rk et al., 2022;Liu et al., 2023).Contrastive learning is typically employed to attract representations of 2D graphs with their corresponding 3D conformations of the same molecule, and repulse those from different molecules.Another school of study is generative methods that bridge 2D and 3D modalities via mutual prediction (Figure 1(a-b)), such as taking 2D graphs as input to predict 3D information, and vice versa (Liu et al., 2022b;",
    "hard_negative": [
      6628106,
      52877454,
      3144218,
      3626819,
      3292002,
      52895589
    ],
    "easy_negative": [
      221377002,
      18793175,
      243865253
    ]
  },
  {
    "index": 1572,
    "source_corpus_id": 53116049,
    "ref_id": "b23",
    "citation_corpus_id": 3144218,
    "start": 3786,
    "end": 3808,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "The prior knowledge about the semantic/functional structure of the world helps to improve the navigation.",
    "curr": "We propose to use Graph Convolutional Networks (GCNs) (Kipf & Welling, 2017) to incorporate the prior knowledge into a Deep Reinforcement Learning framework.",
    "next": "The knowledge of the agent is encoded in a graph.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      9471817,
      1797761,
      240070849
    ]
  },
  {
    "index": 1574,
    "source_corpus_id": 209439835,
    "ref_id": "b10",
    "citation_corpus_id": 3144218,
    "start": 3501,
    "end": 3523,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "These architectures effectively combine node features and graph topology to build distributed node representations.",
    "curr": "GNNs can be used to solve node classification (Kipf & Welling, 2017) and link prediction  tasks, or they can be applied to downstream graph classification (Bacciu et al., 2018).",
    "next": "In literature, such models are usually evaluated on chemical and social domains (Xu et al., 2019).",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      174798983,
      227230675,
      235731975
    ]
  },
  {
    "index": 1575,
    "source_corpus_id": 252846328,
    "ref_id": "b28",
    "citation_corpus_id": 204960716,
    "start": 11385,
    "end": 11404,
    "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    "abstract": "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new stateof-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance. 1",
    "prev": "In a parallel development, the area of natural language processing was dominated by recurrent neural networks (RNNs) before self-attention-based neural networks (Vaswani et al., 2017) revolutionized this field.",
    "curr": "Based on their technique, various auto-encoding models (Devlin et al., 2018;Sanh et al., 2019;Lan et al., 2019) for tasks like sentence classification, sequence-to-sequence models Lewis et al., 2020) for translation or summarizing, and auto-regressive models (Radford et al., 2019;Brown et al., 2020) for natural language generation tasks showed the strength of the self-attention mechanism.",
    "next": "In the light of these successes, transformer-based models have also been devised for tabular data classification (Arik & Pfister, 2019;Somepalli et al., 2021;Kossen et al., 2021) and learning joint representations of tabular and textual data (Yin et al., 2020).",
    "hard_negative": [
      52967399,
      16639476,
      990233
    ],
    "easy_negative": [
      51878811,
      262048351,
      6189725
    ]
  },
  {
    "index": 1577,
    "source_corpus_id": 222130583,
    "ref_id": "b12",
    "citation_corpus_id": 3144218,
    "start": 3718,
    "end": 3739,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "They are constructed by stacking (graph) neural network layers which essentially propagate and transform node features over the given graph topology.",
    "curr": "Different types of layers have been proposed and used in practice, including graph convolutional layers (GCN) (Bruna et al., 2014;Kipf & Welling, 2017), graph attention layers (GAT) (Velickovic et al., 2018) and many others (Hamilton et al., 2017;Wijesinghe & Wang, 2019;Zeng et al., 2020;Abu-El-Haija et al., 2019).",
    "next": "However, most of the existing GNN architectures have two fundamental weaknesses which restrict their learning ability on general graph-structured data.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      252917981,
      253117261,
      10212820
    ]
  },
  {
    "index": 1581,
    "source_corpus_id": 210848920,
    "ref_id": "b17",
    "citation_corpus_id": 196198494,
    "start": 2722,
    "end": 2739,
    "title": "SUMBT: Slot-Utterance Matching for Universal and Scalable Belief Tracking",
    "abstract": "In goal-oriented dialog systems, belief trackers estimate the probability distribution of slotvalues at every dialog turn. Previous neural approaches have modeled domain-and slot-dependent belief trackers, and have difficulty in adding new slot-values, resulting in lack of flexibility of domain ontology configurations. In this paper, we propose a new approach to universal and scalable belief tracker, called slot-utterance matching belief tracker (SUMBT). The model learns the relations between domain-slot-types and slotvalues appearing in utterances through attention mechanisms based on contextual semantic vectors. Furthermore, the model predicts slot-value labels in a non-parametric way. From our experiments on two dialog corpora, WOZ 2.0 and MultiWOZ, the proposed model showed performance improvement in comparison with slot-dependent methods and achieved the state-of-the-art joint accuracy.",
    "prev": "Existing DST models can be categorized into two types: fixed-and open-vocabulary.",
    "curr": "Fixed vocabulary models assume known slot ontology and generate a score for each candidate of (slot,value) Lee et al., 2019).",
    "next": "Recent approaches propose open-vocabulary models that can generate the candidates, especially for slots such as entity names and time, from the dialogue history (Lei et al., 2018;Wu et al., 2019).",
    "hard_negative": [
      53035038,
      3618568,
      8535316,
      44137432
    ],
    "easy_negative": [
      257280201,
      8127220,
      226284006
    ]
  },
  {
    "index": 1584,
    "source_corpus_id": 67856290,
    "ref_id": "b21",
    "citation_corpus_id": 207468,
    "start": 3206,
    "end": 3223,
    "title": "A Hierarchical Neural Autoencoder for Paragraphs and Documents",
    "abstract": "Natural language generation of coherent long texts like paragraphs or longer documents is a challenging problem for recurrent networks models. In this paper, we explore an important step toward this generation task: training an LSTM (Longshort term memory) auto-encoder to preserve and reconstruct multi-sentence paragraphs. We introduce an LSTM model that hierarchically builds an embedding for a paragraph from embeddings for sentences and words, then decodes this embedding to reconstruct the original paragraph. We evaluate the reconstructed paragraph using standard metrics like ROUGE and Entity Grid, showing that neural models are able to encode texts in a way that preserve syntactic, semantic, and discourse coherence. While only a first step toward generating coherent text units from neural models, our work has the potential to significantly impact natural language generation and summarization 1 .",
    "prev": "In both cases, agent behavior is highly coordinated and non-deterministic, and the space of all multi-agent trajectories is naively exponentially large.",
    "curr": "When modeling such sequential data, it is often beneficial to design hierarchical models that can capture long-term coordination using intermediate variables or representations (Li et al., 2015;Zheng et al., 2016).",
    "next": "An attractive use-case for these intermediate variables is to capture interesting highlevel behavioral semantics in an interpretable and manipulable way.",
    "hard_negative": [
      8896392,
      2790679,
      15859864,
      12332957,
      16391334,
      8812081,
      14859321,
      9482302,
      964287,
      11919464,
      92531,
      7176829
    ],
    "easy_negative": [
      7615184,
      28363891,
      2445030
    ]
  },
  {
    "index": 1585,
    "source_corpus_id": 247446906,
    "ref_id": "b7",
    "citation_corpus_id": 11336213,
    "start": 14780,
    "end": 14798,
    "title": "On the Properties of Neural Machine Translation: Encoder-Decoder Approaches",
    "abstract": "Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder-Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.",
    "prev": "We use Equation 1 for directed correlation graphs, and Equation 2 for undirected distance graph.",
    "curr": "Next, to model the temporal dependency in EEGs, we employ Gated Recurrent Units (GRUs) (Cho et al., 2014), a variant of RNN with a gating mechanism.",
    "next": "Specifically, the matrix multiplications in GRUs are replaced with diffusion convolutions (or ChebNet spectral graph convolutions for undirected distance-based graph) (Li et al., 2018), allowing spatiotemporal modeling of EEG signals (referred to as \"DCGRU\"):\nX :,m G f \u03b8 = \u03a6 K\u22121 k=0 \u03b8 k \u039b k \u03a6 X :,m = K\u22121 k=0 \u03b8 k L k X :,m = K\u22121r (t) = \u03c3 \u0398 r G [X (t) , H (t\u22121) ] + b r u (t) = \u03c3 \u0398 u G [X (t) , H (t\u22121) ] + b u(3)C (t) = tanh \u0398 C G [X (t) , (r (t) H (t\u22121) )]+b C H (t) = u (t) H (t\u22121) +(1\u2212u (t) ) C (t) (4)\nHere, X (t) , H (t) denote the input and output of DCGRU at time step t respectively, \u03c3 denotes Sigmoid function, represents the Hadamard product, r (t) , u (t) , C (t) denote reset gate, update gate and candidate at time step t respectively, G denotes the diffusion convolution (or ChebNet spectral graph convolution), \u0398 r , b r , \u0398 u , b u , \u0398 C and b C are the weights and biases for the corresponding convolutional filters.",
    "hard_negative": [
      5590763,
      8884845,
      10766958,
      14323132
    ],
    "easy_negative": [
      196206113,
      5074049,
      1968934
    ]
  },
  {
    "index": 1589,
    "source_corpus_id": 264802494,
    "ref_id": "b35",
    "citation_corpus_id": 230433941,
    "start": 9391,
    "end": 9408,
    "title": "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    "abstract": "Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were \"virtual tokens\". We apply prefix-tuning to GPT-2 for table-totext generation and to BART for summarization. We show that by modifying only 0.1% of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training.Armen Aghajanyan, Luke Zettlemoyer, and Sonal Gupta. 2020. Intrinsic dimensionality explains the effectiveness of language model fine-tuning. Amodei. 2020. Language models are few-shot learners.",
    "prev": "roficiency in handling sub-optimal data.The Trajectory Transformer (Janner et al., 2021) trains on sequences of discretized states, actions, and rewards, indicating a more direct solution.Our work focuses on utilizing the cross-domain knowledge, i.e., language pre-training, as privileged information to enhance DT-based methods, which thus is orthogonal to these works.",
    "curr": "Large Language Models (LLMs) have been the most pronounced application of the Transformer architecture in recent years (Radford et al., 2018;2019;Brown et al., 2020;OpenAI, 2023;Devlin et al., 2018;Touvron et al., 2023a;b).Pre-trained on massive amounts of corpus, LLMs have shown surprising few-shot and even zero-shot ability in language tasks, such as GPT series (Radford et al., 2018;2019;Brown et al., 2020;OpenAI, 2023).To personalize LLMs for different downstream user applications with computational efficiency, researchers commonly utilize parameter-efficient finetuning techniques (Hu et al., 2021;Zhang et al., 2023a;Li & Liang, 2021;Lester et al., 2021;Liu et al., 2022;Wang et al., 2023a) to finetune LLMs.In this work, we use the GPT-2 architecture (Radford et al., 2019) as the backbone due to its affordability and use LoRA (Hu et al., 2021) for downstream finetuning.",
    "next": "LMs for decision making.The great success of LMs in language tasks also motivates researchers to explore the potential of LMs for decision making problems (Ahn et al., 2022;Huang et al., 2022;Driess et al., 2023;Wu et al., 2023).One line of works (Ahn et al., 2022;Huang et al., 2022;Driess et al., 2023;Wu et al., 2023) utilizes LMs for high-level task decomposition and task planning, while their low-level execution policy is learned or designed separately.Another line of works (Li et al., 2022;Reed et al., 2022;Lin et al., 2023;Brohan et al., 2023;Tang et al., 2023;Wang et al., 2023b) exploits the representation and generalization power of pre-trained LMs.Li et al.",
    "hard_negative": [
      215768182,
      233231453
    ],
    "easy_negative": [
      202622732,
      51870433,
      202749964
    ]
  },
  {
    "index": 1593,
    "source_corpus_id": 235293845,
    "ref_id": "b29",
    "citation_corpus_id": 2955580,
    "start": 2338,
    "end": 2354,
    "title": "A Persona-Based Neural Conversation Model",
    "abstract": "We present persona-based models for handling the issue of speaker consistency in neural response generation. A speaker model encodes personas in distributed embeddings that capture individual characteristics such as background information and speaking style. A dyadic speakeraddressee model captures properties of interactions between two interlocutors. Our models yield qualitative performance improvements in both perplexity and BLEU scores over baseline sequence-to-sequence models, with similar gains in speaker consistency as measured by human judges.",
    "prev": "1\n\nINTRODUCTION\n\nNegotiation is ubiquitous in human interaction, from e-commerce to the multi-billion dollar sales of companies.",
    "curr": "Learning how to negotiate effectively involves deep pragmatic understanding and planning the dialogue strategically (Thompson; Bazerman et al., 2000b;Pruitt, 2013  Modern dialogue systems for collaborative tasks such as restaurant or flight reservations have made considerable progress by modeling the dialogue history and structure explicitly using the semantic content, like slot-value pairs (Larionov et al., 2018;Young, 2006), or implicitly with encoder-decoder architectures (Sordoni et al., 2015;Li et al., 2016).",
    "next": "In such tasks, users communicate explicit intentions, enabling systems to map the utterances into specific intent slots (Li et al., 2020).",
    "hard_negative": [
      2177536,
      7356547,
      780171,
      1245593,
      6078795,
      7287895,
      739696,
      11212020,
      10473972
    ],
    "easy_negative": [
      52948476,
      250390754,
      6765873
    ]
  },
  {
    "index": 1594,
    "source_corpus_id": 248964978,
    "ref_id": "b21",
    "citation_corpus_id": 990233,
    "start": 12649,
    "end": 12670,
    "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
    "prev": "It is worth noting that multiple repetitions bring little additional time consumption compared to the inference of GPT, we thus simply set it to 100 for all tasks.",
    "curr": "Evaluation Protocol\n\nWe evaluate the proposed method on nine widely-used text-classification datasets including SST-2 (Socher et al., 2013), SST-5 (Socher et al., 2013), Subj (Pang and Lee, 2004), MR (Pang and Lee, 2005), AP (Zhang et al., 2015), DBPedia (Zhang et al., 2015), AGNews (Zhang et al., 2015), RTE (Dagan et al., 2005), and TREC (Voorhees and Tice, 2000).",
    "next": "SST-2, SST-5, MR and AP are sentiment classification tasks.",
    "hard_negative": [
      5584134,
      2279432,
      3116311,
      7747235,
      15659560,
      1588782,
      806709,
      2678583,
      3264224,
      15616495,
      2091504
    ],
    "easy_negative": [
      851193,
      5663378,
      1524104
    ]
  },
  {
    "index": 1596,
    "source_corpus_id": 202750112,
    "ref_id": "b6",
    "citation_corpus_id": 2768038,
    "start": 3027,
    "end": 3029,
    "title": "Under review as conference paper at ICLR 2015 EMBEDDING ENTITIES AND RELATIONS FOR LEARN- ING AND INFERENCE IN KNOWLEDGE BASES",
    "abstract": "We consider learning representations of entities and relations in KBs using the neural-embedding approach. We show that most existing models, including NTN (Socher et al., 2013)  and TransE (Bordes et al., 2013b), can be generalized under a unified learning framework, where entities are low-dimensional vectors learned from a neural network and relations are bilinear and/or linear mapping functions. Under this framework, we compare a variety of embedding models on the link prediction task. We show that a simple bilinear formulation achieves new state-of-the-art results for the task (achieving a top-10 accuracy of 73.2% vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules such as BornInCitypa, bq^CityInCountrypb, cq \u00f9\u00f1 N ationalitypa, cq. We find that embeddings learned from the bilinear objective are particularly good at capturing relational semantics, and that the composition of relations is characterized by matrix multiplication. More interestingly, we demonstrate that our embedding-based rule extraction approach successfully outperforms a state-ofthe-art confidence-based rule mining approach in mining horn rules that involve compositional reasoning.",
    "prev": "Here, we choose knowledge graph-related tasks to explore due to its representativeness.",
    "curr": "In knowledge base completion (KBC) tasks, embedding-based models [6,7,8,9,10,11] can easily obtain a very competitive score by fitting data using various neural network techniques, but lacking an explicit modeling to construct explanations by directly exploiting graph structure prevents it from being interpretable, a critical property of reasoning, since Euclidean embedding space will not produce a clearly stated and human-readable representation.",
    "next": "One is for the AthletePlaysForTeam task and the other for the OrganizationHiredPerson task.",
    "hard_negative": [
      1077128,
      6343829,
      2141094,
      806709,
      370914,
      9676646
    ],
    "easy_negative": [
      15010267,
      252819470,
      258378273
    ]
  },
  {
    "index": 1607,
    "source_corpus_id": 170079235,
    "ref_id": "b33",
    "citation_corpus_id": 12713052,
    "start": 6923,
    "end": 6927,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "However, these video CNN architectures were the results of careful manual designs by human experts.",
    "curr": "Neural Architecture Search (NAS), the concept of automatically finding better CNN architectures based on data, is becoming increasingly popular [34,35,14].",
    "next": "Rather than relying on human expert knowledge to design a CNN model, neural architecture search allows the machines to generate better performing CNN models optimized for the data.",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      5736418,
      259298560,
      8828761
    ]
  },
  {
    "index": 1617,
    "source_corpus_id": 247778706,
    "ref_id": "b58",
    "citation_corpus_id": 12713052,
    "start": 2622,
    "end": 2638,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "Our code is available at https://github.com/skhu101/GM-NAS.",
    "curr": "INTRODUCTION\n\nIn recent years, there has been a surge of interest in Neural Architecture Search (NAS) (Stanley & Miikkulainen, 2002;Zoph & Le, 2017;Pham et al., 2018;Real et al., 2019; for its ability to identify high-performing architectures in a series of machine learning tasks.",
    "next": "Pioneering works in this field require training and evaluating thousands of architectures from scratch, which consume huge amounts of computational resources (Miikkulainen et al., 2019;Zoph & Le, 2017;.",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      252089843,
      44084020,
      17181515
    ]
  },
  {
    "index": 1623,
    "source_corpus_id": 264490556,
    "ref_id": "b20",
    "citation_corpus_id": 1428702,
    "start": 4397,
    "end": 4416,
    "title": "Learning Word Vectors for Sentiment Analysis",
    "abstract": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term-document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.",
    "prev": "We empirically evaluate our DP framework on commonly studied tasks (in non-privacy literature).Following the influential work of Ziegler et al.",
    "curr": "( 2020), we evaluate two main scenarios: (i) alignment via RL without human in the loop for a positive review generation task on the IMDb dataset (Maas et al., 2011), and (ii) alignment via RL from human feedback (RLHF) for a summarization task on the Reddit TL;DR dataset (V\u00f6lske et al., 2017).Our experimental results indicate that privately aligning LLMs is possible, offering competitive utility while ensuring strong privacy protections.As a representative example, on the IMDb dataset, the average reward obtained by our DP GPT2-Large model for generating positive reviews is 3.37 with \u03f5 = 4, whereas the best performing non-private model achieves an average reward of 3.47.",
    "next": "Our experiments also show that increasing the model size typically leads to more favorable privacyreward trade-offs, hence, we anticipate that as pre-trained LLMs get better, alignment with DP should become easier.",
    "hard_negative": [
      1260035,
      388,
      2279432,
      10473638,
      7105713,
      2787775,
      218515777,
      3264224,
      629094,
      469886
    ],
    "easy_negative": [
      235265634,
      227230657,
      1912220
    ]
  },
  {
    "index": 1626,
    "source_corpus_id": 3495200,
    "ref_id": "b19",
    "citation_corpus_id": 1957433,
    "start": 4669,
    "end": 4694,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "Additionally, for VARMISUSE, learning variable usage semantics (e.g., \"a filename is needed here\") is required.",
    "curr": "This \"fill the blank element\" task is related to methods for learning distributed representations of natural language words, such as Word2Vec (Mikolov et al., 2013) and GLoVe (Pennington et al., 2014).",
    "next": "However, we can learn from a much richer structure such as data flow information.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      196194724,
      10576751,
      219933462
    ]
  },
  {
    "index": 1631,
    "source_corpus_id": 52895739,
    "ref_id": "b25",
    "citation_corpus_id": 8257350,
    "start": 42620,
    "end": 42624,
    "title": "ALTERNATING MULTI-BIT QUANTIZATION FOR RECURRENT NEURAL NETWORKS",
    "abstract": "Recurrent neural networks have achieved excellent performance in many applications. However, on portable devices with limited resources, the models are often too large to deploy. For applications on the server with large scale concurrent requests, the latency during inference can also be very critical for costly computing resources. In this work, we address these problems by quantizing the network, both weights and activations, into multiple binary codes {\u22121, +1}. We formulate the quantization as an optimization problem. Under the key observation that once the quantization coefficients are fixed the binary codes can be derived efficiently by binary search tree, alternating minimization is then applied. We test the quantization for two well-known RNNs, i.e., long short term memory (LSTM) and gated recurrent unit (GRU), on the language models. Compared with the full-precision counter part, by 2-bit quantization we can achieve \u223c16\u00d7 memory saving and \u223c6\u00d7 real inference acceleration on CPUs, with only a reasonable loss in the accuracy. By 3-bit quantization, we can achieve almost no loss in the accuracy or even surpass the original model, with \u223c10.5\u00d7 memory saving and \u223c3\u00d7 real inference acceleration. Both results beat the exiting quantization works with large margins. We extend our alternating quantization to image classification tasks. In both RNNs and feedforward neural networks, the method also achieves excellent performance. rank matrix factorization for deep neural network training with high-dimensional output targets. In ICASSP, pp. 6655-6659. IEEE, 2013.Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015.",
    "prev": "Training and inference on quantized nets can be made more efficient by also quantizing the activation [12,18,23], and such networks have achieved impressive performance on large-scale tasks such as ImageNet classification [18,24].",
    "curr": "In the NLP land, quantized language models have been successfully trained using alternating multi-bit quantization [22].",
    "next": "Theories Li et al.",
    "hard_negative": [
      224893,
      6628106,
      2134321,
      4167933,
      13239389
    ],
    "easy_negative": [
      18875090,
      626648,
      248299679
    ]
  },
  {
    "index": 1633,
    "source_corpus_id": 246634839,
    "ref_id": "b21",
    "citation_corpus_id": 53216818,
    "start": 17956,
    "end": 17976,
    "title": "Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control",
    "abstract": "We propose a \"plan online and learn offline\" framework for the setting where an agent, with an internal model, needs to continually act and learn in the world. Our work builds on the synergistic relationship between local model-based control, global value function learning, and exploration. We study how local trajectory optimization can cope with approximation errors in the value function, and can stabilize and accelerate value function learning. Conversely, we also study how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions. Finally, we also demonstrate how trajectory optimization can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. This exploration is critical for fast and stable learning of the value function. Combining these components enable solutions to complex control tasks, like humanoid locomotion and dexterous in-hand manipulation, in the equivalent of a few minutes of experience in the real world.",
    "prev": "EXPERIMENTS\n\nTo demonstrate the versatility of BAM, we apply it in a variety of scenarios.",
    "curr": "As BAM is a learning paradigm, it can be implemented as a module in a larger framework allowing it to be easily used in settings such as control/reinforcement learning and domain adaptation (Thompson, 1933;Osband et al., 2018;Lowrey et al., 2018;Yoon et al., 2018).",
    "next": "BAM requires the ability to construct the posterior, p(\u03b8 t |D <t , W t ), and evaluate the log marginal likelihood, log p(D t |D <t , W t ).",
    "hard_negative": [
      997870,
      3075448
    ],
    "easy_negative": [
      251404132,
      62722590,
      254018206
    ]
  },
  {
    "index": 1634,
    "source_corpus_id": 261076491,
    "ref_id": "b8",
    "citation_corpus_id": 252222320,
    "start": 8995,
    "end": 8998,
    "title": "PALI: A JOINTLY-SCALED MULTILINGUAL LANGUAGE-IMAGE MODEL",
    "abstract": "Effective scaling and a flexible task interface enable large language models to excel at many tasks. We present PaLI (Pathways Language and Image model), a model that extends this approach to the joint modeling of language and vision. PaLI generates text based on visual and textual inputs, and with this interface performs many vision, language, and multimodal tasks, in many languages. To train PaLI, we make use of large pre-trained encoder-decoder language models and Vision Transformers (ViTs). This allows us to capitalize on their existing capabilities and leverage the substantial cost of training them. We find that joint scaling of the vision and language components is important. Since existing Transformers for language are much larger than their vision counterparts, we train a large, 4-billion parameter ViT (ViT-e) to quantify the benefits from even larger-capacity vision models. To train PaLI, we create a large multilingual mix of pre-training tasks, based on a new image-text training set containing 10B images and texts in over 100 languages. PaLI achieves state-of-the-art in multiple vision and language tasks (such as captioning, visual question-answering, scene-text understanding), while retaining a simple, modular, and scalable design. . MaXM: Towards multilingual visual question answering. arXiv preprint arXiv:2209.05401, 2022b. . Microsoft COCO Captions: Data collection and evaluation server. arXiv preprint arXiv:1504.00325, 2015. . Winner team Mia at TextVQA challenge 2021: Vision-and-language representation learning with pre-trained sequence-to-sequence model. arXiv preprint arXiv:2106.15332, 2021. , et al. Learning transferable visual models from natural language supervision. . Scaling vision with sparse mixture of experts. , et al. Scaling up models and data with t5x and seqio. arXiv preprint arXiv:2203.17189, 2022. Sun. Objects365: A large-scale, high-quality dataset for object detection. In . Learning robust global representations by penalizing local predictive power.",
    "prev": "UC2 [67] expands English multimodal data using machine translation and introduces specific pretraining objectives to enhance fine-grained alignment between image regions and multilingual tokens.",
    "curr": "In the era of LLMs, PaLI [9] develops a 17B multilingual language-image model based on 10B image-text pairs spanning 100 languages.",
    "next": "Differing from these studies, which try to simultaneously achieve multilingual and multimodel alignment, we focus on effectively leveraging pretrained multilingual LLMs in multimodal learning across various languages.",
    "hard_negative": [
      225039882,
      225040574,
      204901567,
      243865674,
      237490295
    ],
    "easy_negative": [
      14487901,
      204009111,
      222341606
    ]
  },
  {
    "index": 1635,
    "source_corpus_id": 257219618,
    "ref_id": "b27",
    "citation_corpus_id": 211258652,
    "start": 2676,
    "end": 2694,
    "title": "Training Question Answering Models From Synthetic Data",
    "abstract": "Question and answer generation is a data augmentation method that aims to improve question answering (QA) models given the limited amount of human labeled data. However, a considerable gap remains between synthetic and human-generated question-answer pairs. This work aims to narrow this gap by taking advantage of large language models and explores several factors such as model size, quality of pretrained models, scale of data synthesized, and algorithmic choices. On the SQUAD1.1 question answering task, we achieve higher accuracy using solely synthetic questions and answers than when using the SQUAD1.1 training set questions alone. Removing access to real Wikipedia data, we synthesize questions and answers from a synthetic corpus generated by an 8.3 billion parameter GPT-2 model. With no access to human supervision and only access to other models, we are able to train state of the art question answering networks on entirely model-generated data that achieve 88.4 Exact Match (EM) and 93.9 F1 score on the SQUAD1.1 dev set. We further apply our methodology to SQUAD2.0 and show a 2.8 absolute gain on EM score compared to prior work using synthetic data.",
    "prev": "Training gaussian mixture models at scale via coresets.",
    "curr": "INTRODUCTION\n\nOwing to the superior generative capacity of large-scale pre-trained language models (PLMs), there has been an emerging trend of using these powerful models (e.g., GPT) to generate training data for downstream tasks (Anaby-Tavor et al., 2020;Puri et al., 2020;Kumar et al., 2020;Lee et al., 2021, inter alia).",
    "next": "Among them, a new line of generation-based zero-shot learning using the unfinetuned PLM pushes the envelope further (Schick & Sch\u00fctze, 2021;Ye et al., 2022a;Meng et al., 2022), featuring total annotation-free training for downstream tasks.",
    "hard_negative": [
      52967399,
      9192723,
      1809816,
      173188058
    ],
    "easy_negative": [
      14826968,
      248377455,
      254854257
    ]
  },
  {
    "index": 1645,
    "source_corpus_id": 52086172,
    "ref_id": "b1",
    "citation_corpus_id": 748227,
    "start": 1282,
    "end": 1303,
    "title": "Generating Sentences from a Continuous Space",
    "abstract": "The standard recurrent neural network language model (rnnlm) generates sentences one word at a time and does not work from an explicit global sentence representation. In this work, we introduce and study an rnn-based variational autoencoder generative model that incorporates distributed latent representations of entire sentences. This factorization allows it to explicitly model holistic properties of sentences such as style, topic, and high-level syntactic features. Samples from the prior over these sentence representations remarkably produce diverse and well-formed sentences through simple deterministic decoding. By examining paths through this latent space, we are able to generate coherent novel sentences that interpolate between known sentences. We present techniques for solving the difficult learning problem presented by this model, demonstrate its effectiveness in imputing missing words, explore many interesting properties of the model's latent sentence space, and present negative results on the use of the model in language modeling.",
    "prev": "INTRODUCTION\n\nDeep generative models trained via Stochastic Gradient Variational Bayes (SGVB) (Kingma & Welling, 2014a; efficiently couple the expressiveness of deep neural networks with the robustness to uncertainty of probabilistic latent variables.",
    "curr": "This combination has lead to their success in tasks ranging from image generation (Gregor et al., 2015;Rezende et al., 2016) to semi-supervised learning Maal\u00f8e et al., 2016) to language modeling (Bowman et al., 2016).",
    "next": "Various extensions to SGVB have been proposed (Burda et al., 2016;Maal\u00f8e et al., 2016;Salimans et al., 2015), but one conspicuous absence is an extension to Bayesian nonparametric processes.",
    "hard_negative": [
      216848261,
      1988653,
      3509328,
      9672033,
      207468,
      11212020,
      10181753,
      252796
    ],
    "easy_negative": [
      204401755,
      237489742,
      219307752
    ]
  },
  {
    "index": 1651,
    "source_corpus_id": 237532682,
    "ref_id": "b24",
    "citation_corpus_id": 220265858,
    "start": 2913,
    "end": 2916,
    "title": "GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding",
    "abstract": "Neural network scaling has been critical for improving the model quality in many real-world machine learning applications with vast amounts of training data and compute. Although this trend of scaling is affirmed to be a sure-fire approach for better model quality, there are challenges on the path such as the computation cost, ease of programming, and efficient implementation on parallel devices. GShard is a module composed of a set of lightweight annotation APIs and an extension to the XLA compiler. It provides an elegant way to express a wide range of parallel computation patterns with minimal changes to the existing model code. GShard enabled us to scale up multilingual neural machine translation Transformer model with Sparsely-Gated Mixture-of-Experts beyond 600 billion parameters using automatic sharding. We demonstrate that such a giant model can efficienctly be trained on 2048 TPU v3 accelerators in 4 days to achieve far superior quality for translation from 100 languages to English compared to the prior art.Preprint. Under review.",
    "prev": "For many of these tasks the scaling behavior of neural networks is highly predictable; model fit or test loss can be described precisely as a function of its number of parameters [18,21,16,17,31].",
    "curr": "Neural machine translation (NMT) has long enjoyed the benefits of scaling [19,4,25], but studies investigating the scaling behavior of NMT models are missing.",
    "next": "We present the first large-scale systematic study of scaling laws for encoder-decoder Transformer models applied to NMT [36].",
    "hard_negative": [
      541460,
      174799399,
      6359641,
      6053988
    ],
    "easy_negative": [
      3166233,
      51872949,
      199668753
    ]
  },
  {
    "index": 1655,
    "source_corpus_id": 108367114,
    "ref_id": "b4",
    "citation_corpus_id": 21671720,
    "start": 3313,
    "end": 3333,
    "title": "Published as a conference paper at ICLR 2018 LEVERAGING GRAMMAR AND REINFORCEMENT LEARNING FOR NEURAL PROGRAM SYNTHESIS",
    "abstract": "Program synthesis is the task of automatically generating a program consistent with a specification. Recent years have seen proposal of a number of neural approaches for program synthesis, many of which adopt a sequence generation paradigm similar to neural machine translation, in which sequence-to-sequence models are trained to maximize the likelihood of known reference programs. While achieving impressive results, this strategy has two key limitations. First, it ignores Program Aliasing: the fact that many different programs may satisfy a given specification (especially with incomplete specifications such as a few input-output examples). By maximizing the likelihood of only a single reference program, it penalizes many semantically correct programs, which can adversely affect the synthesizer performance. Second, this strategy overlooks the fact that programs have a strict syntax that can be efficiently checked. To address the first limitation, we perform reinforcement learning on top of a supervised model with an objective that explicitly maximizes the likelihood of generating semantically correct programs. For addressing the second limitation, we introduce a training procedure that directly maximizes the probability of generating syntactically correct programs that fulfill the specification. We show that our contributions lead to improved accuracy of the models, especially in cases where the training data is limited.",
    "prev": "In this paper, we consider two problem settings.",
    "curr": "The first is the Karel domain and the recently proposed Karel synthesis model (Bunel et al., 2018).",
    "next": "We identify many distributions of input examples and DSL programs for which the Karel synthesis model performs poorly.",
    "hard_negative": [
      12718048,
      2783746,
      7034786,
      2009318,
      1844940,
      7147309,
      2468625,
      6715185
    ],
    "easy_negative": [
      2855290,
      201670412,
      16208337
    ]
  },
  {
    "index": 1656,
    "source_corpus_id": 222140630,
    "ref_id": "b30",
    "citation_corpus_id": 6954272,
    "start": 2373,
    "end": 2392,
    "title": "MULTI-TASK SEQUENCE TO SEQUENCE LEARNING",
    "abstract": "Sequence to sequence learning has recently emerged as a new paradigm in supervised learning. To date, most of its applications focused on only one task and not much work explored this framework for multiple tasks. This paper examines three multi-task learning (MTL) settings for sequence to sequence models: (a) the oneto-many setting -where the encoder is shared between several tasks such as machine translation and syntactic parsing, (b) the many-to-one setting -useful when only the decoder can be shared, as in the case of translation and image caption generation, and (c) the many-to-many setting -where multiple encoders and decoders are shared, which is the case with unsupervised objectives and translation. Our results show that training on a small amount of parsing and image caption data can improve the translation quality between English and German by up to 1.5 BLEU points over strong single-task baselines on the WMT benchmarks. Furthermore, we have established a new state-of-the-art result in constituent parsing with 93.0 F 1 . Lastly, we reveal interesting properties of the two unsupervised learning objectives, autoencoder and skip-thought, in the MTL context: autoencoder helps less in terms of perplexities but more on BLEU scores compared to skip-thought. * Minh-Thang Luong is also a student at Stanford University.",
    "prev": "Deep multi-task learning (Deep MTL) has shown a similar ability to adapt knowledge across tasks whose observed variables are embedded in a shared space.",
    "curr": "Examples include vision, where the input for all tasks (photograph, drawing, or otherwise) is pixels arranged in a 2D plane (Zhang et al., 2014;Misra et al., 2016;Rebuffi et al., 2017); natural language (Collobert & Weston, 2008;Luong et al., 2016;Hashimoto et al., 2017), speech processing (Seltzer & Droppo, 2013;Huang et al., 2015), and genomics (Alipanahi et al., 2015), which exploit the 1D structure of text, waveforms, and nucleotide sequences; and video game-playing (Jaderberg et al., 2017;Teh et al., 2017), where interactions are organized across space and time.",
    "next": "Yet, many real-world prediction tasks have no such spatial organization; their input and output variables are simply labeled values, e.g., the height of a tree, the cost of a haircut, or the score on a standardized test.",
    "hard_negative": [
      2863491,
      1245593,
      359451,
      12639289,
      5590763,
      11212020,
      252796
    ],
    "easy_negative": [
      18950810,
      5164322,
      248366298
    ]
  },
  {
    "index": 1662,
    "source_corpus_id": 263608162,
    "ref_id": "b13",
    "citation_corpus_id": 233296808,
    "start": 1503,
    "end": 1523,
    "title": "The Power of Scale for Parameter-Efficient Prompt Tuning",
    "abstract": "In this work, we explore \"prompt tuning,\" a simple yet effective mechanism for learning \"soft prompts\" to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3's few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method \"closes the gap\" and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed \"prefix tuning\" of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient \"prompt ensembling.\" We release code and model checkpoints to reproduce our experiments. 1ReferencesRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,  Danilo Giampiccolo, Bernardo Magnini, and Idan  Szpektor. 2006. The second PASCAL recognising textual entailment challenge. In Proceedings of the second PASCAL challenges workshop on recognising textual entailment, volume 6, pages 6-4. Venice. . 2019a. SuperGLUE: A stickier benchmark for general-purpose language understanding systems. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.",
    "prev": "F770398E17A9CE9F66E\nPrompt tuning in natural language processing (NLP) has become an increasingly popular method for adapting large language models to specific tasks.However, the transferability of these prompts, especially continuous prompts, between different models remains a challenge.In this work, we propose a zero-shot continuous prompt transfer method, where source prompts are encoded into relative space and the corresponding target prompts are searched for transferring to target models.Experimental results confirm the effectiveness of our method, showing that \"task semantics\" in continuous prompts can be generalized across various language models.Moreover, we find that combining \"task semantics\" from multiple source models can further enhance the generalizability of transfer.",
    "curr": "1\n\nIntroduction\n\nRecently in natural language processing (NLP), there has been a paradigm shift from full language model finetuning to the optimization of a small subset of prompt tokens (Shin et al., 2020;Lester et al., 2021;Li and Liang, 2021;Zhong et al., 2021).As language models have dramatically increased in size and may contain billions of parameters (Brown et al., 2020), the strategy of freezing language models while optimizing the learnable prompt parameters becomes the most affordable and efficient alternative for downstream tasks.This technique, referred to as prompt tuning, has gained substantial recognition for its efficacy across a range of language models (Shin et al., 2020;Lester et al., 2021;Li and Liang, 2021;Zhong et al., 2021).",
    "next": "Various prompt tuning methods have been explored, which can be generally categorized into discrete and continuous cases.Discrete prompt tuning, such as AutoPrompt (Shin et al., 2020), primarily focuses on the selection and optimization of a predetermined set of tokens within a language model's vocabulary.By contrast, continuous prompt tuning (Zhong et al., 2021) allows the modification of continuous prompt embeddings by gradient descent.The latter often offers bet",
    "hard_negative": [
      3626819,
      40100965,
      155091369,
      204960716,
      11816014,
      218470133,
      233231453
    ],
    "easy_negative": [
      2664741,
      237328496,
      207847595
    ]
  },
  {
    "index": 1665,
    "source_corpus_id": 228083457,
    "ref_id": "b2",
    "citation_corpus_id": 52889459,
    "start": 2085,
    "end": 2105,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "INTRODUCTION\n\nSince their introduction by Goodfellow et al.",
    "curr": "(2014), generative adversarial networks (GANs) have seen remarkable progress, with current models capable of generating samples of very high quality (Brock et al., 2018;Karras et al., 2019a;2019b).",
    "next": "In recent years, particular effort has been invested in constructing controllable models, which allow manipulating attributes of the generated images.",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      12147910,
      226283900,
      17001271
    ]
  },
  {
    "index": 1668,
    "source_corpus_id": 253265269,
    "ref_id": "b25",
    "citation_corpus_id": 244116787,
    "start": 27226,
    "end": 27229,
    "title": "Published as a conference paper at ICLR 2022 SALIENT IMAGENET: HOW TO DISCOVER SPURIOUS FEATURES IN DEEP LEARNING?",
    "abstract": "a) class: band aid, spurious feature: fingers, -41.54% (b) class: space bar, spurious feature: keys, -46.15% (c) class: plate, spurious feature: food, -32.31% (d) class: butterfly, spurious feature: flowers, -21.54% (e) class: potter's wheel, spurious feature: vase, -21.54%",
    "prev": "However, most of these datasets are built to assess the model performance when going away from training data distribution and, thus, provide almost no understanding about the nature of the in-distribution errors.",
    "curr": "Currently, the only ImageNet extensions that help analyzing the in-distribution model errors are the multiclass relabelling or saliency of the validation set [24,4,30,26].",
    "next": "However, this relabelling only explains one type of model error that is caused by the co-occurrences of other objects in the scene.",
    "hard_negative": [
      219721312,
      52962991,
      196199409
    ],
    "easy_negative": [
      210152110,
      69289238,
      11703983
    ]
  },
  {
    "index": 1671,
    "source_corpus_id": 263830421,
    "ref_id": "b47",
    "citation_corpus_id": 259138847,
    "start": 2287,
    "end": 2290,
    "title": "The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers",
    "abstract": "This paper studies the curious phenomenon for machine learning models with Transformer architectures that their activation maps are sparse. By activation map we refer to the intermediate output of the multi-layer perceptrons (MLPs) after a ReLU activation function, and by \"sparse\" we mean that on average very few entries (e.g., 3.0% for T5-Base and 6.3% for ViT-B16) are nonzero for each input to MLP. Moreover, larger Transformers with more layers and wider MLP hidden dimensions are sparser as measured by the percentage of nonzero entries. Through extensive experiments we demonstrate that the emergence of sparsity is a prevalent phenomenon that occurs for both natural language processing and vision tasks, on both training and evaluation data, for Transformers of various configurations, at layers of all depth levels, as well as for other architectures including MLP-mixers and 2-layer MLPs. We show that sparsity also emerges using training datasets with random labels, or with random inputs, or with infinite amount of data, demonstrating that sparsity is not a result of a specific family of datasets. We discuss how sparsity immediately implies a way to significantly reduce the FLOP count and improve efficiency for Transformers. Moreover, we demonstrate perhaps surprisingly that enforcing an even sparser activation via Top-k thresholding with a small value of k brings a collection of desired but missing properties for Transformers, namely less sensitivity to noisy training data, more robustness to input corruptions, and better calibration for their prediction confidence. * Equal contribution arXiv:2210.06313v2 [cs.LG] 9 Jun 2023",
    "prev": "Introduction\n\nThe widespread excitement surrounding Large Language Models (LLMs) has sparked significant interest in leveraging AI across diverse domains [5,9,6].However, realizing the potential of LLMs is challenged by their significant computational and memory requirements during inference [60,40,3].To enhance the inference efficiency 1 , various techniques have been explored, including quantization [12,50], speculative decoding [41], pruning [53,71], and weight sparsification [20,15].Among these techniques, achieving activation sparsity offers a compelling advantage by providing a favorable balance between accuracy and speedup, especially on modern hardware like GPUs [51].",
    "curr": "Notably, employing the Rectified Linear Unit (ReLU) activation function [22] in neural networks is recognized for inducing sparse activations and has been adopted in various prior works [27,44,48,69].To reaffirm this property, we employ the OPT model [80], utilizing ReLU, and measure the sparsity of activations in the Feed Forward Network (FFN) between the fully connected layers.As illustrated in Fig.",
    "next": "1a, all layers exhibit sparsity exceeding 90%.On average, across all layers, this activation sparsity results in substantial weight transfer (I/O) savings between the GPU and CPU, impacting 95% of the rows of the down projection layer's weights (Fig.",
    "hard_negative": [
      225039882,
      6628106,
      59317031,
      235422257,
      247011143,
      86611921,
      52967399,
      56657912
    ],
    "easy_negative": [
      219952676,
      1704266,
      260125086
    ]
  },
  {
    "index": 1673,
    "source_corpus_id": 207847719,
    "ref_id": "b1",
    "citation_corpus_id": 49430686,
    "start": 3089,
    "end": 3107,
    "title": "Graph-to-Sequence Learning using Gated Graph Neural Networks",
    "abstract": "Many NLP applications can be framed as a graph-to-sequence learning problem. Previous work proposing neural architectures on this setting obtained promising results compared to grammar-based approaches but still rely on linearisation heuristics and/or standard recurrent networks to achieve the best performance. In this work, we propose a new model that encodes the full structural information contained in the graph. Our architecture couples the recently proposed Gated Graph Neural Networks with an input transformation that allows nodes and edges to have their own hidden representations, while tackling the parameter explosion problem present in previous work. Experimental results show that our model outperforms strong baselines in generation from AMR graphs and syntax-based neural machine translation.",
    "prev": "Hence, such methods are not directly applicable for tasks such as link prediction which require relation embedding vectors.",
    "curr": "Initial attempts at learning representations for relations in graphs (Monti et al., 2018;Beck et al., 2018) have shown some performance gains on tasks like node classification and neural machine translation.",
    "next": "There has been extensive research on embedding Knowledge Graphs (KG) Wang et al., 2017) where representations of both nodes and relations are jointly learned.",
    "hard_negative": [
      7138313,
      6628106,
      284436,
      3144218,
      18600354,
      12942757,
      217895,
      1557806,
      1032750,
      9135033,
      8393918,
      8066499,
      23678406,
      1423962,
      5834589,
      912349,
      5590763,
      5634542,
      455928,
      14519034
    ],
    "easy_negative": [
      15026764,
      225067490,
      15730471
    ]
  },
  {
    "index": 1678,
    "source_corpus_id": 221971208,
    "ref_id": "b33",
    "citation_corpus_id": 11754890,
    "start": 8747,
    "end": 8751,
    "title": "Representation Learning Using Multi-Task Deep Neural Networks for Semantic Classification and Information Retrieval",
    "abstract": "Methods of deep neural networks (DNNs)have recently demonstrated superior performance on a number of natural language processing tasks. However, in most previous work, the models are learned based on either unsupervised objectives, which does not directly optimize the desired task, or singletask supervised objectives, which often suffer from insufficient training data. We develop a multi-task DNN for learning representations across multiple tasks, not only leveraging large amounts of cross-task data, but also benefiting from a regularization effect that leads to more general representations to help tasks in new domains. Our multi-task DNN approach combines tasks of multiple-domain classification (for query classification) and information retrieval (ranking for web search), and demonstrates significant gains over strong baselines in a comprehensive set of domain adaptation.",
    "prev": "A prominent approach uses explicit parameter sharing; for instance, by means of common low-level layers leading to different heads.",
    "curr": "Among others, this has been successfully applied to vision [72], language [34], and reinforcement learning [18] tasks.",
    "next": "In addition, a variety of ways to combine taskspecific representations have arisen, such as cross-stitch networks [41], or lateral connections [53].",
    "hard_negative": [
      990233,
      2141094,
      1957433,
      9079100,
      1306065,
      7478738,
      85205,
      11616343,
      629094,
      216034672,
      10473972
    ],
    "easy_negative": [
      26147350,
      17247976,
      17872035
    ]
  },
  {
    "index": 1680,
    "source_corpus_id": 423406,
    "ref_id": "b26",
    "citation_corpus_id": 3116311,
    "start": 2566,
    "end": 2586,
    "title": "Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions",
    "abstract": "We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model's ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.",
    "prev": "In contrast to sequential models, these models' architectures are organized according to each sentence's syntactic structure, that is, the hierarchical organization of words into nested phrases that characterizes human intuitions about how words combine to form grammatical sentences.",
    "curr": "Prior work on tree-structured models has assumed that trees are either provided together with the input sentences (Clark et al., 2008;Grefenstette & Sadrzadeh, 2011;Socher et al., 2011;2013;Tai et al., 2015) or that they are predicted based on explicit treebank annotations jointly with the downstream task (Bowman et al., 2016;Dyer et al., 2016).",
    "next": "The last approach for constructing sentence representations uses convolutional neural networks to produce the representation in a bottom up manner, either with syntactic information (Ma et al., 2015) or without (Kim, 2014;Kalchbrenner et al., 2014).",
    "hard_negative": [
      388,
      2279432,
      6684426,
      9656604,
      866726,
      7105713,
      1688003,
      6627923,
      3264224,
      629094,
      2527473
    ],
    "easy_negative": [
      227231695,
      251564410,
      245385766
    ]
  },
  {
    "index": 1682,
    "source_corpus_id": 5071138,
    "ref_id": "b4",
    "citation_corpus_id": 26501419,
    "start": 3485,
    "end": 3505,
    "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    "abstract": "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K questionanswer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a featurebased classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that Trivi-aQA is a challenging testbed that is worth significant future study. 1",
    "prev": "It is therefore critical, that the dataset benchmarks established for the RC task keep progressing in complexity to reflect the challenges that arise in true language understanding, thereby enabling the development of models and techniques to solve these challenges.",
    "curr": "For RC in particular, there has been significant progress over the recent years with several benchmark datasets, the most popular of which are the SQuAD dataset (Rajpurkar et al., 2016a), TriviaQA (Joshi et al., 2017), MS MARCO (Nguyen et al., 2016), MovieQA (Tapaswi et al., 2016) and clozestyle datasets (Mostafazadeh et al., 2016;Onishi et al., 2016;Hermann et al., 2015).",
    "next": "However, these benchmarks, owing to both the nature of the passages and the QA pairs to evaluate the RC task, have 2 primary limitations in studying language understanding: (i) Other than MovieQA, which is a small dataset of 15K QA pairs, all other largescale RC datasets deal only with factual descriptive passages and not narratives (involving events with causality linkages that require reasoning and background knowledge) which is the case with a lot of real-world content such as story books, movies, news reports, etc.",
    "hard_negative": [
      6360322,
      6401679,
      8535316,
      215514151,
      8764466,
      16483125,
      9526475,
      11816014,
      1373518,
      2381275,
      9027681,
      216034672,
      5761781,
      6857205
    ],
    "easy_negative": [
      18125610,
      12036979,
      219310290
    ]
  },
  {
    "index": 1691,
    "source_corpus_id": 251648935,
    "ref_id": "b21",
    "citation_corpus_id": 1428702,
    "start": 2565,
    "end": 2583,
    "title": "Learning Word Vectors for Sentiment Analysis",
    "abstract": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term-document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.",
    "prev": "This is problematic precisely because many black box models, such as deep neural networks, perform well by creating complex structures and combining features in their latent layers.",
    "curr": "To address this, recent methods have been proposed to learn the interaction between features (Sundararajan et al., 2020a;Maas et al., 2011).",
    "next": "Their definition of interaction assumes features affect each other symmetrically; however, in many real-world applications, feature interactions may be asymmetrical.",
    "hard_negative": [
      1260035,
      388,
      2279432,
      10473638,
      7105713,
      2787775,
      218515777,
      3264224,
      629094,
      469886
    ],
    "easy_negative": [
      6573652,
      14333463,
      37020102
    ]
  },
  {
    "index": 1693,
    "source_corpus_id": 253080775,
    "ref_id": "b35",
    "citation_corpus_id": 53296520,
    "start": 7985,
    "end": 8006,
    "title": "COMMONSENSEQA: A Question Answering Challenge Targeting Commonsense Knowledge",
    "abstract": "When answering a question, people often draw upon their rich world knowledge in addition to the particular context. Recent work has focused primarily on answering questions given some relevant document or context, and required very little general background. To investigate question answering with prior knowledge, we present COMMONSENSEQA: a challenging new dataset for commonsense question answering. To capture common sense beyond associations, we extract from CON-CEPTNET (Speer et al., 2017) multiple target concepts that have the same semantic relation to a single source concept. Crowd-workers are asked to author multiple-choice questions that mention the source concept and discriminate in turn between each of the target concepts. This encourages workers to create questions with complex semantics that often require prior knowledge. We create 12,247 questions through this procedure and demonstrate the difficulty of our task with a large number of strong baselines. Our best baseline is based on BERT-large (Devlin et al., 2018)  and obtains 56% accuracy, well below human performance, which is 89%.",
    "prev": "On the other hand, ELI5 (Fan et al., 2019) (Jhamtani & Clark, 2020), and EntailmentBank (Dalvi et al., 2021) focus on explanation and reasoning much like WIKIWHY, albeit with significant differences (Table 1).",
    "curr": "CoS-E's explanations for CommonsenseQA (Talmor et al., 2019) mark an important first step, but the commonsense explanations have limited depth, often requiring a single hop of reasoning.",
    "next": "eQASC and EntailmentBank feature richer explanations with more complex structure, tightly focusing on grade school level science facts.",
    "hard_negative": [
      1726501,
      1119274,
      26501419,
      1957433,
      1461182,
      3626819,
      11816014,
      1994584
    ],
    "easy_negative": [
      174804249,
      218900756,
      252819288
    ]
  },
  {
    "index": 1700,
    "source_corpus_id": 238354231,
    "ref_id": "b30",
    "citation_corpus_id": 56657912,
    "start": 19776,
    "end": 19780,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "We consider input perturbations that are common in the literature: (a) white noise; (b) salt and pepper; and (c) adversarial perturbations (see Section F).",
    "curr": "We evaluate the average performance of NFM with different model architectures on CIFAR-10 [38], CIFAR-100 [38], ImageNet [13], and CIFAR-10c [31].",
    "next": "We use a pre-activated residual network (ResNet) with depth 18 [ [36]; and noisy mixup [76].",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      53095963,
      7351982,
      27855180
    ]
  },
  {
    "index": 1701,
    "source_corpus_id": 226278174,
    "ref_id": "b27",
    "citation_corpus_id": 211126567,
    "start": 4863,
    "end": 4880,
    "title": "Published as a conference paper at ICLR 2020 QUERY2BOX: REASONING OVER KNOWLEDGE GRAPHS IN VECTOR SPACE USING BOX EMBEDDINGS",
    "abstract": "Answering complex logical queries on large-scale incomplete knowledge graphs (KGs) is a fundamental yet challenging task. Recently, a promising approach to this problem has been to embed KG entities as well as the query into a vector space such that entities that answer the query are embedded close to the query. However, prior work models queries as single points in the vector space, which is problematic because a complex query represents a potentially large set of its answer entities, but it is unclear how such a set can be represented as a single point. Furthermore, prior work can only handle queries that use conjunctions (\u2227) and existential quantifiers (\u2203). Handling queries with logical disjunctions (\u2228) remains an open problem. Here we propose QUERY2BOX, an embedding-based framework for reasoning over arbitrary queries with \u2227, \u2228, and \u2203 operators in massive and incomplete KGs. Our main insight is that queries can be embedded as boxes (i.e., hyper-rectangles), where a set of points inside the box corresponds to a set of answer entities of the query. We show that conjunctions can be naturally represented as intersections of boxes and also prove a negative result that handling disjunctions would require embedding with dimension proportional to the number of KG entities. However, we show that by transforming queries into a Disjunctive Normal Form, QUERY2BOX is capable of handling arbitrary logical queries with \u2227, \u2228, \u2203 in a scalable manner. We demonstrate the effectiveness of QUERY2BOX on three large KGs and show that QUERY2BOX achieves up to 25% relative improvement over the state of the art. * Equal contributions. Project website with data and code: http://snap.stanford.edu/ query2box",
    "prev": "We then propose two approaches for identifying the most likely values for the variable nodes in a query -either by continuous or by combinatorial optimisation.",
    "curr": "Recent work on embedding logical queries on KGs (Hamilton et al., 2018;Daza & Cochez, 2020;Ren et al., 2020) has suggested that in order to go beyond link prediction, more elaborate architectures, and a large and diverse dataset with millions of queries is required.",
    "next": "In this work, we show that this is not the case, and demonstrate that it is possible to use an efficient neural link predictor trained for 1-hop query answering, to generalise to up to 8 complex query structures.",
    "hard_negative": [
      67855617,
      21662980,
      6585702,
      13468104,
      3473900,
      11440692,
      11212020,
      5959482
    ],
    "easy_negative": [
      2620283,
      27026305,
      6041224
    ]
  },
  {
    "index": 1703,
    "source_corpus_id": 52895409,
    "ref_id": "b22",
    "citation_corpus_id": 3568073,
    "start": 32598,
    "end": 32619,
    "title": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024 2 . We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.",
    "prev": "), CelebA (Liu et al.",
    "curr": "(2015)), and CelebAHQ (Karras et al., 2018) datasets.",
    "next": "We compare our approach to recent stabilization techniques: WGAN-GP , instance noise , spectral normalization (SN) , and gradient penalty (GP) , as well as the original GAN  on CIFAR-10.",
    "hard_negative": [
      18828233,
      6628106
    ],
    "easy_negative": [
      160187,
      235097231,
      227231794
    ]
  },
  {
    "index": 1708,
    "source_corpus_id": 262217283,
    "ref_id": "b31",
    "citation_corpus_id": 251442769,
    "start": 4896,
    "end": 4899,
    "title": "Published as a conference paper at ICLR 2023 SIMPLIFIED STATE SPACE LAYERS FOR SEQUENCE MODELING",
    "abstract": "Models using structured state space sequence (S4) layers have achieved state-ofthe-art performance on long-range sequence modeling tasks. An S4 layer combines linear state space models (SSMs), the HiPPO framework, and deep learning to achieve high performance. We build on the design of the S4 layer and introduce a new state space layer, the S5 layer. Whereas an S4 layer uses many independent single-input, single-output SSMs, the S5 layer uses one multi-input, multi-output SSM. We establish a connection between S5 and S4, and use this to develop the initialization and parameterization used by the S5 model. The result is a state space layer that can leverage efficient and widely implemented parallel scans, allowing S5 to match the computational efficiency of S4, while also achieving state-of-the-art performance on several long-range sequence modeling tasks. S5 averages 87.4% on the long range arena benchmark, and 98.5% on the most difficult Path-X task. Re. Efficiently modeling long sequences with structured state",
    "prev": "In biological neural networks, the emergence of diverse neural timescales occurs via a variety of interacting mechanisms.The timescales of individual neurons' activity are determined by cellular and synaptic processes, such as the membrane or synaptic time constants that vary across brain areas and neuron types [19,20].These single-neuron timescales characterize the timescale of neural activity in the absence of recurrent interactions.However, neurons are embedded within rich network structures that also shape neural dynamics introducing network-mediated timescales.The strength of recurrent connections [21,22,23], as well as their topology [24,25,7,26] give rise to network-mediated timescales that can be much longer than single-neuron timescales.",
    "curr": "Heterogeneous and tunable single-neuron timescales have been proposed as a mechanism to adapt the timescales of RNN dynamics to task requirements and improve their performance [27,28,29,30,31,32].In these studies, the time constants of individual neurons are trained together with network connectivity.For tasks with long temporal dependencies, the distribution of trained single-neuron timescales becomes heterogeneous according to the task's memory requirements [27].Explicit training of single-neuron timescales improves network performance in benchmark RNN tasks in rate [28,29] and spiking [30,31,27] networks and leads to greater robustness [27] and adaptability to novel stimuli [32].While these studies propose the adaptability of single-neuron timescales as a potential mechanism for solving time-dependent tasks, the exact contribution of single-neuron and network-mediated timescales in optimally solving the tasks is unknown.",
    "next": "Here, we study how single-neuron and network-mediated timescales shape the dynamics and performance of RNNs trained on long-memory tasks.We show that the extent to which longer single-neuron or network-mediated timescales are necessary for solving such tas",
    "hard_negative": [
      51559,
      11336213,
      67855286,
      222067132
    ],
    "easy_negative": [
      199555238,
      37962359,
      15140656
    ]
  },
  {
    "index": 1712,
    "source_corpus_id": 257365136,
    "ref_id": "b24",
    "citation_corpus_id": 40100965,
    "start": 1609,
    "end": 1630,
    "title": "Universal Language Model Fine-tuning for Text Classification",
    "abstract": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\u00d7 more data. We opensource our pretrained models and code 1 .",
    "prev": "1 * Work done during an internship at MIT-IBM Watson AI Lab.",
    "curr": "INTRODUCTION\n\nFinetuning pretrained language models (PLMs) has led to significant improvements across various downstream NLP tasks Howard & Ruder, 2018;Raffel et al., 2020).",
    "next": "However, the conventional paradigm of full task-specific finetuning (FT) is difficult to scale to multiple tasks, given that modern PLMs can have hundreds of millions (or even billions) of parameters.",
    "hard_negative": [
      16299141,
      28971531,
      16386838,
      7928230,
      7942973,
      3626819,
      10728540,
      1428702,
      14337532,
      4460159
    ],
    "easy_negative": [
      8592595,
      11388219,
      16583045
    ]
  },
  {
    "index": 1715,
    "source_corpus_id": 174801410,
    "ref_id": "b19",
    "citation_corpus_id": 53221030,
    "start": 1967,
    "end": 1988,
    "title": "JANOSSY POOLING: LEARNING DEEP PERMUTATION- INVARIANT FUNCTIONS FOR VARIABLE-SIZE INPUTS",
    "abstract": "We consider a simple and overarching representation for permutation-invariant functions of sequences (or set functions). Our approach, which we call Janossy pooling, expresses a permutation-invariant function as the average of a permutation-sensitive function applied to all reorderings of the input sequence. This allows us to leverage the rich and mature literature on permutation-sensitive functions to construct novel and flexible permutation-invariant functions. If carried out naively, Janossy pooling can be computationally prohibitive. To allow computational tractability, we consider three kinds of approximations: canonical orderings of sequences, functions with k-order interactions, and stochastic optimization algorithms with random permutations. Our framework unifies a variety of existing work in the literature, and suggests possible modeling and algorithmic extensions. We explore a few in our experiments, which demonstrate improved performance over current state-of-the-art methods.",
    "prev": "While there has been recent progress on learning such functions (Zaheer et al., 2017;Qi et al., 2017), they compress a set of any size down to a single feature vector in one step.",
    "curr": "This can be a significant bottleneck in what these functions can represent efficiently, particularly when relations between elements of the set need to be modeled (Murphy et al., 2019;Zhang et al., 2019b).",
    "next": "Decoder: This turns the latent space back into a set.",
    "hard_negative": [
      22191393,
      5590763
    ],
    "easy_negative": [
      199577786,
      46160206,
      1266013
    ]
  },
  {
    "index": 1718,
    "source_corpus_id": 199577786,
    "ref_id": "b14",
    "citation_corpus_id": 1957433,
    "start": 6784,
    "end": 6809,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "2 An RL-based Generator-Evaluator Architecture Given a passage X p \" tx p 1 , x p 2 , ..., x p N u and a target answer X a \" tx a 1 , x a 2 , ..., x a L u, the task of natural question generation is to generate the best natural language question\u0176 \" ty 1 , y 2 , ..., y T u which maximizes the conditional likelihood\u0176 \" argmax Y P pY |X p , X a q.",
    "curr": "We use 300-dim GloVe (Pennington et al., 2014) embeddings and 1024-dim BERT (Devlin et al., 2018) embeddings to embed each word in the passage and the answer.",
    "next": "Let us denote g p i and g a j as the GloVe embeddings of passage word x p i and answer word x a j , respectively.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      6615197,
      227231304,
      256416262
    ]
  },
  {
    "index": 1721,
    "source_corpus_id": 251647798,
    "ref_id": "b45",
    "citation_corpus_id": 12713052,
    "start": 2868,
    "end": 2885,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "The most common way of constructing a deep CNN is to stack a number of convolutional layers as well as other basic layers organized with the predefined feature connection topology.",
    "curr": "Along with great advances in CNN architecture design by manual engineering (Krizhevsky et al., 2012;He et al., 2016;Howard et al., 2017) and automatic searching (Zoph & Le, 2017;Pham et al., 2018;Howard et al., 2019), lots of prevailing classification backbones have been presented.",
    "next": "Recent works Hu et al., 2018b;Chen et al., 2020) show that incorporating attention mechanisms into convolutional blocks can further push the performance boundaries of modern CNNs, and thus it has attracted great research interest in the deep learning community.",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      2507032,
      229365678,
      445781
    ]
  },
  {
    "index": 1723,
    "source_corpus_id": 238419164,
    "ref_id": "b4",
    "citation_corpus_id": 52255687,
    "start": 3282,
    "end": 3307,
    "title": "Data Statements for Natural Language Processing: Toward Mitigating System Bias and Enabling Better Science",
    "abstract": "In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development. Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations. We present a form that data statements can take and explore the implications of adopting them as part of regular practice. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.",
    "prev": "Specifically for machine learning, recent reproducibility initiatives (Pineau et al., 2021) nicely summarize how differences in used data, miss-or under-specification of training and evaluation metrics, along with frequent over-claims of conclusions beyond gathered empirical evidence impose persisting obstacles in our current literature.",
    "curr": "Similar conclusions have been reached in related works focused on specifics of reinforcement learning (Li & Talwalkar, 2019), neural architecture search (Lindauer & Hutter, 2020), human-centered machine learning model cards (Mitchell et al., 2019), or general dataset sheet specifications (Bender & Friedman, 2018;Gebru et al., 2018), which all make valuable propositions to overcome existing gaps through the creation of standardized best-practice (check-)lists.",
    "next": "It should thus come as no surprise that the emerging work in continual learning is no stranger to the above challenges.",
    "hard_negative": [
      21670658,
      1721388,
      1389483,
      7105713,
      16633800,
      6323786,
      1083991,
      7396193,
      15872106,
      13997424
    ],
    "easy_negative": [
      10451956,
      10432514,
      21686891
    ]
  },
  {
    "index": 1725,
    "source_corpus_id": 221136343,
    "ref_id": "b2",
    "citation_corpus_id": 3495200,
    "start": 2036,
    "end": 2039,
    "title": "LEARNING TO REPRESENT PROGRAMS WITH GRAPHS",
    "abstract": "Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures. In this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VARNAMING, in which a network attempts to predict the name of a variable given its usage, and VARMISUSE, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VARMISUSE task in many cases. Additionally, our testing showed that VARMISUSE identifies a number of bugs in mature open-source projects.",
    "prev": "Introduction\n\nGraph neural networks (GNNs) have received substantial attention in recent years due to their ability to model irregularly structured data.",
    "curr": "As a result, they are extensively used for applications as diverse as molecular interactions [10,44], social networks [15], recommendation systems [38] or program understanding [3].",
    "next": "Recent advancements have centered around building more sophisticated models [30,15,40], including new types of layers [24,39,45] and better aggregation functions [8].",
    "hard_negative": [
      11336213,
      1957433,
      8393918
    ],
    "easy_negative": [
      12822295,
      259376503,
      248496326
    ]
  },
  {
    "index": 1739,
    "source_corpus_id": 18114929,
    "ref_id": "b21",
    "citation_corpus_id": 5959482,
    "start": 2209,
    "end": 2212,
    "title": "Efficient Estimation of Word Representations in Vector Space",
    "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities. arXiv:1301.3781v3 [cs.CL] 7 Sep 2013 1 The test set is available at www.fit.vutbr.cz/\u02dcimikolov/rnnlm/word-test.v1.txt 2",
    "prev": "INTRODUCTION\n\nDistributed representations are embeddings of words in a real vector space, achieved via an appropriate function that models the interaction between neighboring words in sentences (e.g.",
    "curr": ": neural networks [6,23,13], log-bilinear models [25,22], co-occurrence statistics [28,19]).",
    "next": "Such an approach has been strikingly successful in capturing the syntactic and semantic similarity between words (and pairs of words), via simple linear algebraic relations between their corresponding vector representations.",
    "hard_negative": [
      629094,
      633992,
      5278106,
      1428702
    ],
    "easy_negative": [
      40900120,
      31764,
      232021885
    ]
  },
  {
    "index": 1742,
    "source_corpus_id": 259936734,
    "ref_id": "b3",
    "citation_corpus_id": 222067132,
    "start": 2938,
    "end": 2940,
    "title": "Published as a conference paper at ICLR 2021 RETHINKING ATTENTION WITH PERFORMERS",
    "abstract": "We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attentionkernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can also be used to efficiently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efficient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers. * Equal contribution. Correspondence to {kchoro,lcolwell}@google.com. Code for Transformer models on protein data can be found in github.com/google-research/ google-research/tree/master/protein_lm and Performer code can be found in github.com/ google-research/google-research/tree/master/performer. Google AI Blog: https:// ai.googleblog.com/2020/10/rethinking-attention-with-performers.html Published as a conference paper at ICLR 2021 layers(Child et al., 2019). Unfortunately, there is a lack of rigorous guarantees for the representation power produced by such methods, and sometimes the validity of sparsity patterns can only be verified empirically through trial and error by constructing special GPU operations (e.g. either writing C++ CUDA kernels (Child et al., 2019) or using TVMs(Beltagy et al., 2020)). Other techniques which aim to reduce Transformers' space complexity include reversible residual layers allowing one-time activation storage in training(Kitaev et al., 2020)and shared attention weights(Xiao et al., 2019). These constraints may impede application to long-sequence problems, where approximations of the attention mechanism are not sufficient. Approximations based on truncated back-propagation  are also unable to capture long-distance correlations since the gradients are only propagated inside a localized window. Other methods propose biased estimation of regular attention but only in the non-causal setting and with large mean squared error .In response, we introduce the first Transformer architectures, Performers, capable of provably accurate and practical estimation of regular (softmax) full-rank attention, but of only linear space and time complexity and not relying on any priors such as sparsity or low-rankness. Performers use the Fast Attention Via positive Orthogonal Random features (FAVOR+) mechanism, leveraging new methods for approximating softmax and Gaussian kernels, which we propose. We believe these methods are of independent interest, contributing to the theory of scalable kernel methods. Consequently, Performers are the first linear architectures fully compatible (via small amounts of fine-tuning) with regular Transformers, providing strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and lower variance of the approximation.FAVOR+ can be also applied to efficiently model other kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, that are beyond the reach of regular Transformers, and find for them optimal attention-kernels. FAVOR+ can also be applied beyond the Transformer scope as a more scalable replacement for regular attention, which itself has a wide variety of uses in computer vision(Fu et al., 2019), reinforcement learning (Zambaldi et al., 2019), training with softmax cross entropy loss, and even combinatorial optimization (Vinyals et al., 2015).",
    "prev": "Emerging use cases such as long document querying and story writing have demonstrated a need for models with such long context.",
    "curr": "To reduce the computational requirement of attention on such long context, there have been numerous methods proposed to approximate attention [2,3,4,8,9,14,19,20].",
    "next": "Though these methods have seen some use cases, as far as we know, most large-scale training runs still use standard attention.",
    "hard_negative": [
      13747425,
      5273326,
      49667762,
      202888885
    ],
    "easy_negative": [
      202540071,
      1890099,
      10573134
    ]
  },
  {
    "index": 1743,
    "source_corpus_id": 247292764,
    "ref_id": "b19",
    "citation_corpus_id": 221785486,
    "start": 2746,
    "end": 2764,
    "title": "Published as a conference paper at ICLR 2021 LEARNING FROM PROTEIN STRUCTURE WITH GEOMETRIC VECTOR PERCEPTRONS",
    "abstract": "Learning on 3D structures of large biomolecules is emerging as a distinct area in machine learning, but there has yet to emerge a unifying network architecture that simultaneously leverages the geometric and relational aspects of the problem domain. To address this gap, we introduce geometric vector perceptrons, which extend standard dense layers to operate on collections of Euclidean vectors. Graph neural networks equipped with such layers are able to perform both geometric and relational reasoning on efficient representations of macromolecules. We demonstrate our approach on two important problems in learning from protein structure: model quality assessment and computational protein design. Our approach improves over existing classes of architectures on both problems, including state-ofthe-art convolutional neural networks and graph neural networks. We release our code at https://github.com/drorlab/gvp.",
    "prev": "Despite its effectiveness in various applications, a more intrinsic and informative representation for molecules is the 3D geometry, also known as conformation, where atoms are represented as their Cartesian coordinates.",
    "curr": "The 3D structures determine the biological and physical properties of molecules and hence play a key role in many applications such as computational drug and material design (Thomas et al., 2018;Gebauer et al., 2021;Jing et al., 2021;Batzner et al., 2021).",
    "next": "Unfortunately, how to predict stable molecular conformation remains a challenging problem.",
    "hard_negative": [
      8227328,
      211842237
    ],
    "easy_negative": [
      63313260,
      226262270,
      263711403
    ]
  },
  {
    "index": 1745,
    "source_corpus_id": 51979536,
    "ref_id": "b26",
    "citation_corpus_id": 5037032,
    "start": 3358,
    "end": 3361,
    "title": "ZERO-SHOT VISUAL IMITATION",
    "abstract": "The current dominant paradigm for imitation learning relies on strong supervision of expert actions to learn both what and how to imitate.We pursue an alternative paradigm wherein an agent first explores the world without any expert supervision and then distills its experience into a goal-conditioned skill policy with a novel forward consistency loss.In our framework, the role of the expert is only to communicate the goals (i.e., what to imitate) during inference.The learned policy is then employed to mimic the expert (i.e., how to imitate) after seeing just a sequence of images demonstrating the desired task.Our method is \"zero-shot\" in the sense that the agent never has access to expert actions during training or for the task demonstration at inference.We evaluate our zero-shot imitator in two real-world settings: complex rope manipulation with a Baxter robot and navigation in previously unseen office environments with a TurtleBot.Through further experiments in VizDoom simulation, we provide evidence that better mechanisms for exploration lead to learning a more capable policy which in turn improves end task performance.Videos, models, and more details are available at https://pathak22.github.io/zeroshot-imitation/. * Denotes equal contribution.",
    "prev": "There are plenty of other examples, from playing Minecraft to visiting your local zoo, where no extrinsic rewards are required.",
    "curr": "Indeed, there is evidence that pre-training an agent on a given environment using only intrinsic rewards allows it to learn much faster when fine-tuned to a novel task in a novel environment [27,28].",
    "next": "Yet, so far, there has been no systematic study of learning with only intrinsic rewards.",
    "hard_negative": [
      6628106,
      14724343
    ],
    "easy_negative": [
      7059362,
      219307387,
      18047795
    ]
  },
  {
    "index": 1750,
    "source_corpus_id": 259108646,
    "ref_id": "b1",
    "citation_corpus_id": 235436185,
    "start": 2817,
    "end": 2820,
    "title": "BEIT: BERT Pre-Training of Image Transformers",
    "abstract": "We introduce a self-supervised vision representation model BEIT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT [DCLT19] developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16\u00d716 pixels), and visual tokens (i.e., discrete tokens). We first \"tokenize\" the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEIT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.",
    "prev": "Code shall be released.",
    "curr": "Introduction\n\nImage recognition and image generation are both fundamental tasks in the field of computer vision [2,26,59,41,17,31,56,18].",
    "next": "Recognition tasks aim to perceive and understand the visual world, while generation tasks aim to create new visual data for various applications.",
    "hard_negative": [
      14307651,
      52055130,
      218581596,
      4009713
    ],
    "easy_negative": [
      6367073,
      6896607,
      238353807
    ]
  },
  {
    "index": 1751,
    "source_corpus_id": 202749904,
    "ref_id": "b36",
    "citation_corpus_id": 49882757,
    "start": 2961,
    "end": 2979,
    "title": "ClariNet: Parallel Wave Generation in End-to-End Text-to-Speech",
    "abstract": "In this work, we propose an alternative solution for parallel wave generation by WaveNet. In contrast to parallel WaveNet (Oord et al., 2018), we distill a Gaussian inverse autoregressive flow from the autoregressive WaveNet by minimizing a novel regularized KL divergence between their highly-peaked output distributions. Our method computes the KL divergence in closed-form, which simplifies the training algorithm and provides very efficient distillation. In addition, we propose the first text-to-wave neural architecture for speech synthesis, which is fully convolutional and enables fast end-to-end training from scratch. It significantly outperforms the previous pipeline that connects a text-to-spectrogram model to a separately trained WaveNet (Ping et al., 2018). We also successfully distill a parallel waveform synthesizer conditioned on the hidden representation in this end-to-end model. 2 * These authors contributed equally to this work. Correspondence to <weiping.thu@gmail.com>. Our method is named after the musical instrument clarinet, whose sound resembles human voice.2 Audio samples are in https://clarinet-demo.github.io/ arXiv:1807.07281v2 [cs.CL] 30 Jul 2018",
    "prev": "A lot of recent research on neural models for TTS has focused on improving parallelism by predicting multiple time steps in parallel, e.g.",
    "curr": "using flow-based models (van den Oord et al., 2018;Ping et al., 2019;Prenger et al., 2019;Kim et al., 2019).",
    "next": "Such highly parallelisable models are more suitable to run efficiently on modern hardware.",
    "hard_negative": [
      8451212,
      8768364,
      11212020,
      3480671
    ],
    "easy_negative": [
      2173974,
      7776388,
      9218202
    ]
  },
  {
    "index": 1757,
    "source_corpus_id": 246634117,
    "ref_id": "b32",
    "citation_corpus_id": 211132756,
    "start": 7648,
    "end": 7667,
    "title": "Published as a conference paper at ICLR 2020 SCALABLE AND ORDER-ROBUST CONTINUAL LEARN- ING WITH ADDITIVE PARAMETER DECOMPOSITION",
    "abstract": "While recent continual learning methods largely alleviate the catastrophic problem on toy-sized datasets, some issues remain to be tackled to apply them to real-world problem domains. First, a continual learning model should effectively handle catastrophic forgetting and be efficient to train even with a large number of tasks. Secondly, it needs to tackle the problem of order-sensitivity, where the performance of the tasks largely varies based on the order of the task arrival sequence, as it may cause serious problems where fairness plays a critical role (e.g. medical diagnosis). To tackle these practical challenges, we propose a novel continual learning method that is scalable as well as order-robust, which instead of learning a completely shared set of weights, represents the parameters for each task as a sum of task-shared and sparse task-adaptive parameters. With our Additive Parameter Decomposition (APD), the task-adaptive parameters for earlier tasks remain mostly unaffected, where we update them only to reflect the changes made to the task-shared parameters. This decomposition of parameters effectively prevents catastrophic forgetting and order-sensitivity, while being computation-and memory-efficient. Further, we can achieve even better scalability with APD using hierarchical knowledge consolidation, which clusters the task-adaptive parameters to obtain hierarchically shared parameters. We validate our network with APD, APD-Net, on multiple benchmark datasets against state-of-the-art continual learning methods, which it largely outperforms in accuracy, scalability, and order-robustness.",
    "prev": "In order to find the optimal structure for each of the sequential tasks, Reinforced Continual Learning (RCL) (Xu & Zhu, 2018) leverages reinforcement learning and (Li et al., 2019) adapts architecture search.",
    "curr": "APD (Yoon et al., 2020) adds additional task-specific parameters for each task and selectively learns the task-shared parameters.",
    "next": "Regularization-based methods.",
    "hard_negative": [
      14124313,
      53100211,
      3693512,
      13570924,
      4009713,
      54443381
    ],
    "easy_negative": [
      5888923,
      248118908,
      219708470
    ]
  },
  {
    "index": 1764,
    "source_corpus_id": 59310641,
    "ref_id": "b36",
    "citation_corpus_id": 1998416,
    "start": 2092,
    "end": 2111,
    "title": "Effective Approaches to Attention-based Neural Machine Translation",
    "abstract": "An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. 1",
    "prev": "RNNs integrate context information by updating a hidden state at every time-step, CNNs summarize a fixed size context through multiple layers, while as self-attention directly summarizes all context.",
    "curr": "Attention assigns context elements attention weights which define a weighted sum over context representations Sukhbaatar et al., 2015;Chorowski et al., 2015;Luong et al., 2015).",
    "next": "Source-target attention summarizes information from another sequence such as in machine translation while as self-attention operates over the current sequence.",
    "hard_negative": [
      9709731,
      2863491,
      5590763,
      8884845,
      1245593,
      12639289
    ],
    "easy_negative": [
      256808549,
      14045921,
      229924184
    ]
  },
  {
    "index": 1765,
    "source_corpus_id": 252762544,
    "ref_id": "b3",
    "citation_corpus_id": 233033916,
    "start": 3203,
    "end": 3224,
    "title": "What Will it Take to Fix Benchmarking in Natural Language Understanding?",
    "abstract": "Evaluation for many natural language understanding (NLU) tasks is broken: Unreliable and biased systems score so highly on standard benchmarks that there is little room for researchers who develop better systems to demonstrate their improvements. The recent trend to abandon IID benchmarks in favor of adversarially-constructed, out-of-distribution test sets ensures that current models will perform poorly, but ultimately only obscures the abilities that we want our benchmarks to measure. In this position paper, we lay out four criteria that we argue NLU benchmarks should meet. We argue most current benchmarks fail at these criteria, and that adversarial data collection does not meaningfully address the causes of these failures. Instead, restoring a healthy evaluation ecosystem will require significant progress in the design of benchmark datasets, the reliability with which they are annotated, their size, and the ways they handle social bias.",
    "prev": "(Wallace et al., 2022) A major concern is that adversarial data collection proliferates idiosyncratic examples that do well in fooling models but eliminate coverage of necessary yet easier test cases.",
    "curr": "This can, in turn, reduce dataset diversity and limit external validity (Bowman & Dahl, 2021).",
    "next": "A growing line of theoretical and empirical research on static benchmarks has improved our understanding of the strengths and limitations of this setting.",
    "hard_negative": [
      5074049,
      21670658,
      235408131,
      25422730,
      222291723,
      174799757,
      73729169,
      7228830,
      207757985,
      202540590,
      218971825,
      52019251,
      222080326,
      52255687,
      218487111,
      156053191,
      5034059,
      202235596,
      222124366,
      11816014,
      86611921,
      207756753,
      52123220,
      2381275,
      1428702,
      216035815,
      52967399,
      47018994,
      196181887
    ],
    "easy_negative": [
      61030,
      219179868,
      10160110
    ]
  },
  {
    "index": 1768,
    "source_corpus_id": 219558527,
    "ref_id": "b42",
    "citation_corpus_id": 202539496,
    "start": 1428,
    "end": 1431,
    "title": "Entity, Relation, and Event Extraction with Contextualized Span Representations",
    "abstract": "We examine the capabilities of a unified, multitask framework for three information extraction tasks: named entity recognition, relation extraction, and event extraction. Our framework (called DYGIE++) accomplishes all tasks by enumerating, refining, and scoring text spans designed to capture local (withinsentence) and global (cross-sentence) context. Our framework achieves state-of-theart results across all tasks, on four datasets from a variety of domains. We perform experiments comparing different techniques to construct span representations. Contextualized embeddings like BERT perform well at capturing relationships among entities in the same or adjacent sentences, while dynamic span graph updates model long-range crosssentence relationships. For instance, propagating span representations via predicted coreference links can enable the model to disambiguate challenging entity mentions. Our code is publicly available at https://github. com/dwadden/dygiepp and can be easily adapted for new tasks or datasets.",
    "prev": "Generally, we observe a decrease in their relative impact when modifying the fine-tuning process based on our findings.",
    "curr": "Introduction\n\nFine-tuning self-supervised pre-trained models has significantly boosted state-of-the-art performance on Natural Language Processing (NLP) tasks [13,28,43,51,56].",
    "next": "One of the most effective models for this process is BERT [7].",
    "hard_negative": [
      20744,
      41479182,
      2797612,
      51877560,
      102352698,
      3626819,
      2476229,
      11816014,
      2114517,
      2367456,
      4891749,
      49544037,
      52118895
    ],
    "easy_negative": [
      243950143,
      262083735,
      1701627
    ]
  },
  {
    "index": 1770,
    "source_corpus_id": 259847777,
    "ref_id": "b4",
    "citation_corpus_id": 52889459,
    "start": 4588,
    "end": 4608,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "INTRODUCTION\n\nA generative adversarial network (GAN) (Goodfellow et al., 2014) is a popular approach for generative modeling.",
    "curr": "GANs have achieved remarkable performance in various domains such as image (Brock et al., 2019;Karras et al., 2019;, audio (Kumar et al., 2019;Kong et al., 2020), and video (Tulyakov et al., 2018;Hao et al., 2021).",
    "next": "The aim of GAN is to learn a target probability measure via a neural network, called a generator.",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      14071375,
      5087840,
      735495
    ]
  },
  {
    "index": 1779,
    "source_corpus_id": 108297336,
    "ref_id": "b17",
    "citation_corpus_id": 13123084,
    "start": 2460,
    "end": 2481,
    "title": "Published as a conference paper at ICLR 2017 TEMPORAL ENSEMBLING FOR SEMI-SUPERVISED LEARNING",
    "abstract": "In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels.",
    "prev": "Semi-supervised learning is particularly valuable in applications such as medical imaging, where labeled data may be scarce and expensive (Oliver et al., 2018).",
    "curr": "Currently the best semi-supervised results are obtained by consistency-enforcing approaches (Bachman et al., 2014;Laine and Aila, 2017;Tarvainen and Valpola, 2017;Miyato et al., 2017;Park et al., 2017).",
    "next": "These methods use unlabeled data to stabilize their predictions under input or weight perturbations.",
    "hard_negative": [
      1965764,
      2780493,
      6230637,
      9398766,
      1487550
    ],
    "easy_negative": [
      15124020,
      10477942,
      8749531
    ]
  },
  {
    "index": 1784,
    "source_corpus_id": 257404922,
    "ref_id": "b72",
    "citation_corpus_id": 237372712,
    "start": 18004,
    "end": 18024,
    "title": "MINIF2F: A CROSS-SYSTEM BENCHMARK FOR FORMAL OLYMPIAD-LEVEL MATHEMATICS",
    "abstract": "We present miniF2F, a dataset of formal Olympiad-level mathematics problems statements intended to provide a unified cross-system benchmark for neural theorem proving. The miniF2F benchmark currently targets Metamath, Lean, Isabelle (partially) and HOL Light (partially) and consists of 488 problem statements drawn from the AIME, AMC, and the International Mathematical Olympiad (IMO), as well as material from high-school and undergraduate mathematics courses. We report baseline results using GPT-f (Polu & Sutskever, 2020), a neural theorem prover based on GPT-3 (Brown et al., 2020)  and provide an analysis of its performance. We intend for miniF2F to be a community-driven effort and hope that our benchmark will help spur advances in neural theorem proving.",
    "prev": "Through ablations, we study the effectiveness of Magnushammer and the contribution of its training components.",
    "curr": "More experimental results and details can be found in Appendix E.\n\n\nExperimental details\n\nBenchmarks In our experiments, we use two benchmarks: PISA (Jiang et al., 2021) and MiniF2F (Zheng et al., 2022).",
    "next": "PISA contains problems randomly selected from the Archive of Formal Proofs; we use the same 1000 problems as  for our evaluations.",
    "hard_negative": [
      220363813,
      5034059,
      11816014,
      2381275,
      85504763
    ],
    "easy_negative": [
      10299657,
      7466220,
      10414714
    ]
  },
  {
    "index": 1786,
    "source_corpus_id": 247292326,
    "ref_id": "b3",
    "citation_corpus_id": 54443381,
    "start": 12166,
    "end": 12189,
    "title": "EFFICIENT LIFELONG LEARNING WITH A-GEM",
    "abstract": "In lifelong learning, the learner is presented with a sequence of tasks, incrementally building a data-driven prior which may be leveraged to speed up learning of a new task. In this work, we investigate the efficiency of current lifelong approaches, in terms of sample complexity, computational and memory cost. Towards this end, we first introduce a new and a more realistic evaluation protocol, whereby learners observe each example only once and hyper-parameter selection is done on a small and disjoint set of tasks, which is not used for the actual learning experience and evaluation. Second, we introduce a new metric measuring how quickly a learner acquires a new skill. Third, we propose an improved version of GEM (Lopez-Paz & Ranzato, 2017), dubbed Averaged GEM (A-GEM), which enjoys the same or even better performance as GEM, while being almost as computationally and memory efficient as EWC  and other regularizationbased methods. Finally, we show that all algorithms including A-GEM can learn even more quickly if they are provided with task descriptors specifying the classification tasks under consideration. Our experiments on several standard lifelong learning benchmarks demonstrate that A-GEM has the best trade-off between accuracy and efficiency. 1",
    "prev": "Memory-based methods (Parisi et al., 2019) have achieved excellent performances in accommodating new knowledge while retaining previously learned experience.",
    "curr": "Such memory-based methods, such as gradient episodic memory (GEM) (Lopez-Paz & Ranzato, 2017) and averaged gradient episodic memory (A-GEM) (Chaudhry et al., 2018), store a subset of data from previous tasks and replay the memorized data when training on the current task.",
    "next": "For instance, A-GEM treats the losses on the episodic memories of previous tasks as inequality constraints in optimizing the objectives of current tasks and changes the model updates from the plain gradient g to g \u2212 wg ref , where g ref is the gradient computed from the loss on the memorized data and w is a non-negative weight.",
    "hard_negative": [
      22014305,
      49667227
    ],
    "easy_negative": [
      2926851,
      9765725,
      219300190
    ]
  },
  {
    "index": 1788,
    "source_corpus_id": 245329426,
    "ref_id": "b53",
    "citation_corpus_id": 212877887,
    "start": 4132,
    "end": 4149,
    "title": "THE INGREDIENTS OF REAL-WORLD ROBOTIC REINFORCEMENT LEARNING",
    "abstract": "The success of reinforcement learning for real world robotics has been, in many cases limited to instrumented laboratory scenarios, often requiring arduous human effort and oversight to enable continuous learning. In this work, we discuss the elements that are needed for a robotic learning system that can continually and autonomously improve with data collected in the real world. We propose a particular instantiation of such a system, using dexterous manipulation as our case study. Subsequently, we investigate a number of challenges that come up when learning without instrumentation. In such settings, learning must be feasible without manually designed resets, using only on-board perception, and without hand-engineered reward functions. We propose simple and scalable solutions to these challenges, and then demonstrate the efficacy of our proposed system on a set of dexterous robotic manipulation tasks, providing an in-depth analysis of the challenges associated with this learning paradigm. We demonstrate that our complete system can learn without any human intervention, acquiring a variety of vision-based skills with a real-world three-fingered hand. Results and videos can be found at https://sites.google.com/view/realworld-rl/.",
    "prev": "6.1).",
    "curr": "Moreover, while prior work has examined settings such as RL without resets (Eysenbach et al., 2017;Zhu et al., 2020;, ecological RL (Co-Reyes et al., 2020), or RL amidst non-stationarity (Xie et al., 2020) in isolated scenarios, these settings are not well-represented in existing benchmarks.",
    "next": "As a result, there is not a consistent formal framework for evaluating autonomy in reinforcement learning and there is limited work in this direction compared to the vast literature on reinforcement learning.",
    "hard_negative": [
      12256925,
      27254961,
      3162051,
      52055130
    ],
    "easy_negative": [
      218684613,
      248366220,
      256461173
    ]
  },
  {
    "index": 1794,
    "source_corpus_id": 49667762,
    "ref_id": "b17",
    "citation_corpus_id": 2009318,
    "start": 4768,
    "end": 4794,
    "title": "NEURAL GPUS LEARN ALGORITHMS",
    "abstract": "Learning an algorithm from examples is a fundamental problem that has been widely studied. It has been addressed using neural networks too, in particular by Neural Turing Machines (NTMs). These are fully differentiable computers that use backpropagation to learn their own programming. Despite their appeal NTMs have a weakness that is caused by their sequential nature: they are not parallel and are are hard to train due to their large depth when unfolded. We present a neural network architecture to address this problem: the Neural GPU. It is based on a type of convolutional gated recurrent unit and, like the NTM, is computationally universal. Unlike the NTM, the Neural GPU is highly parallel which makes it easier to train and efficient to run. An essential property of algorithms is their ability to handle inputs of arbitrary size. We show that the Neural GPU can be trained on short instances of an algorithmic task and successfully generalize to long instances. We verified it on a number of tasks including long addition and long multiplication of numbers represented in binary. We train the Neural GPU on numbers with up-to 20 bits and observe no errors whatsoever while testing it, even on much longer numbers. To achieve these results we introduce a technique for training deep recurrent networks: parameter sharing relaxation. We also found a small amount of dropout and gradient noise to have a large positive effect on learning and generalization.",
    "prev": "h t i represents the representation for input symbol 1 \u2264 i \u2264 m at recurrent time-step t. With dynamic halting, T is dynamically determined for each position (Section 2.2).",
    "curr": "bias may be crucial for several algorithmic and language understanding tasks of varying complexity: in contrast to models such as the Neural Turing Machine (Graves et al., 2014), the Neural GPU (Kaiser & Sutskever, 2016) or Stack RNNs , the Transformer does not generalize well to input lengths not encountered during training.",
    "next": "In this paper, we introduce the Universal Transformer (UT), a parallel-in-time recurrent self-attentive sequence model which can be cast as a generalization of the Transformer model, yielding increased theoretical capabilities and improved results on a wide range of challenging sequence-to-sequence tasks.",
    "hard_negative": [
      7823468,
      12639289
    ],
    "easy_negative": [
      252624558,
      17755594,
      549335
    ]
  },
  {
    "index": 1798,
    "source_corpus_id": 220249831,
    "ref_id": "b40",
    "citation_corpus_id": 1428702,
    "start": 32626,
    "end": 32645,
    "title": "Learning Word Vectors for Sentiment Analysis",
    "abstract": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term-document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.",
    "prev": "C Additional Results\n\nC.1 Simulating heteroskedastic noise on IMDB-review.",
    "curr": "IMDB-review dataset has a total of 50,000 (25,000 positive and 25,000 negative reviews) movie reviews for binary sentiment classification [Maas et al., 2011].",
    "next": "To simulate heteroskedastic noise for this binary classification problem, we project 5% of the labels of negative reviews to positive, and 40% in the reverse direction.",
    "hard_negative": [
      1260035,
      388,
      2279432,
      10473638,
      7105713,
      2787775,
      218515777,
      3264224,
      629094,
      469886
    ],
    "easy_negative": [
      244908227,
      14345307,
      32269436
    ]
  },
  {
    "index": 1812,
    "source_corpus_id": 2906360,
    "ref_id": "b14",
    "citation_corpus_id": 6715185,
    "start": 1751,
    "end": 1776,
    "title": "Published as a conference paper at ICLR 2016 NEURAL PROGRAMMER: INDUCING LATENT PROGRAMS WITH GRADIENT DESCENT",
    "abstract": "Deep neural networks have achieved impressive supervised classification performance in many tasks including image recognition, speech recognition, and sequence to sequence learning. However, this success has not been translated to applications like question answering that may involve complex arithmetic and logic reasoning. A major limitation of these models is in their inability to learn even simple arithmetic and logic operations. For example, it has been shown that neural networks fail to learn to add two binary numbers reliably. In this work, we propose Neural Programmer, a neural network augmented with a small set of basic arithmetic and logic operations that can be trained end-to-end using backpropagation. Neural Programmer can call these augmented operations over several steps, thereby inducing compositional programs that are more complex than the built-in operations. The model learns from a weak supervision signal which is the result of execution of the correct program, hence it does not require expensive annotation of the correct program itself. The decisions of what operations to call, and what data segments to apply to are inferred by Neural Programmer. Such decisions, during training, are done in a differentiable fashion so that the entire network can be trained jointly by gradient descent. We find that training the model is difficult, but it can be greatly improved by adding random noise to the gradient. On a fairly complex synthetic table-comprehension dataset, traditional recurrent networks and attentional models perform poorly while Neural Programmer typically obtains nearly perfect accuracy. * Work done during an internship at Google.",
    "prev": "INTRODUCTION\n\nA dream of artificial intelligence is to build systems that can write computer programs.",
    "curr": "Recently, there has been much interest in program-like neural network models (Graves et al., 2014;Kurach et al., 2015;Joulin & Mikolov, 2015;Grefenstette et al., 2015;Sukhbaatar et al., 2015;Neelakantan et al., 2016;Kaiser & Sutskever, 2016;Reed & de Freitas, 2016;Zaremba et al., 2016;Graves et al., 2016), but none of these can write programs; that is, they do not generate human-readable source code.",
    "next": "Only very recently, Riedel et al.",
    "hard_negative": [
      14472576,
      1174836,
      1969092,
      9027681,
      11171811,
      216034672,
      340852
    ],
    "easy_negative": [
      3289985,
      11860229,
      13082999
    ]
  },
  {
    "index": 1818,
    "source_corpus_id": 244527108,
    "ref_id": "b29",
    "citation_corpus_id": 13298214,
    "start": 22862,
    "end": 22884,
    "title": "LEARNING TO NAVIGATE IN COMPLEX ENVIRONMENTS",
    "abstract": "Learning to navigate in complex environments with dynamic elements is an important milestone in developing AI agents. In this work we formulate the navigation question as a reinforcement learning problem and show that data efficiency and task performance can be dramatically improved by relying on additional auxiliary tasks leveraging multimodal sensory inputs. In particular we consider jointly learning the goal-driven reinforcement learning problem with auxiliary depth prediction and loop closure classification tasks. This approach can learn to navigate from raw sensory input in complicated 3D mazes, approaching human-level performance even under conditions where the goal location changes frequently. We provide detailed analysis of the agent behaviour 1 , its ability to localise, and its network activity dynamics, showing that the agent implicitly learns key navigation abilities.",
    "prev": "The first class of methods studies the usage of data augmentation for broadening the data distribution for training more robust feature representation (Laskin et al., 2020;Kostrikov et al., 2020;Schwarzer et al., 2021;Yarats et al., 2021).",
    "curr": "The second class explores the role of auxiliary tasks in learning representations, such as weakly-supervised classification and location recognition, for dealing with sparse and delayed supervision (Lee et al., 2020b;Mirowski et al., 2017;Oord et al., 2018).",
    "next": "The third class of methods, specifically tailored to model-based RL models, leverages generative modelling of environment dynamics, enabling joint learning of the representations and the dynamics model (Ha and Schmidhuber, 2018;Buesing et al., 2018;Hafner et al., 2019;Lee et al., 2020a;Schrittwieser et al., 2020;Hafner et al., 2020b).",
    "hard_negative": [
      8395799,
      14717992
    ],
    "easy_negative": [
      12624704,
      245855900,
      44171985
    ]
  },
  {
    "index": 1821,
    "source_corpus_id": 229923865,
    "ref_id": "b38",
    "citation_corpus_id": 53216818,
    "start": 7813,
    "end": 7834,
    "title": "Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control",
    "abstract": "We propose a \"plan online and learn offline\" framework for the setting where an agent, with an internal model, needs to continually act and learn in the world. Our work builds on the synergistic relationship between local model-based control, global value function learning, and exploration. We study how local trajectory optimization can cope with approximation errors in the value function, and can stabilize and accelerate value function learning. Conversely, we also study how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions. Finally, we also demonstrate how trajectory optimization can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. This exploration is critical for fast and stable learning of the value function. Combining these components enable solutions to complex control tasks, like humanoid locomotion and dexterous in-hand manipulation, in the equivalent of a few minutes of experience in the real world.",
    "prev": "RELATED WORK\n\nOffline and Model-based RL: A number of prior works have studied the problem of learning behaviors from existing offline datasets.",
    "curr": "While recent progress has been made in applying model-free RL techniques to this problem of offline or batch RL (Fujimoto et al., 2019;Wu et al., 2019;Kumar et al., 2019;Nair et al., 2020b), one approach that has shown promise is offline model-based RL (Lowrey et al., 2019;Kidambi et al., 2020;Yu et al., 2020;Argenson & Dulac-Arnold, 2020), where the agent learns a predictive model of the world from data.",
    "next": "Such model-based methods have seen success both in the offline and online RL settings, and have a rich history of being effective for planning (Deisenroth & Rasmussen, 2011;Watter et al., 2015;McAllister & Rasmussen, 2016;Chua et al., 2018;Amos et al., 2018;Hafner et al., 2019b;Nagabandi et al., 2018;Kahn et al., 2020;Dong et al., 2020) or policy optimization (Sutton, 1991;Weber et al., 2017;Ha & Schmidhuber, 2018;Janner et al., 2019;Wang & Ba, 2019;Hafner et al., 2019a).",
    "hard_negative": [
      997870,
      3075448
    ],
    "easy_negative": [
      30167491,
      227230663,
      17069935
    ]
  },
  {
    "index": 1822,
    "source_corpus_id": 260350986,
    "ref_id": "b1",
    "citation_corpus_id": 173188048,
    "start": 4872,
    "end": 4892,
    "title": "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms",
    "abstract": "We introduce a large-scale dataset of math word problems and an interpretable neural math problem solver that learns to map problems to operation programs. Due to annotation challenges, current datasets in this domain have been either relatively small in scale or did not offer precise operational annotations over diverse problem types. We introduce a new representation language to model precise operation programs corresponding to each math problem that aim to improve both the performance and the interpretability of the learned models. Using this representation language, our new dataset, MathQA, significantly enhances the AQuA dataset with fully-specified operational programs. We additionally introduce a neural sequence-to-program model enhanced with automatic problem categorization. Our experiments show improvements over competitive baselines in our MathQA as well as the AQuA datasets. The results are still significantly lower than human performance indicating that the dataset poses new challenges for future research. Our dataset is available at: https: //math-qa.github.io/math-QA/.",
    "prev": "Namely, given multiple solutions to a question, it uses confidence scores as weights to vote among the answers, which provides a soft way to focus on more accurate solutions.",
    "curr": "We evaluate SelfCheck on three math tasks, namely GSM8K (Cobbe et al., 2021), MathQA (Amini et al., 2019), and MATH (Hendrycks et al., 2021).",
    "next": "For all datasets, we find that using SelfCheck achieves a significant increase in final answer accuracies compared with simple majority voting and other baselines.",
    "hard_negative": [
      2423360,
      6628106,
      12451537,
      11336213,
      12777818,
      12728987,
      428579,
      52009450,
      2228719,
      51881520,
      11212020,
      3960255
    ],
    "easy_negative": [
      333574,
      252847504,
      219299910
    ]
  },
  {
    "index": 1823,
    "source_corpus_id": 263605855,
    "ref_id": "b35",
    "citation_corpus_id": 3104920,
    "start": 14891,
    "end": 14895,
    "title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions",
    "abstract": "We propose to use the visual denotations of linguistic expressions (i.e. the set of images they describe) to define novel denotational similarity metrics, which we show to be at least as beneficial as distributional similarities for two tasks that require semantic inference. To compute these denotational similarities, we construct a denotation graph, i.e. a subsumption hierarchy over constituents and their denotations, based on a large corpus of 30K images and 150K descriptive captions.",
    "prev": "We fine-tune a LoRA module on the pre-trained SEED-LLaMA with the template as below,\n\nUSER: <Instruction> ASSISTANT: <Answer>\n\nOnly the content of <Answer> is accounted for loss.The overall instruction tuning phase takes 16 hours for SEED-LLaMA-8B and 27 hours for SEED-LLaMA-14B with 32 A100-80G GPUs.",
    "curr": "Image \u2192 Text Text \u2192 Image Image \u2192 Text Text \u2192 Image\nR@1 R@5 R@10 R@1 R@5 R@10 R@m R@1 R@5 R@10 R@1 R@5 R@10 R@m BLIP-2 [11] 81.9  4 Experiment\n\n\nSEED Tokenizer\n\nEvaluation of Causal Embeddings.We evaluate the performance of Causal Q-Former on the imagetext retrieval using COCO [35] and Flickr30K [36].The performance is measured by Recall@K (R@K).Note that we adopt the dual-stream paradigm for inference and remove the image-textmatching (ITM) re-rank module in BLIP-2 for a fair comparison.As shown in Tab.",
    "next": "1, our Causal Q-former achieves better results than BLIP-2 in terms of an aggregated metric Recall@mean.It demonstrates that the output query embeddings with causal dependency do not drop performance than the output embeddings with bi-directional attention in BLIP-2.",
    "hard_negative": [
      9558665,
      13507979,
      8635289,
      7634844,
      2122915,
      12549805,
      3196382,
      15430366,
      5522668,
      6890477,
      10702193,
      12233462
    ],
    "easy_negative": [
      218537892,
      232257645,
      198967754
    ]
  },
  {
    "index": 1829,
    "source_corpus_id": 253581364,
    "ref_id": "b4",
    "citation_corpus_id": 202749904,
    "start": 1952,
    "end": 1976,
    "title": "HIGH FIDELITY SPEECH SYNTHESIS WITH ADVERSARIAL NETWORKS",
    "abstract": "Generative adversarial networks have seen rapid development in recent years and have led to remarkable improvements in generative modelling of images. However, their application in the audio domain has received limited attention, and autoregressive models, such as WaveNet, remain the state of the art in generative modelling of audio signals such as human speech. To address this paucity, we introduce GAN-TTS, a Generative Adversarial Network for Text-to-Speech. Our architecture is composed of a conditional feed-forward generator producing raw speech audio, and an ensemble of discriminators which operate on random windows of different sizes. The discriminators analyse the audio both in terms of general realism, as well as how well the audio corresponds to the utterance that should be pronounced. To measure the performance of GAN-TTS, we employ both subjective human evaluation (MOS -Mean Opinion Score), as well as novel quantitative metrics (Fr\u00e9chet DeepSpeech Distance and Kernel DeepSpeech Distance), which we find to be well correlated with MOS. We show that GAN-TTS is capable of generating high-fidelity speech with naturalness comparable to the state-of-the-art models, and unlike autoregressive models, it is highly parallelisable thanks to an efficient feed-forward generator. Listen to GAN-TTS reading this abstract at https://storage.googleapis.com/ deepmind-media/research/abstract.wav.",
    "prev": "However, this usually suffers from poor synthesis quality due to the training/inference mismatch of the acoustic model and vocoder.",
    "curr": "End-toend training methods has been recently proposed to tackle such issues (Bi\u0144kowski et al., 2020;Weiss et al., 2021;Donahue et al., 2021;.",
    "next": "Despite the high quality, however, the training process of end-to-end models is often costly, as the waveform synthesis part needs to be trained again when training each different model.",
    "hard_negative": [
      49882757,
      17272965,
      6628106,
      17127188,
      26100519,
      3366315,
      5687613,
      6104263,
      3568073,
      13890001,
      67856213,
      52890982,
      84591,
      52889459
    ],
    "easy_negative": [
      16314205,
      235097478,
      16095657
    ]
  },
  {
    "index": 1834,
    "source_corpus_id": 260378993,
    "ref_id": "b5",
    "citation_corpus_id": 51880415,
    "start": 14628,
    "end": 14642,
    "title": "How Much Attention Do You Need? A Granular Analysis of Neural Machine Translation Architectures",
    "abstract": "With recent advances in network architectures for Neural Machine Translation (NMT) recurrent models have effectively been replaced by either convolutional or self-attentional approaches, such as in the Transformer. While the main innovation of the Transformer architecture is its use of self-attentional layers, there are several other aspects, such as attention with multiple heads and the use of many attention layers, that distinguish the model from previous baselines. In this work we take a fine-grained look at the different architectures for NMT. We introduce an Architecture Definition Language (ADL) allowing for a flexible combination of common building blocks. Making use of this language, we show in experiments that one can bring recurrent and convolutional models very close to the Transformer performance by borrowing concepts from the Transformer architecture, but not using self-attention. Additionally, we find that self-attention is much more important for the encoder side than for the decoder side, where it can be replaced by a RNN or CNN without a loss in performance in most settings. Surprisingly, even a model without any target side self-attention performs well.",
    "prev": "Normalization In Transformers, MoE layers are typically used to replace the feedforward layer in each encoder block.",
    "curr": "Thus, when using pre-normalization as most modern Transformer architectures (Domhan, 2018;Xiong et al., 2020;Riquelme et al., 2021;Fedus et al., 2022), the inputs to the MoE layer are \"layer normalized\".",
    "next": "This causes stability issues when scaling the model dimension d, since the softmax approaches a one-hot vector as d \u2192 \u221e (see Appendix E).",
    "hard_negative": [
      512833,
      12639289
    ],
    "easy_negative": [
      11890804,
      10687761,
      227231285
    ]
  },
  {
    "index": 1838,
    "source_corpus_id": 252693138,
    "ref_id": "b3",
    "citation_corpus_id": 11336213,
    "start": 1830,
    "end": 1848,
    "title": "On the Properties of Neural Machine Translation: Encoder-Decoder Approaches",
    "abstract": "Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder-Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.",
    "prev": "We demonstrate perplexity improvements with this new model on the Penn Treebank language modeling benchmark.",
    "curr": "INTRODUCTION\n\nStandard recurrent neural networks (RNNs), including simple RNNs (Elman, 1990), GRUs (Cho et al., 2014), and LSTMs (Hochreiter & Schmidhuber, 1997), rely on a fixed, finite number of neurons to remember information across timesteps.",
    "next": "When implemented with finite precision, they are theoretically just very large finite automata, restricting the class of formal languages they recognize to regular languages (Kleene, 1951).",
    "hard_negative": [
      5590763,
      8884845,
      10766958,
      14323132
    ],
    "easy_negative": [
      231855409,
      241583770,
      2687019
    ]
  },
  {
    "index": 1839,
    "source_corpus_id": 229153786,
    "ref_id": "b20",
    "citation_corpus_id": 14091946,
    "start": 4509,
    "end": 4530,
    "title": "Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies",
    "abstract": "The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture's grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1% errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.",
    "prev": "However, long-range dependencies have usually been studied with respect to a particular linguistic function (e.g.",
    "curr": "subject-verb number agreement (Linzen et al., 2016;Gulordava et al., 2018;Lakretz et al., 2019), and there has been less attention on the broader question of how sensitivity to prior context -broadly construed -is functionally organized within these recurrent networks.",
    "next": "Therefore, drawing on prior work in the neuroscience literature, here we demonstrate a model-free approach to mapping processing timescale in recurrent neural networks.",
    "hard_negative": [
      6628106,
      14099741,
      17352617,
      3925937,
      10915381,
      13313501,
      11212020,
      1195002
    ],
    "easy_negative": [
      60156140,
      3242607,
      250390471
    ]
  },
  {
    "index": 1841,
    "source_corpus_id": 247696299,
    "ref_id": "b7",
    "citation_corpus_id": 11336213,
    "start": 27125,
    "end": 27143,
    "title": "On the Properties of Neural Machine Translation: Encoder-Decoder Approaches",
    "abstract": "Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder-Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.",
    "prev": "PERIMENTS\n\nThis section evaluates our approach on a diverse set of dynamical systems from the robotics domain in simulations and real systems.We show that HiP-RSSM outperforms contemporary recurrent state-space models (RSSMs) and recurrent neural networks (RNNs) by a significant margin under changing dynamics scenarios.Further, we show that HiP-RSSM outperforms these models even under situations with partial observability/ missing values.We also baseline our HiP-RSSM with contemporary multi-task models and improve performance, particularly in modelling non-Markovian dynamics and under partial observability.Finally, the visualizations of the Gaussian latent task variables in HiP-RSSM demonstrates that they learn meaningful representations of the causal factors of variations in dynamics in an unsupervised fashion.",
    "curr": "We consider the following baselines:\n\n\u2022 RNNs -We compare our method to two widely used recurrent neural network architectures, LSTMs (Hochreiter & Schmidhuber, 1997) and GRUs (Cho et al., 2014).",
    "next": "\u2022 RSSMs -Among several RSSMs from the literature, we chose RKN (Becker et al., 2019) as these have shown excellent performance for dynamics learning (Shaj et al., 2020) and relies on exact inference as in our case.",
    "hard_negative": [
      5590763,
      8884845,
      10766958,
      14323132
    ],
    "easy_negative": [
      258378297,
      13888490,
      12783537
    ]
  },
  {
    "index": 1856,
    "source_corpus_id": 246634950,
    "ref_id": "b29",
    "citation_corpus_id": 3548196,
    "start": 2650,
    "end": 2669,
    "title": "Published as a conference paper at ICLR 2018 SENSITIVITY AND GENERALIZATION IN NEURAL NETWORKS: AN EMPIRICAL STUDY",
    "abstract": "In practice it is often found that large over-parameterized neural networks generalize better than their smaller counterparts, an observation that appears to conflict with classical notions of function complexity, which typically favor smaller models. In this work, we investigate this tension between complexity and generalization through an extensive empirical exploration of two natural metrics of complexity related to sensitivity to input perturbations. Our experiments survey thousands of models with various fully-connected architectures, optimizers, and other hyper-parameters, as well as four different image classification datasets.We find that trained neural networks are more robust to input perturbations in the vicinity of the training data manifold, as measured by the norm of the input-output Jacobian of the network, and that it correlates well with generalization. We further establish that factors associated with poor generalization -such as full-batch training or using random labels -correspond to lower robustness, while factors associated with good generalization -such as data augmentation and ReLU non-linearities -give rise to more robust functions. Finally, we demonstrate how the input-output Jacobian norm can be predictive of generalization at the level of individual test points. * Work done as a member of the Google Brain Residency program (g.co/brainresidency)",
    "prev": "INTRODUCTION\n\nMost recent breakthroughs in deep learning are fairly achieved with the increased complexity of over-parameterized networks (Brown et al., 2020;Raffel et al., 2020;Dosovitskiy et al., 2021;Fedus et al., 2021. arXiv:2101Jumper et al., 2021;Berner et al., 2019).",
    "curr": "It is well-known that large models train better (Neyshabur et al., 2019;Novak et al., 2018;Allen-Zhu et al., 2019), generalize better (Hendrycks & Dietterich, 2019;Xie & Yuille, 2020;Zhao et al., 2018), and transfer better (Chen et al., 2020b;a;2021b).",
    "next": "However, the upsurge of large models exacerbates the gap between research and practice since many real-life applications demand compact and efficient networks.",
    "hard_negative": [
      24029589,
      3531730,
      3708505,
      29778779
    ],
    "easy_negative": [
      23832010,
      1868213,
      246973327
    ]
  },
  {
    "index": 1861,
    "source_corpus_id": 252780443,
    "ref_id": "b81",
    "citation_corpus_id": 1957433,
    "start": 10170,
    "end": 10194,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "Background: Pre-trained Language Models\n\nIn this section, we discuss background surrounding pretrained language models, pretraining objectives and other unified pretraining proposals.",
    "curr": "Pre-trained Language Models\n\nLearning pre-trained representations for language is a far-reaching pillar of modern NLP research, dating back to (Mikolov et al., 2013;Pennington et al., 2014;Neumann et al., 2018;Dai & Le, 2015;Howard & Ruder, 2018).",
    "next": "The first pre-trained Transformer, GPT, was proposed by (Radford et al., 2019) and was trained as a causal language model.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      38327613,
      239016040,
      11917544
    ]
  },
  {
    "index": 1862,
    "source_corpus_id": 265038030,
    "ref_id": "b14",
    "citation_corpus_id": 3366315,
    "start": 2403,
    "end": 2423,
    "title": "Published as a conference paper at ICLR 2018 SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.Published as a conference paper at ICLR 2018\u2022 Lipschitz constant is the only hyper-parameter to be tuned, and the algorithm does not require intensive tuning of the only hyper-parameter for satisfactory performance. \u2022 Implementation is simple and the additional computational cost is small.",
    "prev": "The original GAN is, however, highly unstable and often suffers from mode collapse.",
    "curr": "Much of recent researches has focused on improving the stability of GANs (Radford et al., 2015;Heusel et al., 2017;Miyato et al., 2018;Karras et al., 2018).",
    "next": "On the theoretical aspect, Nagarajan & Kolter (2017) proved that gradient based training of the original GAN is locally stable.",
    "hard_negative": [
      6628106,
      5687613,
      18828233,
      3633127,
      14570343,
      11758569
    ],
    "easy_negative": [
      11334834,
      248571807,
      17348875
    ]
  },
  {
    "index": 1863,
    "source_corpus_id": 253238010,
    "ref_id": "b12",
    "citation_corpus_id": 222090060,
    "start": 13015,
    "end": 13042,
    "title": "Published as a conference paper at ICLR 2021 INTERPRETING GRAPH NEURAL NETWORKS FOR NLP WITH DIFFERENTIABLE EDGE MASKING",
    "abstract": "Graph neural networks (GNNs) have become a popular approach to integrating structural inductive biases into NLP models. However, there has been little work on interpreting them, and specifically on understanding which parts of the graphs (e.g. syntactic trees or co-reference structures) contribute to a prediction. In this work, we introduce a post-hoc method for interpreting the predictions of GNNs which identifies unnecessary edges. Given a trained GNN model, we learn a simple classifier that, for every edge in every layer, predicts if that edge can be dropped. We demonstrate that such a classifier can be trained in a fully differentiable fashion, employing stochastic gates and encouraging sparsity through the expected L 0 norm. We use our technique as an attribution method to analyse GNN models for two tasks -question answering and semantic role labelling -providing insights into the information flow in these models. We show that we can drop a large proportion of edges without deteriorating the performance of the model, while we can analyse the remaining edges for interpreting model predictions.",
    "prev": "the input features or intermediate embeddings of each point.",
    "curr": "Some methods to interpret graph neural networks can be applied to geometric data (Ying et al., 2019;Luo et al., 2020;Schlichtkrull et al., 2021;Yuan et al., 2021 Luo et al., 2020).",
    "next": "So, some works focusing on improving the attention mechanism for better interpretability (Bai et al., 2021;Miao et al., 2022), some propose to identify representative prototypes during training Chen et al., 2019a), and some methods (Taghanaki et al., 2020;Sun et al., 2022) adopt the information bottleneck principle (Tishby et al., 2000).",
    "hard_negative": [
      155092736,
      196203277,
      9192723,
      159041048,
      182953113,
      102354588,
      53216170,
      25717172,
      102351414,
      1450294,
      52116920,
      202734286,
      49214673,
      30535508,
      5779419,
      51974493,
      49544037,
      59599719,
      52090220,
      2103669,
      195316733
    ],
    "easy_negative": [
      236772881,
      10938115,
      10308240
    ]
  },
  {
    "index": 1864,
    "source_corpus_id": 256503575,
    "ref_id": "b25",
    "citation_corpus_id": 5037032,
    "start": 2287,
    "end": 2308,
    "title": "ZERO-SHOT VISUAL IMITATION",
    "abstract": "The current dominant paradigm for imitation learning relies on strong supervision of expert actions to learn both what and how to imitate.We pursue an alternative paradigm wherein an agent first explores the world without any expert supervision and then distills its experience into a goal-conditioned skill policy with a novel forward consistency loss.In our framework, the role of the expert is only to communicate the goals (i.e., what to imitate) during inference.The learned policy is then employed to mimic the expert (i.e., how to imitate) after seeing just a sequence of images demonstrating the desired task.Our method is \"zero-shot\" in the sense that the agent never has access to expert actions during training or for the task demonstration at inference.We evaluate our zero-shot imitator in two real-world settings: complex rope manipulation with a Baxter robot and navigation in previously unseen office environments with a TurtleBot.Through further experiments in VizDoom simulation, we provide evidence that better mechanisms for exploration lead to learning a more capable policy which in turn improves end task performance.Videos, models, and more details are available at https://pathak22.github.io/zeroshot-imitation/. * Denotes equal contribution.",
    "prev": "Beyond hand-crafting reward functions that are non-trivial, imitation learning (IL) offers a data-driven way to learn behaviors and recover informative rewards from expert demonstrations without access to any explicit reward (Arora & Doshi, 2021;Hussein et al., 2017).",
    "curr": "Recently, visual imitation learning (VIL) (Pathak et al., 2018;Rafailov et al., 2021) has attracted increasing attention, which aims to learn from high-dimensional visual demonstrations like image sequences or videos.",
    "next": "Compared with previous IL works tackling low-dimensional inputs, i.e.",
    "hard_negative": [
      6628106,
      14724343
    ],
    "easy_negative": [
      166105659,
      219301030,
      22670081
    ]
  },
  {
    "index": 1866,
    "source_corpus_id": 255340832,
    "ref_id": "b45",
    "citation_corpus_id": 3257353,
    "start": 5264,
    "end": 5282,
    "title": "That's So Annoying!!!: A Lexical and Frame-Semantic Embedding Based Data Augmentation Approach to Automatic Categorization of Annoying Behaviors using #petpeeve Tweets *",
    "abstract": "We propose a novel data augmentation approach to enhance computational behavioral analysis using social media text. In particular, we collect a Twitter corpus of the descriptions of annoying behaviors using the #petpeeve hashtags. In the qualitative analysis, we study the language use in these tweets, with a special focus on the fine-grained categories and the geographic variation of the language. In quantitative analysis, we show that lexical and syntactic features are useful for automatic categorization of annoying behaviors, and frame-semantic features further boost the performance; that leveraging large lexical embeddings to create additional training instances significantly improves the lexical model; and incorporating frame-semantic embedding achieves the best overall performance.",
    "prev": "However, the label of the augmented pair will still be \"Entailment\".",
    "curr": "Karimi et al., 2021;Fadaee et al., 2017;Sennrich et al., 2015;Wang & Yang, 2015;Andreas, 2020;Kobayashi, 2018).",
    "next": "These augmentation methods are largely tailored to a particular modality in isolation.",
    "hard_negative": [
      4981128,
      7298732,
      7766064,
      12861120,
      972881,
      2812117,
      2456677,
      14113765,
      15244007,
      629094,
      2717798
    ],
    "easy_negative": [
      53166698,
      238418995,
      2089367
    ]
  },
  {
    "index": 1867,
    "source_corpus_id": 211068995,
    "ref_id": "b21",
    "citation_corpus_id": 49881601,
    "start": 2786,
    "end": 2809,
    "title": "Efficient Training on Very Large Corpora via Gramian Estimation",
    "abstract": "We study the problem of learning similarity functions over very large corpora using neural network embedding models. These models are typically trained using SGD with sampling of random observed and unobserved pairs, with a number of samples that grows quadratically with the corpus size, making it expensive to scale to very large corpora. We propose new efficient methods to train these models without having to sample unobserved pairs. Inspired by matrix factorization, our approach relies on adding a global quadratic penalty to all pairs of examples and expressing this term as the matrix-inner-product of two generalized Gramians. We show that the gradient of this term can be efficiently computed by maintaining estimates of the Gramians, and develop variance reduction schemes to improve the quality of the estimates. We conduct large-scale experiments that show a significant improvement in training time and generalization quality compared to traditional sampling methods. * Google Research. arXiv:1807.07187v1 [stat.ML] 18 Jul 2018 1 In many applications, it is desirable for the two embedding functions u, v to share certain parameters, e.g. embeddings of categorical features common to left and right items; hence, we use the same \u03b8 for both.2 This also includes cosine similarity models when the embedding functions u, v are normalized. 3 One advantage of an inner-product model is that it allows for efficient retrieval: given a query item x, the problem of retrieving items y with high similarity to x is a maximum inner product search problem (MIPS), which can be approximated efficiently [Shrivastava and Li, 2014, Neyshabur andSrebro, 2015].",
    "prev": "Many real-world applications besides query-document retrieval can be cast into this form.",
    "curr": "For example, in recommendation systems, q represents a user query and d represents a candidate item to recommend (Krichene et al., 2019).",
    "next": "In extreme multi-label classification, q represents a web-page document and d represents the categories or hashtags of interests (Jain et al., 2019;.",
    "hard_negative": [
      1957433,
      5959482
    ],
    "easy_negative": [
      52894096,
      261494452,
      238744065
    ]
  },
  {
    "index": 1869,
    "source_corpus_id": 86393936,
    "ref_id": "b6",
    "citation_corpus_id": 3300406,
    "start": 4712,
    "end": 4734,
    "title": "EIGENOPTION DISCOVERY THROUGH THE DEEP SUCCESSOR REPRESENTATION",
    "abstract": "Options in reinforcement learning allow agents to hierarchically decompose a task into subtasks, having the potential to speed up learning and planning. However, autonomously learning effective sets of options is still a major challenge in the field. In this paper we focus on the recently introduced idea of using representation learning methods to guide the option discovery process. Specifically, we look at eigenoptions, options obtained from representations that encode diffusive information flow in the environment. We extend the existing algorithms for eigenoption discovery to settings with stochastic transitions and in which handcrafted features are not available. We propose an algorithm that discovers eigenoptions while learning non-linear state representations from raw pixels. It exploits recent successes in the deep reinforcement learning literature and the equivalence between proto-value functions and the successor representation. We use traditional tabular domains to provide intuition about our approach and Atari 2600 games to demonstrate its potential.",
    "prev": "PVFs have also been proposed by neuroscientists as a model for the emergence of grid cells in the entorhinal cortex (Stachenfeld et al., 2017).",
    "curr": "The use of PVFs for discovering subgoals in reinforcement learning has been investigated in (Machado et al., 2017) and combined with function approximation in (Machado et al., 2018), though using a less rigorous approach to eigenfunction approximation than SpIN.",
    "next": "A qualitative comparison of the two approaches is given in the supplementary material in Sec.",
    "hard_negative": [
      7774489,
      14717992
    ],
    "easy_negative": [
      64829188,
      199379317,
      36220023
    ]
  },
  {
    "index": 1871,
    "source_corpus_id": 247222625,
    "ref_id": "b30",
    "citation_corpus_id": 29842525,
    "start": 3190,
    "end": 3216,
    "title": "Published as a conference paper at ICLR 2017 AUTOENCODING VARIATIONAL INFERENCE FOR TOPIC MODELS",
    "abstract": "Topic models are one of the most popular methods for learning representations of text, but a major challenge is that any change to the topic model requires mathematically deriving a new inference algorithm. A promising approach to address this problem is autoencoding variational Bayes (AEVB), but it has proven difficult to apply to topic models in practice. We present what is to our knowledge the first effective AEVB based inference method for latent Dirichlet allocation (LDA), which we call Autoencoded Variational Inference For Topic Model (AVITM). This model tackles the problems caused for AEVB by the Dirichlet prior and by component collapsing. We find that AVITM matches traditional methods in accuracy with much better inference time. Indeed, because of the inference network, we find that it is unnecessary to pay the computational cost of running variational optimization on test data. Because AVITM is black box, it is readily applied to new topic models. As a dramatic illustration of this, we present a new topic model called ProdLDA, that replaces the mixture model in LDA with a product of experts. By changing only one line of code from LDA, we find that ProdLDA yields much more interpretable topics, even if LDA is trained via collapsed Gibbs sampling.",
    "prev": "Bayesian inference of a BPTM is usually based on Gibbs sampling or variational inference (VI), which can be less scalable for big corpora and need to be customized accordingly.",
    "curr": "With the recent development in auto-encoding VI, originated from variational autoencoders (VAEs) (Kingma & Welling, 2014;Rezende et al., 2014), deep neural networks have been successfully used to develop neural topic models (NTMs) (Miao et al., 2016;Srivastava & Sutton, 2017;Burkhardt & Kramer, 2019;Zhang et al., 2018;Dieng et al., 2020;Zhao et al., 2021).",
    "next": "The key advantage of NTMs is that approximate posterior inference can be carried out easily via a forward pass of the encoder network, without the need for expensive iterative inference scheme per test observation as in both Gibbs sampling and conventional VI.",
    "hard_negative": [
      7775454,
      15702125
    ],
    "easy_negative": [
      182952848,
      5723599,
      34277164
    ]
  },
  {
    "index": 1874,
    "source_corpus_id": 220920191,
    "ref_id": "b35",
    "citation_corpus_id": 3626819,
    "start": 2303,
    "end": 2324,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "We will release the source codes as soon as possible.",
    "curr": "INTRODUCTION\n\nPre-trained models (PTMs) like ELMo (Peters et al., 2018), GPT (Radford et al., 2018) and BERT (Devlin et al., 2019) have shown remarkable success of effectively transferring knowledge learned from large-scale unlabeled data to downstream NLP tasks, such as text classification (Socher et al., 2013) and natural language inference (Bowman et al., 2015;, with limited or no training data.",
    "next": "To extend such pretraining-finetuning paradigm to multiple languages, some endeavors such as multilingual BERT (Devlin et al., 2019) and XLM (Conneau & Lample, 2019) have been made for learning cross-lingual representation.",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      8535316,
      11336213,
      9917468,
      20472740,
      34032948,
      10489017,
      1957433,
      1222212,
      12688069,
      15026764,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      214503011,
      235422140,
      227044274
    ]
  },
  {
    "index": 1875,
    "source_corpus_id": 246634506,
    "ref_id": "b37",
    "citation_corpus_id": 3292002,
    "start": 28464,
    "end": 28489,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "3(c), we compare the test accuracy averaged on eight graphs when using different GNNs e.g.",
    "curr": "GCN, SGC (Wu et al., 2019) and GAT (Velickovic et al., 2018), for data generation (See Appendix G for more results).",
    "next": "The results verify that our approach achieves consistently superior performance in different cases.",
    "hard_negative": [
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      11175910,
      252624657,
      195345563
    ]
  },
  {
    "index": 1876,
    "source_corpus_id": 263671952,
    "ref_id": "b15",
    "citation_corpus_id": 40100965,
    "start": 2275,
    "end": 2299,
    "title": "Universal Language Model Fine-tuning for Text Classification",
    "abstract": "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100\u00d7 more data. We opensource our pretrained models and code 1 .",
    "prev": "y targeted outcomes, akin to goal-conditioned policies in reinforcement learning.We show that the pre-trained OC-GFN model can allow for a direct extraction of a policy capable of sampling from any new reward functions in downstream tasks.Nonetheless, adapting OC-GFN on a downstream task-specific reward involves an intractable marginalization over possible outcomes.We propose a novel way to approximate this marginalization by learning an amortized predictor enabling efficient fine-tuning.Extensive experimental results validate the efficacy of our approach, demonstrating the effectiveness of pre-training the OC-GFN, and its ability to swiftly adapt to downstream tasks and discover modes more efficiently.This work may serve as a foundation for further exploration of pre-training strategies in the context of GFlowNets.",
    "curr": "Introduction\n\nUnsupervised learning on large stores of data on the internet has resulted in significant advances in a variety of domains (Devlin et al., 2018, Henaff, 2020, Howard and Ruder, 2018, Radford et al., 2019).Pre-training with unsupervised objectives, such as next-token prediction in auto-regressive language models (Radford et al., 2019), on large-scale unlabelled data enables the development of models that can be effectively fine-tuned for novel tasks using few samples (Brown et al., 2020).Unsupervised learning at scale allows models to learn good representations, which enables data-efficient adaptation to novel tasks, and is central to the recent development towards larger models.",
    "next": "On the other hand, in the context of amortized inference, Generative Flow Networks (GFlowNets; Bengio et al., 2021) enable learning generative models for sampling from high-dimensional distributions over discrete compositional objects.Inspired by reinforcement learning (RL), GFlowNets learn a stochastic policy to sequentially generate compositional objects with a probability proportional to a given reward, instead of reward maximization.Therefore, GFlowNets have found success in applicat",
    "hard_negative": [
      16299141,
      28971531,
      16386838,
      7928230,
      7942973,
      3626819,
      10728540,
      1428702,
      14337532,
      4460159
    ],
    "easy_negative": [
      16758264,
      18324075,
      247228
    ]
  },
  {
    "index": 1878,
    "source_corpus_id": 233287919,
    "ref_id": "b5",
    "citation_corpus_id": 1998416,
    "start": 4092,
    "end": 4112,
    "title": "Effective Approaches to Attention-based Neural Machine Translation",
    "abstract": "An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches on the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems that already incorporate known techniques such as dropout. Our ensemble model using different attention architectures yields a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker. 1",
    "prev": "Reinforce (Sutton et al., 2000), PPO (Schulman et al., 2017)) are applied to update the permutation-generating encoder.",
    "curr": "then, the left-to-right autoregressive order has been essential for application domains such as image captioning (Vinyals et al., 2015b;Xu et al., 2015), machine translation (Luong et al., 2015;Bahdanau et al., 2015) and distant fields like image synthesis (van den Oord et al., 2016).",
    "next": "However, interest in non left-to-right autoregressive orders is resurfacing (Welleck et al., 2019b;Stern et al., 2019), and evidence G\u016b et al., 2018;Alvarez-Melis & Jaakkola, 2017) suggests adaptive orders may produce more accurate autoregressive models.",
    "hard_negative": [
      9709731,
      2863491,
      5590763,
      8884845,
      11212020,
      1245593,
      12639289
    ],
    "easy_negative": [
      18203211,
      222177083,
      252847462
    ]
  },
  {
    "index": 1879,
    "source_corpus_id": 257232422,
    "ref_id": "b16",
    "citation_corpus_id": 3144218,
    "start": 15698,
    "end": 15719,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": ", N T , the nonlinear activation function \u03c1 : R \u2192 R after each layer, and parameters \u03b6.",
    "curr": "For graph convolutional networks, we adapt the approach by Kipf & Welling (2017) to data z 0 e \u2208 R N 0 on edges e: The t th layer is given by\n(5) z t +1 e = \u03c1 W t +1 1 z t e + W t +1 2 \u1ebd\u2208N (e) z t\u1ebd + b t +1 where W t +1 1 \u2208 R N t +1 \u00d7N t and W t +1 2 \u2208 R N t +1\n\u00d7N t are small matrices with learnable parameters and b t +1 \u2208 R N t +1 is the bias, all stored in the parameters \u03b6.",
    "next": "We define the neighborhood of an edge in a triangle mesh as N (e) := {\u1ebd \u2208 E | e and\u1ebd share a vertex}.",
    "hard_negative": [
      8393918,
      17682909
    ],
    "easy_negative": [
      16575107,
      11529538,
      2053042
    ]
  },
  {
    "index": 1880,
    "source_corpus_id": 252668917,
    "ref_id": "b0",
    "citation_corpus_id": 202776931,
    "start": 29650,
    "end": 29671,
    "title": "JuICe: A Large Scale Distantly Supervised Dataset for Open Domain Context-based Code Generation",
    "abstract": "Interactive programming with interleaved code snippet cells and natural language markdown is recently gaining popularity in the form of Jupyter notebooks, which accelerate prototyping and collaboration. To study code generation conditioned on a long context history, we present JuICe, a corpus of 1.5 million examples with a curated test set of 3.7K instances based on online programming assignments. Compared with existing contextual code generation datasets, JuICe provides refined human-curated data, open-domain code, and an order of magnitude more training data. Using JuICe, we train models for two tasks:(1) generation of the API call sequence in a code cell, and (2) full code cell generation, both conditioned on the NL-Code history up to a particular code cell. Experiments using current baseline code generation models show that both context and distant supervision aid in generation, and that the dataset is challenging for current systems.",
    "prev": "In most of those cases, only directly relevant input information is given to the model.",
    "curr": "In contrast, a few previous works instantiate benchmarks that measure the ability to generate programs given surrounding program context beyond the target program, such as variables and other methods (Iyer et al., 2018) or alternating \"cells\" of preceding code and text blocks (Agashe et al., 2019), while the primary focus is to generate the target program itself.",
    "next": "We propose a new benchmark that requires a progressive generation of subprograms through multi-turn prompts.",
    "hard_negative": [
      15412473,
      91184134,
      6628106,
      497108,
      8174613,
      4955031,
      12718048,
      2623009,
      14434979,
      52125417,
      340852,
      1675452
    ],
    "easy_negative": [
      2650292,
      222339089,
      18717361
    ]
  },
  {
    "index": 1882,
    "source_corpus_id": 264426077,
    "ref_id": "b44",
    "citation_corpus_id": 228376209,
    "start": 12136,
    "end": 12140,
    "title": "CONVEX POTENTIAL FLOWS: UNIVERSAL PROBABILITY DISTRIBUTIONS WITH OPTIMAL TRANSPORT AND CONVEX OPTIMIZATION",
    "abstract": "Flow-based models are powerful tools for designing probabilistic models with tractable density. This paper introduces Convex Potential Flows (CP-Flow), a natural and efficient parameterization of invertible models inspired by the optimal transport (OT) theory. CP-Flows are the gradient map of a strongly convex neural potential function. The convexity implies invertibility and allows us to resort to convex optimization to solve the convex conjugate for efficient inversion. To enable maximum likelihood training, we derive a new gradient estimator of the log-determinant of the Jacobian, which involves solving an inverse-Hessian vector product using the conjugate gradient method. The gradient estimator has constantmemory cost, and can be made effectively unbiased by reducing the error tolerance level of the convex optimization routine. Theoretically, we prove that CP-Flows are universal density approximators and are optimal in the OT sense. Our empirical results show that CP-Flow performs competitively on standard benchmarks of density estimation and variational inference. arXiv:2012.05942v1 [cs.LG] 10 Dec 2020 for generative adversarial networks. arXiv preprint arXiv:1802.05957, 2018. . Ot-flow: Fast and accurate continuous normalizing flows via optimal transport. arXiv preprint arXiv:2006.00104, 2020. George Papamakarios, Theo Pavlakou, and Iain Murray. Masked autoregressive flow for density estimation. Ludger R\u00fcschendorf and Svetlozar T Rachev. A characterization of random variables with minimum l2-distance. Journal of multivariate analysis, 32(1):48-54, 1990. Filippo Santambrogio. Optimal transport for applied mathematicians. Birk\u00e4user, NY, 55(58-63):94, 2015.",
    "prev": "The simple proof of this result follows by combining properties of input convex neural networks from Amos et al.",
    "curr": "[4] and the characterization of proximal operators from Gribonval and Nikolova [43] (see Appendix C.1).The C 2 condition for the nonlinearity 3 g is imposed to ensure differentiability of the ICNN \u03c8 \u03b8 and the LPN f \u03b8 , which will become useful shortly.Although this rules out popular choices like Rectifying Linear Units (ReLUs), there exist a wide range of eligible options satisfying all the constraints.Following [45], we adopt the softplus function g(x) = 1 \u03b2 log(1 + exp (\u03b2x)), a \u03b2-smooth approximation of ReLU.Importantly, LPN can be highly expressive (representing any continous proximal operator) under reasonable settings, given the universality of ICNN [45].",
    "next": "Networks that are defined as gradients of ICNN have been explored in inverse problems in a related work.Cohen et al.",
    "hard_negative": [
      53477919,
      52908831,
      8768364
    ],
    "easy_negative": [
      6320413,
      13754018,
      252847484
    ]
  },
  {
    "index": 1887,
    "source_corpus_id": 223953610,
    "ref_id": "b15",
    "citation_corpus_id": 84591,
    "start": 6923,
    "end": 6945,
    "title": "Adversarial Feature Learning",
    "abstract": "The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing generators learn to \"linearize semantics\" in the latent space of such models. Intuitively, such latent spaces may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.",
    "prev": "There has been a wide range of research on self-supervised learning of visual representations in which properties of the images themselves act as supervision.",
    "curr": "The objectives for these methods cover a variety of tasks such as solving jigsaw puzzles (Noroozi & Favaro, 2016), colorizing grayscale images , learning to count (Noroozi et al., 2017), predicting context (Doersch et al., 2015), inpainting (Pathak et al., 2016), adversarial training (Donahue et al., 2017) and predicting image rotations (Gidaris et al., 2018).",
    "next": "This type of representation learning is not limited to learning from single frames.",
    "hard_negative": [
      9665723,
      11758569,
      11212020
    ],
    "easy_negative": [
      258740875,
      13277562,
      27583030
    ]
  },
  {
    "index": 1888,
    "source_corpus_id": 3508167,
    "ref_id": "b9",
    "citation_corpus_id": 12639289,
    "start": 17885,
    "end": 17889,
    "title": "Recurrent Continuous Translation Models",
    "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
    "prev": "We use a simplified version of this neural attention mechanism in SliceNet, as introduced above.",
    "curr": "Convolutional architectures have been used to obtain good results in word-level neural machine translation starting from [10] and later in [14].",
    "next": "These early models used a standard RNN on top of the convolution to generate the output.",
    "hard_negative": [
      1274371,
      10691183,
      16391184,
      8476273,
      8608051,
      806709
    ],
    "easy_negative": [
      2410333,
      1912220,
      15273358
    ]
  },
  {
    "index": 1891,
    "source_corpus_id": 253117027,
    "ref_id": "b26",
    "citation_corpus_id": 235313916,
    "start": 5490,
    "end": 5510,
    "title": "Provably Secure Generative Linguistic Steganography",
    "abstract": "Generative linguistic steganography mainly utilized language models and applied steganographic sampling (stegosampling) to generate high-security steganographic text (stegotext). However, previous methods generally lead to statistical differences between the conditional probability distributions of stegotext and natural text, which brings about security risks. In this paper, to further ensure security, we present a novel provably secure generative linguistic steganographic method ADG, which recursively embeds secret information by Adaptive Dynamic Grouping of tokens according to their probability given by an offthe-shelf language model. We not only prove the security of ADG mathematically, but also conduct extensive experiments on three public corpora to further verify its imperceptibility. The experimental results reveal that the proposed method is able to generate stegotext with nearly perfect security.",
    "prev": " approximation procedures to construct couplings between one factorable distribution and one autoregressively specified distribution, both having arbitrarily large supports, while still retaining marginalization guarantees.We show that, because ciphertext can be made to look uniformly random, and any distribution of covertext can be specified autoregressively, iMEC can be leveraged to perform steganography with arbitrary covertext distributions and plaintext messages.To the best of our knowledge, this represents the first instance of a steganography algorithm with perfect security guarantees that is applicable to arbitrary distributions of covertext.",
    "curr": "In our experiments, we evaluate iMEC using GPT-2 (Radford et al., 2019) (a language model), WaveRNN (Kalchbrenner et al., 2018) (an audio model), and Image Transfomer (an image model) as covertext distributions.We compare against arithmetic coding (Ziegler et al., 2019), Meteor (Kaptchuk et al., 2021), and adaptive dynamic grouping (ADG) (Zhang et al., 2021), other recent methods for performing information theoretic-steganography with deep generative models.To examine empirical security, we estimate the KL divergence between the stegotext and the covertext for each method.For iMEC, we find that the divergence is on the order of numerical precision, in agreement with our theoretical guarantees.In contrast, arithmetic coding, Meteor, and ADG yield KL divergences many orders of magnitude larger, reflecting their weaker security guarantees.To examine encoding efficiency, we measure the number of bits transmitted per step.We find that iMEC generally yields superior efficiency results to those of arithmetic coding, Meteor, and ADG, despite its stricter constraints.",
    "next": "We would summarize our theoretical results as showing that minimum entropy coupling-based approaches are the most information efficient perfect security approaches and our empirical results as showing that minimum entropy coupling-based approaches can be more information efficient t",
    "hard_negative": [
      1428702,
      10494183
    ],
    "easy_negative": [
      5380171,
      16566127,
      5265778
    ]
  },
  {
    "index": 1894,
    "source_corpus_id": 246411225,
    "ref_id": "b22",
    "citation_corpus_id": 222208633,
    "start": 3132,
    "end": 3150,
    "title": "DEFORMABLE DETR: DEFORMABLE TRANSFORMERS FOR END-TO-END OBJECT DETECTION",
    "abstract": "DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10\u00d7 less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code shall be released. * Equal contribution. \u2020 This work is done when Weijie Su is an intern at SenseTime Research.",
    "prev": "However, due to its ineffective design and use of queries, DETR suffers from significantly slow training convergence, usually requiring 500 epochs to achieve a good performance.",
    "curr": "To address this issue, many follow-up works attempted to improve the design of DETR queries for both faster training convergence and better performance (Zhu et al., 2021;Gao et al., 2021;Meng et al., 2021;.",
    "next": "Despite all the progress, the role of the learned queries in DETR is still not fully understood or utilized.",
    "hard_negative": [
      6628106,
      3608234,
      59310641,
      209315300
    ],
    "easy_negative": [
      15534684,
      21713133,
      218973828
    ]
  },
  {
    "index": 1904,
    "source_corpus_id": 49671490,
    "ref_id": "b5",
    "citation_corpus_id": 14089312,
    "start": 2314,
    "end": 2316,
    "title": "Published as a conference paper at ICLR 2017 PRUNING FILTERS FOR EFFICIENT CONVNETS",
    "abstract": "The success of CNNs in various applications is accompanied by a significant increase in the computation and parameter storage costs. Recent efforts toward reducing these overheads involve pruning and compressing the weights of various layers without hurting original accuracy. However, magnitude-based pruning of weights reduces a significant number of parameters from the fully connected layers and may not adequately reduce the computation costs in the convolutional layers due to irregular sparsity in the pruned networks. We present an acceleration method for CNNs, where we prune filters from CNNs that are identified as having a small effect on the output accuracy. By removing whole filters in the network together with their connecting feature maps, the computation costs are reduced significantly. In contrast to pruning weights, this approach does not result in sparse connectivity patterns. Hence, it does not need the support of sparse convolution libraries and can work with existing efficient BLAS libraries for dense matrix multiplications. We show that even simple filter pruning techniques can reduce inference costs for VGG-16 by up to 34% and ResNet-110 by up to 38% on CIFAR10 while regaining close to the original accuracy by retraining the networks.",
    "prev": "This poses an issue for deploying these models in applications that require real-time inferencing and lowmemory footprint, such as self-driving vehicles, human-machine interaction on mobile devices, and robotics.",
    "curr": "Motivated by these applications, many methods have been proposed for model compression and acceleration, including techniques such as pruning [5,6,7], quantization [8,9], and low-rank factorization [10,11,12].",
    "next": "Most of these methods have been applied to single-scale inputs, without considering multi-resolution processing.",
    "hard_negative": [
      14124313,
      4167933
    ],
    "easy_negative": [
      47016928,
      52006529,
      238638452
    ]
  },
  {
    "index": 1909,
    "source_corpus_id": 258170309,
    "ref_id": "b3",
    "citation_corpus_id": 235436185,
    "start": 1740,
    "end": 1742,
    "title": "BEIT: BERT Pre-Training of Image Transformers",
    "abstract": "We introduce a self-supervised vision representation model BEIT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT [DCLT19] developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16\u00d716 pixels), and visual tokens (i.e., discrete tokens). We first \"tokenize\" the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEIT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.",
    "prev": "It starts from a pretext task trained on large unlabeled data, where the learned representation is fine-tuned on downstream tasks.",
    "curr": "This approach has shown great success in 2D images [8,15,18,4,17,61] and natural language processing (NLP) [13,5] .",
    "next": "Recently, people started looking into self-supervised pretraining on point cloud data due to its importance in 3D analysis and robotics applications.",
    "hard_negative": [
      14307651,
      52055130,
      218581596,
      4009713
    ],
    "easy_negative": [
      258486924,
      18394591,
      29302677
    ]
  },
  {
    "index": 1912,
    "source_corpus_id": 58981508,
    "ref_id": "b13",
    "citation_corpus_id": 3568073,
    "start": 1587,
    "end": 1608,
    "title": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024 2 . We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.",
    "prev": "INTRODUCTION\n\nGraphic design is an important visual communication tool in our modern world, encompassing everything from book covers to magazine layouts to web design.",
    "curr": "Whereas methods for generating realistic natural-looking images have made significant progress lately, particularly with Generative Adversarial Networks (GANs) (Karras et al., 2018), methods for creating designs are far more primitive.",
    "next": "This is, in part, due to the difficulty of finding data representations suitable for learning.",
    "hard_negative": [
      18828233,
      6628106
    ],
    "easy_negative": [
      20292670,
      258822885,
      202670323
    ]
  },
  {
    "index": 1913,
    "source_corpus_id": 203591628,
    "ref_id": "b1",
    "citation_corpus_id": 186206508,
    "start": 2406,
    "end": 2432,
    "title": "Monotonic Infinite Lookback Attention for Simultaneous Machine Translation",
    "abstract": "Simultaneous machine translation begins to translate each source sentence before the source speaker is finished speaking, with applications to live and streaming scenarios. Simultaneous systems must carefully schedule their reading of the source sentence to balance quality against latency. We present the first simultaneous translation system to learn an adaptive schedule jointly with a neural machine translation (NMT) model that attends over all source tokens read thus far. We do so by introducing Monotonic Infinite Lookback (MILk) attention, which maintains both a hard, monotonic attention head to schedule the reading of the source sentence, and a soft attention head that extends from the monotonic head back to the beginning of the source. We show that MILk's adaptive schedule allows it to arrive at latency-quality trade-offs that are favorable to those of a recently proposed wait-k strategy for many latency values.",
    "prev": "Monotonic attention mechanisms fall into learned policy category.",
    "curr": "Recent work exploring monotonic attention variants for simultaneous translation include: hard monotonic attention (Raffel et al., 2017), monotonic chunkwise attention (MoChA) (Chiu & Raffel, 2018) and monotonic infinite lookback attention (MILk) (Arivazhagan et al., 2019).",
    "next": "MILk in particular has shown better quality / latency trade-offs than fixed policy approaches, such as wait-k (Ma et al., 2019) or wait-if-* (Cho & Esipova, 2016) policies.",
    "hard_negative": [
      6628106,
      2957867,
      3538865,
      724894,
      14139006
    ],
    "easy_negative": [
      6911768,
      17347947,
      7627541
    ]
  },
  {
    "index": 1918,
    "source_corpus_id": 238856856,
    "ref_id": "b40",
    "citation_corpus_id": 2703040,
    "start": 7673,
    "end": 7694,
    "title": "COVARIANT COMPOSITIONAL NETWORKS FOR LEARNING GRAPHS",
    "abstract": "Most existing neural networks for learning graphs address permutation invariance by conceiving of the network as a message passing scheme, where each node sums the feature vectors coming from its neighbors. We argue that this imposes a limitation on their representation power, and instead propose a new general architecture for representing objects consisting of a hierarchy of parts, which we call covariant compositional networks (CCNs). Here, covariance means that the activation of each neuron must transform in a specific way under permutations, similarly to steerability in CNNs. We achieve covariance by making each activation transform according to a tensor representation of the permutation group, and derive the corresponding tensor aggregation rules that each neuron must implement. Experiments show that CCNs can outperform competing methods on standard graph learning benchmarks.While MPNNs have been very successful in applications and are an active field of research, they differ from classical CNNs in a fundamental way: the internal feature representations in CNNs are equivariant to such transformations of the inputs as translation and rotations (Cohen & Welling, 2016a;b), the internal representations in MPNNs are fully invariant. This is a direct result of the fact that MPNNs deal with the permutation invariance issue in graphs simply by summing the messages coming from each neighbor. In this paper we argue that this is a serious limitation that restricts the representation power of MPNNs.MPNNs are ultimately compositional (part-based) models, that build up the representation of the graph from the representations of a hierarchy of subgraphs. To address the covariance issue, we study the covariance behavior of such networks in general, introducing a new general class of neural network architectures, which we call compositional networks (comp-nets). One advantage of this generalization is that instead of focusing attention on the mechanics of how information propagates from node to node, it emphasizes the connection to convolutional networks, in particular, it shows that what is missing from MPNNs is essentially the analog of steerability.",
    "prev": "Cohen & Welling (2016) observed that a viable approach to generalize CNNs to other data types could involve considering equivariance to more general transformation groups.",
    "curr": "This idea has been used to construct networks equivariant to a wide variety of transformations such as planar rotations (Worrall et al., 2017;Weiler et al., 2018b;Bekkers et al., 2018;Veeling et al., 2018;Smets et al., 2020), 3D rotations Esteves et al., 2018;Worrall & Brostow, 2018;Weiler et al., 2018a;Kondor et al., 2018a;Perraudin et al., 2019), permutations (Zaheer et al., 2017;Hartford et al., 2018;Kondor et al., 2018b;Maron et al., 2019a;, general Euclidean isometries (Weiler et al., 2018a;Weiler & Cesa, 2019;Finzi et al., 2020), scaling (Marcos et al., 2018;Worrall & Welling, 2019;Sosnovik et al., 2020) and more exotic symmetries (Bogatskiy et al., 2020;Shutty & Wierzynski, 2020;Finzi et al., 2021) etc.",
    "next": "A quite general theory of equivariant/invariant networks has also emerged.",
    "hard_negative": [
      3144218,
      17682909
    ],
    "easy_negative": [
      18703601,
      1999816,
      233365188
    ]
  },
  {
    "index": 1919,
    "source_corpus_id": 58981389,
    "ref_id": "b14",
    "citation_corpus_id": 252796,
    "start": 18858,
    "end": 18862,
    "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
    "abstract": "There is a growing consensus that significant, rapid progress can be made in both text understanding and spoken language understanding by investigating those phenomena that occur most centrally in naturally occurring unconstrained materials and by attempting to automatically extract information about language from very large corpora. Such corpora are beginning to serve as important research tools for investigators in natural language processing, speech recognition, and integrated spoken language systems, as well as in theoretical linguistics. Annotated corpora promise to be valuable for enterprises as diverse as the automatic construction of statistical models for the grammar of the written and the colloquial spoken language, the development of explicit formal theories of the differing grammars of writing and speech, the investigation of prosodic phenomena in speech, and the evaluation and comparison of the adequacy of parsing models.In this paper, we review our experience with constructing one such large annotated corpus--the Penn Treebank, a corpus 1 consisting of over 4.5 million words of American English. During the first three-year phase of the Penn Treebank Project (1989)(1990)(1991)(1992), this corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure. These materials are available to members of the Linguistic Data Consortium; for details, see Section 5.1.The paper is organized as follows. Section 2 discusses the POS tagging task. After outlining the considerations that informed the design of our POS tagset and presenting the tagset itself, we describe our two-stage tagging process, in which text is first assigned POS tags automatically and then corrected by human annotators. Section 3 briefly presents the results of a comparison between entirely manual and semi-automated tagging, with the latter being shown to be superior on three counts: speed, consistency, and accuracy. In Section 4, we turn to the bracketing task. Just as with the tagging task, we have partially automated the bracketing task: the output of",
    "prev": "In language modeling, given a sequence of words or characters, the model must predict the next word or character.",
    "curr": "For character-level language modeling, we train and evaluate models on Penn Treebank [15].",
    "next": "To increase the coverage of our experiments, we train and evaluate the word-level language models on the Wikitext-2 dataset, which is twice as large as Penn Treebank and features a larger vocabulary [17].",
    "hard_negative": [
      696805,
      3166885,
      2369736,
      12951757,
      5153623,
      2769726
    ],
    "easy_negative": [
      18860664,
      6863482,
      235254335
    ]
  },
  {
    "index": 1920,
    "source_corpus_id": 235683534,
    "ref_id": "b22",
    "citation_corpus_id": 208117506,
    "start": 2801,
    "end": 2820,
    "title": "Transformers: State-of-the-Art Natural Language Processing",
    "abstract": "Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. Transformers is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered stateof-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. Transformers is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at https://github.com/ huggingface/transformers.",
    "prev": "BERT (Devlin et al., 2019) is a particularly popular choice: it has been widely adopted in academia and industry, and aspects of its performance have been reported on in thousands of research papers (see, e.g., Rogers et al., 2020, for an overview).",
    "curr": "Because pre-training large language models is computationally expensive (Strubell et al., 2019), researchers often rely on the release of model checkpoints through libraries such as HuggingFace Transformers (Wolf et al., 2020), which enable them to use large-scale language models without repeating the pre-training work.",
    "next": "Consequently, most published results are based on a small number of publicly released model checkpoints.",
    "hard_negative": [
      209202658,
      40100965,
      14068874,
      189762527
    ],
    "easy_negative": [
      248085670,
      9844885,
      3104463
    ]
  },
  {
    "index": 1921,
    "source_corpus_id": 238419305,
    "ref_id": "b13",
    "citation_corpus_id": 54101493,
    "start": 2944,
    "end": 2966,
    "title": "IMAGENET-TRAINED CNNS ARE BIASED TOWARDS TEXTURE; INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS",
    "abstract": "Convolutional Neural Networks (CNNs) are commonly thought to recognise objects by learning increasingly complex representations of object shapes. Some recent studies suggest a more important role of image textures. We here put these conflicting hypotheses to a quantitative test by evaluating CNNs and human observers on images with a texture-shape cue conflict. We show that ImageNettrained CNNs are strongly biased towards recognising textures rather than shapes, which is in stark contrast to human behavioural evidence and reveals fundamentally different classification strategies. We then demonstrate that the same standard architecture (ResNet-50) that learns a texture-based representation on ImageNet is able to learn a shape-based representation instead when trained on 'Stylized-ImageNet', a stylized version of ImageNet. This provides a much better fit for human behavioural performance in our well-controlled psychophysical lab setting (nine experiments totalling 48,560 psychophysical trials across 97 observers) and comes with a number of unexpected emergent benefits such as improved object detection performance and previously unseen robustness towards a wide range of image distortions, highlighting advantages of a shape-based representation. de Beeck. Deep neural networks as a computational model for human shape sensitivity. DiCarlo. Performance-optimized hierarchical models predict neural responses in higher visual cortex.",
    "prev": "For example, a DNN trained for the task of animal recognition may recognize ducks while attending on water backgrounds, given the strong correlations between such background cues and the target label (Choe et al., 2020).",
    "curr": "These shortcut biases often result in a striking qualitative difference between human and machine recognition systems; for example, convolutional neural networks (CNNs) trained on ImageNet extensively rely on texture features, while humans would preferentially look at the global shape of objects (Geirhos et al., 2019).",
    "next": "In other cases, the shortcut bias arises in models that suppress certain streams of inputs: visual question answering (VQA) models often neglect the entire image cues, for one does not require images to answer questions like \"what color is the banana in the image?\"",
    "hard_negative": [
      56657912,
      68222714
    ],
    "easy_negative": [
      8394195,
      17332745,
      9586648
    ]
  },
  {
    "index": 1922,
    "source_corpus_id": 253244237,
    "ref_id": "b9",
    "citation_corpus_id": 67855860,
    "start": 5780,
    "end": 5802,
    "title": "Attention is not Explanation",
    "abstract": "Attention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful \"explanations\" for predictions. We find that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our findings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do. Code to reproduce all experiments is available at https://github.com/successar/ AttentionExplanation.",
    "prev": "\u2022 Finally, we identified heads reliably writing in the opposite direction of the correct answer.",
    "curr": "Explanations for model behavior can easily be misleading or non-rigorous (Jain & Wallace, 2019;Bolukbasi et al., 2021).",
    "next": "To remedy this problem, we formulate three criteria to help validate our circuit explanations.",
    "hard_negative": [
      990233,
      8495258,
      12664997,
      7205805,
      51979567,
      52113465,
      5509327,
      1428702,
      982761
    ],
    "easy_negative": [
      18733074,
      14849678,
      227230372
    ]
  },
  {
    "index": 1924,
    "source_corpus_id": 252111177,
    "ref_id": "b72",
    "citation_corpus_id": 227209335,
    "start": 4956,
    "end": 4959,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "On the other hand, MLE tends to be intractable for complex models, and hence requires approximate variational or Monte Carlo inference techniques such as those used in variational auto-encoders (VAE), or special model structures such as normalizing flow and auto-regressive models, to yield tractable likelihood, causing difficult trade-offs between expressive power and computational cost.",
    "curr": "Recently, advances have been made by representing the transport plan implicitly as a continuous time process, such as flow models with neural ordinary differential equations (ODEs) [e.g., 6,56] and diffusion models by stochastic differential equations (SDEs) [e.g., 73,23,80,11,82]; in these models, a neural network is trained to represent the drift force of the processes and a numerical ODE/SDE solver is used to simulate the process during inference.",
    "next": "The key idea is that, by leveraging the mathematical structures of ODEs/SDEs, the continuous-time models can be trained efficiently without resorting to minimax or traditional approximate inference techniques.",
    "hard_negative": [
      52889459,
      52908831
    ],
    "easy_negative": [
      5981377,
      52847536,
      249204528
    ]
  },
  {
    "index": 1930,
    "source_corpus_id": 257353502,
    "ref_id": "b97",
    "citation_corpus_id": 238531645,
    "start": 9113,
    "end": 9130,
    "title": "Published as a conference paper at ICLR 2022 TAMING SPARSELY ACTIVATED TRANSFORMER WITH STOCHASTIC EXPERTS",
    "abstract": "Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts. In this paper, we propose a new expert-based model, THOR (Transformer witH StOchastic ExpeRts). Unlike classic expert-based models, such as the Switch Transformer(Fedus et al., 2021), experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions. We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model(Kim et al., 2021)that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/ Stochastic-Mixture-of-Experts. * Work was done during an internship at Microsoft.",
    "prev": "Fortunately, recent investigations Lepikhin et al., 2020;Fedus et al., 2021) have proved the effectiveness of MoEs with sparsely activated experts (i.e., SMoE) at both training and inference stages, which greatly trim down the cost and scale language models to enormous sizes like trillions of parameters (Fedus et al., 2021).",
    "curr": "This efficient fashion of SMoEs gains increasing popularity in various NLP Lepikhin et al., 2020;Zuo et al., 2022;Jiang et al., 2021) and vision (Riquelme et al., 2021;Eigen et al., 2013;Ahmed et al., 2016;Gross et al., 2017;Yang et al., 2019a;Abbas & Andreopoulos, 2020;Pavlitskaya et al., 2020) tasks.",
    "next": "However, its sparse-gated manner incurs several downsides, including: (1) Unstable training.",
    "hard_negative": [
      91184134,
      6628106,
      12462234,
      174799399,
      207847598,
      59310641,
      13751870,
      44131019,
      204960716,
      5034059,
      199528271,
      52967399,
      215814515
    ],
    "easy_negative": [
      44987870,
      5848469,
      235097397
    ]
  },
  {
    "index": 1931,
    "source_corpus_id": 53215110,
    "ref_id": "b3",
    "citation_corpus_id": 7100502,
    "start": 1719,
    "end": 1742,
    "title": "What do Neural Machine Translation Models Learn about Morphology?",
    "abstract": "Neural machine translation (MT) models obtain state-of-the-art performance while maintaining a simple, end-to-end architecture. However, little is known about what these models learn about source and target languages during the training process.In this work, we analyze the representations learned by neural MT models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part-of-speech and morphological tagging tasks. We conduct a thorough investigation along several parameters: word-based vs. character-based representations, depth of the encoding layer, the identity of the target language, and encoder vs. decoder representations. Our data-driven, quantitative evaluation sheds light on important aspects in the neural MT system and its ability to capture word structure. 1",
    "prev": "* Equal contribution 1\n\nINTRODUCTION\n\nNeural machine translation (NMT) systems achieve state-of-the-art results by learning from large amounts of example translations, typically without additional linguistic information.",
    "curr": "Recent studies have shown that representations learned by NMT models contain a non-trivial amount of linguistic information on multiple levels: morphological (Belinkov et al., 2017), syntactic (Shi et al., 2016b), and semantic (Hill et al., 2017).",
    "next": "These studies use trained NMT models to generate feature representations for words, and use these representations to predict certain linguistic properties.",
    "hard_negative": [
      14259080,
      11631121,
      16076435,
      5077395,
      10887722,
      13972671,
      2330566,
      94792,
      1712853,
      7708374,
      13858533,
      11754739
    ],
    "easy_negative": [
      1900253,
      16957322,
      11591887
    ]
  },
  {
    "index": 1935,
    "source_corpus_id": 60440651,
    "ref_id": "b14",
    "citation_corpus_id": 3366315,
    "start": 2403,
    "end": 2423,
    "title": "Published as a conference paper at ICLR 2018 SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.Published as a conference paper at ICLR 2018\u2022 Lipschitz constant is the only hyper-parameter to be tuned, and the algorithm does not require intensive tuning of the only hyper-parameter for satisfactory performance. \u2022 Implementation is simple and the additional computational cost is small.",
    "prev": "The original GAN is, however, highly unstable and often suffers from mode collapse.",
    "curr": "Much of recent researches has focused on improving the stability of GANs (Radford et al., 2015;Heusel et al., 2017;Miyato et al., 2018;Karras et al., 2018).",
    "next": "On the theoretical aspect, Nagarajan & Kolter (2017) proved that gradient based training of the original GAN is locally stable.",
    "hard_negative": [
      6628106,
      5687613,
      18828233,
      3633127,
      14570343,
      11758569
    ],
    "easy_negative": [
      16579596,
      53576265,
      250179914
    ]
  },
  {
    "index": 1940,
    "source_corpus_id": 224705241,
    "ref_id": "b26",
    "citation_corpus_id": 13123084,
    "start": 5753,
    "end": 5773,
    "title": "Published as a conference paper at ICLR 2017 TEMPORAL ENSEMBLING FOR SEMI-SUPERVISED LEARNING",
    "abstract": "In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels.",
    "prev": "Consistency regularization and entropy minimization are two common strategies for SSL.",
    "curr": "The intuition behind consistencybased approaches (Laine & Aila, 2016;Sajjadi et al., 2016;Miyato et al., 2018;Tarvainen & Valpola, 2017) is that, the model output should remain unchanged when the input is perturbed.",
    "next": "On the other hand, the entropy minimization strategy (Grandvalet & Bengio, 2005) argues that the unlabeled data can be used to ensured classes are well-separated, which can be achieved by encouraging the model to output low-entropy predictions.",
    "hard_negative": [
      1965764,
      2780493,
      6230637,
      9398766,
      1487550
    ],
    "easy_negative": [
      259370789,
      202592085,
      62276728
    ]
  },
  {
    "index": 1942,
    "source_corpus_id": 259165244,
    "ref_id": "b2",
    "citation_corpus_id": 5034059,
    "start": 3574,
    "end": 3577,
    "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    "abstract": "For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusively tailored to a specific task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating and analyzing the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and find that multi-task training on all our tasks yields better results than training a separate model for each task. However, the low absolute performance of our best model indicates the need for improved general NLU systems. son. 2013. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint 1312.3005.",
    "prev": "Introduction\n\nRecent remarkable breakthroughs achieved by large language models (LLMs) like GPT-4 [1] have elicited widespread astonishment.",
    "curr": "Considering the extensive and profound natural language understanding and generation abilities exhibited by LLMs [2], the conventional benchmarks [3,4] focusing on relatively narrow and superficial abilities are no longer as helpful for testing them.",
    "next": "It has become necessary to construct better benchmarks for effectively comparing LLMs and providing valuable diagnostic results.",
    "hard_negative": [
      5074049,
      388,
      2937095,
      2213896,
      25422730,
      4537113,
      990233,
      16661147,
      3432876,
      1957433,
      3626819,
      11816014,
      1994584,
      2135897,
      3264224,
      4421747,
      16639476,
      4567927
    ],
    "easy_negative": [
      232021967,
      227151731,
      52012577
    ]
  },
  {
    "index": 1945,
    "source_corpus_id": 219721312,
    "ref_id": "b4",
    "citation_corpus_id": 54101493,
    "start": 1727,
    "end": 1735,
    "title": "IMAGENET-TRAINED CNNS ARE BIASED TOWARDS TEXTURE; INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS",
    "abstract": "Convolutional Neural Networks (CNNs) are commonly thought to recognise objects by learning increasingly complex representations of object shapes. Some recent studies suggest a more important role of image textures. We here put these conflicting hypotheses to a quantitative test by evaluating CNNs and human observers on images with a texture-shape cue conflict. We show that ImageNettrained CNNs are strongly biased towards recognising textures rather than shapes, which is in stark contrast to human behavioural evidence and reveals fundamentally different classification strategies. We then demonstrate that the same standard architecture (ResNet-50) that learns a texture-based representation on ImageNet is able to learn a shape-based representation instead when trained on 'Stylized-ImageNet', a stylized version of ImageNet. This provides a much better fit for human behavioural performance in our well-controlled psychophysical lab setting (nine experiments totalling 48,560 psychophysical trials across 97 observers) and comes with a number of unexpected emergent benefits such as improved object detection performance and previously unseen robustness towards a wide range of image distortions, highlighting advantages of a shape-based representation. de Beeck. Deep neural networks as a computational model for human shape sensitivity. DiCarlo. Performance-optimized hierarchical models predict neural responses in higher visual cortex.",
    "prev": "However, the actual model reliability and robustness depend on the specific set of correlations that is used, and on how those correlations are combined.",
    "curr": "Indeed, outside of the training distribution, model predictions can deviate wildly from human expectations either due to relying on correlations that humans do not perceive [JLT18; Ily+19; Jac+19], or due to overusing correlations, such as texture [Gei+19;Bak+18] and color [YS02], that humans do use (but to a lesser degree).",
    "next": "Characterizing the correlations that models depend on thus has important implications for understanding model behavior, in general.",
    "hard_negative": [
      56657912,
      68222714
    ],
    "easy_negative": [
      9882011,
      14251173,
      9470648
    ]
  },
  {
    "index": 1946,
    "source_corpus_id": 2514328,
    "ref_id": "b2",
    "citation_corpus_id": 11336213,
    "start": 2046,
    "end": 2064,
    "title": "On the Properties of Neural Machine Translation: Encoder-Decoder Approaches",
    "abstract": "Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder-Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.",
    "prev": "We show experimentally that not only do our models require fewer operations, they also lead to better performance overall on evaluation tasks.",
    "curr": "INTRODUCTION\n\nThe class of Recurrent Neural Network models (RNNs) is particularly well suited to dealing with sequential data, and has been successfully applied to a diverse array of tasks, such as language modeling and speech recognition (Mikolov, 2012), machine translation (Mikolov, 2012;Cho et al., 2014a), or acoustic modeling (Robinson et al., 1993;Graves & Jaitly, 2014) among others.",
    "next": "Two factors have been instrumental in allowing this paradigm to be so widely adopted and give rise to the aforementioned successes.",
    "hard_negative": [
      8884845,
      10766958,
      14323132
    ],
    "easy_negative": [
      218974002,
      3608203,
      263884182
    ]
  },
  {
    "index": 1949,
    "source_corpus_id": 261682404,
    "ref_id": "b3",
    "citation_corpus_id": 219708602,
    "start": 3032,
    "end": 3034,
    "title": "Published as a conference paper at ICLR 2021 GENERALIZED ENERGY BASED MODELS",
    "abstract": "We introduce the Generalized Energy Based Model (GEBM) for generative modelling. These models combine two trained components: a base distribution (generally an implicit model), which can learn the support of data with low intrinsic dimension in a high dimensional space; and an energy function, to refine the probability mass on the learned support. Both the energy function and base jointly constitute the final model, unlike GANs, which retain only the base distribution (the \"generator\"). GEBMs are trained by alternating between learning the energy and the base. We show that both training stages are well-defined: the energy is learned by maximising a generalized likelihood, and the resulting energy-based loss provides informative gradients for learning the base. Samples from the posterior on the latent space of the trained model can be obtained via MCMC, thus finding regions in this space that produce better quality samples. Empirically, the GEBM samples on image-generation tasks are of much better quality than those from the learned generator alone, indicating that all else being equal, the GEBM will outperform a GAN of the same complexity. When using normalizing flows as base measures, GEBMs succeed on density modelling tasks, returning comparable performance to direct maximum likelihood of the same networks.",
    "prev": "Under review.",
    "curr": "arXiv:2309.05153v2 [stat.ML] 12 Sep 2023\n\nIntroduction\n\nEnergy-based models (EBMs), as a class of probabilistic generative models, have exhibited their flexibility and practicality in a variety of application scenarios, such as realistic image synthesis [1,2,3,4,5,6,7,8], graph generation [9], compositional generation [10,11], video generation [12], 3D generation [13,14,15], simulation-based inference [16], stochastic optimization [17], out-ofdistribution detection [18,19], continue learning [20] , internal learning [21], learning set funtion [22], image style transfer [23], continuous inverse optimal control [24], and latent space modeling [25].",
    "next": "Despite the recent successes of the EBMs, their training and sampling have been challenging because of the intractability of the normalizing constant.",
    "hard_negative": [
      53018855,
      3531856
    ],
    "easy_negative": [
      4983428,
      10977241,
      2388321
    ]
  },
  {
    "index": 1953,
    "source_corpus_id": 2468625,
    "ref_id": "b9",
    "citation_corpus_id": 2009318,
    "start": 2042,
    "end": 2045,
    "title": "NEURAL GPUS LEARN ALGORITHMS",
    "abstract": "Learning an algorithm from examples is a fundamental problem that has been widely studied. It has been addressed using neural networks too, in particular by Neural Turing Machines (NTMs). These are fully differentiable computers that use backpropagation to learn their own programming. Despite their appeal NTMs have a weakness that is caused by their sequential nature: they are not parallel and are are hard to train due to their large depth when unfolded. We present a neural network architecture to address this problem: the Neural GPU. It is based on a type of convolutional gated recurrent unit and, like the NTM, is computationally universal. Unlike the NTM, the Neural GPU is highly parallel which makes it easier to train and efficient to run. An essential property of algorithms is their ability to handle inputs of arbitrary size. We show that the Neural GPU can be trained on short instances of an algorithmic task and successfully generalize to long instances. We verified it on a number of tasks including long addition and long multiplication of numbers represented in binary. We train the Neural GPU on numbers with up-to 20 bits and observe no errors whatsoever while testing it, even on much longer numbers. To achieve these results we introduce a technique for training deep recurrent networks: parameter sharing relaxation. We also found a small amount of dropout and gradient noise to have a large positive effect on learning and generalization.",
    "prev": "Introduction\n\nA central goal of Artificial Intelligence are machines we can not just program but also teach.",
    "curr": "A recent and important step towards this goal are neural architectures that can learn to perform algorithms akin to traditional computers, using primitives such as memory access and stack manipulation [5,9,10,14,19].",
    "next": "These architectures can be trained through standard gradient descent methods, and enable machines to learn complex behaviors from input-output pairs or program traces.",
    "hard_negative": [
      7823468,
      12639289
    ],
    "easy_negative": [
      202539655,
      15292611,
      6218136
    ]
  },
  {
    "index": 1955,
    "source_corpus_id": 17984798,
    "ref_id": "b28",
    "citation_corpus_id": 18380217,
    "start": 2048,
    "end": 2074,
    "title": "Cross-lingual Transfer of Named Entity Recognizers without Parallel Corpora",
    "abstract": "We propose an approach to cross-lingual named entity recognition model transfer without the use of parallel corpora. In addition to global de-lexicalized features, we introduce multilingual gazetteers that are generated using graph propagation, and cross-lingual word representation mappings without the use of parallel data. We target the e-commerce domain, which is challenging due to its unstructured and noisy nature. The experiments have shown that our approaches beat the strong MT baseline, where the English model is transferred to two languages: Spanish and Chinese.",
    "prev": "An important challenge for sequence tagging is how to transfer knowledge from one task to another, which is often referred to as transfer learning (Pan & Yang, 2010).",
    "curr": "Transfer learning can be used in several settings, notably for low-resource languages (Zirikly & Hagiwara, 2015;Wang & Manning, 2014) and low-resource domains such as biomedical corpora (Kim et al., 2003) and Twitter corpora (Ritter et al., 2011)).",
    "next": "In these cases, transfer learning can improve performance by taking advantage of more plentiful labels from related tasks.",
    "hard_negative": [
      10674977,
      2810082,
      629094,
      14068874,
      10986188,
      2037646,
      891605,
      6698104
    ],
    "easy_negative": [
      233181806,
      256461158,
      15248370
    ]
  },
  {
    "index": 1961,
    "source_corpus_id": 245131359,
    "ref_id": "b9",
    "citation_corpus_id": 3073252,
    "start": 25222,
    "end": 25242,
    "title": "Published as a conference paper at ICLR 2017 LEARNING TO GENERATE SAMPLES FROM NOISE THROUGH INFUSION TRAINING",
    "abstract": "In this work, we investigate a novel training procedure to learn a generative model as the transition operator of a Markov chain, such that, when applied repeatedly on an unstructured random noise sample, it will denoise it into a sample that matches the target distribution from the training set. The novel training procedure to learn this progressive denoising operation involves sampling from a slightly different chain than the model chain used for generation in the absence of a denoising target. In the training chain we infuse information from the training target example that we would like the chains to reach with a high probability. The thus learned transition operator is able to produce quality and varied samples in a small number of steps. Experiments show competitive results compared to the samples generated with a basic Generative Adversarial Net.",
    "prev": "Further Related Work.",
    "curr": "Generative modeling by learning stochastic processes has a long history (Movellan, 2008;Lyu, 2009;Sohl-Dickstein et al., 2011;Alain et al., 2016;Goyal et al., 2017;Bordes et al., 2017;Song & Ermon, 2019;Ho et al., 2020).",
    "next": "We build on Song et al.",
    "hard_negative": [
      2187805,
      11758569
    ],
    "easy_negative": [
      12096827,
      251929366,
      56475856
    ]
  },
  {
    "index": 1978,
    "source_corpus_id": 247628243,
    "ref_id": "b32",
    "citation_corpus_id": 7478738,
    "start": 2895,
    "end": 2916,
    "title": "Linguistic Regularities in Continuous Space Word Representations",
    "abstract": "Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, \"King -Man + Woman\" results in a vector very close to \"Queen.\" We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems.",
    "prev": "Precisely approximating this large number of rare events is one of the foundational challenges for models of natural language (Good, 1953;Jelinek, 1980;Katz, 1987;Kneser & Ney, 1995;Wood et al., 2011;Goldwater et al., 2011).",
    "curr": "Autoregressive neural language models (Bengio et al., 2003;Mikolov et al., 2013;Radford et al., 2019) attempt to do so by decomposing the probability of an event (a sequence) into a series of conditional distributions, each parameterized by a shared neural network.",
    "next": "Recently, a growing body work has sought to understand how these language models (LM) fit the distribution of a language beyond standard measures such Published as a conference paper at ICLR 2022 as perplexity.",
    "hard_negative": [
      5278106,
      15637201,
      629094,
      252796
    ],
    "easy_negative": [
      6122370,
      16080480,
      232021769
    ]
  },
  {
    "index": 1984,
    "source_corpus_id": 249848272,
    "ref_id": "b91",
    "citation_corpus_id": 3432876,
    "start": 9885,
    "end": 9908,
    "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    "abstract": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",
    "prev": "NLP.",
    "curr": "Tasks with text as the only input and output modalities, including text classification (Williams et al., 2018), question answering (Rajpurkar et al., 2016) and text summarization (Graff et al., 2003).",
    "next": "Language Modeling.",
    "hard_negative": [
      10202504,
      14429450,
      5555594,
      28495499,
      6628106,
      3104920,
      8495258,
      11866664,
      11262376,
      34032948,
      1957433,
      5471801,
      15978939,
      30758763,
      252796
    ],
    "easy_negative": [
      3259134,
      252367868,
      1297066
    ]
  },
  {
    "index": 1988,
    "source_corpus_id": 263334319,
    "ref_id": "b47",
    "citation_corpus_id": 233296494,
    "start": 5101,
    "end": 5118,
    "title": "Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity",
    "abstract": "When primed with only a handful of training samples, very large, pretrained language models such as GPT-3 have shown competitive results when compared to fully-supervised, finetuned, large, pretrained language models. We demonstrate that the order in which the samples are provided can make the difference between near state-of-the-art and random guess performance: essentially some permutations are \"fantastic\" and some not. We analyse this phenomenon in detail, establishing that: it is present across model sizes (even for the largest current models), it is not related to a specific subset of samples, and that a given good permutation for one model is not transferable to another. While one could use a development set to determine which permutations are performant, this would deviate from the true fewshot setting as it requires additional annotated data. Instead, we use the generative nature of language models to construct an artificial development set and based on entropy statistics of the candidate permutations on this set, we identify performant prompts. Our method yields a 13% relative improvement for GPTfamily models across eleven different established text classification tasks.",
    "prev": " and using it to train agents via reinforcement learning (RL) (Sutton & Barto, 2018).Our method, named Motif, uses an LLM to express preferences over pairs of event captions extracted from a dataset of observations and then distills them into an intrinsic reward.The resulting reward is then maximized directly or in combination with an extrinsic reward coming from the environment.A guiding principle in the design of Motif is the observation that it is often easier to evaluate than to generate (Sutton, 2001;Schulman, 2023).Motif's LLM expresses preferences over textual event captions; these are only required to be coarse descriptions of events happening in the environment rather than fine-grained step-by-step portrayals of the current observations.The LLM is not even asked to understand the low-level action space, which may be composite or continuous.",
    "curr": "In comparison, an approach using an LLM as a policy typically requires a complete text interface with the environment (Wang et al., 2023;Yao et al., 2022).When using Motif, the LLM remains in the space of high-level knowledge it was trained on, but leverages the capabilities of deep RL algorithms to deal with decision-making under rich observation and action spaces.",
    "next": "We apply Motif to the challenging NetHack Learning Environment (NLE) (K\u00fcttler et al., 2020), and learn intrinsic rewards from Llama 2's preferences (Touvron et al., 2023) on a dataset of gameplays.This dataset, collected by policies of different levels of proficiency, only contains observations from the environment, without any action or reward information.Using this framework, we show that the resulting intrinsic reward drastically improves subsequent learning of a policy by RL.Motif excels in both relatively dense reward tasks, such as maximizing the game score, and extremely sparse reward tasks, such as the oracle task.To our knowledge, our paper is the first to make progress on this task without leveraging expert demonstrations.Notably, an agent trained only through Mot",
    "hard_negative": [
      3264224,
      3626819,
      388,
      52967399,
      21850704,
      202541043,
      990233
    ],
    "easy_negative": [
      11247175,
      245123965,
      173188095
    ]
  },
  {
    "index": 1991,
    "source_corpus_id": 5592690,
    "ref_id": "b12",
    "citation_corpus_id": 2100831,
    "start": 1708,
    "end": 1733,
    "title": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text",
    "abstract": "We present MCTest, a freely available set of stories and associated questions intended for research on the machine comprehension of text. Previous work on machine comprehension (e.g., semantic modeling) has made great strides, but primarily focuses either on limited-domain datasets, or on solving a more restricted goal (e.g., open-domain relation extraction). In contrast, MCTest requires machines to answer multiple-choice reading comprehension questions about fictional stories, directly tackling the high-level goal of open-domain machine comprehension. Reading comprehension can test advanced abilities such as causal reasoning and understanding the world, yet, by being multiple-choice, still provide a clear metric. By being fictional, the answer typically can be found only in the story itself. The stories and questions are also carefully limited to those a young child would understand, reducing the world knowledge that is required for the task. We present the scalable crowd-sourcing methods that allow us to cheaply construct a dataset of 500 stories and 2000 questions. By screening workers (with grammar tests) and stories (with grading), we have ensured that the data is the same quality as another set that we manually edited, but at one tenth the editing cost. By being open-domain, yet carefully restricted, we hope MCTest will serve to encourage research and provide a clear metric for advancement on the machine comprehension of text.",
    "prev": "INTRODUCTION\n\nMachine comprehension of text is one of the ultimate goals of natural language processing.",
    "curr": "While the ability of a machine to understand text can be assessed in many different ways, in recent years, several benchmark datasets have been created to focus on answering questions as a way to evaluate machine comprehension (Richardson et al., 2013;Hermann et al., 2015;Hill et al., 2016;Rajpurkar et al., 2016).",
    "next": "In this setup, typically the machine is first presented with a piece of text such as a news article or a story.",
    "hard_negative": [
      1321,
      3038382,
      5734707,
      9111381,
      15197674,
      12131065
    ],
    "easy_negative": [
      2685794,
      10363587,
      241583323
    ]
  },
  {
    "index": 1992,
    "source_corpus_id": 260886874,
    "ref_id": "b6",
    "citation_corpus_id": 7164502,
    "start": 21353,
    "end": 21377,
    "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments",
    "abstract": "We describe METEOR, an automatic metric for machine translation evaluation that is based on a generalized concept of unigram matching between the machineproduced translation and human-produced reference translations. Unigrams can be matched based on their surface forms, stemmed forms, and meanings; furthermore, METEOR can be easily extended to include more advanced matching strategies.Once all generalized unigram matches between the two strings have been found, METEOR computes a score for this matching using a combination of unigram-precision, unigram-recall, and a measure of fragmentation that is designed to directly capture how well-ordered the matched words in the machine translation are in relation to the reference. We evaluate METEOR by measuring the correlation between the metric scores and human judgments of translation quality. We compute the Pearson R correlation value between its scores and human quality assessments of the LDC TIDES 2003 Arabic-to-English and Chinese-to-English datasets.We perform segment-bysegment correlation, and show that METEOR gets an R correlation value of 0.347 on the Arabic data and 0.331 on the Chinese data. This is shown to be an improvement on using simply unigramprecision, unigram-recall and their harmonic F1 combination. We also perform experiments to show the relative contributions of the various mapping modules.",
    "prev": "Further, our coding problems, derived from HumanEval, are very specific, such as keeping track of a bank account balance (see Figure 14).",
    "curr": "Prior work on evaluating code explanations (Lu et al., 2021;Cui et al., 2022) has relied on metrics such as METEOR (Banerjee & Lavie, 2005) or BLEU (Papineni et al., 2002).",
    "next": "By chaining code explanation with code synthesis, we can evaluate this task using the execution-based pass@k metric overcoming the major limitations of BLEU and other heuristics-based metrics (Reiter, 2018).",
    "hard_negative": [
      9469794,
      11728052,
      1745463
    ],
    "easy_negative": [
      33379735,
      429356,
      258486858
    ]
  },
  {
    "index": 2000,
    "source_corpus_id": 249431362,
    "ref_id": "b43",
    "citation_corpus_id": 1957433,
    "start": 14162,
    "end": 14187,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "Step 2 -Candidate selection For each word w i in s sequentially, a set of substitution candidates C of N elements is extracted.",
    "curr": "This candidate set is constructed from the counter-fitted GloVe (Pennington et al., 2014) synonym embeddings by the authors of Mrk\u0161i\u0107 et al.",
    "next": "(2016).",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      15074076,
      241583497,
      17303724
    ]
  },
  {
    "index": 2004,
    "source_corpus_id": 50783524,
    "ref_id": "b27",
    "citation_corpus_id": 2578649,
    "start": 3179,
    "end": 3195,
    "title": "Chinese Dependency Parsing with Large Scale Automatically Constructed Case Structures",
    "abstract": "This paper proposes an approach using large scale case structures, which are automatically constructed from both a small tagged corpus and a large raw corpus, to improve Chinese dependency parsing. The case structure proposed in this paper has two characteristics: (1) it relaxes the predicate of a case structure to be all types of words which behaves as a head; (2) it is not categorized by semantic roles but marked by the neighboring modifiers attached to a head. Experimental results based on Penn Chinese Treebank show the proposed approach achieved 87.26% on unlabeled attachment score, which significantly outperformed the baseline parser without using case structures.",
    "prev": "In previous work, before the rise of deep learning, the semi-supervised parsing setting has been mainly tackled with two-step algorithms.",
    "curr": "On the one hand, feature extraction methods first learn an intermediate representation using an unlabeled dataset which is then used as input to train a supervised parser (Koo et al., 2008;Yu et al., 2008;Chen et al., 2009;Suzuki et al., 2011).",
    "next": "On the other hand, the self-training and co-training methods start by learning a supervised parser that is then used to label extra data.",
    "hard_negative": [
      6785675,
      1219991,
      1619100,
      2712224,
      1661089,
      16858536,
      12615602,
      11062835,
      9450557,
      9404516,
      2126193,
      7212789
    ],
    "easy_negative": [
      252819386,
      319124,
      221655222
    ]
  },
  {
    "index": 2005,
    "source_corpus_id": 3538627,
    "ref_id": "b19",
    "citation_corpus_id": 1957433,
    "start": 30873,
    "end": 30898,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "B.2 COUNTING MODELS\n\nEach of the considered counting models makes use of the same basic architecture for encoding the question and comparing it with each of the detected objects.",
    "curr": "For each model, we initialized the word embeddings from GloVe (Pennington et al., 2014) and encoded the question with an LSTM of hidden size 1024.",
    "next": "The only differences in the model-specific implementations of the language module was the hidden size of the scoring function f S .",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      235097435,
      6830876,
      6339908
    ]
  },
  {
    "index": 2009,
    "source_corpus_id": 220525844,
    "ref_id": "b19",
    "citation_corpus_id": 3285020,
    "start": 2273,
    "end": 2276,
    "title": "BEYOND SHARED HIERARCHIES: DEEP MULTITASK LEARNING THROUGH SOFT LAYER ORDERING",
    "abstract": "Existing deep multitask learning (MTL) approaches align layers shared between tasks in a parallel ordering. Such an organization significantly constricts the types of shared structure that can be learned. The necessity of parallel ordering for deep MTL is first tested by comparing it with permuted ordering of shared layers.The results indicate that a flexible ordering can enable more effective sharing, thus motivating the development of a soft ordering approach, which learns how shared layers are applied in different ways for different tasks. Deep MTL with soft ordering outperforms parallel ordering methods across a series of domains. These results suggest that the power of deep MTL comes from learning highly general building blocks that can be assembled to meet the demands of each task.",
    "prev": "If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions.",
    "curr": "Many different compositional representations for handling multiple tasks have been proposed over the last few years [32,9,13,19].",
    "next": "In this work, we address the novel question of how to learn these compositional structures in a lifelong learning setting.",
    "hard_negative": [
      11754890,
      6954272,
      3047732,
      3666937
    ],
    "easy_negative": [
      247450508,
      14536586,
      14031454
    ]
  },
  {
    "index": 2011,
    "source_corpus_id": 226964491,
    "ref_id": "b1",
    "citation_corpus_id": 7164502,
    "start": 22571,
    "end": 22595,
    "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments",
    "abstract": "We describe METEOR, an automatic metric for machine translation evaluation that is based on a generalized concept of unigram matching between the machineproduced translation and human-produced reference translations. Unigrams can be matched based on their surface forms, stemmed forms, and meanings; furthermore, METEOR can be easily extended to include more advanced matching strategies.Once all generalized unigram matches between the two strings have been found, METEOR computes a score for this matching using a combination of unigram-precision, unigram-recall, and a measure of fragmentation that is designed to directly capture how well-ordered the matched words in the machine translation are in relation to the reference. We evaluate METEOR by measuring the correlation between the metric scores and human judgments of translation quality. We compute the Pearson R correlation value between its scores and human quality assessments of the LDC TIDES 2003 Arabic-to-English and Chinese-to-English datasets.We perform segment-bysegment correlation, and show that METEOR gets an R correlation value of 0.347 on the Arabic data and 0.331 on the Chinese data. This is shown to be an improvement on using simply unigramprecision, unigram-recall and their harmonic F1 combination. We also perform experiments to show the relative contributions of the various mapping modules.",
    "prev": "Evaluation Metrics For discriminative tasks, we choose accuracy as our metric following other conventional question answering tasks.",
    "curr": "For generative tasks, we report automated metrics including BLEU (Papineni et al., 2002), METEOR (Banerjee & Lavie, 2005), CIDEr (Vedantam et al., 2015), and SPICE (Anderson et al., 2016) following the leaderboard of COMMONGEN (Lin et al., 2020).",
    "next": "Results for COMMONGEN are on the test set and others are on the official development set.",
    "hard_negative": [
      9469794,
      11728052,
      1745463
    ],
    "easy_negative": [
      11602876,
      263310924,
      319552
    ]
  },
  {
    "index": 2012,
    "source_corpus_id": 208513914,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 1683,
    "end": 1705,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "For machine translation, DeFINE improves the efficiency of the Transformer model by about 1.4 times while delivering similar performance.",
    "curr": "INTRODUCTION\n\nNeural models for NLP tasks, such as language modeling and machine translation, require large vocabularies for generality (Chelba et al., 2013;Bahdanau et al., 2015;Luong et al., 2015;Merity et al., 2017).",
    "next": "These models often employ a similar architecture: tokens (e.g., words, sub-words, or characters), represented as one-hot vectors, are mapped to a dense continuous space; they are then processed by a context model; finally, the contextualized representations are mapped back to a vocabulary-sized vector for computing next-token probabilities.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      237055435,
      264038748,
      14968961
    ]
  },
  {
    "index": 2013,
    "source_corpus_id": 67877096,
    "ref_id": "b23",
    "citation_corpus_id": 13298214,
    "start": 2083,
    "end": 2106,
    "title": "LEARNING TO NAVIGATE IN COMPLEX ENVIRONMENTS",
    "abstract": "Learning to navigate in complex environments with dynamic elements is an important milestone in developing AI agents. In this work we formulate the navigation question as a reinforcement learning problem and show that data efficiency and task performance can be dramatically improved by relying on additional auxiliary tasks leveraging multimodal sensory inputs. In particular we consider jointly learning the goal-driven reinforcement learning problem with auxiliary depth prediction and loop closure classification tasks. This approach can learn to navigate from raw sensory input in complicated 3D mazes, approaching human-level performance even under conditions where the goal location changes frequently. We provide detailed analysis of the agent behaviour 1 , its ability to localise, and its network activity dynamics, showing that the agent implicitly learns key navigation abilities.",
    "prev": "This step of task-independent exploration is quite critical yet often ignored in current approaches for navigation.",
    "curr": "When it comes to navigation, currently there are two paradigms: (a) geometric reconstruction and path-planning based approaches (Hartley & Zisserman, 2003;Thrun et al., 2005;LaValle, 2006), and (b) learning-based approaches (Mirowski et al., 2017;Savinov et al., 2018;Zhu et al., 2017).",
    "next": "SLAM-based approaches, first build a map and then use localization and path planning for navigation.",
    "hard_negative": [
      8395799,
      14717992
    ],
    "easy_negative": [
      9351555,
      2523524,
      53081799
    ]
  },
  {
    "index": 2018,
    "source_corpus_id": 231846526,
    "ref_id": "b12",
    "citation_corpus_id": 12308095,
    "start": 59365,
    "end": 59383,
    "title": "COUNTERING ADVERSARIAL IMAGES USING INPUT TRANSFORMATIONS",
    "abstract": "This paper investigates strategies that defend against adversarial-example attacks on image-classification systems by transforming the inputs before feeding them to the system. Specifically, we study applying image transformations such as bit-depth reduction, JPEG compression, total variance minimization, and image quilting before feeding the image to a convolutional network classifier. Our experiments on ImageNet show that total variance minimization and image quilting are very effective defenses in practice, in particular, when the network is trained on transformed images. The strength of those defenses lies in their non-differentiable nature and their inherent randomness, which makes it difficult for an adversary to circumvent the defenses. Our best defense eliminates 60% of strong gray-box and 90% of strong black-box attacks by a variety of major attack methods.",
    "prev": "We compare the robust accuracy with different magnitude with 20-step attack with a step size of 2/255.",
    "curr": "For BPDA attack, we apply median smoothing, JPEGFilter and BitSqueezing as input transformation adapted from(Guo et al., 2018) as defense strategies.",
    "next": "For SPSA attack, we follow(Uesato et al., 2018)  and set the Adam learning rate 0.01, perturbation size \u03b4 = 0.01.",
    "hard_negative": [
      604334,
      14307651,
      6706414
    ],
    "easy_negative": [
      195352204,
      51918625,
      227320045
    ]
  },
  {
    "index": 2022,
    "source_corpus_id": 263608710,
    "ref_id": "b36",
    "citation_corpus_id": 155092004,
    "start": 2118,
    "end": 2139,
    "title": "BERT Rediscovers the Classical NLP Pipeline",
    "abstract": "Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such model, BERT, and aim to quantify where linguistic information is captured within the network. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence: POS tagging, parsing, NER, semantic roles, then coreference. Qualitative analysis reveals that the model can and often does adjust this pipeline dynamically, revising lowerlevel decisions on the basis of disambiguating information from higher-level representations.",
    "prev": "pose a notion of \"tree averaging,\" based on which we further propose a novel ensemble method for unsupervised parsing.To improve inference efficiency, we further distill the ensemble knowledge into a student model; such an ensemble-then-distill process is an effective approach to mitigate the over-smoothing problem existing in common multi-teacher distilling methods.Experiments show that our method surpasses all previous approaches, consistently demonstrating its effectiveness and robustness across various runs, with different ensemble components, and under domain-shift conditions.",
    "curr": "1\n\nIntroduction\n\nConstituency parsing is a core task in natural language processing (NLP), which interprets a sentence and induces its constituency tree, a syntactic structure representation that organizes words and phrases into a hierarchy (Carnie, 2007).It has wide applications in various downstream tasks, including semantic role labeling (Mohammadshahi and Henderson, 2023) and explainability of AI models (Tenney et al., 2019).Traditionally, parsing is accomplished by supervised models trained with linguistically annotated treebanks (Charniak, 2000), which are expensive to obtain and may not be available for low-resource scenarios.Also, these supervised parsers often underperform when encountering domain shifts.This motivates researchers to explore unsupervised methods as it eliminates the need for annotated data.",
    "next": "To address unsupervised parsing, researchers have proposed various heuristics and indirect supervision signals.Clark (2001) employs context distribution clustering to induce a probabilistic context-free grammar (PCFG;Booth, 1969).Klein and Manning (2002) define a joint distribution for sentences and parse structures, the latter learned by expectation-maximization (EM) algorithms.Snyder et al.",
    "hard_negative": [
      52113185,
      3626819,
      14068874,
      7197724,
      3011504,
      52123220,
      21663989,
      436023,
      108300988,
      24461982
    ],
    "easy_negative": [
      11063874,
      236457320,
      53082743
    ]
  },
  {
    "index": 2024,
    "source_corpus_id": 249063147,
    "ref_id": "b43",
    "citation_corpus_id": 222291132,
    "start": 24869,
    "end": 24889,
    "title": "FAIRSEQ S2T: Fast Speech-to-Text Modeling with FAIRSEQ",
    "abstract": "We introduce FAIRSEQ S2T, a FAIRSEQ (Ott et al., 2019) extension for speech-to-text (S2T) modeling tasks such as end-to-end speech recognition and speech-to-text translation. It follows FAIRSEQ's careful design for scalability and extensibility. We provide end-to-end workflows from data pre-processing, model training to offline (online) inference. We implement state-of-the-art RNN-based as well as Transformer-based models and opensource detailed training recipes. FAIRSEQ's machine translation models and language models can be seamlessly integrated into S2T workflows for multi-task learning or transfer learning. FAIRSEQ S2T documentation and examples are available at https: //github.com/pytorch/fairseq/tree/ master/examples/speech_to_text.",
    "prev": "In decoding speed, latency is computed as the time to decode the single n-frame speech sample averaged over the test set using 1 V100 GPU.",
    "curr": "We compare TranSpeech with other systems using the publicly-available fairseq framework (Ott et al., 2019), including 1) Direct ASR, where we transcribe S2ST data with open-sourced ASR as reference and compute BELU; 2) Direct TTS, where we synthesize speech samples with target units, and then transcribe the speech to text and compute BELU; 3) S2T+TTS cascaded system, where we train the S2T basic transformer model (Wang et al., 2020a) and then apply TTS model Kong et al., 2020) for speech generation; 4) basic transformer (Lee et al., 2021a) without using text, and 5) basic norm transformer (Lee et al., 2021b) with speaker normalization.",
    "next": "Table 1 summarizes the translation accuracy and inference latency among all systems, and we have the following observations: 1) Bilateral perturbation (3 vs. 4) improves S2ST performance by a large margin of 2.9 BLEU points.",
    "hard_negative": [
      91184134,
      13705623,
      3297437,
      44084020,
      13751870,
      204960716,
      203591628,
      3988816,
      15349458,
      202565731
    ],
    "easy_negative": [
      7586668,
      237451171,
      1101808
    ]
  },
  {
    "index": 2028,
    "source_corpus_id": 49416020,
    "ref_id": "b20",
    "citation_corpus_id": 3144218,
    "start": 6353,
    "end": 6374,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "If one accepts the value of convolutions as prima facie, a natural solution is to replace convolutions with graph shift invariant filters which are known to be valid generalizations of (convolutional) time invariant filters (Bruna et al., 2014).",
    "curr": "This idea is not only natural but has been demonstrated to work well in practical implementations of Graph Neural Networks (GNNs) (Defferrard et al., 2016;Gama et al., 2018;Gilmer et al., 2017;Henaff et al., 2015;Kipf & Welling, 2017).",
    "next": "Same as Euclidean scattering transforms, our graph scattering transforms differ from GNNs in that they do not have to be trained.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      14310891,
      442560,
      53244635
    ]
  },
  {
    "index": 2030,
    "source_corpus_id": 237491843,
    "ref_id": "b8",
    "citation_corpus_id": 13807351,
    "start": 11366,
    "end": 11368,
    "title": "ENTROPY-SGD: BIASING GRADIENT DESCENT INTO WIDE VALLEYS",
    "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under certain assumptions. Our experiments on convolutional and recurrent neural networks demonstrate that Entropy-SGD compares favorably to state-of-the-art techniques in terms of generalization error and training time.",
    "prev": "In Adam, the bias-corrected first and second moment estimates, i.e., m k andD k in (2), are as follows:\nm k = 1\u2212\u03b21 1\u2212\u03b2 k 1 k i=1 \u03b2 k\u2212i 1 g i ,D k = 1\u2212\u03b22 1\u2212\u03b2 k 2 k i=1 \u03b2 k\u2212i 2 diag(g i g i ).",
    "curr": "(5)\nThere have been many other first-order methods with adaptive scaling [24,9,23,40].",
    "next": "The methods described so far have only used the information of the gradient for preconditioning m k in (2).",
    "hard_negative": [
      17272965,
      16209268,
      252796
    ],
    "easy_negative": [
      208309981,
      9861697,
      211259315
    ]
  },
  {
    "index": 2031,
    "source_corpus_id": 256615445,
    "ref_id": "b11",
    "citation_corpus_id": 52890982,
    "start": 7848,
    "end": 7852,
    "title": "ADVERSARIAL AUDIO SYNTHESIS",
    "abstract": "While Generative Adversarial Networks (GANs) have seen wide success at the problem of synthesizing realistic images, they have seen little application to audio generation. Unlike for images, a barrier to success is that the best discriminative representations for audio tend to be non-invertible, and thus cannot be used to synthesize listenable outputs. In this paper we introduce WaveGAN, a first attempt at applying GANs to unsupervised synthesis of raw-waveform audio. Our experiments demonstrate that WaveGAN can produce intelligible words from a small vocabulary of speech, and can also synthesize audio from other domains such as drums, bird vocalizations, and piano. Qualitatively, we find that human judges prefer the sound quality of generated examples from WaveGAN over those from a method which na\u00efvely apply GANs on image-like audio feature representations.",
    "prev": "Related Work\n\n\nGenerative Models for Audio\n\nDeep generative models for audio, learn, directly or implicitly, the distribution of mixtures, represented in our notation by p(y), possibly conditioning on additional data such as text.",
    "curr": "Various general-purpose generative models, such as autoregressive models, GANs [12], and diffusion models, have been adapted for use in the audio field.",
    "next": "Autoregressive models have a well-established presence in audio modeling [69].",
    "hard_negative": [
      2187805,
      26100519,
      3568073,
      3338083,
      11758569
    ],
    "easy_negative": [
      247761945,
      219179431,
      259833824
    ]
  },
  {
    "index": 2033,
    "source_corpus_id": 231933756,
    "ref_id": "b2",
    "citation_corpus_id": 256189,
    "start": 2143,
    "end": 2162,
    "title": "Semi-Supervised Learning for Neural Machine Translation",
    "abstract": "While end-to-end neural machine translation (NMT) has made remarkable progress recently, NMT systems only rely on parallel corpora for parameter estimation. Since parallel corpora are usually limited in quantity, quality, and coverage, especially for low-resource languages, it is appealing to exploit monolingual corpora to improve NMT. We propose a semisupervised approach for training NMT models on the concatenation of labeled (parallel corpora) and unlabeled (monolingual corpora) data. The central idea is to reconstruct the monolingual corpora using an autoencoder, in which the sourceto-target and target-to-source translation models serve as the encoder and decoder, respectively. Our approach can not only exploit the monolingual corpora of the target language, but also of the source language. Experiments on the Chinese-English dataset show that our approach achieves significant improvements over state-of-the-art SMT and NMT systems.",
    "prev": "Cross Entropy Loss update backward model\n\nINTRODUCTION\n\nWhile Neural Machine Translation (NMT) delivers state-of-the-art performance across many translation tasks, this performance is usually contingent on the existence of large amounts of training data (Sutskever et al., 2014;Vaswani et al., 2017).",
    "curr": "Since large parallel training datasets are often unavailable for many languages and domains, various methods have been developed to leverage abundant monolingual corpora (Gulcehre et al., 2015;Cheng et al., 2016;Sennrich et al., 2016;Xia et al., 2016;Hoang et al., 2018;Song et al., 2019;He et al., 2020).",
    "next": "Among such methods, one particularly popular approach is back-translation (BT; Sennrich et al.",
    "hard_negative": [
      2863491,
      11336213,
      3116311,
      1245593,
      11791923,
      12639289,
      15769924,
      384994,
      8884845,
      11212020
    ],
    "easy_negative": [
      125969731,
      248780413,
      30217455
    ]
  },
  {
    "index": 2034,
    "source_corpus_id": 250408279,
    "ref_id": "b24",
    "citation_corpus_id": 5033497,
    "start": 9056,
    "end": 9078,
    "title": "Phrase-Based & Neural Unsupervised Machine Translation",
    "abstract": "Machine translation systems achieve near human-level performance on some languages, yet their effectiveness strongly relies on the availability of large amounts of parallel sentences, which hinders their applicability to the majority of language pairs. This work investigates how to learn to translate when having access to only large monolingual corpora in each language. We propose two model variants, a neural and a phrase-based model. Both versions leverage a careful initialization of the parameters, the denoising effect of language models and automatic generation of parallel data by iterative back-translation. These models are significantly better than methods from the literature, while being simpler and having fewer hyper-parameters. On the widely used WMT'14 English-French and WMT'16 German-English benchmarks, our models respectively obtain 28.1 and 25.2 BLEU points without using a single parallel sentence, outperforming the state of the art by more than 11 BLEU points. On low-resource languages like English-Urdu and English-Romanian, our methods achieve even better results than semisupervised and supervised approaches leveraging the paucity of available bitexts. Our code for NMT and PBSMT is publicly available. 1",
    "prev": ".",
    "curr": "y i\u22121 ))\n\nCOMMON OBJECTIVE FUNCTIONS\n\nTransCoder (Roziere et al., 2020) learns to translate between programming languages by leveraging three unsupervised objectives developed for natural language (Lample et al., 2018b):\n\nMasked Language Modeling (MLM) trains an encoder to predict randomly masked inputs.",
    "next": "It is commonly used to pre-train embeddings for natural (Devlin et al., 2018; and programming languages (Kanade et al., 2020;.",
    "hard_negative": [
      8313873,
      8822680,
      3295641,
      1395225,
      8608051,
      2166461,
      3470398,
      10527293,
      9752897,
      11591887,
      3515219,
      9352546,
      207556454,
      5590763,
      8680683,
      5147501,
      8884845,
      3518190
    ],
    "easy_negative": [
      215888916,
      8525297,
      2889892
    ]
  },
  {
    "index": 2037,
    "source_corpus_id": 263830324,
    "ref_id": "b0",
    "citation_corpus_id": 235436185,
    "start": 2822,
    "end": 2839,
    "title": "BEIT: BERT Pre-Training of Image Transformers",
    "abstract": "We introduce a self-supervised vision representation model BEIT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT [DCLT19] developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16\u00d716 pixels), and visual tokens (i.e., discrete tokens). We first \"tokenize\" the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEIT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.",
    "prev": "ntation learning is one of the most fundamental problems in 3D computer vision, especially with the rapid development of 3D sensors (e.g., LiDAR) and the growing demands in realworld applications, e.g., autonomous driving, augmented/virtual reality and robotics.Existing methods make great progress in 3D model architecture (Qi et al., 2017a;b;Yu et al., 2021;Wang et al., 2019), learning objective (Yu et al., 2022;Wang et al., 2021), task-oriented modeling (Zhou et al., 2020;Yin et al., 2021;Zhao et al., 2021), etc.However, most of the works explore at a relatively small scale, with limited parameters, data, and task scenarios.Learning scalable 3D representation that can transfer in the wild is relatively unexplored and remains a challenging problem.",
    "curr": "In the past few years, scaling up pre-trained language models (Brown et al., 2020;Liu et al., 2019;Raffel et al., 2020) has largely revolutionized natural language processing.Some recent works (Radford et al., 2021;Dosovitskiy et al., 2020;Bao et al., 2021;He et al., 2022;Fang et al., 2022) translate the progress from language to 2D vision via model and data scaling.Motivated by their success, it is appealing that we can also lift this success from 2D to 3D, i.e., to learn a scalable 3D representation model that can transfer in the 3D world.Recently, as the release of a large-scale 3D dataset Objaverse (Deitke et al., 2023b), a few works have tried to explore scalable pretraining in 3D, but either still limit to the small-scale 3D backbones (Xue et al., 2023a;b), or can hardly scale to a relatively larger size (Liu et al., 2023), e.g., 72M in Fig.",
    "next": "1.",
    "hard_negative": [
      14307651,
      52055130,
      218581596,
      4009713
    ],
    "easy_negative": [
      1519369,
      1922244,
      8925228
    ]
  },
  {
    "index": 2041,
    "source_corpus_id": 263622509,
    "ref_id": "b9",
    "citation_corpus_id": 245334837,
    "start": 18430,
    "end": 18450,
    "title": "RVS: WHAT IS ESSENTIAL FOR OFFLINE RL VIA SUPERVISED LEARNING?",
    "abstract": "Recent work has shown that supervised learning alone, without temporal difference (TD) learning, can be remarkably effective for offline RL. When does this hold true, and which algorithmic components are necessary? Through extensive experiments, we boil supervised learning for offline RL down to its essential elements. In every environment suite we consider, simply maximizing likelihood with a two-layer feedforward MLP is competitive with state-of-the-art results of substantially more complex methods based on TD learning or sequence modeling with Transformers. Carefully choosing model capacity (e.g., via regularization or architecture) and choosing which information to condition on (e.g., goals or rewards) are critical for performance. These insights serve as a field guide for practitioners doing Reinforcement Learning via Supervised Learning (which we coin RvS learning). They also probe the limits of existing RvS methods, which are comparatively weak on random data, and suggest a number of open problems.",
    "prev": "(2021), as the initial RTG we set a target RTG that represents the desired performance.During the inference, DC receives the current trajectory data, generates an action to obtain the next state and reward, and subsequently subtracts the reward from the preceding RTG.",
    "curr": "RELATED WORKS\n\nReturn-Conditioned BC Both DC and DT fall under the category of return-conditioned BC, an active research field of offline RL (Kumar et al., 2019;Schmidhuber, 2019;Chen et al., 2021;Emmons et al., 2021;David et al., 2023).For example, RvS (Emmons et al., 2021)  Offline RL with Online Finetuning It is known that the performance of models trained through offline learning is often limited by the quality of the dataset.Thus, finetuning through online interactions can improve the performance of offline-pretrained models (Zhang et al., 2022;Luo et al., 2023).Overcoming the limitations of DT for online applications, Zheng et al.",
    "next": "(2022) proposed an Online Decision Transformer (ODT), which includes a stochastic policy and an additional maxentropy objective in the loss function.A similar method can be applied to DC for online finetuning.",
    "hard_negative": [
      199000713,
      221112471,
      53776053,
      28202810,
      21529792,
      232428253,
      16326763
    ],
    "easy_negative": [
      203935,
      14613502,
      18349465
    ]
  },
  {
    "index": 2044,
    "source_corpus_id": 251953252,
    "ref_id": "b45",
    "citation_corpus_id": 10910955,
    "start": 1980,
    "end": 2000,
    "title": "Distant supervision for relation extraction without labeled data",
    "abstract": "Modern models of relation extraction for tasks like ACE are based on supervised learning of relations from small hand-labeled corpora. We investigate an alternative paradigm that does not require labeled corpora, avoiding the domain dependence of ACEstyle algorithms, and allowing the use of corpora of any size. Our experiments use Freebase, a large semantic database of several thousand relations, to provide distant supervision. For each pair of entities that appears in some Freebase relation, we find all sentences containing those entities in a large unlabeled corpus and extract textual features to train a relation classifier. Our algorithm combines the advantages of supervised IE (combining 400,000 noisy pattern features in a probabilistic classifier) and unsupervised IE (extracting large numbers of relations from large corpora of any domain). Our model is able to extract 10,000 instances of 102 relations at a precision of 67.6%. We also analyze feature performance, showing that syntactic parse features are particularly helpful for relations that are ambiguous or lexically distant in their expression.",
    "prev": "INTRODUCTION\n\nNamed entity recognition (NER) is the task of identifying text spans associated with named entities and classifying them into a predefined set of entity types such as person, location, etc.",
    "curr": "As a fundamental component in information extraction systems (Nadeau & Sekine, 2007), NER has been shown to be of benefit to various downstream tasks such as relation extraction (Mintz et al., 2009), coreference resolution (Chang et al., 2013), and fine-grained opinion mining (Choi et al., 2006).",
    "next": "(Karpukhin et al., 2020) and entity linking Zhang et al., 2021a), we propose an efficient BI-encoder for NameD Entity Recognition (BINDER).",
    "hard_negative": [
      8186401,
      8835255,
      3179848,
      10977241,
      226541,
      12893808
    ],
    "easy_negative": [
      2551477,
      5566192,
      226262197
    ]
  },
  {
    "index": 2045,
    "source_corpus_id": 238408406,
    "ref_id": "b7",
    "citation_corpus_id": 29153681,
    "start": 15612,
    "end": 15637,
    "title": "META-LEARNING WITH DIFFERENTIABLE CLOSED-FORM SOLVERS",
    "abstract": "Adapting deep networks to new concepts from a few examples is challenging, due to the high computational requirements of standard fine-tuning procedures.Most work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent. Nonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently. In this paper, we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning. The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression, as part of its own internal model, enabling it to quickly adapt to novel data. This requires back-propagating errors through the solver steps. While normally the cost of the matrix operations involved in such a process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage. We propose both closed-form and iterative solvers, based on ridge regression and logistic regression components. Our methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks.",
    "prev": "These absolute improvements sometimes constitute significantly to the baseline accuracy in terms of relative importance.",
    "curr": "Datasets:\n\nWe perform experiments on four widely-used and publicly available benchmarks: mini-ImageNet (Vinyals et al., 2016), CIFAR-FS (Bertinetto et al., 2019), tiered-ImageNet , and CUB (Wah et al., 2011).",
    "next": "Each dataset consists of non-overlapping base, validation, and novel classes.",
    "hard_negative": [
      3431470,
      12122362
    ],
    "easy_negative": [
      541539,
      16470003,
      2268489
    ]
  },
  {
    "index": 2046,
    "source_corpus_id": 199000713,
    "ref_id": "b19",
    "citation_corpus_id": 3626819,
    "start": 2459,
    "end": 2479,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "In contrast to supervised and semi-supervised learning, the learner has access only to unlabeled data.",
    "curr": "Even though the task seems ill-posed as there is no natural objective one should optimize, by leveraging domain knowledge this approach can be successfully applied to a variety of problem areas, including image (Kolesnikov et al., 2019;van den Oord et al., 2018;H\u00e9naff et al., 2019;Tian et al., 2019;Hjelm et al., 2019;Bachman et al., 2019) and video classification (Wang and Gupta, 2015;Sun et al., 2019) and natural language understanding (van den Oord et al., 2018;Peters et al., 2018;Devlin et al., 2019).",
    "next": "Recently, there has been a revival of approaches inspired by the InfoMax principle (Linsker, 1988): We choose a representation g(x) maximizing the mutual information (MI) between the input and its representation, possibly subject to some structural constraints.",
    "hard_negative": [
      6300165,
      41479182,
      8535316,
      11336213,
      990233,
      9917468,
      20472740,
      34032948,
      10489017,
      1957433,
      1222212,
      12688069,
      15026764,
      11816014,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      4953086,
      8657922,
      184482940
    ]
  },
  {
    "index": 2050,
    "source_corpus_id": 259088588,
    "ref_id": "b0",
    "citation_corpus_id": 221818900,
    "start": 3278,
    "end": 3281,
    "title": "DIFFWAVE: A VERSATILE DIFFUSION MODEL FOR AUDIO SYNTHESIS",
    "abstract": "In this work, we propose DiffWave, a versatile Diffusion probabilistic model for conditional and unconditional Waveform generation. The model is nonautoregressive, and converts the white noise signal into structured waveform through a Markov chain with a constant number of steps at synthesis. It is efficiently trained by optimizing a variant of variational bound on the data likelihood. DiffWave produces high-fidelity audios in Different Waveform generation tasks, including neural vocoding conditioned on mel spectrogram, class-conditional generation, and unconditional generation. We demonstrate that DiffWave matches a strong WaveNet vocoder in terms of speech quality (MOS: 4.44 versus 4.43), while synthesizing orders of magnitude faster. In particular, it significantly outperforms autoregressive and GAN-based waveform models in the challenging unconditional generation task in terms of audio quality and sample diversity from various automatic and human evaluations.",
    "prev": "Generating speech from a silent video has seen significant progress in recent years, partly due to advancements made in deep generative models.",
    "curr": "Specifically in applications such as text-to-speech and mel-spectogram-to-audio (neural vocoder) [1,2].",
    "next": "Despite these advancements, many lip-to-speech methods produce satisfying results only when applied to datasets with a limited number of speakers, and constrained vocabularies, like GRID [3] and TCD-TIMIT [4].",
    "hard_negative": [
      6628106,
      67856213,
      52890982
    ],
    "easy_negative": [
      218974314,
      1100249,
      1182860
    ]
  },
  {
    "index": 2065,
    "source_corpus_id": 1741724,
    "ref_id": "b10",
    "citation_corpus_id": 12639289,
    "start": 9644,
    "end": 9673,
    "title": "Recurrent Continuous Translation Models",
    "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
    "prev": ".",
    "curr": ", a T ] given an input sequence x (Cho et al., 2014;Kalchbrenner & Blunsom, 2013;Sutskever et al., 2014).",
    "next": "Here a i \u2208 A where A is a vocabulary of words.",
    "hard_negative": [
      1274371,
      10691183,
      16391184,
      8476273,
      8608051,
      806709
    ],
    "easy_negative": [
      174802532,
      53023047,
      6640765
    ]
  },
  {
    "index": 2067,
    "source_corpus_id": 263909212,
    "ref_id": "b31",
    "citation_corpus_id": 259129237,
    "start": 3448,
    "end": 3466,
    "title": "Published as a conference paper at ICLR 2023 METAGL: EVALUATION-FREE SELECTION OF GRAPH LEARNING MODELS VIA META-LEARNING",
    "abstract": "Given a graph learning task, such as link prediction, on a new graph, how can we select the best method as well as its hyperparameters (collectively called a model) without having to train or evaluate any model on the new graph? Model selection for graph learning has been largely ad hoc. A typical approach has been to apply popular methods to new datasets, but this is often suboptimal. On the other hand, systematically comparing models on the new graph quickly becomes too costly, or even impractical. In this work, we develop the first meta-learning approach for evaluation-free graph learning model selection, called METAGL, which utilizes the prior performances of existing methods on various benchmark graph datasets to automatically select an effective model for the new graph, without any model training or evaluations. To quantify similarities across a wide variety of graphs, we introduce specialized meta-graph features that capture the structural characteristics of a graph. Then we design G-M network, which represents the relations among graphs and models, and develop a graph-based meta-learner operating on this G-M network, which estimates the relevance of each model to different graphs. Extensive experiments show that using METAGL to select a model for the new graph greatly outperforms several existing meta-learning techniques tailored for graph learning model selection (up to 47% better), while being extremely fast at test time (\u223c1 sec).",
    "prev": "As exemplified in Figure 1 (a & b), a simplistic model selector relies on predefined task-specific models for subtasks, increasing the likelihood of intermediate errors and compromising the overall reasoning process.",
    "curr": "Moreover, existing traditional model selection methods, though effective in various domains (Zhao et al., 2021;Park et al., 2022;Lee et al., 2022; Zitovsky Adapting these methods to multi-modal reasoning scenarios, which necessitate multiple models for subtasks, is challenging due to the oversight of subtask dependencies.",
    "next": "To this end, we formally define the problem of model selection in multi-modal reasoning scenarios as our first contribution, and then introduce the M 3 framework (Model Selector for Multi-Modal Reasoning) as our preliminary remedy for the field.",
    "hard_negative": [
      3144218,
      3292002
    ],
    "easy_negative": [
      219306504,
      15171205,
      247656619
    ]
  },
  {
    "index": 2076,
    "source_corpus_id": 3005102,
    "ref_id": "b6",
    "citation_corpus_id": 252796,
    "start": 17284,
    "end": 17305,
    "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
    "abstract": "There is a growing consensus that significant, rapid progress can be made in both text understanding and spoken language understanding by investigating those phenomena that occur most centrally in naturally occurring unconstrained materials and by attempting to automatically extract information about language from very large corpora. Such corpora are beginning to serve as important research tools for investigators in natural language processing, speech recognition, and integrated spoken language systems, as well as in theoretical linguistics. Annotated corpora promise to be valuable for enterprises as diverse as the automatic construction of statistical models for the grammar of the written and the colloquial spoken language, the development of explicit formal theories of the differing grammars of writing and speech, the investigation of prosodic phenomena in speech, and the evaluation and comparison of the adequacy of parsing models.In this paper, we review our experience with constructing one such large annotated corpus--the Penn Treebank, a corpus 1 consisting of over 4.5 million words of American English. During the first three-year phase of the Penn Treebank Project (1989)(1990)(1991)(1992), this corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure. These materials are available to members of the Linguistic Data Consortium; for details, see Section 5.1.The paper is organized as follows. Section 2 discusses the POS tagging task. After outlining the considerations that informed the design of our POS tagset and presenting the tagset itself, we describe our two-stage tagging process, in which text is first assigned POS tags automatically and then corrected by human annotators. Section 3 briefly presents the results of a comparison between entirely manual and semi-automated tagging, with the latter being shown to be superior on three counts: speed, consistency, and accuracy. In Section 4, we turn to the bracketing task. Just as with the tagging task, we have partially automated the bracketing task: the output of",
    "prev": "EXPERIMENTS\n\nIn this section we show that despite its simplicity, the CFN network achieves performance comparable to the much more complex LSTM network on the word level language modeling task.",
    "curr": "We use two datasets for these experiments, namely the Penn Treebank corpus (Marcus et al., 1993) and the Text8 corpus (Mikolov et al., 2014).",
    "next": "We consider both one-layer and two-layer CFNs and LSTMs for our experiments.",
    "hard_negative": [
      696805,
      3166885,
      2369736,
      12951757,
      5153623,
      2769726
    ],
    "easy_negative": [
      220047252,
      254205099,
      53216389
    ]
  },
  {
    "index": 2081,
    "source_corpus_id": 252600018,
    "ref_id": "b9",
    "citation_corpus_id": 211171605,
    "start": 1322,
    "end": 1341,
    "title": "CodeBERT: A Pre-Trained Model for Programming and Natural Languages",
    "abstract": "We present CodeBERT, a bimodal pre-trained model for programming language (PL) and natural language (NL). CodeBERT learns general-purpose representations that support downstream NL-PL applications such as natural language code search, code documentation generation, etc. We develop Code-BERT with Transformer-based neural architecture, and train it with a hybrid objective function that incorporates the pre-training task of replaced token detection, which is to detect plausible alternatives sampled from generators. This enables us to utilize both \"bimodal\" data of NL-PL pairs and \"unimodal\" data, where the former provides input tokens for model training while the latter helps to learn better generators. We evaluate CodeBERT on two NL-PL applications by fine-tuning model parameters. Results show that CodeBERT achieves state-of-the-art performance on both natural language code search and code documentation generation. Furthermore, to investigate what type of knowledge is learned in CodeBERT, we construct a dataset for NL-PL probing, and evaluate in a zero-shot setting where parameters of pre-trained models are fixed. Results show that CodeBERT performs better than previous pre-trained models on NL-PL probing. 1",
    "prev": "We propose subtokenziation that reduces average length by 17% without downstream performance drop, and show that a carefully chosen subtokenization may improve quality by 0.5-2%, possibly with some length increase.",
    "curr": "INTRODUCTION\n\nWith the inspiration from the success of large language model (LM) pretraining in natural language processing (NLP), BERT-like models have been widely adopted for source code processing (Feng et al., 2020;Kanade et al., 2020), as code has a similar discrete sequential structure to natural text.",
    "next": "Being trained on huge source code corpora in a self-supervised manner, large LMs often substantially outperform domain-specific models developed purposely for applied tasks, especially in the tasks with limited parallel / labelled data (Ahmad et al., 2021a).",
    "hard_negative": [
      51926976,
      213152193,
      8820379
    ],
    "easy_negative": [
      6295338,
      241583411,
      67457706
    ]
  },
  {
    "index": 2084,
    "source_corpus_id": 49303347,
    "ref_id": "b8",
    "citation_corpus_id": 5590763,
    "start": 14348,
    "end": 14366,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "For multimodal time series datasets, we choose the Memory Fusion Network (MFN) (Zadeh et al., 2018a) as our multimodal encoder Q(Z y X 1\u2236M ).",
    "curr": "We use Long Short-term Memory (LSTM) networks (Hochreiter & Schmidhuber, 1997) for functions Q(Z a{1\u2236M } X 1\u2236M ), decoder LSTM networks (Cho et al., 2014) for functions F 1\u2236M , and FCNNs for functions G y , G a{1\u2236M } and D. Details are provided in the appendix and the code is available at <anonymous>.",
    "next": "EXPERIMENTS\n\nIn order to show that MFM learns multimodal representations that are discriminative, generative and interpretable, we design the following experiments.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      1250256,
      53083661,
      5925661
    ]
  },
  {
    "index": 2085,
    "source_corpus_id": 256105170,
    "ref_id": "b12",
    "citation_corpus_id": 3292002,
    "start": 3280,
    "end": 3304,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "( 2019), consider encoding the potential interactions between instance pairs, but this requires sufficient degrees of freedom that significantly increases learning difficulty from limited labels (Fatemi et al., 2021) and hinders the scalability to large systems (Wu et al., 2022b).",
    "curr": "Turning to a simpler problem setting where putative instance relations are instantiated as an observed graph, remarkable progress has been made in designing expressive architectures such as graph neural networks (GNNs) (Scarselli et al., 2008;Kipf & Welling, 2017;Velickovic et al., 2018;Wu et al., 2019;Chen et al., 2020a; for harnessing inter-connections between instances as a geometric prior (Bronstein et al., 2017).",
    "next": "However, the observed relations can be incomplete/noisy, due to error-prone data collection, or generated by an artificial construction independent from downstream targets.",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      5840519,
      15007880,
      226262228
    ]
  },
  {
    "index": 2089,
    "source_corpus_id": 263334596,
    "ref_id": "b7",
    "citation_corpus_id": 3144218,
    "start": 3753,
    "end": 3756,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "rs that can subsequently be utilized in different downstream tasks.In particular, MRL now underpins a variety of biochemical applications spanning molecular property prediction to the design of novel drug candidates [1][2][3].",
    "curr": "Traditional approaches often encode chemical compounds with fingerprints, such as extendedconnectivity fingerprints [4,5], which indicate the existence of certain substructures as binary bits in a fixed-length sequence.Such line-based representations are concise and efficient, but have limited expressive power and have difficulty in capturing 3D structural information such as bonding geometries and global shapes, which can be important for analyzing molecular properties and chemical reactivity [6,7].Recently, Graph Neural Networks (GNNs) have become an increasingly popular method of learning molecular representations by treating molecules as graph-structured objects.Existing GNN models for MRL can be broadly classified into two categories: 2D topological models [8][9][10][11] and 3D geometric models [12][13][14][15][16][17].2D GNNs typically model the molecular connectivity as a flat 2D      graph with atoms as nodes and bonds as edges, learning representations of chemical environments by iteratively passing messages between neighboring atoms.Although powerful in the absence of structural information, 2D GNNs may fail to capture key conformational effects or stereochemical properties like chirality [18,19], which is critical for modeling molecular interactions in areas such as drug design or chemical catalysis.Conversely, 3D GNNs are designed to model molecular conformers (conformations), which describe the structure of molecules in 3D space.Thus, these models have found widespread adoption for modeling electronic properties, predicting conformer energies and forces, and scoring interactions between ligands and proteins, amongst other applications.",
    "next": "Q i H I N 1 0 0 s Q M 1 T X i o 4 A L / U U K T d C 7 J 1 I c S j k O P c 0 M s R r K c i w H / x",
    "hard_negative": [
      8393918,
      17682909
    ],
    "easy_negative": [
      232021727,
      4936499,
      248780190
    ]
  },
  {
    "index": 2090,
    "source_corpus_id": 248986239,
    "ref_id": "b0",
    "citation_corpus_id": 222208634,
    "start": 25868,
    "end": 25889,
    "title": "Published as a conference paper at ICLR 2021 LEARNING TO RECOMBINE AND RESAMPLE DATA FOR COMPOSITIONAL GENERALIZATION",
    "abstract": "Flexible neural sequence models outperform grammar-and automaton-based counterparts on a variety of tasks. However, neural models perform poorly in settings requiring compositional generalization beyond the training data-particularly to rare or unseen subsequences. Past work has found symbolic scaffolding (e.g. grammars or automata) essential in these settings. We describe R&R, a learned data augmentation scheme that enables a large category of compositional generalizations without appeal to latent symbolic structure. R&R has two components: recombination of original training examples via a prototype-based generative model and resampling of generated examples to encourage extrapolation. Training an ordinary neural sequence model on a dataset augmented with recombined and resampled examples significantly improves generalization in two language processing problems-instruction following (SCAN) and morphological analysis (SIGMORPHON 2018)-where R&R enables learning of new constructions and tenses from as few as eight initial examples. . Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In",
    "prev": "While approaches with symbolic components are able to achieve 100% accuracy on SCAN (Chen et al., 2020;Liu et al., 2020;Nye et al., 2020;Shaw et al., 2021), they require complicated model training and grammar inference algorithms to search in a large grammar space.",
    "curr": "Another line of work on SCAN designs data augmentation schemes (Andreas, 2020;Aky\u00fcrek et al., 2021;Lake, 2019).",
    "next": "Both Andreas (2020) and Aky\u00fcrek et al.",
    "hard_negative": [
      53045504,
      52006529,
      16911296,
      748227,
      1844940,
      52273813,
      11212020,
      44115640,
      54203451
    ],
    "easy_negative": [
      38208051,
      17698534,
      5381395
    ]
  },
  {
    "index": 2094,
    "source_corpus_id": 232170254,
    "ref_id": "b22",
    "citation_corpus_id": 212874725,
    "start": 9172,
    "end": 9193,
    "title": "Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning",
    "abstract": "Off-policy estimation for long-horizon problems is important in many real-life applications such as healthcare and robotics, where high-fidelity simulators may not be available and on-policy evaluation is expensive or impossible. Recently,[21]proposed an approach that avoids the curse of horizon suffered by typical importance-sampling-based methods. While showing promising results, this approach is limited in practice as it requires data be drawn from the stationary distribution of a known behavior policy. In this work, we propose a novel approach that eliminates such limitations. In particular, we formulate the problem as solving for the fixed point of a certain operator. Using tools from Reproducing Kernel Hilbert Spaces (RKHSs), we develop a new estimator that computes importance ratios of stationary distributions, without knowledge of how the off-policy data are collected. We analyze its asymptotic consistency and finite-sample generalization. Experiments on benchmarks verify the effectiveness of our approach.In this paper, we introduce a novel approach for the off-policy estimation problem that overcome these drawbacks. The main contributions of our work are three-fold:\u2022 We formulate the off-policy estimation problem into one of solving for the fixed point of an operator.Different from the related, and similar, Bellman operator that goes forward in time, this operator is backward in time.\u2022 We develop a new algorithm, which does not have the aforementioned limitations of[21], and analyze its generalization bounds. Specifically, the algorithm does not require that the off-policy data come from the stationary distribution, or that the behavior policy be known.\u2022 We empirically demonstrate the effectiveness of our method on several classic control benchmarks. In particular, we show that, unlike [21], our method is effective even if the off-policy data has not reached the stationary distribution.",
    "prev": "For example,D n can be either collected from a single MDP governed by an unknown, time-varying, non-Markovian behavior policy (in which case (s i , a i ) = (s i+1 , a i+1 )), or be a combination of many short MDP segments (in which case (s i , a i ) may not equal (s i+1 , a i+1 )).",
    "curr": "Note that this significantly relaxes the data assumptions in recent works (Liu et al., 2018a;Mousavi et al., 2020;, which require (s i , a i ) n i=1 to be independent or i.i.d.",
    "next": "Eq (3) is a correctness requirement of the confidence interval.",
    "hard_negative": [
      2863491,
      22163777
    ],
    "easy_negative": [
      36849009,
      2220461,
      3906068
    ]
  },
  {
    "index": 2105,
    "source_corpus_id": 57825721,
    "ref_id": "b11",
    "citation_corpus_id": 2009318,
    "start": 1541,
    "end": 1566,
    "title": "NEURAL GPUS LEARN ALGORITHMS",
    "abstract": "Learning an algorithm from examples is a fundamental problem that has been widely studied. It has been addressed using neural networks too, in particular by Neural Turing Machines (NTMs). These are fully differentiable computers that use backpropagation to learn their own programming. Despite their appeal NTMs have a weakness that is caused by their sequential nature: they are not parallel and are are hard to train due to their large depth when unfolded. We present a neural network architecture to address this problem: the Neural GPU. It is based on a type of convolutional gated recurrent unit and, like the NTM, is computationally universal. Unlike the NTM, the Neural GPU is highly parallel which makes it easier to train and efficient to run. An essential property of algorithms is their ability to handle inputs of arbitrary size. We show that the Neural GPU can be trained on short instances of an algorithmic task and successfully generalize to long instances. We verified it on a number of tasks including long addition and long multiplication of numbers represented in binary. We train the Neural GPU on numbers with up-to 20 bits and observe no errors whatsoever while testing it, even on much longer numbers. To achieve these results we introduce a technique for training deep recurrent networks: parameter sharing relaxation. We also found a small amount of dropout and gradient noise to have a large positive effect on learning and generalization.",
    "prev": "Our study also reveals some minimal sets of elements needed to obtain these completeness results.",
    "curr": "INTRODUCTION\n\nThere is an increasing interest in designing neural network architectures capable of learning algorithms from examples (Graves et al., 2014;Grefenstette et al., 2015;Joulin & Mikolov, 2015;Kaiser & Sutskever, 2016;Kurach et al., 2016;Dehghani et al., 2018).",
    "next": "A key requirement for any such an architecture is thus to have the capacity of implementing arbitrary algorithms, that is, to be Turing complete.",
    "hard_negative": [
      7823468,
      12639289
    ],
    "easy_negative": [
      11608317,
      3512605,
      14656464
    ]
  },
  {
    "index": 2109,
    "source_corpus_id": 264128047,
    "ref_id": "b46",
    "citation_corpus_id": 247595263,
    "start": 2745,
    "end": 2764,
    "title": "SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS",
    "abstract": "Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and ARC-challenge (+3.9%).",
    "prev": "by asking for the most probable answer to a question) or discriminatively (e.g.",
    "curr": "by presenting a (question, answer) pair and asking whether the answer is acceptable) and, these two procedures do not always produce consistent results: generative procedures may fail when probability mass is spread across multiple contradicting answers (Wang et al., 2022;Mitchell et al., 2022), while discriminative procedures may fail due to miscalibration (Han et al., 2022;Chen et al., 2022) or subtle dependence on question wording (Jiang et al., 2020).Given these noisy and often-conflicting signals, how should we distill out an LM's best guess at the truth?This paper presents an approach for reconciling generative and discriminative LM decoding procedures by formulating decoding as a signaling game (Lewis, 2008) that we call the CONSENSUS GAME.At a high level, this game features a GENERATOR agent that must communicate an abstract correct or incorrect value to a DISCRIMINATOR agent, but may only do so using a set of candidate natural language strings (Fig.",
    "next": "1).Intuitively, an effective strategy for this game (i.e.",
    "hard_negative": [
      235368289,
      53296520,
      211066379,
      248377325,
      560565,
      165163607,
      203905467,
      247447167
    ],
    "easy_negative": [
      2879445,
      245425026,
      218974534
    ]
  },
  {
    "index": 2112,
    "source_corpus_id": 235417126,
    "ref_id": "b5",
    "citation_corpus_id": 222130583,
    "start": 2803,
    "end": 2822,
    "title": "ADAPTIVE UNIVERSAL GENERALIZED PAGERANK GRAPH NEURAL NETWORK",
    "abstract": "In many important graph data processing applications the acquired information includes both node features and observations of the graph topology. Graph neural networks (GNNs) are designed to exploit both sources of evidence but they do not optimally trade-off their utility and integrate them in a manner that is also universal. Here, universality refers to independence on homophily or heterophily graph assumptions. We address these issues by introducing a new Generalized PageRank (GPR) GNN architecture that adaptively learns the GPR weights so as to jointly optimize node feature and topological information extraction, regardless of the extent to which the node labels are homophilic or heterophilic. Learned GPR weights automatically adjust to the node label pattern, irrelevant on the type of initialization, and thereby guarantee excellent learning performance for label patterns that are usually hard to handle. Furthermore, they allow one to avoid feature over-smoothing, a process which renders feature information nondiscriminative, without requiring the network to be shallow. Our accompanying theoretical analysis of the GPR-GNN method is facilitated by novel synthetic benchmark datasets generated by the so-called contextual stochastic block model. We also compare the performance of our GNN architecture with that of several state-ofthe-art GNNs on the problem of node-classification, using well-known benchmark homophilic and heterophilic datasets. The results demonstrate that GPR-GNN offers significant performance improvement compared to existing techniques on both synthetic and benchmark data. Our implementation is available online.",
    "prev": "The node representations can then be utilized for downstream node classification or regression tasks.",
    "curr": "Due to this neighborhood aggregation mechanism, several existing works posit that many GNNs implicitly assume strong homophily and homophily is critical for GNNs to achieve strong performance on SSNC (Zhu et al., 2020b;a;Chien et al., 2021;Maurya et al., 2021;Halcrow et al., 2020;Lim et al., 2021).",
    "next": "In general, homophily describes the phenomenon that nodes tend to connect with \"similar\" or \"alike\" others.",
    "hard_negative": [
      3144218,
      3292002,
      210843644
    ],
    "easy_negative": [
      16382303,
      81979508,
      246062387
    ]
  },
  {
    "index": 2115,
    "source_corpus_id": 236154781,
    "ref_id": "b52",
    "citation_corpus_id": 17127188,
    "start": 29887,
    "end": 29906,
    "title": "MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS",
    "abstract": "State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction problems such as semantic segmentation are structurally different from image classification. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multiscale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy.",
    "prev": "All models are trained for 300 epochs on 8 Tesla V100 GPUs with a total batch size of 1024.",
    "curr": "E1 = 4 L1 = 2 E1 = 4 L1 = 2 E1 = 8 L1 = 3 E1 = 8 L1 = 3 E1 = 4 L1 = 3 E1 = 4 L1 = 2 E1 = 4 L1 = 2 E1 = 4 L1 = 2 Stage 2 H 8 \u00d7 W 8 Overlapping Patch Embedding S2 = 2 S2 = 2 C2 = 128 C2 = 192 C2 = 192 C2 = 256 CycleMLP Block E2 = 4 L2 = 2 E2 = 4 L2 = 3 E2 = 8 L2 = 4 E2 = 8 L2 = 8 E2 = 4 L2 = 4 E1 = 4 L1 = 2 E1 = 4 L1 = 2 E1 = 4 L1 = 2\nStage 3 \n\n\nF SAMPLING STRATEGIES\n\nWe explore more sampling strategies in this subsection, including random sampling and dilated sampling inspired by dilated convolution (Yu & Koltun, 2016;Chen et al., 2018) (as shown in Figure 6).",
    "next": "We also compare the dense sampling method with ours.",
    "hard_negative": [
      14124313,
      1996665
    ],
    "easy_negative": [
      13696025,
      238856856,
      259370819
    ]
  },
  {
    "index": 2126,
    "source_corpus_id": 244954755,
    "ref_id": "b55",
    "citation_corpus_id": 204788663,
    "start": 2249,
    "end": 2271,
    "title": "VARIBAD: A VERY GOOD METHOD FOR BAYES-ADAPTIVE DEEP RL VIA META-LEARNING",
    "abstract": "Trading off exploration and exploitation in an unknown environment is key to maximising expected return during learning. A Bayes-optimal policy, which does so optimally, conditions its actions not only on the environment state but on the agent's uncertainty about the environment. Computing a Bayes-optimal policy is however intractable for all but the smallest tasks. In this paper, we introduce variational Bayes-Adaptive Deep RL (variBAD), a way to meta-learn to perform approximate inference in an unknown environment, and incorporate task uncertainty directly during action selection. In a grid-world domain, we illustrate how variBAD performs structured online exploration as a function of task uncertainty. We further evaluate variBAD on MuJoCo domains widely used in meta-RL and show that it achieves higher online return than existing methods. * . Robust and efficient transfer learning with hidden parameter markov decision processes. In Advances in neural information processing systems, 2017.",
    "prev": "Introduction\n\nMeta-reinforcement learning algorithms aim to address the sample complexity challenge of conventional reinforcement learning (RL) methods by learning to learn -utilizing the experience of solving prior tasks in order to solve new tasks more quickly.",
    "curr": "Such methods can be exceptionally powerful, learning to solve tasks that are structurally similar to the meta-training tasks with just a few dozen trials (Finn et al., 2017;Duan et al., 2016;Wang et al., 2016;Zintgraf et al., 2020).",
    "next": "However, prior work on meta-reinforcement learning is generally concerned with asymptotic meta-learning performance, or how well the meta-trained policy can adapt to a single new task at the end of a long meta-training period.",
    "hard_negative": [
      13748235,
      53015479,
      3707461
    ],
    "easy_negative": [
      15389304,
      9348004,
      195064954
    ]
  },
  {
    "index": 2131,
    "source_corpus_id": 259936996,
    "ref_id": "b34",
    "citation_corpus_id": 5034059,
    "start": 2168,
    "end": 2172,
    "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    "abstract": "For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusively tailored to a specific task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating and analyzing the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and find that multi-task training on all our tasks yields better results than training a separate model for each task. However, the low absolute performance of our best model indicates the need for improved general NLU systems. son. 2013. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint 1312.3005.",
    "prev": "Under review.",
    "curr": "Introduction\n\nLarge language models (LLMs) have proven to be extremely capable of generating coherent and fluent text when provided with high-level prompts, performing excellently on popular benchmarks [35] and finding use in production systems such as GPT-4 [28].",
    "next": "Such capabilities have raised the bar for automated text generation, and allow us to explore more nuanced ways of utilizing LMs to produce text.",
    "hard_negative": [
      5074049,
      388,
      2937095,
      2213896,
      25422730,
      4537113,
      990233,
      16661147,
      3432876,
      1957433,
      3626819,
      11816014,
      1994584,
      2135897,
      3264224,
      4421747,
      16639476,
      4567927
    ],
    "easy_negative": [
      941678,
      44066484,
      32545704
    ]
  },
  {
    "index": 2133,
    "source_corpus_id": 252762561,
    "ref_id": "b3",
    "citation_corpus_id": 53115163,
    "start": 12019,
    "end": 12038,
    "title": "EXPLORATION BY RANDOM NETWORK DISTILLATION",
    "abstract": "We introduce an exploration bonus for deep reinforcement learning methods that is easy to implement and adds minimal overhead to the computation performed. The bonus is the error of a neural network predicting features of the observations given by a fixed randomly initialized neural network. We also introduce a method to flexibly combine intrinsic and extrinsic rewards. We find that the random network distillation (RND) bonus combined with this increased flexibility enables significant progress on several hard exploration Atari games. In particular we establish state of the art performance on Montezuma's Revenge, a game famously difficult for deep reinforcement learning methods. To the best of our knowledge, this is the first method that achieves better than average human performance on this game without using demonstrations or having access to the underlying state of the game, and occasionally completes the first level.",
    "prev": "Intrinsic motivation.",
    "curr": "There has been a line of research to incorporate intrinsic motivation (Burda et al., 2018, Pathak et al., 2017, Zhang et al., 2021 for improving exploration in RL.",
    "next": "Yet, such ideas have not been explored with GFlowNets because the current mathematical framework of GFlowNets only allows for terminal rewards, unlike the standard RL frameworks.",
    "hard_negative": [
      12256925,
      3461154
    ],
    "easy_negative": [
      8825906,
      253098237,
      2363663
    ]
  },
  {
    "index": 2134,
    "source_corpus_id": 257632050,
    "ref_id": "b10",
    "citation_corpus_id": 52979229,
    "start": 2547,
    "end": 2551,
    "title": "Dynamic Channel Pruning: Feature Boosting and Suppression",
    "abstract": "Making deep convolutional neural networks more accurate typically comes at the cost of increased computational and memory resources. In this paper, we exploit the fact that the importance of features computed by convolutional layers is highly input-dependent, and propose feature boosting and suppression (FBS), a new method to predictively amplify salient convolutional channels and skip unimportant ones at run-time. FBS introduces small auxiliary connections to existing convolutional layers. In contrast to channel pruning methods which permanently remove channels, it preserves the full network structures and accelerates convolution by dynamically skipping unimportant input and output channels. FBS-augmented networks are trained with conventional stochastic gradient descent, making it readily available for many state-of-the-art CNNs. We compare FBS to a range of existing channel pruning and dynamic execution schemes and demonstrate large improvements on ImageNet classification. Experiments show that FBS can accelerate VGG-16 by 5\u00d7 and improve the speed of ResNet-18 by 2\u00d7, both with less than 0.6% top-5 accuracy loss. * These authors contributed equally.",
    "prev": "This makes it possible to exit at a certain layer to reach a final verdict on classification, if the corresponding classifier is confident enough of its decision.",
    "curr": "Several other sub-techniques of conditional computation exist and have been well-studied, including layer skipping [14], channel skipping in convolutional neural networks [11], or reinforcement learning methods for input-dependent dropout policies [4].",
    "next": "Although there are many diverse methods [15], the general intuitions as to why conditional computation can improve the performance of neural networks remain the same: First, the computation units are chosen in an adaptive manner to process the features that are particular to the given input pattern.",
    "hard_negative": [
      94224,
      14124313,
      3635880
    ],
    "easy_negative": [
      5574231,
      253447464,
      15968908
    ]
  },
  {
    "index": 2137,
    "source_corpus_id": 259076022,
    "ref_id": "b16",
    "citation_corpus_id": 235794968,
    "start": 1852,
    "end": 1870,
    "title": "Direct Speech-to-Speech Translation With Discrete Units",
    "abstract": "We present a direct speech-to-speech translation (S2ST) model that translates speech from one language to speech in another language without relying on intermediate text generation. We tackle the problem by first applying a self-supervised discrete speech encoder on the target speech and then training a sequenceto-sequence speech-to-unit translation (S2UT) model to predict the discrete representations of the target speech. When target text transcripts are available, we design a joint speech and text training framework that enables the model to generate dual modality output (speech and text) simultaneously in the same inference pass. Experiments on the Fisher Spanish-English dataset show that the proposed framework yields improvement of 6.7 BLEU compared with a baseline direct S2ST model that predicts spectrogram features. When trained without any text transcripts, our model performance is comparable to models that predict spectrograms and are trained with text supervision, showing the potential of our system for translation between unwritten languages 1 .",
    "prev": "Different from conventional cascade approach (Lavie et al., 1997;Baldridge, 2004;Nakamura et al., 2006), the direct approach (Jia et al., 2019(Jia et al., , 2022a has the advantages of low latency and simplified pipeline.",
    "curr": "Existing direct S2ST approaches can be further classified according to whether the model predicts continuous mel-spectrogram features (Dong et al., 2022) or discrete units (Lee et al., 2022).",
    "next": "Unit-based approach has become more popular due to several reasons: (1) It allows researchers to take advantage of existing NLP modeling techniques by treating acoustic unit as a new language.",
    "hard_negative": [
      91184134,
      227840539,
      222291132,
      13751870,
      13753208
    ],
    "easy_negative": [
      51878477,
      237513633,
      256827099
    ]
  },
  {
    "index": 2140,
    "source_corpus_id": 259096014,
    "ref_id": "b11",
    "citation_corpus_id": 236912915,
    "start": 10917,
    "end": 10933,
    "title": "Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification",
    "abstract": "Tuning pre-trained language models (PLMs) with task-specific prompts has been a promising approach for text classification. Particularly, previous studies suggest that prompttuning has remarkable superiority in the lowdata scenario over the generic fine-tuning methods with extra classifiers. The core idea of prompt-tuning is to insert text pieces, i.e., template, to the input and transform a classification problem into a masked language modeling problem, where a crucial step is to construct a projection, i.e., verbalizer, between a label space and a label word space. A verbalizer is usually handcrafted or searched by gradient descent, which may lack coverage and bring considerable bias and high variances to the results. In this work, we focus on incorporating external knowledge into the verbalizer, forming a knowledgeable prompt-tuning (KPT), to improve and stabilize prompt-tuning. Specifically, we expand the label word space of the verbalizer using external knowledge bases (KBs) and refine the expanded label word space with the PLM itself before predicting with the expanded label word space. Extensive experiments on zero and few-shot text classification tasks demonstrate the effectiveness of knowledgeable prompt-tuning. Our source code is publicly available at https://github.com/ thunlp/KnowledgeablePromptTuning.",
    "prev": "In this paper, we make the first attempt to explore the different domain representations of the adapters with high-rank and low-rank embedding spaces.",
    "curr": "PARAMETER-EFFICIENT FINE-TUNING\n\nRecently, Parameter-Efficient Fine-Tuning (PEFT) has gained significant traction within the field of natural language processing (NLP) (Hu et al., 2021;Houlsby et al., 2019;Zaken et al., 2021;Hu et al., 2022;Gao et al., 2021;He et al., 2021;Vu et al., 2022;Qin et al., 2021).",
    "next": "Adapter-based models, a form of PEFT, have gained popularity in NLP.",
    "hard_negative": [
      210838924,
      222339089,
      1499545,
      202888986,
      202539551,
      202540839,
      233296182,
      3626819,
      11816014,
      1428702,
      52967399,
      230437613,
      202541043,
      229923710
    ],
    "easy_negative": [
      220060895,
      1791896,
      207852710
    ]
  },
  {
    "index": 2141,
    "source_corpus_id": 214390104,
    "ref_id": "b10",
    "citation_corpus_id": 11202498,
    "start": 6287,
    "end": 6304,
    "title": "Knowledge Graph Embedding via Dynamic Mapping Matrix",
    "abstract": "Knowledge graphs are useful resources for numerous AI applications, but they are far from completeness. Previous work such as TransE, TransH and TransR/CTransR regard a relation as translation from head entity to tail entity and the CTransR achieves state-of-the-art performance. In this paper, we propose a more fine-grained model named TransD, which is an improvement of TransR/CTransR. In TransD, we use two vectors to represent a named symbol object (entity and relation). The first one represents the meaning of a(n) entity (relation), the other one is used to construct mapping matrix dynamically. Compared with TransR/CTransR, TransD not only considers the diversity of relations, but also entities. TransD has less parameters and has no matrix-vector multiplication operations, which makes it can be applied on large scale graphs. In Experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Evaluation results show that our approach outperforms stateof-the-art methods.",
    "prev": "For example, TransE (Bordes et al., 2013) models the score as a distance of the translated subject to an object representation.",
    "curr": "This method has lead to many variations (Ji et al., 2015;Nguyen et al., 2016;Wang et al., 2014), but is limited in the relation systems it can model (Kazemi & Poole, 2018) and does not lead to state of the art performances on current benchmarks.",
    "next": "Finally Schlichtkrull et al.",
    "hard_negative": [
      1671874,
      806709
    ],
    "easy_negative": [
      15350907,
      12315936,
      219303520
    ]
  },
  {
    "index": 2145,
    "source_corpus_id": 258999763,
    "ref_id": "b35",
    "citation_corpus_id": 201646309,
    "start": 20021,
    "end": 20025,
    "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    "abstract": "BERT(Devlin et al., 2018)and RoBERTa (Liu  et al., 2019)  has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT.We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods. 1",
    "prev": "the concept distribution.We report the FID [19] score with respect to the concept images for each concept separately (FID per concept) and for all concepts as a dataset (FID entire set).",
    "curr": "(iii) We employ SentenceBERT [36] to measure the element diversity by estimating the dissimilarity of the tokens in the decomposition (Token diversity).This metric further substantiates the meaningfulness by showing that the decomposition is diverse.",
    "next": "Results\n\nThe results, averaged across all 188 concepts, are reported in Tab.",
    "hard_negative": [
      388,
      2937095,
      28971531,
      5033484,
      10241043,
      990233,
      195345563,
      3432876,
      12549805,
      1957433,
      11650107,
      646594,
      18283203,
      3264224,
      5394019,
      4421747,
      10181753
    ],
    "easy_negative": [
      17191078,
      239998631,
      236179533
    ]
  },
  {
    "index": 2146,
    "source_corpus_id": 234487049,
    "ref_id": "b6",
    "citation_corpus_id": 7164502,
    "start": 21912,
    "end": 21936,
    "title": "METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments",
    "abstract": "We describe METEOR, an automatic metric for machine translation evaluation that is based on a generalized concept of unigram matching between the machineproduced translation and human-produced reference translations. Unigrams can be matched based on their surface forms, stemmed forms, and meanings; furthermore, METEOR can be easily extended to include more advanced matching strategies.Once all generalized unigram matches between the two strings have been found, METEOR computes a score for this matching using a combination of unigram-precision, unigram-recall, and a measure of fragmentation that is designed to directly capture how well-ordered the matched words in the machine translation are in relation to the reference. We evaluate METEOR by measuring the correlation between the metric scores and human judgments of translation quality. We compute the Pearson R correlation value between its scores and human quality assessments of the LDC TIDES 2003 Arabic-to-English and Chinese-to-English datasets.We perform segment-bysegment correlation, and show that METEOR gets an R correlation value of 0.347 on the Arabic data and 0.331 on the Chinese data. This is shown to be an improvement on using simply unigramprecision, unigram-recall and their harmonic F1 combination. We also perform experiments to show the relative contributions of the various mapping modules.",
    "prev": "For the retrieval augmentation, we use the training set as the retrieval database, i.e., D = D (see Step 1 in Section 2.2.2).",
    "curr": "For more details about data processing, please refer to Appendix D. Similar to previous works (Zhang et al., 2020;Wan et al., 2018;Fernandes et al., 2018;Iyer et al., 2016), BLEU (Papineni et al., 2002), METEOR (Banerjee & Lavie, 2005) and ROUGE-L (Lin, 2004) are used as our automatic evaluation metrics.",
    "next": "These metrics are popular for evaluating machine translation and text summarization tasks.",
    "hard_negative": [
      9469794,
      11728052,
      1745463
    ],
    "easy_negative": [
      232021785,
      214503011,
      13873204
    ]
  },
  {
    "index": 2161,
    "source_corpus_id": 246996576,
    "ref_id": "b6",
    "citation_corpus_id": 3144218,
    "start": 2328,
    "end": 2350,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "embedding) aims to preserve the high-dimensional complex graph information involving node features and link structures in a low-dimensional embedding space, which requires effective feature selection and dimension reduction (Hamilton et al., 2017b).",
    "curr": "Graph neural networks (GNNs) have done great jobs to this end, but most of them rely on node labels from specific downstream tasks to be trained in a semi-supervised fashion (Kipf & Welling, 2017;Hamilton et al., 2017a;Wu et al., 2019;Veli\u010dkovi\u0107 et al., 2018a;Klicpera et al., 2019;Chien et al., 2021).",
    "next": "However, similar to other domains, unsupervised representation learning is preferred in many cases, not only because labeled data is not always available (Hu et al., 2020;Xie et al., 2021), but also task-agnostic representations can better transfer and generalize among different scenarios (Erhan et al., 2010;Bengio, 2012;Radford et al., 2016).",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      233296043,
      7379462,
      52121142
    ]
  },
  {
    "index": 2163,
    "source_corpus_id": 252693405,
    "ref_id": "b6",
    "citation_corpus_id": 247939224,
    "start": 8490,
    "end": 8509,
    "title": "Why Exposure Bias Matters: An Imitation Learning Perspective of Error Accumulation in Language Generation",
    "abstract": "Current language generation models suffer from issues such as repetition, incoherence, and hallucinations. An often-repeated hypothesis is that this brittleness of generation models is caused by the training and the generation procedure mismatch, also referred to as exposure bias. In this paper, we verify this hypothesis by analyzing exposure bias from an imitation learning perspective. We show that exposure bias leads to an accumulation of errors, analyze why perplexity fails to capture this accumulation, and empirically show that this accumulation results in poor generation quality.",
    "prev": "Algorithms such as Schedule Sampling (SS) (Bengio et al., 2015), Parallel SS (Duckworth et al., 2019), SS for Transformers (Mihaylova & Martins, 2019), Diffential SS (Goyal et al., 2017), LOLS (Lampouras & Vlachos, 2016;Chang et al., 2015), TextGAIL (Wu et al., 2021b), and SEARNN (Leblond et al., 2017), have been inspired by DAGGER (Ross et al., 2011) and SEARN (Daum\u00e9 et al., 2009).",
    "curr": "However, these algorithms are known to suffer from exposure bias in generation (Chiang & Chen, 2021;Arora et al., 2022) and the cliff MDP problem (Husz\u00e1r, 2015;Agarwal et al., 2019;Swamy et al., 2021).",
    "next": "RL for Large Action Spaces.",
    "hard_negative": [
      3913537,
      203610243,
      201660357,
      1880070,
      34984289,
      14096841,
      207869708,
      44134226,
      7287895,
      199577786,
      212945787
    ],
    "easy_negative": [
      44708701,
      256662499,
      250920542
    ]
  },
  {
    "index": 2177,
    "source_corpus_id": 257279878,
    "ref_id": "b16",
    "citation_corpus_id": 204788776,
    "start": 9215,
    "end": 9233,
    "title": "A MUTUAL INFORMATION MAXIMIZATION PERSPEC- TIVE OF LANGUAGE REPRESENTATION LEARNING",
    "abstract": "We show state-of-the-art word representation learning methods maximize an objective function that is a lower bound on the mutual information between different parts of a word sequence (i.e., a sentence). Our formulation provides an alternative perspective that unifies classical word embedding models (e.g., Skip-gram) and modern contextual embeddings (e.g., BERT, XLNet). In addition to enhancing our theoretical understanding of these methods, our derivation leads to a principled framework that can be used to construct new self-supervised tasks. We provide an example by drawing inspirations from related methods based on mutual information maximization that have been successful in computer vision, and introduce a simple self-supervised objective that maximizes the mutual information between a global sentence representation and n-grams in the sentence. Our analysis offers a holistic view of representation learning methods to transfer knowledge and translate progress across multiple domains (e.g., natural language processing, computer vision, audio processing).",
    "prev": "(2)\nHere sim(\u00b7, \u00b7) is the cosine similarity between two vectors, and \u03c4 is a temperature hyperparameter.",
    "curr": "Surged from InfoNCE (Oord et al., 2018), contrastive learning undergoes a rapid growth (Tian et al., 2019;Chen et al., 2020a;He et al., 2020;Wang et al., 2021) and has demonstrated state-of-theart performance on self-supervised tasks (Chen et al., 2020b;Kong et al., 2020).",
    "next": "Nevertheless, several works also point out contrastive learning is still vulnerable to adversarial attack when we transfer the learned features to the downstream classification (Ho & Nvasconcelos, 2020;Kim et al., 2020).",
    "hard_negative": [
      6628106,
      3525802,
      1957433,
      3626819,
      5034059,
      11816014,
      52055130,
      40100965,
      52967399,
      47018994
    ],
    "easy_negative": [
      2086563,
      233365288,
      11628220
    ]
  },
  {
    "index": 2178,
    "source_corpus_id": 219636414,
    "ref_id": "b0",
    "citation_corpus_id": 780171,
    "start": 2013,
    "end": 2016,
    "title": "Data-Driven Response Generation in Social Media",
    "abstract": "We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.",
    "prev": "Introduction\n\nDesigning a task-oriented dialogue system is a popular and challenging research topic in the recent decades.",
    "curr": "In contrast to open-domain dialogue systems [1], it aims to help people complete real-life tasks through dialogues without human service (e.g., booking tickets) [2].",
    "next": "In a task-oriented dialogue task, each dialogue is defined with a goal which includes user requests (i.e., represented as a set of key words known as slot values).",
    "hard_negative": [
      14386564,
      12305296,
      1060508,
      59940,
      1963942,
      10534951,
      12131372,
      2713391,
      5219389,
      17309374,
      9482302,
      13043395,
      6990165,
      11169623,
      1922162,
      10181753,
      7785983
    ],
    "easy_negative": [
      390045,
      212806126,
      261494545
    ]
  },
  {
    "index": 2179,
    "source_corpus_id": 15280949,
    "ref_id": "b8",
    "citation_corpus_id": 2937095,
    "start": 2467,
    "end": 2486,
    "title": "Learning Distributed Representations of Sentences from Unlabelled Data",
    "abstract": "Unsupervised methods for learning distributed representations of words are ubiquitous in today's NLP research, but far less is known about the best ways to learn distributed phrase or sentence representations from unlabelled data. This paper is a systematic comparison of models that learn such representations. We find that the optimal approach depends critically on the intended application. Deeper, more complex models are preferable for representations to be used in supervised systems, but shallow log-bilinear models work best for building representation spaces that can be decoded with simple spatial distance metrics. We also propose two new unsupervised representation-learning objectives designed to optimise the trade-off between training time, domain portability and performance.",
    "prev": "Those methods generally fall into two categories.",
    "curr": "The first consists of universal sentence embeddings usually trained by unsupervised learning (Hill et al., 2016).",
    "next": "This includes SkipThought vectors , ParagraphVector (Le & Mikolov, 2014), recursive auto-encoders (Socher et al., 2011;2013), Sequential Denoising Autoencoders (SDAE), FastSent (Hill et al., 2016), etc.",
    "hard_negative": [
      388,
      216848261,
      10028211,
      14745914,
      14169402,
      11650107,
      9079100,
      18597583,
      3509328,
      1306065,
      85205,
      3264224,
      5590763,
      10181753
    ],
    "easy_negative": [
      7103969,
      247292399,
      258463987
    ]
  },
  {
    "index": 2184,
    "source_corpus_id": 263671662,
    "ref_id": "b55",
    "citation_corpus_id": 227209335,
    "start": 3571,
    "end": 3574,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "Nowadays, generative models like (Wasserstein) GANs [10,24] and VAEs [36] have turned out to be a suitable tool for approximating probability distributions.In this context, the field of gradient flows in measure spaces received increasing attention.",
    "curr": "[67] proposed to apply the Langevin dynamics in order to generate samples from a known potential, which corresponds to simulating a Wasserstein gradient flow with respect to the Kullback-Leibler (KL) divergence, see [33].Scorebased and diffusion models extend this approach by estimating the gradients of the potential from training data, see [19,31,55,56] and achieved state-of-the-art results.The simulation of Wasserstein gradient flows with other functionals than KL, based on the JKO scheme, was considered in [4,5,22,48].",
    "next": "In this paper, we focus on gradient flows with respect to MMD with negative distance kernel K(x, y) = \u2212\u2225x \u2212 y\u2225, which is also known as energy distance, see [54,61,63,64].While MMDs have shown great success at comparing two distributions in general, see [25,26,62], their combination with the negative distance kernel results in many additional desirable properties as translation and scale equivariance [64], efficient computation [30], and a good sample complexity [26].",
    "hard_negative": [
      52908831,
      52889459
    ],
    "easy_negative": [
      248780115,
      218974101,
      16516994
    ]
  },
  {
    "index": 2192,
    "source_corpus_id": 248006483,
    "ref_id": "b92",
    "citation_corpus_id": 226964491,
    "start": 6933,
    "end": 6952,
    "title": "PRE-TRAINING TEXT-TO-TEXT TRANSFORMERS FOR CONCEPT-CENTRIC COMMON SENSE",
    "abstract": "Pre-trained language models (PTLM) have achieved impressive results in a range of natural language understanding (NLU) and generation (NLG) tasks. However, current pre-training objectives such as masked token prediction (for BERT-style PTLMs) and masked span infilling (for T5-style PTLMs) do not explicitly model the relational commonsense knowledge about everyday concepts, which is crucial to many downstream tasks that need common sense to understand or generate. To augment PTLMs with concept-centric commonsense knowledge, in this paper, we propose both generative and contrastive objectives for learning common sense from the text, and use them as intermediate self-supervised learning tasks for incrementally pre-training PTLMs (before task-specific fine-tuning on downstream datasets). Furthermore, we develop a joint pre-training framework to unify generative and contrastive objectives so that they can mutually reinforce each other. Extensive experimental results show that our method, concept-aware language model (CALM) 1 , can pack more commonsense knowledge into the parameters of a pre-trained text-to-text transformer without relying on external knowledge graphs, yielding better performance on both NLU and NLG tasks. We show that while only incrementally pre-trained on a relatively small corpus for a few steps, CALM outperforms baseline methods by a consistent margin and even comparable with some larger PTLMs, which suggests that CALM can serve as a general, \"plug-and-play\" method for improving the commonsense reasoning ability of a PTLM. * Equal contribution. The work was done when Wangchunshu was visiting USC. 1 Our code and data will be made public at: https://github.com/INK-USC/CALM arXiv:2011.07956v1 [cs.CL] 24 Oct 2020 Preprint. Work in progress.knowledge, prior works mainly focus on training larger models(Brown et al., 2020), adding specific architectures to exploit external knowledge(Peters et al., 2019), or incorporating knowledge bases for pre-training . In this paper, we instead look to explicitly teach pre-trained models to write and reason with common concepts through novel pre-training strategies. We present two kinds of self-supervised pre-training tasks: concept-to-sentence generation (C2S) and concept order recovering (COR). C2S trains the pre-trained model to compose (\"write\") sentences given a set of concepts, and expects the generated sentences to be fluent and plausible in terms of commonsense. COR aims to teach models to detect and revise a corrupted sentence with incorrect ordering of concepts. As illustrated inFigure 1, both tasks require a pre-trained model to recall relevant commonsense facts about the concepts and to understand the underlying commonsense relations between them. Both of the proposed objectives can explicitly encourage the model to capture the relational concept-centric commonsense knowledge and perform compositional reasoning.",
    "prev": "(Kassner & Sch\u00fctze, 2020), and being unable to compare commonsense concepts, such as time (Qin et al., 2021) and digits (Talmor et al., 2020).",
    "curr": "To enhance the performance of LMs on knowledge-intensive NLG tasks 1 , prior studies have proposed to re-train LMs with knowledge-aware objectives (Zhou et al., 2021;Xiong et al., 2020;Khandelwal et al., 2020) or add special architectures to encode knowledge (Bosselut et al., 2019;Logan et al., 2019;Peters et al., 2019b) from external resources (e.g., knowledge graphs such as CONCEPTNET (Speer et al., 2017) and ATOMIC ).",
    "next": "These methods, though yielding impressive results on many downstream tasks, can be computationally expensive.",
    "hard_negative": [
      4711425,
      2924682,
      7164502,
      1957433,
      6216506
    ],
    "easy_negative": [
      5815524,
      8704366,
      34997657
    ]
  },
  {
    "index": 2193,
    "source_corpus_id": 252692968,
    "ref_id": "b5",
    "citation_corpus_id": 26501419,
    "start": 1790,
    "end": 1810,
    "title": "TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    "abstract": "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K questionanswer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a featurebased classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23% and 40% vs. 80%), suggesting that Trivi-aQA is a challenging testbed that is worth significant future study. 1",
    "prev": "INTRODUCTION\n\nLarge language models (LLMs) have achieved impressive in-context few-shot performance on knowledge-intensive NLP tasks (Brown et al., 2020;Rae et al., 2021;Hoffmann et al., 2022;Chowdhery et al., 2022).",
    "curr": "For example, in open-domain question answering (Chen et al., 2017), demonstrated by only a few examples of question-answer pairs, LLMs are able to answer arbitrary factoid questions (Joshi et al., 2017;Yang et al., 2018;Kwiatkowski et al., 2019).",
    "next": "Recent research (Guu et al., 2020;Lewis et al., 2020;Izacard et al., 2022) shows that retrieval-augmentation can further improve LLMs' performance on knowledge-intensive tasks by conditioning the LLMs on retrieved relevant passages from an external corpus.",
    "hard_negative": [
      6360322,
      6401679,
      8535316,
      215514151,
      8764466,
      16483125,
      9526475,
      11816014,
      1373518,
      2381275,
      2100831,
      9027681,
      216034672,
      5761781,
      6857205
    ],
    "easy_negative": [
      257219903,
      2684375,
      10772041
    ]
  },
  {
    "index": 2195,
    "source_corpus_id": 252762275,
    "ref_id": "b6",
    "citation_corpus_id": 560565,
    "start": 3205,
    "end": 3225,
    "title": "Solving General Arithmetic Word Problems",
    "abstract": "This paper presents a novel approach to automatically solving arithmetic word problems. This is the first algorithmic approach that can handle arithmetic problems with multiple steps and operations, without depending on additional annotations or predefined templates. We develop a theory for expression trees that can be used to represent and evaluate the target arithmetic expressions; we use it to uniquely decompose the target arithmetic problem to multiple classification problems; we then compose an expression tree, combining these with world knowledge through a constrained inference framework. Our classifiers gain from the use of quantity schemas that supports better extraction of features. Experimental results show that our method outperforms existing systems, achieving state of the art performance on benchmark datasets of arithmetic word problems.",
    "prev": "Specifically, the hand-drafting involves nontrivial efforts in designs of both questions and their reasoning chains for demonstrations.",
    "curr": "Moreover, human efforts for designing task-specific demonstrations are even more: different tasks, such as arithmetic [Roy and Roth, 2015] and commonsense reasoning [Talmor et al., 2019], require different ways of demonstrations.",
    "next": "To eliminate such manual designs, we advocate another Auto-CoT paradigm to automatically construct demonstrations with questions and reasoning chains.",
    "hard_negative": [
      10312772,
      8471750,
      12451537,
      17364624,
      3146611,
      12585594,
      10048734,
      11162815
    ],
    "easy_negative": [
      220363877,
      260710127,
      43839109
    ]
  },
  {
    "index": 2196,
    "source_corpus_id": 202749994,
    "ref_id": "b5",
    "citation_corpus_id": 13046179,
    "start": 2061,
    "end": 2087,
    "title": "A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS",
    "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.Published as a conference paper at ICLR 2017 one method which outperforms the baseline on some (but not all) tasks. This new method evaluates the quality of a neural network's input reconstruction to determine if an example is abnormal.",
    "prev": "This is particularly necessary for deep neural network classifiers, which can be easily fooled by OOD data (Nguyen et al., 2015).",
    "curr": "Several approaches have been proposed for OOD detection on top of or within a neural network classifier (Hendrycks & Gimpel, 2017;Lakshminarayanan et al., 2017;Liang et al., 2018;Lee et al., 2018).",
    "next": "Nonetheless, OOD detection is not limited to classification tasks nor to labeled data sets.",
    "hard_negative": [
      6628106,
      7105713,
      2879445,
      1428702,
      6706414
    ],
    "easy_negative": [
      29661510,
      7875725,
      776812
    ]
  },
  {
    "index": 2197,
    "source_corpus_id": 238856644,
    "ref_id": "b61",
    "citation_corpus_id": 211132990,
    "start": 7324,
    "end": 7341,
    "title": "BATCHENSEMBLE: AN ALTERNATIVE APPROACH TO EFFICIENT ENSEMBLE AND LIFELONG LEARNING",
    "abstract": "Ensembles, where multiple neural networks are trained individually and their predictions are averaged, have been shown to be widely successful for improving both the accuracy and predictive uncertainty of single neural networks. However, an ensemble's cost for both training and testing increases linearly with the number of networks, which quickly becomes untenable. In this paper, we propose BatchEnsemble 1 , an ensemble method whose computational and memory costs are significantly lower than typical ensembles. BatchEnsemble achieves this by defining each weight matrix to be the Hadamard product of a shared weight among all ensemble members and a rank-one matrix per member. Unlike ensembles, BatchEnsemble is not only parallelizable across devices, where one device trains one member, but also parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. Across CIFAR-10, CIFAR-100, WMT14 EN-DE/EN-FR translation, and out-of-distribution tasks, BatchEnsemble yields competitive accuracy and uncertainties as typical ensembles; the speedup at test time is 3X and memory reduction is 3X at an ensemble of size 4. We also apply BatchEnsemble to lifelong learning, where on Split-CIFAR-100, BatchEnsemble yields comparable performance to progressive neural networks while having a much lower computational and memory costs. We further show that BatchEnsemble can easily scale up to lifelong learning on Split-ImageNet which involves 100 sequential learning tasks. * Partial work done as part of the Google Student Researcher Program.",
    "prev": "\u2022 Our second, light-weight method ( EDST Ensemble) yields many free tickets in one single run, which is more efficient to train and test than a single dense model, while approaching the performance of the traditional dense ensemble.",
    "curr": "INTRODUCTION\n\nEnsembles (Hansen & Salamon, 1990;Levin et al., 1990) of neural networks have received large success in terms of the predictive accuracy (Perrone & Cooper, 1992;Breiman, 1996;Dietterich, 2000;Xie et al., 2013), uncertainty estimation (Fort et al., 2019;Lakshminarayanan et al., 2017;Wen et al., 2020;Havasi et al., 2021), and out-of-distribution robustness (Ovadia et al., 2019a;Gustafsson et al., 2020).",
    "next": "Given the fact that there are a wide variety of local minima solutions located in the high dimensional optimization landscape of deep neural networks and various randomness (e.g., random initialization, random mini-batch shuffling) occurring during training, neural networks trained with different random seeds usually converge to different low-loss basins with similar error rates (Fort et al., 2019;Ge et al., 2015;Kawaguchi, 2016;Wen et al., 2019).",
    "hard_negative": [
      3861760,
      53100211,
      3536221,
      54443381,
      56657912,
      53033211
    ],
    "easy_negative": [
      252183546,
      44491584,
      1534697
    ]
  },
  {
    "index": 2199,
    "source_corpus_id": 234762955,
    "ref_id": "b5",
    "citation_corpus_id": 52889459,
    "start": 2903,
    "end": 2906,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "Gaussian distribution.",
    "curr": "Due to this structure, in some cases code dimensions acquire specific meanings which can be related to human-interpretable concepts (e.g., the rotation or size of an object); however, the code space in high-quality generators (e.g., BigGAN [6], BigBiGANs [11], StyleGAN [22]) is usually not easily in-terpretable.",
    "next": "Nonetheless, it is intuitive that an efficient generative process should account for the structure of natural images.",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      237490428,
      17732879,
      14149896
    ]
  },
  {
    "index": 2200,
    "source_corpus_id": 238419231,
    "ref_id": "b18",
    "citation_corpus_id": 189898036,
    "start": 2120,
    "end": 2138,
    "title": "Gradient Descent Maximizes the Margin of Homogeneous Neural Networks",
    "abstract": "Recent works on implicit regularization have shown that gradient descent converges to the max-margin direction for logistic regression with one-layer or multi-layer linear networks. In this paper, we generalize this result to homogeneous neural networks, including fully-connected and convolutional neural networks with ReLU or LeakyReLU activations. In particular, we study the gradient flow (gradient descent with infinitesimal step size) optimizing the logistic loss or cross-entropy loss of any homogeneous model (possibly non-smooth), and show that if the training loss decreases below a certain threshold, then we can define a smoothed version of the normalized margin which increases over time. We also formulate a natural constrained optimization problem related to margin maximization, and prove that both the normalized margin and its smoothed version converge to the objective value at a KKT point of the optimization problem. Furthermore, we extend the above results to a large family of loss functions. We conduct several experiments to justify our theoretical finding on MNIST and CIFAR-10 datasets. For gradient descent with constant learning rate, we observe that the normalized margin indeed keeps increasing after the dataset is fitted, but the speed is very slow. However, if we schedule the learning rate more carefully, we can observe a more rapid growth of the normalized margin. Finally, as margin is closely related to robustness, we discuss potential benefits of training longer for improving the robustness of the model. model fits the training data perfectly). For example, given a Convolutional Neural Network (CNN) that has achieved 100% training accuracy, one can easily make the cross-entropy loss arbitrarily small by scaling up the weight and bias parameters (W , b) at the last layer, i.e., transforming (W , b) to (cW , cb) for large enough c > 0. This means that, similar to linear logistic regression, CNNs also have some parameters whose scale does not matter, and hence a promising and meaningful research direction is to study whether their convergent direction maximizes the margin. In general, we observe that the following three properties that are usually satisfied by modern deep neural networks:1. Partial Homogeneity. The output of the neural network is (positively) homogeneous with respect to a part of its parameters (e.g., the parameters at the last linear layer);2. Separability. The training set is separable by the neural network for some set of parameters, i.e., the neural network has sufficient representation power to achieve 100% training accuracy (this is true for state-of-the-art CNNs for image classification, and many of them even have enough capacity to fit randomly labeled data easily [Zhang et al., 2017]);3. No finite minima on the loss function. The loss function used to measure the similarity between the network output and ground-truth is lower bounded by a constant (e.g., 0) but it does not have finite minima (e.g., exponential loss, logistic loss, cross-entropy loss).Simplifications. For simplicity and ease of presentation, we make the following simplifications. First, as the most prominent examples of homogeneous neural networks are all non-smooth (e.g., ReLU networks), we turn to analyze the case of training neural networks by gradient flow (more precisely, subgradient flow in Clarke's sense).Second, we ensure Separability as follows: we assume that after time t 0 , the training loss is smaller than a threshold, and the threshold here is chosen to be so small that the training accuracy is guaranteed to be 100% (e.g., for the logistic loss and cross-entropy loss, the threshold can be set to ln 2). In this paper, we focus on analyzing the behavior of the network after t 0 .",
    "prev": "Under certain regimes, the size of the neural networks used in practice is so large that the training data is fit perfectly and an infinite-width approximation is appropriate.",
    "curr": "In this setting, what matters to obtain good generalization is to fit the data using the right inductive bias, which is specified by how network parameters are controlled [Wei et al., 2020] together with the training algorithm used [Lyu and Li, 2020].",
    "next": "The infinite-width two-layer neural network model has been studied from several perspectives due to its simplicity.",
    "hard_negative": [
      52920337,
      604334
    ],
    "easy_negative": [
      9721691,
      222349276,
      6422949
    ]
  },
  {
    "index": 2203,
    "source_corpus_id": 258865597,
    "ref_id": "b43",
    "citation_corpus_id": 13807351,
    "start": 10005,
    "end": 10029,
    "title": "ENTROPY-SGD: BIASING GRADIENT DESCENT INTO WIDE VALLEYS",
    "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under certain assumptions. Our experiments on convolutional and recurrent neural networks demonstrate that Entropy-SGD compares favorably to state-of-the-art techniques in terms of generalization error and training time.",
    "prev": "The notion of the loss landscape sharpness and its connection to generalization has been extensively studied, both empirically [Keskar et al., 2016, Jiang et al., 2019, Neyshabur et al., 2017a, Dinh et al., 2017 and theoretically [McAllester, 1999, Dziugaite and Roy, 2017, Neyshabur et al., 2017b.",
    "curr": "These studies have motivated the development of methods [Hochreiter and Schmidhuber, 1997, Mobahi, 2016, Izmailov et al., 2018, Chaudhari et al., 2019 that aim to improve model generalization by manipulating or penalizing sharpness.",
    "next": "Among these methods, Sharpness-Aware Minimization (SAM) [Foret et al., 2020, Andriushchenko and Flammarion, 2022, Wen et al., 2023 has shown to be highly effective and scalable for DNNs.",
    "hard_negative": [
      17272965,
      16209268,
      252796
    ],
    "easy_negative": [
      12462181,
      15667475,
      247939414
    ]
  },
  {
    "index": 2219,
    "source_corpus_id": 259298561,
    "ref_id": "b9",
    "citation_corpus_id": 232076011,
    "start": 4771,
    "end": 4791,
    "title": "Published as a conference paper at ICLR 2021 GRADIENT DESCENT ON NEURAL NETWORKS TYPI- CALLY OCCURS AT THE EDGE OF STABILITY",
    "abstract": "We empirically demonstrate that full-batch gradient descent on neural network training objectives typically operates in a regime we call the Edge of Stability. In this regime, the maximum eigenvalue of the training loss Hessian hovers just above the value 2/(step size), and the training loss behaves non-monotonically over short timescales, yet consistently decreases over long timescales. Since this behavior is inconsistent with several widespread presumptions in the field of optimization, our findings raise questions as to whether these presumptions are relevant to neural network training. We hope that our findings will inspire future efforts aimed at rigorously understanding optimization at the Edge of Stability.arXiv:2103.00065v3 [cs.LG] 23 Nov 2022Published as a conference paper at ICLR 2021 this happens, gradient descent does not diverge entirely or stall. Instead, it enters a regime we call the Edge of Stability 1 ( \u00a73.2), in which (1) the sharpness hovers right at, or just above, the value 2/\u03b7; and (2) the train loss behaves non-monotonically, yet consistently decreases over long timescales. In this regime, gradient descent is constantly \"trying\" to increase the sharpness, but is constantly restrained from doing so. The net effect is that gradient descent continues to successfully optimize the training objective, but in such a way as to avoid further increasing the sharpness. 2",
    "prev": "The different panels show the predictor function f obtained when training with different step sizes.",
    "curr": "condition only characterizes the linearized dynamics, it has been empirically shown to hold in realworld neural-network training (Cohen et al., 2020;Gilmer et al., 2022).",
    "next": "The linear stability condition turns out to have a strong effect on the nature of the network that is obtained upon convergence, both in terms of the end-to-end predictor function (Mulayoff et al., 2021), and in terms of the way this function is implemented by the network (Mulayoff & Michaeli, 2020).",
    "hard_negative": [
      16299141,
      211678094,
      204734206,
      211258622
    ],
    "easy_negative": [
      170711184,
      208332503,
      34842395
    ]
  },
  {
    "index": 2222,
    "source_corpus_id": 52948121,
    "ref_id": "b16",
    "citation_corpus_id": 16496273,
    "start": 5667,
    "end": 5689,
    "title": "Efficient Learning of Domain-invariant Image Representations",
    "abstract": "We present an algorithm that learns representations which explicitly compensate for domain mismatch and which can be efficiently realized as linear classifiers. Specifically, we form a linear transformation that maps features from the target (test) domain to the source (training) domain as part of training the classifier. We optimize both the transformation and classifier parameters jointly, and introduce an efficient cost function based on misclassification loss. Our method combines several features previously unavailable in a single algorithm: multi-class adaptation through representation learning, ability to map across heterogeneous feature spaces, and scalability to large datasets. We present experiments on several image datasets that demonstrate improved accuracy and computational advantages compared to previous approaches.",
    "prev": "RELATED WORK\n\nDomain adaptation (cf.",
    "curr": "Csurka (2017) for a recent review) is generally approached either as domaininvariant learning (Hoffman et al., 2013;Herath et al., 2017;Ganin & Lempitsky, 2015) or as a statistical alignment problem (Tzeng et al., 2014;Long et al., 2015).",
    "next": "Our work focuses on unsupervised adaptation methods in the context of deep learning.",
    "hard_negative": [
      15978939,
      15036406
    ],
    "easy_negative": [
      51869513,
      249204530,
      5134380
    ]
  },
  {
    "index": 2230,
    "source_corpus_id": 256615676,
    "ref_id": "b25",
    "citation_corpus_id": 86611921,
    "start": 2659,
    "end": 2684,
    "title": "Natural Questions: A Benchmark for Question Answering Research",
    "abstract": "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.453",
    "prev": "As shown in Figure 1(a), they first conduct search in individual modalities, including text, image, video, etc.",
    "curr": "(Bajaj et al., 2016;Grubinger et al., 2008;Kwiatkowski et al., 2019;Awad et al., 2021), and then fuse the retrieval results from various verticals together, e.g., building another ranking layer on top of these single/cross modality retrievers (Escalante et al., 2008;Grubinger et al., 2008).",
    "next": "Both relevance modeling and retrieval result fusion are usually entwined to achieve more accurate multi-modal retrieval results.",
    "hard_negative": [
      3618568,
      7228830,
      52057510,
      26501419,
      3432876,
      52183757,
      11816014,
      1373518,
      2381275,
      2100831,
      3662564,
      2593903,
      47018994,
      5761781,
      14915449
    ],
    "easy_negative": [
      220835448,
      10409932,
      10500352
    ]
  },
  {
    "index": 2234,
    "source_corpus_id": 264289064,
    "ref_id": "b14",
    "citation_corpus_id": 247519233,
    "start": 2431,
    "end": 2456,
    "title": "TOXIGEN: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection",
    "abstract": "Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create TOXIGEN, a new large-scale and machinegenerated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model (Brown et al., 2020). Controlling machine generation in this way allows TOXIGEN to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of TOXIGEN and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that TOXI-GEN can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset.",
    "prev": "1 Warning: This paper contains qualitative examples that may be viewed as offensive or harmful.",
    "curr": "INTRODUCTION\n\nLarge Language Models (LLMs) are increasingly being employed for a wide variety of domains, with use-cases including creative writing, chatbots, and semantic search among others (Touvron et al., 2023b;Taori et al., 2023;Ouyang et al., 2022;Bai et al., 2022a;b;Brown et al., 2020).Many of these applications are inherently subjective and require generations that cater to different demographics, cultural and societal norms, or simply individual preferences (Hartvigsen et al., 2022;Zhang et al., 2023;Solaiman & Dennison, 2021;Blodgett et al., 2020;Dunbar et al., 1997).By virtue of their large-scale training, current language models are exposed to diverse data that allows them to represent a multitude of such opinions (Glaese et al., 2022;Durmus et al., 2023;Santurkar et al., 2023).However, expressing these diverse opinions requires steering the LLM generations to user requirements.This brings forth the key question studied in this work:\n\nHow do we efficiently adapt LLMs to align closely with the opinions of specific interest groups?",
    "next": "Broadly, prior work has explored two modes of steering language models, which trade-off training complexity with test-time engineering.On one end, prompt engineering approaches avoid explicit modifications to the parameters of the language model and elicit desired behavior by crafting a suitable prompt.Often, the prompt is augmented with a few in-context examples (Brown et al., 2020;Taori et al., 2023;Chowdhery et al., 2022).While pr",
    "hard_negative": [
      21731209,
      9662636,
      225067055,
      15281983
    ],
    "easy_negative": [
      195064081,
      14771874,
      237329472
    ]
  },
  {
    "index": 2235,
    "source_corpus_id": 3067546,
    "ref_id": "b27",
    "citation_corpus_id": 14124313,
    "start": 6927,
    "end": 6931,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "Related Work\n\nDeepening feed-forward neural networks has generally returned dividends in performance.",
    "curr": "For example, see the improvement on the ImageNet [3] classification task when transitioning from AlexNet [15] to VGG-16 [28] to ResNet [8].",
    "next": "Unfortunately, greater depth also makes training more challenging, at least when employing a first-order optimization algorithm with a randomly initialized stack of layers.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      15273963,
      17987597,
      250390891
    ]
  },
  {
    "index": 2236,
    "source_corpus_id": 248887644,
    "ref_id": "b25",
    "citation_corpus_id": 3366315,
    "start": 15043,
    "end": 15063,
    "title": "Published as a conference paper at ICLR 2018 SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.Published as a conference paper at ICLR 2018\u2022 Lipschitz constant is the only hyper-parameter to be tuned, and the algorithm does not require intensive tuning of the only hyper-parameter for satisfactory performance. \u2022 Implementation is simple and the additional computational cost is small.",
    "prev": "These constraints are the Riemannian analog to the Lipschitz constraint in the dual formulation of the 1-Wasserstein distance on R D .",
    "curr": "Constraints of this type are challenging to enforce in gradientbased optimization, and the Wasserstein GAN literature has explored approximations Gulrajani et al., 2017;Miyato et al., 2018).",
    "next": "We follow the standard technique introduced by Gulrajani et al.",
    "hard_negative": [
      6628106,
      5687613,
      18828233,
      3633127,
      14570343,
      11758569
    ],
    "easy_negative": [
      263850902,
      236478313,
      52139821
    ]
  },
  {
    "index": 2238,
    "source_corpus_id": 218522109,
    "ref_id": "b28",
    "citation_corpus_id": 7071211,
    "start": 4237,
    "end": 4257,
    "title": "Published as a conference paper at ICLR 2017 ON DETECTING ADVERSARIAL PERTURBATIONS",
    "abstract": "Machine learning and deep learning in particular has advanced tremendously on perceptual tasks in recent years. However, it remains vulnerable against adversarial perturbations of the input that have been crafted specifically to fool the system while being quasi-imperceptible to a human. In this work, we propose to augment deep neural networks with a small \"detector\" subnetwork which is trained on the binary classification task of distinguishing genuine data from data containing adversarial perturbations. Our method is orthogonal to prior work on addressing adversarial perturbations, which has mostly focused on making the classification network itself more robust. We show empirically that adversarial perturbations can be detected surprisingly well even though they are quasi-imperceptible to humans. Moreover, while the detectors have been trained to detect only a specific adversary, they generalize to similar and weaker adversaries. In addition, we propose an adversarial attack that fools both the classifier and the detector and a novel training procedure for the detector that counteracts this attack.",
    "prev": "Besides, the proposed defenses have been shown to be limited and often not effective and easy to overcome (Athalye et al., 2018).",
    "curr": "Alternatively, a large body of work has focused on detection of adversarial examples (Bhagoji et al., 2017;Feinman et al., 2017;Gong et al., 2017;Grosse et al., 2017;Metzen et al., 2017;Hendrycks & Gimpel, 2017;Li & Li, 2017;Xu et al., 2017;Pang et al., 2018;Roth et al., 2019;Bahat et al., 2019;Ma et al., 2018;Zheng & Hong, 2018;Tian et al., 2018).",
    "next": "While training robust classifiers focuses on maintaining performance in presence of adversarial examples, adversarial detection only cares for detecting such examples.",
    "hard_negative": [
      6628106,
      604334,
      6706414,
      14124313
    ],
    "easy_negative": [
      10969305,
      8488024,
      8463747
    ]
  },
  {
    "index": 2239,
    "source_corpus_id": 219965819,
    "ref_id": "b18",
    "citation_corpus_id": 58981389,
    "start": 3871,
    "end": 3875,
    "title": "Stable Recurrent Models",
    "abstract": "Stability is a fundamental property of dynamical systems, yet to this date it has had little bearing on the practice of recurrent neural networks. In this work, we conduct a thorough investigation of stable recurrent models. Theoretically, we prove stable recurrent neural networks are well approximated by feed-forward networks for the purpose of both inference and training by gradient descent. Empirically, we demonstrate stable recurrent models often perform as well as their unstable counterparts on benchmark sequence tasks. Taken together, these findings shed light on the effective power of recurrent networks and suggest much of sequence learning happens, or can be made to happen, in the stable regime. Moreover, our results help to explain why in many cases practitioners succeed in replacing recurrent models by feed-forward models. *",
    "prev": "The motivation for viewing RNNs as dynamical systems is that it allows us to borrow tools from stability analysis to study the long-term behavior of the hidden state.",
    "curr": "From this point of view, an unstable unit presents an exploding gradients problem, whereas the gradients of a stable model do not explode over time [19].",
    "next": "On the other hand, a stable recurrent unit can suffer from vanishing gradients, which in turn leads to catastrophic forgetting [20].",
    "hard_negative": [
      16299141,
      252796,
      3005102,
      212756
    ],
    "easy_negative": [
      226262400,
      8010515,
      21728300
    ]
  },
  {
    "index": 2241,
    "source_corpus_id": 220830766,
    "ref_id": "b2",
    "citation_corpus_id": 2906360,
    "start": 2784,
    "end": 2804,
    "title": "DEEPCODER: LEARNING TO WRITE PROGRAMS",
    "abstract": "We develop a first line of attack for solving programming competition-style problems from input-output examples using deep learning. The approach is to train a neural network to predict properties of the program that generated the outputs from the inputs. We use the neural network's predictions to augment search techniques from the programming languages community, including enumerative search and an SMT-based solver. Empirically, we show that our approach leads to an order of magnitude speedup over the strong non-augmented baselines and a Recurrent Neural Network approach, and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites.Published as a conference paper at ICLR 2017 show orders-of-magnitude improvements over optimized standard search techniques and a Recurrent Neural Network-based approach to the problem.",
    "prev": " own creation.",
    "curr": "INTRODUCTION\n\nProgram synthesis is a longstanding goal of artificial intelligence research (Manna & Waldinger, 1971;Summers, 1977), but it remains difficult in part because of the challenges of search (Alur et al., 2013;Gulwani et al., 2017).The objective in program synthesis is to automatically write a program given a specification of its intended behavior, and current state of the art methods typically perform some form of search over a space of possible programs.Many different search methods have been explored in the literature, both with and without learning.These include search within a version-space algebra (Gulwani, 2011), bottom-up enumerative search (Udupa et al., 2013), stochastic search (Schkufza et al., 2013), genetic programming (Koza, 1994), reducing the synthesis problem to logical satisfiability (Solar-Lezama et al., 2006), beam search with a sequence-to-sequence neural network (Devlin et al., 2017), learning to perform premise selection to guide search (Balog et al., 2017), learning to prioritize grammar rules within top-down search (Lee et al., 2018), and learned search based on partial executions (Ellis et al., 2019;Zohar & Wolf, 2018;Chen et al., 2019).",
    "next": "While these approaches have yielded significant progress, none of them completely capture the following important intuition: human programmers routinely write complex programs by first writing sub-programs and then analyzing their intermediate results to compose them in appropriate ways.We propose a new learning-guided system for synthesis, called BUSTLE, 1 which follows this intuition in a straightforward manner.Given a specification of a program's intended behavior (in this paper given by input-output examples), BUSTLE performs bottom-up enumerative search for a satisfying program, following Udupa et al.",
    "hard_negative": [
      2926851,
      7034786,
      6715185
    ],
    "easy_negative": [
      1604930,
      6575946,
      7083365
    ]
  },
  {
    "index": 2243,
    "source_corpus_id": 264172260,
    "ref_id": "b42",
    "citation_corpus_id": 3693334,
    "start": 67046,
    "end": 67063,
    "title": "Visualizing the Loss Landscape of Neural Nets",
    "abstract": "Neural network training relies on our ability to find \"good\" minimizers of highly non-convex loss functions. It is well-known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and wellchosen training parameters (batch size, learning rate, optimizer) produce minimizers that generalize better. However, the reasons for these differences, and their effects on the underlying loss landscape, are not well understood. In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple \"filter normalization\" method that helps us visualize loss function curvature and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture affects the loss landscape, and how training parameters affect the shape of minimizers.",
    "prev": "We provide additional (lower-resolution) heatmaps around neighboorhoods of various cloner policies in Figure 13.",
    "curr": "In addition to stochastic gradient directions, we visualize cross-sections of these landscapes in random directions, like the main figures in (Li et al., 2018).",
    "next": "13 This confirms the generality of our finding in (R1), concerning the fractality of the reward landscape in regions where the loss is extremely smooth and near-convex.",
    "hard_negative": [
      14124313,
      4429876,
      16138044,
      17786716,
      16209268
    ],
    "easy_negative": [
      233305372,
      7888227,
      196198761
    ]
  },
  {
    "index": 2246,
    "source_corpus_id": 259164684,
    "ref_id": "b8",
    "citation_corpus_id": 252907410,
    "start": 3583,
    "end": 3585,
    "title": "SEQUENTIAL LEARNING OF NEURAL NETWORKS FOR PREQUENTIAL MDL",
    "abstract": "Minimum Description Length (MDL) provides a framework and an objective for principled model evaluation. It formalizes Occam's Razor and can be applied to data from non-stationary sources. In the prequential formulation of MDL, the objective is to minimize the cumulative next-step log-loss when sequentially going through the data and using previous observations for parameter estimation. It thus closely resembles a continual-or online-learning problem. In this study, we evaluate approaches for computing prequential description lengths for image classification datasets with neural networks. Considering the computational cost, we find that online-learning with rehearsal has favorable performance compared to the previously widely used block-wise estimation. We propose forward-calibration to better align the models predictions with the empirical observations and introduce replay-streams, a minibatch incremental training technique to efficiently implement approximate random replay while avoiding large in-memory replay buffers. As a result, we present description lengths for a suite of image classification datasets that improve upon previously reported results by large margins.",
    "prev": "Depending on the nature of the data stream, plasticity, not-forgetting and sample-efficiency all play a crucial role during learning.",
    "curr": "Furthermore, when considering the cumulative next-step log-loss under this protocol, it directly corresponds to the prequential description length and is thus a theoretically well motivated evaluation metric for non-stationary scenarios under the Minimum Description Length principle [17,4,7].",
    "next": "In this paper, we propose a new method based on Kalman filters which explicitly takes into account non-stationaries in the data stream.",
    "hard_negative": [
      238419341,
      218487319,
      14124313
    ],
    "easy_negative": [
      3264891,
      247748628,
      6219679
    ]
  },
  {
    "index": 2249,
    "source_corpus_id": 822804,
    "ref_id": "b15",
    "citation_corpus_id": 2100831,
    "start": 1390,
    "end": 1415,
    "title": "MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text",
    "abstract": "We present MCTest, a freely available set of stories and associated questions intended for research on the machine comprehension of text. Previous work on machine comprehension (e.g., semantic modeling) has made great strides, but primarily focuses either on limited-domain datasets, or on solving a more restricted goal (e.g., open-domain relation extraction). In contrast, MCTest requires machines to answer multiple-choice reading comprehension questions about fictional stories, directly tackling the high-level goal of open-domain machine comprehension. Reading comprehension can test advanced abilities such as causal reasoning and understanding the world, yet, by being multiple-choice, still provide a clear metric. By being fictional, the answer typically can be found only in the story itself. The stories and questions are also carefully limited to those a young child would understand, reducing the world knowledge that is required for the task. We present the scalable crowd-sourcing methods that allow us to cheaply construct a dataset of 500 stories and 2000 questions. By screening workers (with grammar tests) and stories (with grading), we have ensured that the data is the same quality as another set that we manually edited, but at one tenth the editing cost. By being open-domain, yet carefully restricted, we hope MCTest will serve to encourage research and provide a clear metric for advancement on the machine comprehension of text.",
    "prev": "For example, in textual entailment, one needs to determine whether a hypothesis sentence can be inferred from a premise sentence (Bowman et al., 2015).",
    "curr": "In machine comprehension, given a passage, a question needs to be matched against it in order to find the correct answer (Richardson et al., 2013;Tapaswi et al., 2016).",
    "next": "Table 1 gives two example sequence matching problems.",
    "hard_negative": [
      1321,
      3038382,
      5734707,
      9111381,
      15197674,
      12131065
    ],
    "easy_negative": [
      199379426,
      252716013,
      3102580
    ]
  },
  {
    "index": 2250,
    "source_corpus_id": 252595808,
    "ref_id": "b45",
    "citation_corpus_id": 235254714,
    "start": 1644,
    "end": 1663,
    "title": "Diversifying Dialog Generation via Adaptive Label Smoothing",
    "abstract": "Neural dialogue generation models trained with the one-hot target distribution suffer from the over-confidence issue, which leads to poor generation diversity as widely reported in the literature. Although existing approaches such as label smoothing can alleviate this issue, they fail to adapt to diverse dialog contexts. In this paper, we propose an Adaptive Label Smoothing (AdaLabel) approach that can adaptively estimate a target label distribution at each time step for different contexts. The maximum probability in the predicted distribution is used to modify the soft target distribution produced by a novel light-weight bi-directional decoder module. The resulting target distribution is aware of both previous and future contexts and is adjusted to avoid over-training the dialogue model. Our model can be trained in an endto-end manner. Extensive experiments on two benchmark datasets show that our approach outperforms various competitive baselines in producing diverse responses.",
    "prev": "Further, experiments on two large-scale open-domain dialogue datasets verify that our EqHard-EM algorithm generates high-quality diverse responses 1 .",
    "curr": "INTRODUCTION\n\nOpen-domain dialogue systems aim to generate natural language text utterances to hold open-ended conversations with humans (Li et al., 2017a;Wang et al., 2021b).",
    "next": "These systems have shown great success, and are seamlessly integrated into our society through chatbots.",
    "hard_negative": [
      189927977,
      199551982,
      67855635,
      70349945,
      221818778,
      53081212,
      214803038
    ],
    "easy_negative": [
      1773042,
      220057395,
      221139573
    ]
  },
  {
    "index": 2252,
    "source_corpus_id": 108299957,
    "ref_id": "b53",
    "citation_corpus_id": 4567927,
    "start": 2398,
    "end": 2424,
    "title": "Published as a conference paper at ICLR 2018 LEARNING GENERAL PURPOSE DISTRIBUTED SEN- TENCE REPRESENTATIONS VIA LARGE SCALE MULTI- TASK LEARNING",
    "abstract": "A lot of the recent success in natural language processing (NLP) has been driven by distributed vector representations of words trained on large amounts of text in an unsupervised manner. These representations are typically used as general purpose features for words across a range of NLP problems. However, extending this success to learning representations of sequences of words, such as sentences, remains an open problem. Recent work has explored unsupervised as well as supervised learning techniques with different training objectives to learn general purpose fixed-length sentence representations. In this work, we present a simple, effective multi-task learning framework for sentence representations that combines the inductive biases of diverse training objectives in a single model. We train this model on several data sources with multiple training objectives on over 100 million sentences. Extensive experiments demonstrate that sharing a single recurrent sentence encoder across weakly related tasks leads to consistent improvements over previous methods. We present substantial improvements in the context of transfer learning and low-resource settings using our learned general-purpose representations. 1",
    "prev": "More than half a century since it was first proposed, the Bag-of-Words (BoW) representation (Harris, 1954;Salton et al., 1975;Manning et al., 2008) remains a popular baseline across machine learning (ML), natural language processing (NLP), and information retrieval (IR) communities.",
    "curr": "In recent years, however, BoW was largely eclipsed by representations learned through neural networks, ranging from shallow (Le & Mikolov, 2014;Hill et al., 2016) to recurrent Conneau et al., 2017;Subramanian et al., 2018a), recursive (Socher et al., 2013;Tai et al., 2015), convolutional (Kalchbrenner et al., 2014;Kim, 2014), self-attentive (Vaswani et al., 2017;Cer et al., 2018a) and hybrid architectures (Gan et al., 2017;Tang et al., 2017;Zhelezniak et al., 2018).",
    "next": "Interestingly, Arora et al.",
    "hard_negative": [
      11262376,
      18597583,
      3666937
    ],
    "easy_negative": [
      7784748,
      237157879,
      204961369
    ]
  },
  {
    "index": 2255,
    "source_corpus_id": 31816657,
    "ref_id": "b8",
    "citation_corpus_id": 9818013,
    "start": 12173,
    "end": 12194,
    "title": "Globally Coherent Text Generation with Neural Checklist Models",
    "abstract": "Recurrent neural networks can generate locally coherent text but often have difficulties representing what has already been generated and what still needs to be said -especially when constructing long texts. We present the neural checklist model, a recurrent neural network that models global coherence by storing and updating an agenda of text strings which should be mentioned somewhere in the output. The model generates output by dynamically adjusting the interpolation among a language model and a pair of attention models that encourage references to agenda items. Evaluations on cooking recipes and dialogue system responses demonstrate high coherence with greatly improved semantic coverage of the agenda.",
    "prev": "Table 1 provides examples of annotations in this action lexicon.",
    "curr": "DATASET\n\nFor learning and evaluation, we use a subset of the Now You're Cooking dataset (Kiddon et al., 2016).",
    "next": "We chose 65816 recipes for training, 175 recipes for development, and 700 recipes for testing.",
    "hard_negative": [
      6506243,
      7218315,
      1589010,
      238873,
      13402912,
      6508854,
      2578382,
      969555,
      1354459,
      1918428,
      739696,
      14308601,
      5923323
    ],
    "easy_negative": [
      219303677,
      125362,
      18701000
    ]
  },
  {
    "index": 2259,
    "source_corpus_id": 264128429,
    "ref_id": "b46",
    "citation_corpus_id": 53108063,
    "start": 1756,
    "end": 1770,
    "title": "Mutual Information Maximization for Simple and Accurate Part-Of-Speech Induction",
    "abstract": "We address part-of-speech (POS) induction by maximizing the mutual information between the induced label and its context. We focus on two training objectives that are amenable to stochastic gradient descent (SGD): a novel generalization of the classical Brown clustering objective and a recently proposed variational lower bound. While both objectives are subject to noise in gradient updates, we show through analysis and experiments that the variational lower bound is robust whereas the generalized Brown objective is vulnerable. We obtain strong performance on a multitude of datasets and languages with a simple architecture that encodes morphology and context.",
    "prev": "a by-product, our method also enables the estimation of the entropy of random variables.Armed with such building blocks, we present a general recipe to measure MI, which unfolds in two directions: one uses conditional diffusion process, whereas the other uses joint diffusion processes that allow simultaneous modelling of two random variables.Our results, which derive from a thorough experimental protocol over all the variants of our approach, indicate that our method is more accurate than the main alternatives from the literature, especially for challenging distributions.Furthermore, our methods pass MI self-consistency tests, including data processing and additivity under independence, which instead are a pain-point of existing methods.",
    "curr": "INTRODUCTION\n\nMutual Information (MI) is a central measure to study the non-linear dependence between random variables [Shannon, 1948;MacKay, 2003], and has been extensively used in machine learning for representation learning [Bell & Sejnowski, 1995;Stratos, 2019;Belghazi et al., 2018;Oord et al., 2018;Hjelm et al., 2019], and for both training [Alemi et al., 2016;Chen et al., 2016;Zhao et al., 2018] and evaluating generative models [Alemi & Fischer, 2018;Huang et al., 2020].",
    "next": "For many problems of interest, precise computation of MI is not an easy task [McAllester & Stratos, 2020;Paninski, 2003], and a wide range of techniques for MI estimation have flourished.As the application of existing parametric and non-parametric methods [Pizer et al., 1987;Moon et al., 1995;Kraskov et al., 2004;Gao et al., 2015] to realistic, high-dimensional data is extremely challenging, if not unfeasible, recent research has focused on variational approaches [Barber & Agakov, 2004;Nguyen et al., 2007;Nowozin et al., 2016;Poole et al., 2019;Wunder et al., 2021;Letizia et al., 2023;Federici et al., 2023] and neural estimators [Papamakarios et al., 2017;Belghazi et al., 2018;Oord et al., 2018;Song & Ermon, 2019;Rhodes et al., 2020;Letizia & Tonello, 2022;Brekelmans et a",
    "hard_negative": [
      1114215,
      9558665,
      10986188,
      2727455,
      15690223,
      1916754,
      14153811,
      7784215,
      1957433
    ],
    "easy_negative": [
      1851612,
      38044609,
      781377
    ]
  },
  {
    "index": 2264,
    "source_corpus_id": 258987919,
    "ref_id": "b48",
    "citation_corpus_id": 12130431,
    "start": 1897,
    "end": 1916,
    "title": "INCREMENTAL NETWORK QUANTIZATION: TOWARDS LOSSLESS CNNS WITH LOW-PRECISION WEIGHTS",
    "abstract": "This paper presents incremental network quantization (INQ), a novel method, targeting to efficiently convert any pre-trained full-precision convolutional neural network (CNN) model into a low-precision version whose weights are constrained to be either powers of two or zero. Unlike existing methods which are struggled in noticeable accuracy loss, our INQ has the potential to resolve this issue, as benefiting from two innovations. On one hand, we introduce three interdependent operations, namely weight partition, group-wise quantization and re-training. A wellproven measure is employed to divide the weights in each layer of a pre-trained CNN model into two disjoint groups. The weights in the first group are responsible to form a low-precision base, thus they are quantized by a variable-length encoding method. The weights in the other group are responsible to compensate for the accuracy loss from the quantization, thus they are the ones to be re-trained. On the other hand, these three operations are repeated on the latest re-trained group in an iterative manner until all the weights are converted into low-precision ones, acting as an incremental network quantization and accuracy enhancement procedure. Extensive experiments on the ImageNet classification task using almost all known deep CNN architectures including AlexNet, VGG-16, GoogleNet and ResNets well testify the efficacy of the proposed method. Specifically, at 5-bit quantization (a variable-length encoding: 1 bit for representing zero value, and the remaining 4 bits represent at most 16 different values for the powers of two) 1 , our models have improved accuracy than the 32-bit floating-point references. Taking ResNet-18 as an example, we further show that our quantized models with 4-bit, 3-bit and 2-bit ternary weights have improved or very similar accuracy against its 32-bit floating-point baseline. Besides, impressive results with the combination of network pruning and INQ are also reported. We believe that our method sheds new insights on how to make deep CNNs to be applicable on mobile or embedded devices. The code is available at https://github.com",
    "prev": "Introduction\n\nDeploying and optimizing Deep Neural Networks (DNNs) on real-world systems with bounded computing resources (e.g., edge devices), have led to various techniques for approximating DNNs while maintaining high accuracy and robustness.",
    "curr": "Common approximation techniques are quantization -reducing the numerical precision of weights [Zhou et al., 2017], and pruning -removing weights that have minimal impact on accuracy [Frankle and Carbin, 2019].",
    "next": "For trustworthy deployment of DNNs, randomized smoothing (RS) is a promising approach for obtaining robustness certificates by constructing a smoothed model g from a base network f under noise [Cohen et al., 2019].",
    "hard_negative": [
      14124313,
      2134321,
      1996665
    ],
    "easy_negative": [
      12746489,
      380199,
      3082659
    ]
  },
  {
    "index": 2266,
    "source_corpus_id": 249209990,
    "ref_id": "b13",
    "citation_corpus_id": 218901061,
    "start": 30491,
    "end": 30511,
    "title": "CausaLM: Causal Model Explanation Through Counterfactual Language Models under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) license Computational Linguistics",
    "abstract": "Understanding predictions made by deep neural networks is notoriously difficult, but also crucial to their dissemination. As all machine learning-based methods, they are as good as their training data, and can also capture unwanted biases. While there are tools that can help understand whether such biases exist, they do not distinguish between correlation and causation, and might be ill-suited for text-based models and for reasoning about high-level language concepts. A key problem of estimating the causal effect of a concept of interest on a given model is that this estimation requires the generation of counterfactual examples, which is challenging with existing generation technology. To bridge that gap, we propose CausaLM, a framework for producing causal model explanations using counterfactual language representation models. Our approach is based on fine-tuning of deep contextualized embedding models with auxiliary adversarial tasks derived from the causal graph of the problem. Concretely, we show that by carefully choosing Submission Volume 47, Number 2 auxiliary adversarial pre-training tasks, language representation models such as BERT can effectively learn a counterfactual representation for a given concept of interest, and be used to estimate its true causal effect on model performance. A byproduct of our method is a language representation model that is unaffected by the tested concept, which can be useful in mitigating unwanted bias ingrained in the data. 1",
    "prev": "Related work focuses on understanding if neural networks encode and use concepts (Lucieri et al., 2020;Kim et al., 2018;McGrath et al., 2021), or generate counterfactual explanations to understand model behavior (Ghandeharioun et al., 2021;Abid et al., 2022;Akula et al., 2020).",
    "curr": "Recent works evaluated the causal validity of explanations (Feder et al., 2021;Elazar et al., 2021;Goyal et al., 2019), e.g.",
    "next": "to eliminate potential confounding effects.",
    "hard_negative": [
      13652864,
      21670658,
      168170119,
      3655946,
      6628106,
      52011663,
      73729169,
      215786522,
      207847197,
      24461982,
      21736097,
      218487075,
      7105713,
      52056513,
      3626819,
      67855815,
      219176513,
      222124366,
      218487374,
      52010710,
      196184409,
      5252952,
      17518557,
      203591519,
      1428702,
      52910554,
      52967399,
      5147501,
      15702125,
      67855860,
      6771196
    ],
    "easy_negative": [
      14426518,
      12998021,
      20777094
    ]
  },
  {
    "index": 2267,
    "source_corpus_id": 53443065,
    "ref_id": "b28",
    "citation_corpus_id": 1957433,
    "start": 3553,
    "end": 3578,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "What is missing in the current approaches to models ensembling, is the ability to incorporate side information such as class relationships represented by a graph or via an embedding space.",
    "curr": "For example a semantic class can be represented with a finite dimensional vector in a pretrained word embedding space such as GloVe (Pennington et al., 2014).",
    "next": "The models' predictions can be seen as defining a distribution in this label space defined by word embeddings: if we denote p i to be the confidence of a model on a bin corresponding to a word having an embedding x i , the distribution on the label space is therefore p = i p i \u03b4 xi .",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      258960289,
      13086372,
      253080517
    ]
  },
  {
    "index": 2271,
    "source_corpus_id": 59553561,
    "ref_id": "b36",
    "citation_corpus_id": 259144,
    "start": 33316,
    "end": 33338,
    "title": "Contrastive Estimation: Training Log-Linear Models on Unlabeled Data *",
    "abstract": "Conditional random fields(Lafferty et al., 2001)are quite effective at sequence labeling tasks like shallow parsing(Sha and Pereira, 2003)and namedentity extraction(McCallum and Li, 2003). CRFs are log-linear, allowing the incorporation of arbitrary features into the model. To train on unlabeled data, we require unsupervised estimation methods for log-linear models; few exist. We describe a novel approach, contrastive estimation. We show that the new technique can be intuitively understood as exploiting implicit negative evidence and is computationally efficient. Applied to a sequence labeling problem-POS tagging given a tagging dictionary and unlabeled text-contrastive estimation outperforms EM (with the same feature set), is more robust to degradations of the dictionary, and can largely recover by modeling additional features.",
    "prev": "(2014).",
    "curr": "This underlines the fact that, for established learning algorithms involving negative examples such as (noise) contrastive estimation (Smith & Eisner, 2005;Gutmann & Hyv\u00e4rinen, 2010) or negative sampling (Mikolov et al., 2013), the way in which negative examples are selected can be critical 3 .",
    "next": "It may also help to explain the power of methods like self-play (Silver et al., 2016), in which a model is encouraged to continually challenge itself by posing increasingly difficult learning challenges.",
    "hard_negative": [
      2727455,
      1487550,
      13936575,
      14829769,
      5361885,
      1899106,
      739426,
      17435621,
      63346
    ],
    "easy_negative": [
      10743386,
      237532321,
      259108325
    ]
  },
  {
    "index": 2278,
    "source_corpus_id": 249926641,
    "ref_id": "b44",
    "citation_corpus_id": 3292002,
    "start": 5957,
    "end": 5961,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "In contrast to this, a standard message-passing GNN always (indirectly) processes the entire multi-hop neighborhood around each node, and hence it is often difficult to identify the useful part of the information from this neighborhood due to oversmoothing or oversquashing effects [46; 2] caused by an exponential increase in aggregated information with the number of steps.",
    "curr": "One popular approach that can partially combat this has been attention [70] as it allows for soft gating of node interactions.",
    "next": "While our approach also uses attention for agent transition sampling, the transitions are hard.",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      233199,
      14930756,
      16304583
    ]
  },
  {
    "index": 2281,
    "source_corpus_id": 13764176,
    "ref_id": "b1",
    "citation_corpus_id": 6401679,
    "start": 2188,
    "end": 2209,
    "title": "Semantic Parsing on Freebase from Question-Answer Pairs",
    "abstract": "In this paper, we train a semantic parser that scales up to Freebase. Instead of relying on annotated logical forms, which is especially expensive to obtain at large scale, we learn from question-answer pairs. The main challenge in this setting is narrowing down the huge number of possible logical predicates for a given question. We tackle this problem in two ways: First, we build a coarse mapping from phrases to predicates using a knowledge base and a large text corpus. Second, we use a bridging operation to generate additional predicates based on neighboring predicates. On the dataset of Cai and Yates (2013), despite not having annotated logical forms, our system outperforms their state-of-the-art parser. Additionally, we collected a more realistic and challenging dataset of question-answer pairs and improves over a natural baseline.",
    "prev": "INTRODUCTION\n\nOpen-domain question answering (QA) aims to answer questions from a broad range of domains by effectively marshalling evidence from large open-domain knowledge sources.",
    "curr": "Such resources can be Wikipedia , the whole web (Ferrucci et al., 2010), structured knowledge bases (Berant et al., 2013; or combinations of the above (Baudi\u0161 &\u0160ediv\u1ef3, 2015).",
    "next": "Recent work on open-domain QA has focused on using unstructured text retrieved from the web to build machine comprehension models Dhingra et al., 2017b;.",
    "hard_negative": [
      1619841,
      5667590,
      1140108,
      9963298,
      9337134,
      5869747,
      16483125,
      12926517,
      6143941,
      216804551,
      6228816,
      74065,
      9111381,
      8597719,
      10250712,
      8893912,
      5633240,
      10318045,
      8781666,
      258794,
      10824175,
      340852,
      16639862,
      333563
    ],
    "easy_negative": [
      207852344,
      233231501,
      5219972
    ]
  },
  {
    "index": 2282,
    "source_corpus_id": 259861505,
    "ref_id": "b51",
    "citation_corpus_id": 222208633,
    "start": 4046,
    "end": 4063,
    "title": "DEFORMABLE DETR: DEFORMABLE TRANSFORMERS FOR END-TO-END OBJECT DETECTION",
    "abstract": "DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10\u00d7 less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code shall be released. * Equal contribution. \u2020 This work is done when Weijie Su is an intern at SenseTime Research.",
    "prev": "et al., 2021;Xie et al., 2021;Wang et al., 2021a;H\u00e9naff et al., 2021;Dai et al., 2021b;Bar et al., 2022) or jointly (Wei et al., 2021).The different pretraining possibilities for Object Detection in the literature are illustrated in Figure 1.A pretraining of the backbone tailored to dense tasks has been the subject of many recent efforts (Xiao et al., 2021;Xie et al., 2021;Wang et al., 2021a;H\u00e9naff et al., 2021) (Backbone Pretraining), but few have been interested in incorporating the detection-specific components of the architectures during pretraining (Dai et al., 2021b;Bar et al., 2022;Wei et al., 2021) (Overall Pretraining).Among them, SoCo (Wei et al., 2021) focuses on convolutional architectures and pretrains the whole detector, i.e.",
    "curr": "the backbone along with the detection heads (approach e. in Figure 1), whereas UP-DETR (Dai et al., 2021b) and DETReg (Bar et al., 2022) pretrain only the transformers (Vaswani et al., 2017) in transformer-based object detectors (Carion et al., 2020;Zhu et al., 2021) and keep the backbone fixed (approach c. in Figure 1).Due to the numerous parameters that must be learned and the huge number of iterations needed because of random initialization, pretraining the entire detection model is expensive (Figure 1, e.).On the other hand, pretraining only the detection-specific parts with a fixed backbone leads to fewer parameters and allows leveraging strong pretrained backbones already available.However, fully relying on aligning embeddings given by the fixed backbone during pretraining and those given by the detection head, as done in DETReg or UP-DETR, introduces a discrepancy in the information contained in the features (Figure 1, c.).Indeed, while the pretrained backbone has been trained to learn image-level features, the object detector must understand objectlevel information in the image.Aligning inconsistent features hinders the pretraining quality.",
    "next": "In this work, we propose Proposal Selection Contrast (ProSeCo), an unsupervised pretraining method",
    "hard_negative": [
      6628106,
      3608234,
      59310641,
      209315300
    ],
    "easy_negative": [
      321686,
      540234,
      15147515
    ]
  },
  {
    "index": 2284,
    "source_corpus_id": 53109277,
    "ref_id": "b4",
    "citation_corpus_id": 52114113,
    "start": 15060,
    "end": 15082,
    "title": "WikiAtomicEdits: A Multilingual Corpus of Wikipedia Edits for Modeling Language and Discourse",
    "abstract": "We release a corpus of 43 million atomic edits across 8 languages. These edits are mined from Wikipedia edit history and consist of instances in which a human editor has inserted a single contiguous phrase into, or deleted a single contiguous phrase from, an existing sentence. We use the collected data to show that the language generated during editing differs from the language that we observe in standard corpora, and that models trained on edits encode different aspects of semantics and discourse than models trained on raw, unstructured text. We release the full corpus as a resource to aid ongoing research in semantics, discourse, and representation learning.",
    "prev": "Throughout the evaluation we use a fixed size of 512 for all edit representations.",
    "curr": "DATASETS\n\nNatural Language Edits We use the WikiAtomicEdits (Faruqui et al., 2018) dataset of pairs of short edits on Wikipedia articles.",
    "next": "We sampled 1040K edits from the English insertion portion of the dataset and split the samples into 1000K/20K/20K train-valid-test sets.",
    "hard_negative": [
      17651986,
      1957433,
      3626819,
      9106885,
      6142277,
      14166989,
      2952144,
      14527065,
      11274338,
      29758184,
      11212020,
      3411445,
      5477884
    ],
    "easy_negative": [
      222291705,
      5563699,
      3525078
    ]
  },
  {
    "index": 2286,
    "source_corpus_id": 231942749,
    "ref_id": "b0",
    "citation_corpus_id": 11212020,
    "start": 1715,
    "end": 1738,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "INTRODUCTION\n\nModeling long-range dependencies in data is a central problem in machine learning.",
    "curr": "Selfattention (Bahdanau et al., 2015;Vaswani et al., 2017) has emerged as a popular approach to do so, but the costly memory requirement of self-attention hinders its application to long sequences and multidimensional data such as images 2 .",
    "next": "Linear attention mechanisms (Katharopoulos et al., 2020;Choromanski et al., 2020) offer a scalable remedy for high memory usage but fail to model internal data structure, such as relative distances between pixels or edge relations between nodes in a graph.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      14690359,
      236154781,
      249152222
    ]
  },
  {
    "index": 2296,
    "source_corpus_id": 258967241,
    "ref_id": "b37",
    "citation_corpus_id": 227209335,
    "start": 1931,
    "end": 1934,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "erence attack (MIA), namely Proximal Initialization Attack (PIA), which utilizes groundtruth trajectory obtained by \u03f5 initialized in t = 0 and predicted point to infer memberships.Experimental results indicate that the proposed method can achieve competitive performance with only two queries on both discrete-time and continuous-time diffusion models.Moreover, previous works on the privacy of diffusion models have focused on vision tasks without considering audio tasks.Therefore, we also explore the robustness of diffusion models to MIA in the text-to-speech (TTS) task, which is an audio generation task.To the best of our knowledge, this work is the first to study the robustness of diffusion models to MIA in the TTS task.Experimental results indicate that models with mel-spectrogram (image-like) output are vulnerable to MIA, while models with audio output are relatively robust to MIA.Code is available at https://github.com/kong13661/PIA.",
    "curr": "Introduction\n\nRecently, the diffusion model [13,38,37] has emerged as a powerful approach in the field of generative tasks, achieving notable success in image generation [30,31], audio generation [28,21], video generation [43,14], and other domains.However, like other generative models such as GANs [11] and VAEs [20], the diffusion model may also be exposed to privacy risks [1] and copyright disputes [15].Dangers such as privacy leaks [27] and data reconstruction [49] may compromise the model.Recently, some researchers have explored this topic [9,26,16,3], demonstrating that diffusion models are also vulnerable to privacy issues.",
    "next": "Membership Inference Attacks (MIAs) are the most common privacy risks [35].MIAs can cause privacy concerns directly and can also contribute to privacy issues indirectly as part of data reconstruction.Given a pre-trained model, MIA aims to determine whether a sample is in the training set or not.",
    "hard_negative": [
      52889459,
      52908831
    ],
    "easy_negative": [
      250164038,
      254018376,
      259376471
    ]
  },
  {
    "index": 2308,
    "source_corpus_id": 232417873,
    "ref_id": "b22",
    "citation_corpus_id": 3728944,
    "start": 7554,
    "end": 7577,
    "title": "Published as a conference paper at ICLR 2018 COMPOSITIONAL ATTENTION NETWORKS FOR MACHINE REASONING",
    "abstract": "We present the MAC network, a novel fully differentiable neural network architecture, designed to facilitate explicit and expressive reasoning. MAC moves away from monolithic black-box neural architectures towards a design that encourages both transparency and versatility. The model approaches problems by decomposing them into a series of attention-based reasoning steps, each performed by a novel recurrent Memory, Attention, and Composition (MAC) cell that maintains a separation between control and memory. By stringing the cells together and imposing structural constraints that regulate their interaction, MAC effectively learns to perform iterative reasoning processes that are directly inferred from the data in an end-to-end approach. We demonstrate the model's strength, robustness and interpretability on the challenging CLEVR dataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy, halving the error rate of the previous best model. More importantly, we show that the model is computationally-efficient and data-efficient, in particular requiring 5x less data than existing models to achieve strong results.",
    "prev": "Early studies like (Wu et al., 2016;Gan et al., 2017) typically adopted monolithic network architectures and mainly focused on visual understanding.",
    "curr": "To perform deeper visual reasoning, neural module networks were extensively studied in recent works (Johnson et al., 2017a;Hu et al., 2018;Hudson & Manning, 2018;Amizadeh et al., 2020), where they represent symbolic operations with small neural networks and perform multi-hop reasoning.",
    "next": "Some previous research has also attempted to learn \n\n\nObject Trajectories\n{\" ! \"",
    "hard_negative": [
      3130692,
      12304778,
      2711679
    ],
    "easy_negative": [
      232021930,
      15776904,
      259833871
    ]
  },
  {
    "index": 2310,
    "source_corpus_id": 258947441,
    "ref_id": "b14",
    "citation_corpus_id": 235613377,
    "start": 4196,
    "end": 4215,
    "title": "Published as a conference paper at ICLR 2021 RAPID NEURAL ARCHITECTURE SEARCH BY LEARNING TO GENERATE GRAPHS FROM DATASETS",
    "abstract": "Despite the success of recent Neural Architecture Search (NAS) methods on various tasks which have shown to output networks that largely outperform humandesigned networks, conventional NAS methods have mostly tackled the optimization of searching for the network architecture for a single task (dataset), which does not generalize well across multiple tasks (datasets). Moreover, since such task-specific methods search for a neural architecture from scratch for every given task, they incur a large computational cost, which is problematic when the time and monetary budget are limited. In this paper, we propose an efficient NAS framework that is trained once on a database consisting of datasets and pretrained networks and can rapidly search for a neural architecture for a novel dataset. The proposed MetaD2A (Meta Dataset-to-Architecture) model can stochastically generate graphs (architectures) from a given set (dataset) via a cross-modal latent space learned with amortized meta-learning. Moreover, we also propose a meta-performance predictor to estimate and select the best architecture without direct training on target datasets. The experimental results demonstrate that our model meta-learned on subsets of ImageNet-1K and architectures from NAS-Bench 201 search space successfully generalizes to multiple unseen datasets including CIFAR-10 and CIFAR-100, with an average search time of 33 GPU seconds. Even under MobileNetV3 search space, MetaD2A is 5.5K times faster than NSGANetV2, a transferable NAS method, with comparable performance. We believe that the MetaD2A proposes a new research direction for rapid NAS as well as ways to utilize the knowledge from rich databases of datasets and architectures accumulated over the past years. Code is available at https://github.com/HayeonLee/MetaD2A. * These authors contributed equally to this work. arXiv:2107.00860v1 [cs.LG] 2 Jul 2021 Published as a conference paper at ICLR 2021 Conventional NAS Approach Training NAS Model NAS Model NAS Model",
    "prev": "While existing meta-prediction models only support set-conditioned prediction, the proposed meta-prediction model, DaSS performs the distillation-task-conditioned prediction.",
    "curr": "methods (Lee et al., 2021a;b;Jeong et al., 2021) and 2) zero-cost proxies (Mellor et al., 2021;Abdelfattah et al., 2021).",
    "next": "The former meta-NAS methods learn the generalized search process over multiple tasks, allowing it to adapt to a novel unseen task by transferring the knowledge obtained over the meta-learning phase to the new task without training the NAS framework from scratch.",
    "hard_negative": [
      170078603,
      209531937,
      214184365,
      54438210,
      49868626,
      5590763
    ],
    "easy_negative": [
      16703040,
      219300900,
      219307725
    ]
  },
  {
    "index": 2311,
    "source_corpus_id": 239768818,
    "ref_id": "b62",
    "citation_corpus_id": 14124313,
    "start": 3582,
    "end": 3611,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "Despite this, FLOPs has been used as the most common cost indicator in many research papers, especially in the recent computer vision literature, to quantify model efficiency (Szegedy et al., 2015;He et al., 2016;Feichtenhofer et al., 2019;Fan et al., 2021).",
    "curr": "Likewise, the number of trainable parameters (size of the model) despite being commonly used as the de-facto cost indicator in the NLP community (Devlin et al., 2018;Lan et al., 2019) and previously the vision community (Krizhevsky et al., 2012;Simonyan and Zisserman, 2015;Huang et al., 2017;, can also be misleading when used as a standalone measure of efficiency.",
    "next": "Intuitively, a model can have very few trainable parameters and still be very slow, for instance when the parameters are shared among many computational steps (Lan et al., 2019;Dehghani et al., 2018).",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      7864490,
      261342042,
      222177140
    ]
  },
  {
    "index": 2315,
    "source_corpus_id": 247693714,
    "ref_id": "b19",
    "citation_corpus_id": 202888986,
    "start": 1788,
    "end": 1806,
    "title": "Published as a conference paper at ICLR 2020 ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS",
    "abstract": "Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameterreduction techniques to lower memory consumption and increase the training speed of BERT (Devlin et al., 2019). Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT.Published as a conference paper at ICLR 2020 These solutions address the memory limitation problem, but not the communication overhead. In this paper, we address all of the aforementioned problems, by designing A Lite BERT (ALBERT) architecture that has significantly fewer parameters than a traditional BERT architecture.ALBERT incorporates two parameter reduction techniques that lift the major obstacles in scaling pre-trained models. The first one is a factorized embedding parameterization. By decomposing the large vocabulary embedding matrix into two small matrices, we separate the size of the hidden layers from the size of vocabulary embedding. This separation makes it easier to grow the hidden size without significantly increasing the parameter size of the vocabulary embeddings. The second technique is cross-layer parameter sharing. This technique prevents the parameter from growing with the depth of the network. Both techniques significantly reduce the number of parameters for BERT without seriously hurting performance, thus improving parameter-efficiency. An ALBERT configuration similar to BERT-large has 18x fewer parameters and can be trained about 1.7x faster. The parameter reduction techniques also act as a form of regularization that stabilizes the training and helps with generalization.To further improve the performance of ALBERT, we also introduce a self-supervised loss for sentence-order prediction (SOP). SOP primary focuses on inter-sentence coherence and is designed to address the ineffectiveness  of the next sentence prediction (NSP) loss proposed in the original BERT.As a result of these design decisions, we are able to scale up to much larger ALBERT configurations that still have fewer parameters than BERT-large but achieve significantly better performance. We establish new state-of-the-art results on the well-known GLUE, SQuAD, and RACE benchmarks for natural language understanding. Specifically, we push the RACE accuracy to 89.4%, the GLUE benchmark to 89.4, and the F1 score of SQuAD 2.0 to 92.2.",
    "prev": "Such a unified perspective comes timely for understanding the recent progress in SSL.",
    "curr": "INTRODUCTION\n\nBeyond the success of NLP (Lan et al., 2020;Radford et al., 2019;Devlin et al., 2019;Su et al., 2020;Nie et al., 2020), self-supervised learning (SSL) has also shown its potential in the field of vision tasks (Li et al., 2021;Chen et al., 2021;El-Nouby et al., 2021).",
    "next": "Without the ground-truth label, the core of most SSL methods lies in learning an encoder with augmentation-invariant representation (Bachman et al., 2019;He et al., 2020;Chen et al., 2020a;Caron et al., 2020;.",
    "hard_negative": [
      2937095,
      990233,
      3432876,
      102350771,
      1957433,
      3626819,
      5034059,
      11816014,
      47018994,
      4421747,
      16639476
    ],
    "easy_negative": [
      232021855,
      13422690,
      259370851
    ]
  },
  {
    "index": 2322,
    "source_corpus_id": 5144625,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 1660,
    "end": 1683,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "Using the library, we demonstrate concise and batch-wise parallel implementations for a variety of models from the literature.",
    "curr": "1  The library is called TensorFlow Fold and lives at\n\nINTRODUCTION\n\nTraining deep neural networks directly on minimally pre-processed corpora has led to many recent performance breakthroughs, mainly on problems in domains such as vision (Krizhevsky et al., 2012) and natural language (Bahdanau et al., 2015) where the inputs can be cast as dense n-dimensional arrays (henceforth tensors), or sequences of tensors.",
    "next": "These successes exploit the effectiveness of training via gradient descent on mini-batches of tens to hundreds of inputs, implemented using the parallel SIMD capabilities of modern GPUs (Oh & Jung, 2004) and multi-core CPUs (Vanhoucke et al., 2011).",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      17183883,
      1329203,
      7120497
    ]
  },
  {
    "index": 2327,
    "source_corpus_id": 246285344,
    "ref_id": "b59",
    "citation_corpus_id": 635609,
    "start": 8178,
    "end": 8201,
    "title": "Modeling Annotators: A Generative Approach to Learning from Annotator Rationales *",
    "abstract": "A human annotator can provide hints to a machine learner by highlighting contextual \"rationales\" for each of his or her annotations(Zaidan et al., 2007). How can one exploit this side information to better learn the desired parameters \u03b8? We present a generative model of how a given annotator, knowing the true \u03b8, stochastically chooses rationales. Thus, observing the rationales helps us infer the true \u03b8. We collect substring rationales for a sentiment classification task(Pang and Lee, 2004)and use them to obtain significant accuracy improvements for each annotator. Our new generative approach exploits the rationales more effectively than our previous \"masking SVM\" approach. It is also more principled, and could be adapted to help learn other kinds of probabilistic classifiers for quite different tasks.",
    "prev": "Natural language explanations of decisions Previous work aimed at explaining computer vision classifiers using natural language has focused on generating explanations for individual classification decisions (e.g., Hendricks et al., 2016;Park et al., 2018;Zellers et al., 2019).",
    "curr": "Outside of computer vision, several recent papers have proposed procedures for generating natural language explanations of decisions in text classification models (Zaidan & Eisner, 2008;Camburu et al., 2018;Rajani et al., 2019;Narang et al., 2020) and of representations in more general sequence modeling problems ).",
    "next": "These approaches require task-specific datasets and often specialized training procedures, and do not assist with interpretability at the model level.",
    "hard_negative": [
      15260546,
      388,
      3061036,
      7105713
    ],
    "easy_negative": [
      256460956,
      257637230,
      252819443
    ]
  },
  {
    "index": 2328,
    "source_corpus_id": 260438589,
    "ref_id": "b101",
    "citation_corpus_id": 252715691,
    "start": 8964,
    "end": 8968,
    "title": "GLM-130B: AN OPEN BILINGUAL PRE-TRAINED MODEL",
    "abstract": "We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model at least as good as GPT-3 and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we face numerous unexpected technical and engineering challenges, particularly on loss spikes and disconvergence. In this paper, we introduce the training process of GLM-130B including its design choices, training strategies for both efficiency and stability, and engineering efforts. The resultant GLM-130B model offers significant outperformance over GPT-3 175B on a wide range of popular English benchmarks while the performance advantage is not observed in OPT-175B and BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN 3.0 260B-the largest Chinese language model-across related benchmarks. Finally, we leverage a unique scaling property of GLM-130B to reach INT4 quantization, without quantization aware training and with almost no performance loss, making it the first among 100B-scale models. More importantly, the property allows its effective inference on 4\u00d7RTX 3090 (24G) or 8\u00d7RTX 2080 Ti (11G) GPUs, the most ever affordable GPUs required for using 100B-scale models. The GLM-130B model weights are publicly accessible and its code, training logs, related toolkit, and lessons learned are open-sourced at https://github.comIn this work, we introduce the pre-training of a 100B-scale model-GLM-130B, in terms of engineering efforts, model design choices, training strategies for efficiency and stability, and quantization for affordable inference. As it has been widely realized that it is computationally unaffordable to empirically enumerate all possible designs for training 100B-scale LLMs, we present not only the successful part for training GLM-130B but also many of the failed options and lessons learned. Particularly, the training stability is the decisive factor in the success of training models of such a scale. Different from practices such as manually adjusting learning rates in OPT-175B and using embedding norm in the sacrifice of performance in BLOOM-176B, we experiment with various options and find the strategy of embedding gradient shrink can significantly stabilize the training of GLM-130B.Specifically, GLM-130B is a bilingual (English and Chinese) bidirectional dense model with 130 billion parameters, pre-trained over 400 billion tokens on a cluster of 96 NVIDIA DGX-A100 (8\u00d740G) GPU nodes between May 6 and July 3, 2022. Instead of using the GPT-style architecture, we adopt the General Language Model (GLM) algorithm (Du et al., 2022)  to leverage its bidirectional attention advantage and autoregressive blank infilling objective.Table 1summarizes the comparison between GLM-130B, GPT-3 and another two open-source efforts-OPT-175B and BLOOM-176B, as well as PaLM 540B (Chowdhery et al., 2022)-a 4\u00d7 larger model-as a reference.Altogether, the conceptual uniqueness and engineering efforts enable GLM-130B to exhibit performance that surpasses the level of GPT-3 on a wide range of benchmarks (in total 112 tasks) and also outperforms PaLM 540B in many cases, while outperformance over GPT-3 has not been observed in OPT-175B and BLOOM-176B (Cf.Figure 1 (a)). For zero-shot performance, GLM-130B is better than GPT-3 175B (+5.0%), OPT-175B (+6.5%), and BLOOM-176B (+13.0%) on LAMBADA (Paperno et al., 2016), and achieves 3\u00d7 better performance than GPT-3 on Big-bench-lite (Srivastava  et al., 2022). For the 5-shot MMLU (Hendrycks et al., 2021) tasks, it is better than GPT-3 175B (+0.9%) and BLOOM-176B (+12.7%). As a bilingual LLM also in Chinese, it offers significantly better results than ERNIE TITAN 3.0 260B (Wang et al., 2021)-the largest Chinese LLM-on 7 zero-shot CLUE (Xu et al., 2020) datasets (+24.26%) and 5 zero-shot FewCLUE  ones (+12.75%). Importantly, as summarized inFigure 1 (b), GLM-130B as an open model is associated with significantly less bias and generation toxicity than its 100B-scale counterparts.Finally, we design GLM-130B to empower as many people as possible to conduct 100B-scale LLM studies. First, instead of using 175B+ parameters as OPT and BLOOM, the 130B size is decided because such a size supports inference on a single A100 (8\u00d740G) server. Second, to further lower the GPU requirements, we quantize GLM-130B into INT4 precision without quantization aware training while OPT and BLOOM can only reach INT8. Due to a unique property of the GLM architecture, GLM-130B's INT4 quantization introduces negligible performance degradation, e.g., -0.74% on LAMBADA and even +0.05% on MMLU, making it still better than the uncompressed GPT-3. This enables GLM-130B's fast inference with performance guarantee on a server of 4\u00d7RTX 3090 (24G) or 8\u00d7RTX 2080 Ti (11G), the most ever affordable GPU required for using 100B-scale LLMs to date.We open-source the model checkpoints, code, training logs, related toolkits, and lessons learned.THE DESIGN CHOICES OF GLM-130BThe architecture of a machine learning model defines its inductive bias. However, it has been realized that it is computationally unaffordable to explore various architectural designs for LLMs. We introduce and explain the unique design choices of GLM-130B. 2.1 GLM-130B'S ARCHITECTURE GLM as Backbone. Most recent 100B-scale LLMs, such as GPT-3, PaLM, OPT, and BLOOM, follow the traditional GPT-style (Radford et al., 2019) architecture of decoder-only autoregressive language modeling. In GLM-130B, we instead make an attempt to explore the potential of a bidirectional GLM-General Language Model (Du et al., 2022)-as its backbone.GLM is a transformer-based language model that leverages autoregressive blank infilling as its training objective. Briefly, for a text sequence x = [x 1 , \u00b7 \u00b7 \u00b7 , x n ], text spans {s 1 , \u00b7 \u00b7 \u00b7 , s m } are sampled from it, each of which s i denotes a span of consecutive tokens [s i,1 , \u00b7 \u00b7 \u00b7 , s i,li ] and is replaced (i.e., corrupted) with a single mask token to form x corrupt . The model is asked to recover them autoregressively. To allow interactions between corrupted spans, their visibility to each other is decided by a He. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters.",
    "prev": "However, there is a growing concern that these leading institutes are becoming increasingly conservative in sharing the technical details of their models and roadmaps.",
    "curr": "To catch up with the performance of ChatGPT, the open-source community has devoted substantial efforts [80,90,77,17,102,29,104].",
    "next": "For instance, Self-Instruct [90] introduced an iterative bootstrapping algorithm that leverages offthe-shelf LLMs and a seed set of manually-written instructions to expand the instruction collection.",
    "hard_negative": [
      3782112,
      215745536,
      202539496,
      237416585
    ],
    "easy_negative": [
      237494677,
      6626048,
      18446213
    ]
  },
  {
    "index": 2330,
    "source_corpus_id": 252872997,
    "ref_id": "b21",
    "citation_corpus_id": 202539551,
    "start": 4811,
    "end": 4833,
    "title": "Language Models as Knowledge Bases?",
    "abstract": "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as \"fillin-the-blank\" cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-theart pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https: //github.com/facebookresearch/LAMA.",
    "prev": "Large language models (LLMs), such as GPT-3 (Brown et al., 2020), show remarkable world knowledge on a variety of topics.",
    "curr": "They can be thought of as implicit knowledge bases, noisily condensing the collective knowledge of the Internet in a way that can be easily queried with natural language (Petroni et al., 2019).",
    "next": "As people often write about what things look like, this includes knowledge of visual descriptors.",
    "hard_negative": [
      3226120,
      53296520,
      2924682,
      52113185,
      108300988,
      3626819,
      5034059,
      11816014,
      85205,
      8781666,
      4612975
    ],
    "easy_negative": [
      232335602,
      3524955,
      11025406
    ]
  },
  {
    "index": 2331,
    "source_corpus_id": 264306115,
    "ref_id": "b25",
    "citation_corpus_id": 254408495,
    "start": 1835,
    "end": 1857,
    "title": "Published as a conference paper at ICLR 2023 EDITING MODELS WITH TASK ARITHMETIC",
    "abstract": "Changing how pre-trained models behave-e.g., improving their performance on a downstream task or mitigating biases learned during pre-training-is a common practice when developing machine learning systems. In this work, we propose a new paradigm for steering the behavior of neural networks, centered around task vectors. A task vector specifies a direction in the weight space of a pre-trained model, such that movement in that direction improves performance on the task. We build task vectors by subtracting the weights of a pre-trained model from the weights of the same model after fine-tuning on a task. We show that these task vectors can be modified and combined together through arithmetic operations such as negation and addition, and the behavior of the resulting model is steered accordingly. Negating a task vector decreases performance on the target task, with little change in model behavior on control tasks. Moreover, adding task vectors together can improve performance on multiple tasks at once. Finally, when tasks are linked by an analogy relationship of the form \"A is to B as C is to D\", combining task vectors from three of the tasks can improve performance on the fourth, even when no data from the fourth task is used for training. Overall, our experiments with several models, modalities and tasks show that task arithmetic is a simple, efficient and effective way of editing models. * Correspondence to gamaga@cs.washington.edu.1We use the term editing to refer to any intervention done to a model done after the pre-training stage.",
    "prev": "work and when can it fail?Here, we connect the inaccuracy of weighted-averaging to mismatches in the gradients and propose a new uncertainty-based scheme to improve the performance by reducing the mismatch.The connection also reveals implicit assumptions in other schemes such as averaging, task arithmetic, and Fisher-weighted averaging.Our new method gives consistent improvements for large language models and vision transformers, both in terms of performance and robustness to hyperparameters.",
    "curr": "INTRODUCTION\n\nMerging models through a weighted averaging of their parameters has recently found many applications in deep learning.For example, averaging checkpoints generated during various training runs can improve out-of-distribution generalization (Izmailov et al., 2018;Wortsman et al., 2022b;Gao et al., 2022, inter alia), while averaging models trained on different datasets can borrow knowledge from \"donor tasks\" (Matena & Raffel, 2022) and enforce specific fine-grained behaviors in models (Ilharco et al., 2023;Daheim et al., 2023).The latter is particularly attractive for post-hoc \"editing\" of large pretrained models without retraining, for instance, to remove toxicity from a large language model (LLM).Simple weighted-averaging appears to tackle many difficult knowledge transfer and adaptation problems that machine learning methods have struggled to solve in the past.",
    "next": "The reasons behind the effectiveness of weighted-averaging methods are not well understood.The diversity in applications has led to a large number of averaging schemes, including arithmetic mean (Wortsman et al., 2022b;a), linear interpolation (Ilharco et al., 2023;Ortiz-Jimenez et al., 2023;Yadav et al., 2023), or individual parameter weighing (Matena & Raffel, 2022;Daheim et al., 2023).A prominent hypothesis, known as 'linear mode connectivity', is that when the models land in relatively few low-loss basins their interpolation again lies in them (Frankle et al., 2020;Neyshabur et al., 2020;Wortsman et al., 2022a;Ainsworth et",
    "hard_negative": [
      237416585,
      3693334,
      233296808,
      235313967,
      218487733,
      240288835,
      218487109,
      5034059,
      248693452,
      239050360,
      11816014,
      249147353,
      218500588
    ],
    "easy_negative": [
      7433414,
      248300047,
      11199936
    ]
  },
  {
    "index": 2333,
    "source_corpus_id": 222134085,
    "ref_id": "b26",
    "citation_corpus_id": 3833554,
    "start": 2265,
    "end": 2268,
    "title": "Wasserstein Auto-Encoders",
    "abstract": "We propose the Wasserstein Auto-Encoder (WAE)-a new algorithm for building a generative model of the data distribution. WAE minimizes a penalized form of the Wasserstein distance between the model distribution and the target distribution, which leads to a different regularizer than the one used by the Variational Auto-Encoder (VAE) [1]. This regularizer encourages the encoded training distribution to match the prior. We compare our algorithm with several other techniques and show that it is a generalization of adversarial auto-encoders (AAE)[2]. Our experiments show that WAE shares many of the properties of VAEs (stable training, encoder-decoder architecture, nice latent manifold structure) while generating samples of better quality, as measured by the FID score.",
    "prev": "Finally, we conduct extensive experiments to show that the new proposed autoencoders have favorable performance in learning latent manifold structure, image generation ,and reconstruction.",
    "curr": "Introduction\n\nIn recent years, autoencoders have been used widely as important frameworks in several machine learning and deep learning models, such as generative models [18,27,20] and representation learning models [29].",
    "next": "Formally, autoencoders consist of two components, namely, an encoder and a decoder.",
    "hard_negative": [
      11758569,
      15876696
    ],
    "easy_negative": [
      6149379,
      22336489,
      5620914
    ]
  },
  {
    "index": 2334,
    "source_corpus_id": 248506064,
    "ref_id": "b59",
    "citation_corpus_id": 423406,
    "start": 3433,
    "end": 3437,
    "title": "LEARNING TO COMPOSE WORDS INTO SENTENCES WITH REINFORCEMENT LEARNING",
    "abstract": "We use reinforcement learning to learn tree-structured neural networks for computing representations of natural language sentences. In contrast with prior work on tree-structured models in which the trees are either provided as input or predicted using supervision from explicit treebank annotations, the tree structures in this work are optimized to improve performance on a downstream task. Experiments demonstrate the benefit of learning task-specific composition orders, outperforming both sequential encoders and recursive encoders based on treebank annotations. We analyze the induced trees and show that while they discover some linguistically intuitive structures (e.g., noun phrases, simple verb phrases), they are different than conventional English syntactic structures.",
    "prev": "INTRODUCTION\n\nDiscrete variational auto-encoders (VAEs) are able to represent structured latent spaces in generative learning.",
    "curr": "Consequently VAEs drive extensive research in machine learning applications, including language classification and generation [60,17,54,9,13], molecular synthesis [28,15,48], speech and visual understanding [36,55,3].",
    "next": "Compared to their continuous counterparts, they can improve interpretability by illustrating which terms contributed to the solution [48,40], and they can facilitate the encoding of inductive biases in the learning process, such as images consisting of a small number of objects [12] or tasks requiring intermediate alignments [36,42,1,2].",
    "hard_negative": [
      14429450,
      3116311,
      1364249,
      990233,
      11334816,
      14386356,
      11440692,
      3033526,
      1957433,
      10421567,
      1727568,
      1306065,
      9672033
    ],
    "easy_negative": [
      256662537,
      1223945,
      1416139
    ]
  },
  {
    "index": 2335,
    "source_corpus_id": 235899304,
    "ref_id": "b43",
    "citation_corpus_id": 232146022,
    "start": 3013,
    "end": 3031,
    "title": "Published as a conference paper at ICLR 2021 SHAPLEY EXPLANATION NETWORKS",
    "abstract": "Shapley values have become one of the most popular feature attribution explanation methods. However, most prior work has focused on post-hoc Shapley explanations, which can be computationally demanding due to its exponential time complexity and preclude model regularization based on Shapley explanations during training. Thus, we propose to incorporate Shapley values themselves as latent representations in deep models-thereby making Shapley explanations first-class citizens in the modeling paradigm. This intrinsic explanation approach enables layer-wise explanations, explanation regularization of the model during training, and fast explanation computation at test time. We define the Shapley transform that transforms the input into a Shapley representation given a specific function. We operationalize the Shapley transform as a neural network module and construct both shallow and deep networks, called SHAPNETs, by composing Shapley modules. We prove that our Shallow SHAPNETs compute the exact Shapley values and our Deep SHAPNETs maintain the missingness and accuracy properties of Shapley values. We demonstrate on synthetic and real-world datasets that our SHAPNETs enable layer-wise Shapley explanations, novel Shapley regularizations during training, and fast computation while maintaining reasonable performance. Code is available at https: //github.com/inouye-lab/ShapleyExplanationNetworks.",
    "prev": "First, many works have proposed stochastic estimators (Castro et al., 2009;\u0160trumbelj and Kononenko, 2014;Lundberg and Lee, 2017;Covert et al., 2020) that rely on sampling either feature subsets or permutations; though often consistent, these estimators require many model evaluations and impose an undesirable trade-off between run-time and accuracy.",
    "curr": "Second, some works have proposed model-specific approximations, e.g., for trees  or neural networks (Shrikumar et al., 2017;Chen et al., 2018b;Ancona et al., 2019;Wang et al., 2021); while generally faster, these approaches can still require many model evaluations, often induce bias, and typically lack flexibility regarding the handling held-out features-a subject of ongoing debate in the field (Aas et al., 2019;Janzing et al., 2020;Frye et al., 2020;.",
    "next": "Here, we introduce a new approach for efficient Shapley value estimation: to achieve the fastest possible run-time, we propose learning a separate explainer model that outputs precise Shapley value estimates in a single forward pass.",
    "hard_negative": [
      195218693,
      6628106,
      17127188,
      25717172,
      1450294,
      51942590,
      222134093,
      49214673
    ],
    "easy_negative": [
      8994601,
      57841958,
      256461095
    ]
  },
  {
    "index": 2337,
    "source_corpus_id": 73664641,
    "ref_id": "b26",
    "citation_corpus_id": 3366315,
    "start": 25373,
    "end": 25394,
    "title": "Published as a conference paper at ICLR 2018 SPECTRAL NORMALIZATION FOR GENERATIVE ADVERSARIAL NETWORKS",
    "abstract": "One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_ projection.Published as a conference paper at ICLR 2018\u2022 Lipschitz constant is the only hyper-parameter to be tuned, and the algorithm does not require intensive tuning of the only hyper-parameter for satisfactory performance. \u2022 Implementation is simple and the additional computational cost is small.",
    "prev": "GANs analysis (Sample selection)\n\nWe also applied mmdInf for evaluating the generation quality of GANs.",
    "curr": "We trained BEGAN [Berthelot et al., 2017], DCGAN [Radford et al., 2015], STDGAN [Miyato et al., 2017], Cramer GAN [Bellemare et al., 2017], DFM [Warde-Farley and Bengio, 2016], DRAGAN [Kodali et al., 2017], and Minibatch Discrimination GAN [Salimans et al., 2016], generated 5000 images (using Chainer GAN package 1 with CIFAR10 datasets), and extracted 512 dimensional features by pre-trained Resnet18 [He et al., 2016].",
    "next": "For the true image sets, we subsampled 5000 images from CIFAR10 datasets and computed the 512 dimensional features using the same Resnet18.",
    "hard_negative": [
      6628106,
      5687613,
      18828233,
      3633127,
      14570343,
      11758569
    ],
    "easy_negative": [
      12271006,
      6778398,
      67724965
    ]
  },
  {
    "index": 2338,
    "source_corpus_id": 264306305,
    "ref_id": "b19",
    "citation_corpus_id": 209439843,
    "start": 8637,
    "end": 8641,
    "title": "MEASURING COMPOSITIONAL GENERALIZATION: A COMPREHENSIVE METHOD ON REALISTIC DATA",
    "abstract": "State-of-the-art machine learning methods exhibit limited compositional generalization. At the same time, there is a lack of realistic benchmarks that comprehensively measure this ability, which makes it challenging to find and evaluate improvements. We introduce a novel method to systematically construct such benchmarks by maximizing compound divergence while guaranteeing a small atom divergence between train and test sets, and we quantitatively compare this method to other approaches for creating compositional generalization benchmarks. We present a large and realistic natural language question answering dataset that is constructed according to this method, and we use it to analyze the compositional generalization ability of three machine learning architectures. We find that they fail to generalize compositionally and that there is a surprisingly strong negative correlation between compound divergence and accuracy. We also demonstrate how our method can be used to create new compositionality benchmarks on top of the existing SCAN dataset, which confirms these findings. Radev. Improving text-to-SQL evaluation methodology. In ACL, 2018. URL http://aclweb.org/anthology/P18-1033.Jerry A Fodor and Zenon W Pylyshyn. Connectionism and cognitive architecture: A critical analysis. Cognition, 28(1-2):3-71, 1988. URL https://pdfs.semanticscholar.org/d806/ 76034bfabfea59f35698af0f715a555fcf50.pdf.",
    "prev": ".",
    "curr": "., C p ) is a predefined, ordered list of attributes and \u039b Cp i selects the value in the C p -th attribute that is most relevant to S i .Note that \u03b1 \u2191 only depends on a single object and trivially generalizes to different compositions of objects [20].",
    "next": "Compositional Generalization: To formalize CG, we first formalize compositions.We assume that each state in our MDP can be decomposed using two sets of elements: compounds and atoms.Compounds are sets of elements that can be decomposed into smaller sets of elements, and atoms are sets of elements that cannot be decomposed further.For instance, in the block pushing domain (Figure 1), we can designate each unique object as an atom and designate the co-occurrence of a set of atoms in a scene as a compound.We use A to denote the elements designated to be the atoms and C to denote the compounds.The frequency distribution of the atoms is F A (D) and the frequency distribution of the compositions is F C (D).Given this, compositional generalization is expressed as a property of the train distribution D train and of the test distribution D test undergoing a distributional shift of the compounds, while the distribution of atoms remains the same.",
    "hard_negative": [
      969059,
      3728944,
      348944,
      108296442,
      85504763,
      3986974,
      2711679
    ],
    "easy_negative": [
      12469103,
      2427127,
      13992738
    ]
  },
  {
    "index": 2342,
    "source_corpus_id": 264172506,
    "ref_id": "b0",
    "citation_corpus_id": 256846836,
    "start": 8242,
    "end": 8263,
    "title": "Universal Guidance for Diffusion Models",
    "abstract": "Typical diffusion models are trained to accept a particular form of conditioning, most commonly text, and cannot be conditioned on other modalities without retraining. In this work, we propose a universal guidance algorithm that enables diffusion models to be controlled by arbitrary guidance modalities without the need to retrain any use-specific components. We show that our algorithm successfully generates quality images with guidance functions including segmentation, face recognition, object detection, and classifier signals. Code is available at github.com/arpitbansal297/Universal-Guided-Diffusion.",
    "prev": "We also demonstrate the scalability and universality of our method in text-to-image scenarios by incorporating CLIP  guidance with our design.",
    "curr": "In comparison, we find that the operation of increasing recurrent guidance [Bansal et al., 2023] does not fully exploit the potential and comes at the expense of increasing sampling time.",
    "next": "Related Work\n\nDiffusion models have gained considerable attention due to their capacity and potential.",
    "hard_negative": [
      222140788,
      227209335
    ],
    "easy_negative": [
      219308128,
      21701426,
      13176504
    ]
  },
  {
    "index": 2349,
    "source_corpus_id": 232290456,
    "ref_id": "b17",
    "citation_corpus_id": 211296452,
    "start": 8319,
    "end": 8340,
    "title": "DIFFERENTIABLE REASONING OVER A VIRTUAL KNOWLEDGE BASE",
    "abstract": "We consider the task of answering complex multi-hop questions using a corpus as a virtual knowledge base (KB). In particular, we describe a neural module, DrKIT, that traverses textual data like a KB, softly following paths of relations between mentions of entities in the corpus. At each step the module uses a combination of sparse-matrix TFIDF indices and a maximum inner product search (MIPS) on a special index of contextual representations of the mentions. This module is differentiable, so the full system can be trained end-to-end using gradient based methods, starting from natural language inputs. We also describe a pretraining scheme for the contextual representation encoder by generating hard negative examples using existing knowledge bases. We show that DrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset, cutting the gap between text-based and KB-based state-of-the-art by 70%. On HotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking approach to retrieving the relevant passages required to answer a question. DrKIT is also very efficient, processing 10-100x more queries per second than existing multi-hop systems. 1 * Part of this work was done during an internship at Google. 1",
    "prev": "Among them, multi-hop reasoning is the ability to reason with information collected from multiple passages to derive the answer (Wang et al., 2019a), and it gives a discrete intermediate output of the reasoning process, which can help gauge model's behavior beyond just the final task accuracy .",
    "curr": "Several multi-hop datasets and models have been proposed for the reading comprehension task (Welbl et al., 2018;Yang et al., 2018b;Dua et al., 2019;Dhingra et al., 2020).",
    "next": "We extend multihop reasoning to the video domain by developing a dataset that explicitly requires aggregating clues from different spatiotemporal parts of the video, as well as a multi-hop model that automatically extracts a step-by-step reasoning chain, which improves interpretability and imitates a natural way of thinking.",
    "hard_negative": [
      3618568,
      128345225,
      3986974,
      208267807,
      173990818,
      53218215,
      6018348,
      153312687,
      189927857,
      108300988,
      202773198,
      155100120,
      202558815,
      5011300,
      131773797,
      202660724
    ],
    "easy_negative": [
      13068050,
      20943355,
      10936120
    ]
  },
  {
    "index": 2352,
    "source_corpus_id": 252780742,
    "ref_id": "b21",
    "citation_corpus_id": 56657912,
    "start": 7176,
    "end": 7206,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "(2021);Herrmann et al.",
    "curr": "(2022) showed that carefully tuning the threat model in adversarial training might improve the performance on clean images and in the presence of distribution shifts, such as common corruptions (Hendrycks & Dietterich, 2018).",
    "next": "Adapters.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      12991853,
      27969339,
      49231593
    ]
  },
  {
    "index": 2353,
    "source_corpus_id": 199552081,
    "ref_id": "b4",
    "citation_corpus_id": 990233,
    "start": 1799,
    "end": 1802,
    "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
    "prev": "The StructBERT with structural pre-training gives surprisingly good empirical results on a variety of downstream tasks, including pushing the state-of-the-art on the GLUE benchmark to 84.5 (with Top 1 achievement on the Leaderboard at the time of paper submission), the F1 score on SQuAD v1.1 question answering to 93.0, the accuracy on SNLI to 91.7.",
    "curr": "Introduction\n\nPre-trained language models are a key component in many natural language understanding (NLU) tasks such as semantic textual similarity [3], question answering [4] and sentiment classification [5].",
    "next": "In order to get reliable language representations, neural language models are designed to define the joint probability function of sequences of words in text with unsupervised learning.",
    "hard_negative": [
      5584134,
      2279432,
      3116311,
      7747235,
      15659560,
      1588782,
      806709,
      2678583,
      3264224,
      15616495,
      2091504
    ],
    "easy_negative": [
      15139384,
      1543286,
      46328987
    ]
  },
  {
    "index": 2355,
    "source_corpus_id": 209315801,
    "ref_id": "b13",
    "citation_corpus_id": 3693334,
    "start": 4984,
    "end": 5001,
    "title": "Visualizing the Loss Landscape of Neural Nets",
    "abstract": "Neural network training relies on our ability to find \"good\" minimizers of highly non-convex loss functions. It is well-known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and wellchosen training parameters (batch size, learning rate, optimizer) produce minimizers that generalize better. However, the reasons for these differences, and their effects on the underlying loss landscape, are not well understood. In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple \"filter normalization\" method that helps us visualize loss function curvature and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture affects the loss landscape, and how training parameters affect the shape of minimizers.",
    "prev": "However, if flatness is taken to be the curvature as measured by the second order approximation of the loss, then counterexamples exist.",
    "curr": "In (Dinh et al., 2017), the authors transform a flat minimizer into a sharp one without changing the behavior of the model, and in (Li et al., 2018), the authors show the reverse behavior when weight-decay is not used.",
    "next": "In (McCandlish et al., 2018), the authors predict that the batch size can be increased up to a critical size without any drop in accuracy and empirically validate this claim.",
    "hard_negative": [
      14124313,
      4429876,
      16138044,
      17786716,
      16209268
    ],
    "easy_negative": [
      247446894,
      246634966,
      258841031
    ]
  },
  {
    "index": 2364,
    "source_corpus_id": 207930593,
    "ref_id": "b26",
    "citation_corpus_id": 2593903,
    "start": 15879,
    "end": 15901,
    "title": "The NarrativeQA Reading Comprehension Challenge",
    "abstract": "Reading comprehension (RC)-in contrast to information retrieval-requires integrating information and reasoning about events, entities, and their relations across a full document. Question answering is conventionally used to assess RC ability, in both artificial agents and children learning to read. However, existing RC datasets and tasks are dominated by questions that can be solved by selecting answers using superficial information (e.g., local context similarity or global term frequency); they thus fail to test for the essential integrative aspect of RC. To encourage progress on deeper comprehension of language, we present a new dataset and set of tasks in which the reader must answer questions about stories by reading entire books or movie scripts. These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience. We show that although humans solve the tasks easily, standard RC models struggle on the tasks presented here. We provide an analysis of the dataset and the challenges it presents.",
    "prev": "(2018)) however BookCorpus is no longer distributed due to licensing issues, and the source of data is dynamically changing -which makes exact benchmarking difficult over time.",
    "curr": "The NarrativeQA Book Comprehension Task (Ko\u010disk\u1ef3 et al., 2018) uses Project Gutenberg texts paired with Wikipedia articles, which can be used as summaries.",
    "next": "Due to the requirement of needing a corresponding summary, NarrativeQA contains a smaller selection of books: 1,527 versus the 28,752 books in PG-19.",
    "hard_negative": [
      6360322,
      10299779,
      88504965,
      2625301,
      11022639,
      12131248,
      1957433,
      782782,
      11816014,
      2100831,
      4986998,
      12501880,
      14915449
    ],
    "easy_negative": [
      8493310,
      237365057,
      249191630
    ]
  },
  {
    "index": 2367,
    "source_corpus_id": 247158476,
    "ref_id": "b44",
    "citation_corpus_id": 3292002,
    "start": 3953,
    "end": 3978,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "Our work provides a surprising challenge to this wisdom by providing an isotropic model, called Efficient Graph Convolution (EGC),\n\nx Messages are functions of source and target nodes and hence must be materialized\nAnisotropic b f ( x , b ) a f ( x , a ) c f ( x , c ) d f ( x , d )\nx Messages are functions of source only; propagation can be implemented using matrix multiplication-style approaches Figure 1: Many GNN architectures (e.g.",
    "curr": "GAT (Veli\u010dkovi\u0107 et al., 2018), PNA (Corso et al., 2020)) incorporate sophisticated message functions to improve accuracy (left).",
    "next": "This is problematic as we must materialize messages, leading to O(E) memory consumption and OPs to calculate messages; these dataflow patterns are also difficult to optimize for at the hardware level.",
    "hard_negative": [
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      233304856,
      202774140,
      53081529
    ]
  },
  {
    "index": 2375,
    "source_corpus_id": 260440513,
    "ref_id": "b17",
    "citation_corpus_id": 1957433,
    "start": 6778,
    "end": 6802,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "BASIC DESIGN OF MACHINE COMPREHENSION MODELS\n\nFor single-turn MC, many top-performing models share a similar architecture, consisting of four major components: (1) question encoding, (2) context encoding, (3) reasoning, and finally (4) answer prediction.",
    "curr": "Initially the word embeddings (e.g., Pennington et al., 2014;Peters et al., 2018) of question tokens Q and context tokens C are taken as input and fed into contextual integration layers, such as LSTMs (Hochreiter & Schmidhuber, 1997) or self attentions (Yu et al., 2018), to encode the question and context.",
    "next": "Multiple integration layers provide contextualized representations of context, and are often inter-weaved with attention, which inject question information.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      14432659,
      216642112,
      14471353
    ]
  },
  {
    "index": 2376,
    "source_corpus_id": 257038392,
    "ref_id": "b10",
    "citation_corpus_id": 233296808,
    "start": 5961,
    "end": 5982,
    "title": "The Power of Scale for Parameter-Efficient Prompt Tuning",
    "abstract": "In this work, we explore \"prompt tuning,\" a simple yet effective mechanism for learning \"soft prompts\" to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3's few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method \"closes the gap\" and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed \"prefix tuning\" of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient \"prompt ensembling.\" We release code and model checkpoints to reproduce our experiments. 1ReferencesRoy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro,  Danilo Giampiccolo, Bernardo Magnini, and Idan  Szpektor. 2006. The second PASCAL recognising textual entailment challenge. In Proceedings of the second PASCAL challenges workshop on recognising textual entailment, volume 6, pages 6-4. Venice. . 2019a. SuperGLUE: A stickier benchmark for general-purpose language understanding systems. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.",
    "prev": "While automatically induced prompts suffer of issues such as low-interpretability, we think it is important to continue focusing on them because, besides their better performance (a result we confirm here for AutoPrompt across a range of LMs), they are more promising than manual prompts in terms of scalability, especially in contexts in which it is not sufficient to formulate a single prompt template for a whole task, but each input query demands a distinct prompt formulation (Zhang et al., 2022).",
    "curr": "Concurrent and later work has proposed to replace discrete strings, such as those generated by AutoPrompt, with sequences of arbitrary vectors from the LM's embedding space (Lester et al., 2021;Zhong et al., 2021).",
    "next": "We confirm here that these continuous, or \"soft\" prompts outperform AutoPrompt when trained and tested on the same LM.",
    "hard_negative": [
      3626819,
      40100965,
      155091369,
      204960716,
      11816014,
      230433941,
      218470133,
      233231453
    ],
    "easy_negative": [
      220445624,
      244117423,
      174800674
    ]
  },
  {
    "index": 2378,
    "source_corpus_id": 210919941,
    "ref_id": "b22",
    "citation_corpus_id": 5151364,
    "start": 22747,
    "end": 22768,
    "title": "THE PENN TREEBANK: ANNOTATING PREDICATE ARGUMENT STRUCTURE",
    "abstract": "The Penn Treebank has recently implemented a new syntactic annotation scheme, designed to highlight aspects of predicate-argument structure.This paper discusses the implementation of crucial aspects of this new annotation scheme. It incorporates a more consistent treatment of a wide range of grammatical phenomena, provides a set of coindexed null elements in what can be thought of as \"underlying\" position for phenomena such as wh-movement, passive, and the subjects of infinitival constructions, provides some non-context free annotational mechanism to allow the structure of discontinuous constituents to be easily recovered, and allows for a clear, concise tagging system for some semantic roles.",
    "prev": "We compare Sparse SpiderBoost, SpiderBoost, and SGD.",
    "curr": "We train our LSTM model on the Penn Treebank (Marcus et al., 1994) corpus.",
    "next": "The natural language processing model consists of a word embedding of dimension 128 of 1000 tokens, which is jointly learned with the task.",
    "hard_negative": [
      5410054,
      17643319,
      16624536,
      5598810,
      252796
    ],
    "easy_negative": [
      13936107,
      2588556,
      15275167
    ]
  },
  {
    "index": 2386,
    "source_corpus_id": 211532691,
    "ref_id": "b6",
    "citation_corpus_id": 53115163,
    "start": 2634,
    "end": 2654,
    "title": "EXPLORATION BY RANDOM NETWORK DISTILLATION",
    "abstract": "We introduce an exploration bonus for deep reinforcement learning methods that is easy to implement and adds minimal overhead to the computation performed. The bonus is the error of a neural network predicting features of the observations given by a fixed randomly initialized neural network. We also introduce a method to flexibly combine intrinsic and extrinsic rewards. We find that the random network distillation (RND) bonus combined with this increased flexibility enables significant progress on several hard exploration Atari games. In particular we establish state of the art performance on Montezuma's Revenge, a game famously difficult for deep reinforcement learning methods. To the best of our knowledge, this is the first method that achieves better than average human performance on this game without using demonstrations or having access to the underlying state of the game, and occasionally completes the first level.",
    "prev": "Inspired by human learning, the use of intrinsic motivation has been proposed to encourage agents to learn about their environments even when extrinsic feedback is rarely provided (Schmidhuber, 1991b;2010;Oudeyer et al., 2007;Oudeyer & Kaplan, 2009).",
    "curr": "This type of exploration bonus emboldens the agent to visit new states (Bellemare et al., 2016;Burda et al., 2019b;Ecoffet et al., 2019) or to improve its knowledge and forward prediction of the world dynamics (Pathak et al., 2017;Burda et al., 2019a), and can be highly effective for learning in hard exploration games such as Montezuma's Revenge (Mnih et al., 2016).",
    "next": "However, most hard exploration environments used in previous work have either a limited state space or an easy way to measure similarity between states (Ecoffet et al., 2019) and generally use the same \"singleton\" environment for training and evaluation (Mnih et al., 2016;Burda et al., 2019a).",
    "hard_negative": [
      3461154,
      12256925
    ],
    "easy_negative": [
      221971169,
      5234044,
      17585795
    ]
  },
  {
    "index": 2389,
    "source_corpus_id": 202540355,
    "ref_id": "b35",
    "citation_corpus_id": 1185652,
    "start": 7191,
    "end": 7194,
    "title": "MODELING COMPOSITIONALITY WITH MULTIPLICATIVE RECURRENT NEURAL NETWORKS",
    "abstract": "We present the multiplicative recurrent neural network as a general model for compositional meaning in language, and evaluate it on the task of fine-grained sentiment analysis. We establish a connection to the previously investigated matrixspace models for compositionality, and show they are special cases of the multiplicative recurrent net. Our experiments show that these models perform comparably or better than Elman-type additive recurrent neural networks and outperform matrix-space models on a standard fine-grained sentiment analysis corpus. Furthermore, they yield comparable results to structural deep models on the recently published Stanford Sentiment Treebank without the need for generating parse trees.",
    "prev": "The key difference between our simplicial agent and the relational agent of [69] is that in place of a standard Transformer block we use a 2-simplicial Transformer block.",
    "curr": "Our use of tensor products of value vectors is inspired by the semantics of linear logic in vector spaces [25,47,14] in which an algorithm with multiple inputs computes on the tensor product of those inputs, but this is an old idea in natural language processing, used in models including the second-order RNN [22,50,27,23], multiplicative RNN [62,36], Neural Tensor Network [60] and the factored 3-way Restricted Boltzmann Machine [51], see Appendix D. More recently tensors have been used to model predicates in a number of neural network architectures aimed at logical reasoning [55,18].",
    "next": "The main novelty in our model lies in the introduction of the 2-simplicial attention, which allows these ideas to be incorporated into the Transformer architecture.",
    "hard_negative": [
      990233,
      806709,
      2678583,
      8360910,
      629094
    ],
    "easy_negative": [
      6021702,
      250390644,
      14720944
    ]
  },
  {
    "index": 2392,
    "source_corpus_id": 252284009,
    "ref_id": "b0",
    "citation_corpus_id": 14124313,
    "start": 1841,
    "end": 1844,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "Our code is available at DNC.",
    "curr": "INTRODUCTION\n\nDeep learning models, from convolutional networks (e.g., VGG [1], ResNet [2]) to Transformer-based architectures (e.g., Swin [3]), push forward the state-of-the-art on visual recognition.",
    "next": "With these advancements, parametric softmax classifiers, which learn a set of parameters, i.e., weight vector, and bias term, for each class, have become the de facto regime in the area ( Fig.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      218487704,
      505,
      250390471
    ]
  },
  {
    "index": 2395,
    "source_corpus_id": 3626819,
    "ref_id": "b40",
    "citation_corpus_id": 1957433,
    "start": 2164,
    "end": 2188,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "curr": "Introduction\n\nPre-trained word representations (Mikolov et al., 2013;Pennington et al., 2014) are a key component in many neural language understanding models.",
    "next": "However, learning high quality representations can be challenging.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      1104123
    ],
    "easy_negative": [
      19005379,
      256827819,
      202888735
    ]
  },
  {
    "index": 2406,
    "source_corpus_id": 221970302,
    "ref_id": "b3",
    "citation_corpus_id": 3618568,
    "start": 1725,
    "end": 1744,
    "title": "Reading Wikipedia to Answer Open-Domain Questions",
    "abstract": "This paper proposes to tackle opendomain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.",
    "prev": "INTRODUCTION\n\nOpen domain question answering is a challenging task where the answer to a given question needs to be extracted from a large pool of documents.",
    "curr": "The prevailing approach (Chen et al., 2017) tackles the problem in two stages.",
    "next": "Given a question, a retriever first produces a list of k candidate documents, and a reader then extracts the answer from this set.",
    "hard_negative": [
      6360322,
      14068874,
      12384779,
      1957433,
      11816014,
      10910955,
      5541486,
      216034672,
      11212020,
      14915449,
      2711679
    ],
    "easy_negative": [
      252568200,
      243865386,
      6243869
    ]
  },
  {
    "index": 2408,
    "source_corpus_id": 247245054,
    "ref_id": "b8",
    "citation_corpus_id": 3484654,
    "start": 1957,
    "end": 1976,
    "title": "RECASTING GRADIENT-BASED META-LEARNING AS HIERARCHICAL BAYES",
    "abstract": "Meta-learning allows an intelligent agent to leverage prior learning episodes as a basis for quickly improving performance on a novel task. Bayesian hierarchical modeling provides a theoretical framework for formalizing meta-learning as inference for a set of parameters that are shared across tasks. Here, we reformulate the model-agnostic meta-learning algorithm (MAML) of Finn et al.(2017)as a method for probabilistic inference in a hierarchical Bayesian model. In contrast to prior methods for meta-learning via hierarchical Bayes, MAML is naturally applicable to complex function approximators through its use of a scalable gradient descent procedure for posterior inference. Furthermore, the identification of MAML as hierarchical Bayes provides a way to understand the algorithm's operation as a meta-learning procedure, as well as an opportunity to make use of computational strategies for efficient inference. We use this opportunity to propose an improvement to the MAML algorithm that makes use of techniques from approximate inference and curvature estimation.",
    "prev": "They can readily establish their cognition and understanding of novel tasks, environments, or domains even with very limited experience in the corresponding circumstances.",
    "curr": "Meta-learning, a subfield of machine learning, aims at equipping machines with such capacity to accommodate new scenarios effectively (Vilalta & Drissi, 2002;Grant et al., 2018).",
    "next": "Machines learn to extract task-agnostic information so that their performance on unseen tasks can be improved (Hospedales et al., 2020).",
    "hard_negative": [
      4994434,
      15085443,
      6628106
    ],
    "easy_negative": [
      252819328,
      243865380,
      2579165
    ]
  },
  {
    "index": 2411,
    "source_corpus_id": 195584474,
    "ref_id": "b2",
    "citation_corpus_id": 14711954,
    "start": 4130,
    "end": 4132,
    "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
    "abstract": "We describe a framework for multitask deep reinforcement learning guided by policy sketches. Sketches annotate tasks with sequences of named subtasks, providing information about high-level structural relationships among tasks but not how to implement them-specifically not providing the detailed guidance used by much previous work on learning policy abstractions for RL (e.g. intermediate rewards, subtask completion signals, or intrinsic motivations). To learn from sketches, we present a model that associates every subtask with a modular subpolicy, and jointly maximizes reward over full task-specific policies by tying parameters across shared subpolicies. Optimization is accomplished via a decoupled actor-critic training objective that facilitates learning common behaviors from multiple dissimilar reward functions. We evaluate the effectiveness of our approach in three environments featuring both discrete and continuous control, and with sparse rewards that can be obtained only after completing a number of high-level subgoals. Experiments show that using our approach to learn policies guided by sketches gives better performance than existing techniques for learning task-specific or shared policies, while naturally inducing a library of interpretable primitive behaviors that can be recombined to rapidly adapt to new tasks.",
    "prev": "Each primitive focuses on distinct features of the environment; in this case, one policy focuses on boxes, a second one on gates, and the third one on spheres.",
    "curr": "master policy is trained on a particular state distribution, learning it in a way that generalizes to new environments effectively can, therefore, become the bottleneck for such approaches [31,3].",
    "next": "We argue, and empirically show, that in order to achieve better generalization, the interaction between the low-level primitives and the selection thereof should itself be performed without requiring a single centralized network that understands the entire state space.",
    "hard_negative": [
      9963298,
      806709,
      3130692,
      216034672,
      5249151
    ],
    "easy_negative": [
      9655587,
      5840519,
      163497374
    ]
  },
  {
    "index": 2422,
    "source_corpus_id": 195317051,
    "ref_id": "b9",
    "citation_corpus_id": 49657137,
    "start": 23060,
    "end": 23081,
    "title": "Robust and Scalable Differentiable Neural Computer for Question Answering",
    "abstract": "Deep learning models are often not easily adaptable to new tasks and require task-specific adjustments. The differentiable neural computer (DNC), a memoryaugmented neural network, is designed as a general problem solver which can be used in a wide range of tasks. But in reality, it is hard to apply this model to new tasks. We analyze the DNC and identify possible improvements within the application of question answering. This motivates a more robust and scalable DNC (rsDNC). The objective precondition is to keep the general character of this model intact while making its application more reliable and speeding up its required training time. The rsDNC is distinguished by a more robust training, a slim memory unit and a bidirectional architecture. We not only achieve new state-of-the-art performance on the bAbI task, but also minimize the performance variance between different initializations. Furthermore, we demonstrate the simplified applicability of the rsDNC to new tasks with passable results on the CNN RC task without adaptions.",
    "prev": "* denotes available results from (Santoro et al., 2016).",
    "curr": "Model\n\nError DNC  16.7 \u00b1 7.6 SDNC (Rae et al., 2016) 6.4 \u00b1 2.5 ADNC (Franke et al., 2018) 6.3 \u00b1 2.7 DNC-MD (Csordas & Schmidhuber, 2019) 9.5 \u00b1 1.6 NUTM (DNC core, p=1) 9.7 \u00b1 3.5 NUTM (DNC core, p=2) 7.5 \u00b1 1.6 NUTM (DNC core, p=4) 5.6 \u00b1 1.9 persistent memory mode, which demands fast forgetting old experiences in previous episodes, NUTM outperforms MANN significantly (10-20%) 4 .",
    "next": "Readers are referred to App.",
    "hard_negative": [
      6360322,
      6529193,
      6628106,
      11022639,
      1957433
    ],
    "easy_negative": [
      5912799,
      10801648,
      3153571
    ]
  },
  {
    "index": 2432,
    "source_corpus_id": 214107001,
    "ref_id": "b47",
    "citation_corpus_id": 1389483,
    "start": 1668,
    "end": 1672,
    "title": "Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints",
    "abstract": "Language is increasingly being used to define rich visual recognition problems with supporting image collections sourced from the web. Structured prediction models are used in these tasks to take advantage of correlations between co-occurring labels and visual input but risk inadvertently encoding social biases found in web corpora.In this work, we study data and models associated with multilabel object classification and visual semantic role labeling. We find that (a) datasets for these tasks contain significant gender bias and (b) models trained on these datasets further amplify existing bias. For example, the activity cooking is over 33% more likely to involve females than males in a training set, and a trained model further amplifies the disparity to 68% at test time. We propose to inject corpus-level constraints for calibrating existing structured prediction models and design an algorithm based on Lagrangian relaxation for collective inference. Our method results in almost no performance loss for the underlying recognition task but decreases the magnitude of bias amplification by 47.5% and 40.5% for multilabel classification and visual semantic role labeling, respectively.",
    "prev": "Introduction\n\nThere is an increasing interest in machine learning models to be credible, fair, and more generally interpretable [13].",
    "curr": "Researchers have explored various notions of model interpretability, ranging from trustability [30], fairness of a model [48], to characterizing the model's weak points [22,42].",
    "next": "Even though the goals of these various model interpretability tasks vary, the vast majority of them use so called feature-based explanation, that assign importances to individual features.",
    "hard_negative": [
      355848,
      2321969
    ],
    "easy_negative": [
      13051685,
      218514717,
      219302634
    ]
  },
  {
    "index": 2437,
    "source_corpus_id": 222310549,
    "ref_id": "b34",
    "citation_corpus_id": 14124313,
    "start": 2645,
    "end": 2673,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "Nowadays, as popularized by Convolutional Neural Networks (CNNs) (Krizhevsky et al., 2012), the features used for object recognition are automatically learned, rather than manually designed.",
    "curr": "This change not only eases human efforts on feature engineering, but also yields much better performance on a wide range of visual benchmarks (Simonyan & Zisserman, 2015;He et al., 2016;Girshick et al., 2014;Girshick, 2015;Ren et al., 2015;Long et al., 2015;Chen et al., 2015).",
    "next": "But interestingly, as pointed by Geirhos et al.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      13482942,
      908361,
      13993178
    ]
  },
  {
    "index": 2443,
    "source_corpus_id": 263830945,
    "ref_id": "b31",
    "citation_corpus_id": 254044293,
    "start": 8352,
    "end": 8370,
    "title": "Published as a conference paper at ICLR 2023 LINK PREDICTION WITH NON-CONTRASTIVE LEARNING",
    "abstract": "Graph neural networks (GNNs) are prominent in the graph machine learning domain, owing to their strong performance across various tasks. A recent focal area is the space of graph self-supervised learning (SSL), which aims to derive useful node representations without labeled data. Notably, many state-of-theart graph SSL approaches are contrastive methods, which use a combination of positive and negative samples to learn node representations. Owing to challenges in negative sampling (slowness and model sensitivity), recent literature introduced non-contrastive methods, which instead only use positive samples. Though such methods have shown promising performance in node-level tasks, their suitability for link prediction tasks, which are concerned with predicting link existence between pairs of nodes, and have broad applicability to recommendation systems contexts, is yet unexplored. In this work, we extensively evaluate the performance of existing non-contrastive methods for link prediction in both transductive and inductive settings. While most existing non-contrastive methods perform poorly overall, we find that, surprisingly, BGRL generally performs well in transductive settings. However, it performs poorly in the more realistic inductive settings where the model has to generalize to links to/from unseen nodes. We find that non-contrastive models tend to overfit to the training graph and use this analysis to propose T-BGRL, a novel non-contrastive framework that incorporates cheap corruptions to improve the generalization ability of the model. This simple modification strongly improves inductive performance in 5/6 of our datasets, with up to a 120% improvement in Hits@50-all with comparable speed to other non-contrastive baselines, and up to 14\u00d7 faster than the best-performing contrastive baseline. Our work imparts interesting findings about non-contrastive learning for link prediction and paves the way for future researchers to further expand upon this area.",
    "prev": " the testing time.Moreover, we discover that different nodes within the same graph can have varying amounts of TDS.\u2022 We design a TC inspired message-passing where a node aggregates more from neighbors who are better connected within its computational tree, which can enhance the node's weighted TC.We observe this empirically boosts LP performance and lastly discuss its noncausal limitations.",
    "curr": "Preprint\n\n\nRELATED WORK\n\nVarying Performance of GNNs on Node/Graph Classification.GNNs' efficacy in classification differs across nodes/graphs with varying label quantity (e.g., imbalanced node/graph classification (Zhao et al., 2021a;Wang et al., 2022)) and varying topology quality (e.g., long-tailed (Tang et al., 2020;Liu et al., 2021)/heterophily node classification (Zhu et al., 2020;Mao et al., 2023)).To enhance GNNs' performance for the disadvantaged nodes/graphs in these two varying conditions, previous works either apply data augmentations to derive additional supervision (Wang et al., 2021;Zhao et al., 2022) or design expressive graph convolutions to mitigate structural bias (Zhu et al., 2021).However, none of them tackle the varying performance of nodes in LP.We fill this gap by studying the relationship between node LP performance and its local topology.",
    "next": "GNN-based LP and Node-Centric Evaluation.GNN-based LP works by first learning node embeddings/subgraph embeddings through linear transformation and message-passing, and then applying the scoring function to predict link probability/subgraph class (Zhang & Chen, 2018;Shiao et al., 2022;Guo et al., 2023;Dong et al., 2022).It has achieved new SOTA performance owing to using the neural network to extract task-related information and the message-passing to encode the topological properties (e.g., common neighbors) (Yun et al., 2021;Chamberlain et al., 2022).",
    "hard_negative": [
      3144218,
      243756979
    ],
    "easy_negative": [
      52966647,
      17078428,
      7245829
    ]
  },
  {
    "index": 2446,
    "source_corpus_id": 260682249,
    "ref_id": "b55",
    "citation_corpus_id": 11816014,
    "start": 3720,
    "end": 3724,
    "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
    "abstract": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com.",
    "prev": "LLM-as-Agent\n\nThe advent of Large Language Models (LLMs) [11; 15; 101; 66; 100; 80], such as GPT-4 [56], has brought plenty of new opportunities to this realm.",
    "curr": "Through extensive alignment training [75; 58; 8; 90; 65], LLMs have not only mastered traditional NLP tasks such as question answering [61], natural language inference [10], and text summarization [52], but also showcased an impressive ability to comprehend human intent and execute instructions.",
    "next": "This has spurred the development of various applications like AutoGPT [64], BabyAGI [51], and AgentGPT [1], which employ LLMs for autonomous goal completion, sparking substantial public interest and numerous discussions.",
    "hard_negative": [
      6360322,
      2337034,
      15425307,
      9846946,
      428579,
      8764466,
      14071482,
      1199934,
      8471750,
      1373518,
      12451537,
      2100831,
      15197674,
      5541486,
      226541,
      14915449,
      252796
    ],
    "easy_negative": [
      225041226,
      236460284,
      16029320
    ]
  },
  {
    "index": 2447,
    "source_corpus_id": 231632900,
    "ref_id": "b33",
    "citation_corpus_id": 1957433,
    "start": 5174,
    "end": 5178,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "In computational linguistics there is a long tradition [19] of using distributional properties of linguistic units for quantifying semantic similarities between them, as summarized in the famous quote by JR Firth: \"a word is characterized by the company it keeps\" [14].",
    "curr": "This idea has led to powerful tools such as Latent Semantic Analysis [9], topic modelling [3], and language models like word2vec [30], GloVe [34], and, more recently, BERT [10] which relies on the Transformer model [43].",
    "next": "Specifically word2vec models are trained to maximize the likelihood of a word given its context, GloVe models utilize global word-word co-occurence statistics, and BERT uses a deep neural network with attention to predict masked words (and the next sentence).",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      259376900,
      248512629,
      92327
    ]
  },
  {
    "index": 2448,
    "source_corpus_id": 263610128,
    "ref_id": "b57",
    "citation_corpus_id": 252715691,
    "start": 2226,
    "end": 2244,
    "title": "GLM-130B: AN OPEN BILINGUAL PRE-TRAINED MODEL",
    "abstract": "We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model at least as good as GPT-3 and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we face numerous unexpected technical and engineering challenges, particularly on loss spikes and disconvergence. In this paper, we introduce the training process of GLM-130B including its design choices, training strategies for both efficiency and stability, and engineering efforts. The resultant GLM-130B model offers significant outperformance over GPT-3 175B on a wide range of popular English benchmarks while the performance advantage is not observed in OPT-175B and BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN 3.0 260B-the largest Chinese language model-across related benchmarks. Finally, we leverage a unique scaling property of GLM-130B to reach INT4 quantization, without quantization aware training and with almost no performance loss, making it the first among 100B-scale models. More importantly, the property allows its effective inference on 4\u00d7RTX 3090 (24G) or 8\u00d7RTX 2080 Ti (11G) GPUs, the most ever affordable GPUs required for using 100B-scale models. The GLM-130B model weights are publicly accessible and its code, training logs, related toolkit, and lessons learned are open-sourced at https://github.comIn this work, we introduce the pre-training of a 100B-scale model-GLM-130B, in terms of engineering efforts, model design choices, training strategies for efficiency and stability, and quantization for affordable inference. As it has been widely realized that it is computationally unaffordable to empirically enumerate all possible designs for training 100B-scale LLMs, we present not only the successful part for training GLM-130B but also many of the failed options and lessons learned. Particularly, the training stability is the decisive factor in the success of training models of such a scale. Different from practices such as manually adjusting learning rates in OPT-175B and using embedding norm in the sacrifice of performance in BLOOM-176B, we experiment with various options and find the strategy of embedding gradient shrink can significantly stabilize the training of GLM-130B.Specifically, GLM-130B is a bilingual (English and Chinese) bidirectional dense model with 130 billion parameters, pre-trained over 400 billion tokens on a cluster of 96 NVIDIA DGX-A100 (8\u00d740G) GPU nodes between May 6 and July 3, 2022. Instead of using the GPT-style architecture, we adopt the General Language Model (GLM) algorithm (Du et al., 2022)  to leverage its bidirectional attention advantage and autoregressive blank infilling objective.Table 1summarizes the comparison between GLM-130B, GPT-3 and another two open-source efforts-OPT-175B and BLOOM-176B, as well as PaLM 540B (Chowdhery et al., 2022)-a 4\u00d7 larger model-as a reference.Altogether, the conceptual uniqueness and engineering efforts enable GLM-130B to exhibit performance that surpasses the level of GPT-3 on a wide range of benchmarks (in total 112 tasks) and also outperforms PaLM 540B in many cases, while outperformance over GPT-3 has not been observed in OPT-175B and BLOOM-176B (Cf.Figure 1 (a)). For zero-shot performance, GLM-130B is better than GPT-3 175B (+5.0%), OPT-175B (+6.5%), and BLOOM-176B (+13.0%) on LAMBADA (Paperno et al., 2016), and achieves 3\u00d7 better performance than GPT-3 on Big-bench-lite (Srivastava  et al., 2022). For the 5-shot MMLU (Hendrycks et al., 2021) tasks, it is better than GPT-3 175B (+0.9%) and BLOOM-176B (+12.7%). As a bilingual LLM also in Chinese, it offers significantly better results than ERNIE TITAN 3.0 260B (Wang et al., 2021)-the largest Chinese LLM-on 7 zero-shot CLUE (Xu et al., 2020) datasets (+24.26%) and 5 zero-shot FewCLUE  ones (+12.75%). Importantly, as summarized inFigure 1 (b), GLM-130B as an open model is associated with significantly less bias and generation toxicity than its 100B-scale counterparts.Finally, we design GLM-130B to empower as many people as possible to conduct 100B-scale LLM studies. First, instead of using 175B+ parameters as OPT and BLOOM, the 130B size is decided because such a size supports inference on a single A100 (8\u00d740G) server. Second, to further lower the GPU requirements, we quantize GLM-130B into INT4 precision without quantization aware training while OPT and BLOOM can only reach INT8. Due to a unique property of the GLM architecture, GLM-130B's INT4 quantization introduces negligible performance degradation, e.g., -0.74% on LAMBADA and even +0.05% on MMLU, making it still better than the uncompressed GPT-3. This enables GLM-130B's fast inference with performance guarantee on a server of 4\u00d7RTX 3090 (24G) or 8\u00d7RTX 2080 Ti (11G), the most ever affordable GPU required for using 100B-scale LLMs to date.We open-source the model checkpoints, code, training logs, related toolkits, and lessons learned.THE DESIGN CHOICES OF GLM-130BThe architecture of a machine learning model defines its inductive bias. However, it has been realized that it is computationally unaffordable to explore various architectural designs for LLMs. We introduce and explain the unique design choices of GLM-130B. 2.1 GLM-130B'S ARCHITECTURE GLM as Backbone. Most recent 100B-scale LLMs, such as GPT-3, PaLM, OPT, and BLOOM, follow the traditional GPT-style (Radford et al., 2019) architecture of decoder-only autoregressive language modeling. In GLM-130B, we instead make an attempt to explore the potential of a bidirectional GLM-General Language Model (Du et al., 2022)-as its backbone.GLM is a transformer-based language model that leverages autoregressive blank infilling as its training objective. Briefly, for a text sequence x = [x 1 , \u00b7 \u00b7 \u00b7 , x n ], text spans {s 1 , \u00b7 \u00b7 \u00b7 , s m } are sampled from it, each of which s i denotes a span of consecutive tokens [s i,1 , \u00b7 \u00b7 \u00b7 , s i,li ] and is replaced (i.e., corrupted) with a single mask token to form x corrupt . The model is asked to recover them autoregressively. To allow interactions between corrupted spans, their visibility to each other is decided by a He. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters.",
    "prev": "1 * The first two authors contributed equally.Work done during Jian Xie's internship at OSU NLP Group.",
    "curr": "INTRODUCTION\n\nAfter pre-training on massive corpora, large language models (LLMs) (Brown et al., 2020;Chowdhery et al., 2022;Ouyang et al., 2022;OpenAI, 2022;2023;Zeng et al., 2023;Touvron et al., 2023a) have formed a wealth of parametric memory, such as commonsense and factual knowledge (Petroni et al., 2019;Li et al., 2022;Zhao et al., 2023).However, such parametric memory may be inaccurate or become outdated (Liska et al., 2022;Luu et al., 2022) due to misinformation in the pre-training corpus or the static nature of parametric memory, known to be a major cause for hallucinations (Elazar et al., 2021;Shuster et al., 2021;Ji et al., 2023).",
    "next": "Tool2 (Schick et al., 2023;Qin et al., 2023) or retrieval augmentation (Mallen et al., 2022;Shi et al., 2023;Ram et al., 2023) has emerged as a promising solution by providing external information as new evidence to LLMs, such as ChatGPT Plugins and New Bing.However, external evidence, inevitably, could conflict with LLMs' parametric memory.We refer to external evidence that conflicts with parametric memory as counter-memory.In this paper, we seek to answer the question: how receptive are LLMs to external evidence, especiall",
    "hard_negative": [
      3782112,
      215745536,
      202539496,
      237416585
    ],
    "easy_negative": [
      221097232,
      2131413,
      2694479
    ]
  },
  {
    "index": 2449,
    "source_corpus_id": 226281747,
    "ref_id": "b46",
    "citation_corpus_id": 91184134,
    "start": 32274,
    "end": 32292,
    "title": "FAIRSEQ: A Fast, Extensible Toolkit for Sequence Modeling",
    "abstract": "FAIRSEQ is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found here: https://www.youtube. com/watch?v=OtgDdWtHvto.",
    "prev": "the earth's surface) by simply replacing the CNF in our models with a Riemannian counterpart.",
    "curr": "ACKNOWLEDGMENTS\n\nWe acknowledge the Python community (Van Rossum & Drake Jr, 1995;Oliphant, 2007) for developing the core set of tools that enabled this work, including PyTorch (Paszke et al., 2019), torchdiffeq (Chen, 2018), fairseq (Ott et al., 2019), Jupyter (Kluyver et al., 2016), Matplotlib (Hunter, 2007, seaborn (Waskom et al., 2018), Cython (Behnel et al., 2011), numpy (Oliphant, 2006Van Der Walt et al., 2011), pandas (McKinney, 2012, and SciPy (Jones et al., 2014).",
    "next": ": Both the Jump CNF and Attentive CNF are capable of modeling different the spatial distributions based on event history, so the appearance of a new event effectively shifts the distribution instantaneously.",
    "hard_negative": [
      53079938,
      53218829,
      5033497,
      3297437,
      59310641,
      44084020,
      52113461,
      52892477,
      964287,
      3718988,
      44131019,
      44134226,
      22716243,
      21460834,
      3725815,
      4623739,
      14337532
    ],
    "easy_negative": [
      14719746,
      11876985,
      247518578
    ]
  },
  {
    "index": 2451,
    "source_corpus_id": 15904815,
    "ref_id": "b13",
    "citation_corpus_id": 17048295,
    "start": 18510,
    "end": 18530,
    "title": "The Inside-Outside Recursive Neural Network model for Dependency Parsing",
    "abstract": "We propose the first implementation of an infinite-order generative dependency model. The model is based on a new recursive neural network architecture, the Inside-Outside Recursive Neural Network. This architecture allows information to flow not only bottom-up, as in traditional recursive neural networks, but also topdown. This is achieved by computing content as well as context representations for any constituent, and letting these representations interact. Experimental results on the English section of the Universal Dependency Treebank show that the infinite-order model achieves a perplexity seven times lower than the traditional third-order model using counting, and tends to choose more accurate parses in k-best lists. In addition, reranking with this model achieves state-of-the-art unlabelled attachment scores and unlabelled exact match scores.",
    "prev": "This serves primarily to reduce the minimum length that information has to propagate between nodes in the tree.",
    "curr": "The R3NN can be seen as an extension and combination of several previous tree-based models, which were mainly developed in the context of natural language processing (Le & Zuidema, 2014;Paulus et al., 2014;Irsoy & Cardie, 2013).",
    "next": "CONDITIONING WITH INPUT/OUTPUT EXAMPLES\n\nNow that we have defined a generation process over tree-structured programs, we need a way of conditioning this generation process on a set of input/output examples.",
    "hard_negative": [
      990233,
      9830566,
      1153327,
      12926517,
      806709,
      6628791,
      216094149,
      7901127,
      216086600,
      14038100,
      85205,
      10351190,
      7672793,
      1114215,
      11599080,
      3262717
    ],
    "easy_negative": [
      12815850,
      219899636,
      258378187
    ]
  },
  {
    "index": 2452,
    "source_corpus_id": 244713935,
    "ref_id": "b20",
    "citation_corpus_id": 3292002,
    "start": 3589,
    "end": 3614,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "The vast majority of GNNs follow the message passing paradigm (Gilmer et al., 2017), using learnable non-linear functions to diffuse information on the graph.",
    "curr": "Multiple popular GNN architectures such as GCN (Kipf & Welling, 2017) and GAT (Veli\u010dkovi\u0107 et al., 2018) can be posed as particular flavors of this scheme and considered instances of a more general framework of geometric deep learning (Bronstein et al., 2021).",
    "next": "Some of the drawbacks of the message passing paradigm have now been identified and formalized, including the limits of expressive power (Xu et al., 2019;Morris et al., 2019;Maron et al., 2019) and the problem of over-smoothing (NT & Maehara, 2019;Oono & Suzuki, 2020).",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      67770197,
      55779552,
      243865611
    ]
  },
  {
    "index": 2454,
    "source_corpus_id": 252780973,
    "ref_id": "b15",
    "citation_corpus_id": 210920362,
    "start": 7520,
    "end": 7537,
    "title": "GRAPHAF: A FLOW-BASED AUTOREGRESSIVE MODEL FOR MOLECULAR GRAPH GENERATION",
    "abstract": "Molecular graph generation is a fundamental problem for drug discovery and has been attracting growing attention. The problem is challenging since it requires not only generating chemically valid molecular structures but also optimizing their chemical properties in the meantime. Inspired by the recent progress in deep generative models, in this paper we propose a flow-based autoregressive model for graph generation called GraphAF. GraphAF combines the advantages of both autoregressive and flow-based approaches and enjoys: (1) high model flexibility for data density estimation; (2) efficient parallel computation for training; (3) an iterative sampling process, which allows leveraging chemical domain knowledge for valency checking. Experimental results show that GraphAF is able to generate 68% chemically valid molecules even without chemical knowledge rules and 100% valid molecules with chemical rules. The training process of GraphAF is two times faster than the existing state-of-the-art approach GCPN. After fine-tuning the model for goal-directed property optimization with reinforcement learning, GraphAF achieves state-of-the-art performance on both chemical property optimization and constrained property optimization. 1 * Equal contribution, with order determined by flipping a coin. Work was done during internship at Mila.",
    "prev": "In this paper, we mainly focus on the fourth category of metrics, the metrics that are more or less related to the degree of coverage (or exploration) in the chemical space (other metrics are discussed in Appendix A).",
    "curr": "In this category, commonly used measures include richness, uniqueness, internal diversity, external diversity, KL divergence, and Fr\u00e9chet ChemNet Distance (FCD) (Olivecrona et al., 2017;You et al., 2018;De Cao & Kipf, 2018;Elton et al., 2019;Brown et al., 2019;Popova et al., 2019;Polykovskiy et al., 2020;Shi et al., 2020;Jin et al., 2020;Xie et al., 2021).",
    "next": "Besides, Zhang et al.",
    "hard_negative": [
      6628106,
      2187805
    ],
    "easy_negative": [
      248780258,
      90261373,
      252624779
    ]
  },
  {
    "index": 2455,
    "source_corpus_id": 247011642,
    "ref_id": "b20",
    "citation_corpus_id": 215745290,
    "start": 11083,
    "end": 11145,
    "title": "Pretrained Transformers Improve Out-of-Distribution Robustness",
    "abstract": "Although pretrained Transformers such as BERT achieve high accuracy on indistribution examples, do they generalize to new distributions? We systematically measure out-of-distribution (OOD) generalization for seven NLP datasets by constructing a new robustness benchmark with realistic distribution shifts. We measure the generalization of previous models including bag-of-words models, ConvNets, and LSTMs, and we show that pretrained Transformers' performance declines are substantially smaller. Pretrained transformers are also more effective at detecting anomalous or OOD examples, while many previous models are frequently worse than chance. We examine which factors affect robustness, finding that larger models are not necessarily more robust, distillation can be harmful, and more diverse pretraining data can enhance robustness. Finally, we show where future work can improve OOD robustness. * Equal contribution. https://github.com/camelop/NLP-Robustness",
    "prev": "(Toneva, Sordoni, des Combes, Trischler, Bengio, and Gordon, 2018) look at \"forge ing events\", i.e., when a training examples move from being classi ed correctly to incorrectly, resembling our notion of non-monotonicity.",
    "curr": "OOD Robustness (Hendrycks, Liu, Wallace, Dziedzic, Krishnan, and Song, 2020b;Radford et al., 2021) show that large pretrained models are more robust to distributions shi and (Desai and Durre , 2020) show that large pretrained models are be er calibrated on OOD inputs.",
    "next": "ere is a also long line of literature on OOD detection (Hendrycks and Gimpel, 2016;Geifman and El-Yaniv, 2017;Liang, Li, and Srikant, 2017;Lakshminarayanan, Pritzel, and Blundell, 2016;Jiang, Kim, Guan, and Gupta, 2018;Zhang, Li, Guo, and Guo, 2020), uncertainty estimation (Ovadia, Fertig, Ren, Nado, Sculley, Nowozin, Dillon, Lakshminarayanan, and Snoek, 2019), and accuracy prediction (Deng and Zheng, 2021;Guillory, Shankar, Ebrahimi, Darrell, and Schmidt, 2021;Garg, Balakrishnan, Lipton, Neyshabur, and Sedghi, 2022) under distribution shi .",
    "hard_negative": [
      223637,
      4537113,
      202888986,
      990233,
      7228830,
      3432876,
      1957433,
      201698258,
      208193111,
      1428702,
      3464416,
      5882977,
      174801764,
      52967399,
      155092969,
      3994096,
      56657912,
      102350590
    ],
    "easy_negative": [
      1462388,
      713684,
      245855898
    ]
  },
  {
    "index": 2459,
    "source_corpus_id": 3489117,
    "ref_id": "b43",
    "citation_corpus_id": 12713052,
    "start": 4356,
    "end": 4359,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "Evolutionary techniques [10,37,38,40] offer a flexible approach for discovering variegated models from trivial initial conditions, but often struggle to scale to deep neural nets where the search space is vast, even with enormous compute power [26].",
    "curr": "Reinforcement learning methods [3,44] have been used to train an agent to generate network definitions using policy gradients.",
    "next": "These methods start from trivial architectures and discover models that achieve very high performance, but can require twelve to fifteen thousand full training runs to arrive at a solution.",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      249204459,
      248085838,
      256827819
    ]
  },
  {
    "index": 2463,
    "source_corpus_id": 4885767,
    "ref_id": "b53",
    "citation_corpus_id": 12130431,
    "start": 5439,
    "end": 5442,
    "title": "INCREMENTAL NETWORK QUANTIZATION: TOWARDS LOSSLESS CNNS WITH LOW-PRECISION WEIGHTS",
    "abstract": "This paper presents incremental network quantization (INQ), a novel method, targeting to efficiently convert any pre-trained full-precision convolutional neural network (CNN) model into a low-precision version whose weights are constrained to be either powers of two or zero. Unlike existing methods which are struggled in noticeable accuracy loss, our INQ has the potential to resolve this issue, as benefiting from two innovations. On one hand, we introduce three interdependent operations, namely weight partition, group-wise quantization and re-training. A wellproven measure is employed to divide the weights in each layer of a pre-trained CNN model into two disjoint groups. The weights in the first group are responsible to form a low-precision base, thus they are quantized by a variable-length encoding method. The weights in the other group are responsible to compensate for the accuracy loss from the quantization, thus they are the ones to be re-trained. On the other hand, these three operations are repeated on the latest re-trained group in an iterative manner until all the weights are converted into low-precision ones, acting as an incremental network quantization and accuracy enhancement procedure. Extensive experiments on the ImageNet classification task using almost all known deep CNN architectures including AlexNet, VGG-16, GoogleNet and ResNets well testify the efficacy of the proposed method. Specifically, at 5-bit quantization (a variable-length encoding: 1 bit for representing zero value, and the remaining 4 bits represent at most 16 different values for the powers of two) 1 , our models have improved accuracy than the 32-bit floating-point references. Taking ResNet-18 as an example, we further show that our quantized models with 4-bit, 3-bit and 2-bit ternary weights have improved or very similar accuracy against its 32-bit floating-point baseline. Besides, impressive results with the combination of network pruning and INQ are also reported. We believe that our method sheds new insights on how to make deep CNNs to be applicable on mobile or embedded devices. The code is available at https://github.com",
    "prev": "Another class of approaches uses feature hashing and weight sharing [47,41,10,9,45].",
    "curr": "Building upon the idea of weight-sharing, quantization [19,49,54] or regular structure of weight matrices can be used for reducing the effective number of parameters [53,43,11,12,48].",
    "next": "Despite their favorable empirical effectiveness in compressing neural networks, these works generally lack performance guarantees on the quality of their approximations and/or the size of the resulting compressed network.",
    "hard_negative": [
      14124313,
      1996665
    ],
    "easy_negative": [
      226283618,
      11172437,
      6794841
    ]
  },
  {
    "index": 2465,
    "source_corpus_id": 252907410,
    "ref_id": "b20",
    "citation_corpus_id": 238419341,
    "start": 6942,
    "end": 6959,
    "title": "Causal Direction of Data Collection Matters: Implications of Causal and Anticausal Learning for NLP",
    "abstract": "The principle of independent causal mechanisms (ICM) states that generative processes of real world data consist of independent modules which do not influence or inform each other. While this idea has led to fruitful developments in the field of causal inference, it is not widely-known in the NLP community. In this work, we argue that the causal direction of the data collection process bears nontrivial implications that can explain a number of published NLP findings, such as differences in semi-supervised learning (SSL) and domain adaptation (DA) performance across different settings. We categorize common NLP tasks according to their causal direction and empirically assay the validity of the ICM principle for text data using minimum description length. We conduct an extensive meta-analysis of over 100 published SSL and 30 DA studies, and find that the results are consistent with our expectations based on causal insights. This work presents the first attempt to analyze the ICM principle in NLP, and provides constructive suggestions for future modeling choices. 1 * Equal contribution. 1  The codes are at https://github.com/zhijing-jin/icm4nlp. Given the English sentence above, can you write its Spanish translation? Prompt for annotators [En] This is a beautiful world. [Es] Este es un mundo hermoso. Cause: Effect: Annotation process (Noise) Effect = CausalMechanism (Cause, Noise)",
    "prev": "Contributions.",
    "curr": "Previous work on computing prequential description lengths with neural networks relied on a block-wise (chunk-incremental) approximation: at some positions t a model is trained from random initialization to convergence on data D <t and then their prediction losses on the next intervals are combined (Blier & Ollivier, 2018;Bornschein et al., 2020;Jin et al., 2021;Bornschein et al., 2021;Perez et al., 2021;Whitney et al., 2020).",
    "next": "We investigate alternatives that are inspired by continuouslearning (CL) based methods.",
    "hard_negative": [
      199577473,
      208117506,
      359451,
      272933,
      216867622,
      38407095,
      207852344,
      214693050,
      8509375,
      219176513,
      218487374,
      11816014,
      167217367,
      17518557,
      189762527,
      189898467,
      2067306,
      5590763,
      227034354,
      3030259,
      11212020,
      4623739,
      17716605
    ],
    "easy_negative": [
      252818944,
      235294302,
      9771330
    ]
  },
  {
    "index": 2467,
    "source_corpus_id": 210911499,
    "ref_id": "b0",
    "citation_corpus_id": 54458698,
    "start": 2907,
    "end": 2935,
    "title": "Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning",
    "abstract": "Text-based adventure games provide a platform on which to explore reinforcement learning in the context of a combinatorial action space, such as natural language. We present a deep reinforcement learning architecture that represents the game state as a knowledge graph which is learned during exploration. This graph is used to prune the action space, enabling more efficient exploration. The question of which action to take can be reduced to a question-answering task, a form of transfer learning that pre-trains certain parts of our architecture. In experiments using the TextWorld framework, we show that our proposed technique can learn a control policy faster than baseline alternatives. We have also open-sourced our code at https://github.com/rajammanabrolu/KG-DQN.",
    "prev": "Knowledge graphs provide us with an intuitive way of representing these partially observable worlds.",
    "curr": "Prior works have shown how using knowledge graphs aid in the twin issues of partial observability (Ammanabrolu & Riedl, 2019a) and commonsense reasoning (Ammanabrolu & Riedl, 2019b), but do not use them in the context of generating natural language.",
    "next": "To gain a sense for the challenges surrounding natural language generation, we need to first understand how large this space really is.",
    "hard_negative": [
      3618568,
      2924682
    ],
    "easy_negative": [
      196183388,
      2768038,
      203691261
    ]
  },
  {
    "index": 2483,
    "source_corpus_id": 48352800,
    "ref_id": "b41",
    "citation_corpus_id": 13570924,
    "start": 1540,
    "end": 1544,
    "title": "Variational Continual Learning",
    "abstract": "This paper develops variational continual learning (VCL), a simple but general framework for continual learning that fuses online variational inference (VI) and recent advances in Monte Carlo VI for neural networks. The framework can successfully train both deep discriminative models and deep generative models in complex continual learning settings where existing tasks evolve over time and entirely new tasks emerge. Experimental results show that variational continual learning outperforms state-of-the-art continual learning methods on a variety of tasks, avoiding catastrophic forgetting in a fully automatic way.",
    "prev": "Introduction\n\nThere is a resurgence of research interests in Bayesian deep learning [7,22,[25][26][27]46], which applies Bayesian inference to neural networks for better uncertainty estimation that is crucial for e.g.",
    "curr": "better exploration in reinforcement learning [13,14], resisting adversarial attacks [20,34,36] and continual learning [41].",
    "next": "A popular approach to performing Bayesian inference on neural networks is stochastic gradient Markov chain Monte Carlo (SG-MCMC), which adds properly scaled Gaussian noise to a stochastic gradient ascent procedure [57].",
    "hard_negative": [
      6628106,
      12730344
    ],
    "easy_negative": [
      202889044,
      57350096,
      236207863
    ]
  },
  {
    "index": 2484,
    "source_corpus_id": 252735112,
    "ref_id": "b9",
    "citation_corpus_id": 207880568,
    "start": 2503,
    "end": 2525,
    "title": "Unsupervised Cross-lingual Representation Learning at Scale",
    "abstract": "This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of crosslingual transfer tasks. We train a Transformerbased masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6% average accuracy on XNLI, +13% average F1 score on MLQA, and +2.4% F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7% in XNLI accuracy for Swahili and 11.4% for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing perlanguage performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code, data and models publicly available. 1",
    "prev": "INTRODUCTION\n\nRecent work has shown that presenting explicit reasoning steps (i.e., chains of thought; COT) in English elicits multi-step reasoning abilities of large language models such as GPT-3 and PaLM (Brown et al., 2020;Chowdhery et al., 2022;Wei et al., 2022b, inter alia).",
    "curr": "Pretrained multilingual language models have also achieved impressive performance on various NLP tasks across typologically distinct languages (Conneau et al., 2020;Xue et al., 2021;Chowdhery et al., 2022;Clark et al., 2020;Hu et al., 2020;Ruder et al., 2021, inter alia).",
    "next": "Tasks in existing multilingual benchmarks usually require only simple reasoning steps, and so it is still unclear how well language models perform on tasks that require more complex reasoning in a multilingual setting.",
    "hard_negative": [
      6053988,
      3432876,
      11816014,
      126167342,
      6042994,
      3411445,
      52010710,
      13753208,
      1957433,
      990233
    ],
    "easy_negative": [
      18196992,
      12514667,
      7783423
    ]
  },
  {
    "index": 2485,
    "source_corpus_id": 204090878,
    "ref_id": "b48",
    "citation_corpus_id": 3833554,
    "start": 9391,
    "end": 9415,
    "title": "Wasserstein Auto-Encoders",
    "abstract": "We propose the Wasserstein Auto-Encoder (WAE)-a new algorithm for building a generative model of the data distribution. WAE minimizes a penalized form of the Wasserstein distance between the model distribution and the target distribution, which leads to a different regularizer than the one used by the Variational Auto-Encoder (VAE) [1]. This regularizer encourages the encoded training distribution to match the prior. We compare our algorithm with several other techniques and show that it is a generalization of adversarial auto-encoders (AAE)[2]. Our experiments show that WAE shares many of the properties of VAEs (stable training, encoder-decoder architecture, nice latent manifold structure) while generating samples of better quality, as measured by the FID score.",
    "prev": "In VHE-GAN, the optimization of the encoder parameter E is related to not only the VHE's ELBO, but also the GAN mini-max objective function, forcing the variational posterior q(z | x) to serve as a bridge between VHE and GAN, allowing them to help each other.",
    "curr": "Although there are some models (Mescheder et al., 2017;Makhzani et al., 2015;Tolstikhin et al., 2018;Dumoulin et al., 2017;Donahue et al., 2017;Che et al., 2017;Srivastava et al., 2017;Grover et al., 2018;Larsen et al., 2016; combining VAEs and GANs in various ways, they focus on single-modality tasks while the VHE-GAN on two different modalities.",
    "next": "In Appendix A, we analyze the properties of the VHE-GAN objective function and discuss related works.",
    "hard_negative": [
      11758569,
      15876696
    ],
    "easy_negative": [
      9533139,
      32541803,
      6566858
    ]
  },
  {
    "index": 2490,
    "source_corpus_id": 233307448,
    "ref_id": "b28",
    "citation_corpus_id": 22421874,
    "start": 35001,
    "end": 35028,
    "title": "Knowledge Distillation for Bilingual Dictionary Induction",
    "abstract": "Leveraging zero-shot learning to learn mapping functions between vector spaces of different languages is a promising approach to bilingual dictionary induction. However, methods using this approach have not yet achieved high accuracy on the task. In this paper, we propose a bridging approach, where our main contribution is a knowledge distillation training objective. As teachers, rich resource translation paths are exploited in this role. And as learners, translation paths involving low resource languages learn from the teachers. Our training objective allows seamless addition of teacher translation paths for any given low resource pair. Since our approach relies on the quality of monolingual word embeddings, we also propose to enhance vector representations of both the source and target language with linguistic information. Our experiments on various languages show large performance gains from our distillation training objective, obtaining as high as 17% accuracy improvements.",
    "prev": "(2020) demonstrate that when applied to image data, distillation allows the student neural net to learn multiple visual concepts simultaneously, while, when learning from raw data, neural networks learn concepts sequentially.",
    "curr": "Knowledge distillation has also been used for adversarial attacks (Papernot et al., 2016b;Ross & Doshi-Velez, 2017;Gil et al., 2019;Goldblum et al., 2020), data security (Papernot et al., 2016a;Lopes et al., 2017;, image processing (Li & Hoiem, 2017;Wang et al., 2017;Chen et al., 2018;, natural language processing (Nakashole & Flauger, 2017;Mou et al., 2016;Hu et al., 2018;Freitag et al., 2017), and speech processing (Chebotar & Waters, 2016;Lu et al., 2017;Watanabe et al., 2017;Oord et al., 2018;Shen et al., 2018).",
    "next": "(Z;f (X),p 0 (X)) Loss function on a random data point\n\n\nB GLOSSARY\nPopulation risk L D (f,p) E[ (Z;f (X),p(X))] Empirical risk L n (f,p) E n [ (Z;f (X),p(X))] Population optimal student model f 0 argmin f \u2208F L D (f,p 0 ) Empirical optimal student modelf argmin f \u2208F L n (f,p) f p,q f (X) p L q = E f (X) q p 1/q \u2207 \u03c6\nPartial derivative of (z;\u03c6,\u03c0) with respect to the second input \u2207 \u03c0 Partial derivative of (z;\u03c6,\u03c0) with respect to the third input \u2207 \u03c6\u03c0 [\u2207 \u03c6\u03c0 (z;\u03c6,\u03c0)] i,j = \u2202 2 \u2202\u03c6j \u2202\u03c0i (z;\u03c6,\u03c0)\nq f,p (x) E[\u2207 \u03c6\u03c0 (Z;f (X),p(X)) | X = x] \u03b3 f,p (x) E U \u223cUnif([0,1]) [q f,U p+(1\u2212U )p0 (x)] R(\u03b4;F)\nLocalized Rademacher complexity of function class F \u03b4 n Critical radius \u03b3-corrected loss \u03b3 (z;f (x),p(x)) (z;f (x),p(x))+(y\u2212p(x)) \u03b3(x)f (x) Population \u03b3-risk L D (f,p,\u03b3) E[ \u03b3 (Z;f (X),p(X))] Empirical \u03b3-risk L n (f,p,\u03b3) with probab",
    "hard_negative": [
      6758088,
      12187767,
      891605,
      8030425,
      7185434,
      18634877,
      719133,
      14183678
    ],
    "easy_negative": [
      13619197,
      2847331,
      243865131
    ]
  },
  {
    "index": 2495,
    "source_corpus_id": 53464644,
    "ref_id": "b15",
    "citation_corpus_id": 3626819,
    "start": 7994,
    "end": 7997,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "Instead, we seek to learn embeddings that encode the full structural context in which each amino acid occurs.",
    "curr": "This is inspired partly by the recent success of unsupervised contextual embedding models using bidirectional recurrent neural network language models [15,16] where word embeddings, learned as a function of their context, have been successfully transferred to other tasks.",
    "next": "In particular, we apply a similar language model for the first time on protein sequences as part of our supervised framework.",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      11336213,
      990233,
      9917468,
      20472740,
      34032948,
      10489017,
      1957433,
      1222212,
      12688069,
      15026764,
      11816014,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      11552524,
      202541220,
      9314689
    ]
  },
  {
    "index": 2506,
    "source_corpus_id": 248228159,
    "ref_id": "b32",
    "citation_corpus_id": 56657912,
    "start": 2413,
    "end": 2442,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "This is particularly relevant for the deployment of ML models to the real world, where we need systems that generalize beyond the i.i.d.",
    "curr": "(independent and identically distributed) data setting Djolonga et al., 2020;Koh et al., 2021;Barbu et al., 2019;Azulay & Weiss, 2019;Roy et al., 2018;Gulrajani & Lopez-Paz, 2020;Hendrycks & Dietterich, 2019;Michaelis et al., 2019;Funk et al., 2021).",
    "next": "One instance of such models are agents that learn by interacting with a training environment and we would like them to generalize to other environments with different statistics (Zhang et al., 2018;Pfister et al., 2019;Cobbe et al., 2019;Ahmed et al., 2021;.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      201070267,
      14777407,
      236486163
    ]
  },
  {
    "index": 2508,
    "source_corpus_id": 264436558,
    "ref_id": "b38",
    "citation_corpus_id": 3144218,
    "start": 9332,
    "end": 9354,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "the sum or max operation.Additionally, \u03c6 \u2208 R d \u00d7 R h \u2192 R m represents a readout function.We note that the update equation is local and relies solely on the neighborhood of the node.Both \u03c8 and \u03c6 can be Multi-Layer Perceptrons (MLPs).In our manuscript all MLPs will use the ReLU(t) def.",
    "curr": "= max{0, t} activation function, where t \u2208 R. Several special cases have resulted in the development of a wide range of GNN layers: the most well-known being Graph Convolutional Networks (GCNs) (Kipf & Welling, 2017) and Graph Attention Networks (GATs) (Veli\u010dkovi\u0107 et al., 2018).",
    "next": "Quasi-Metric Spaces.While Riemannian manifolds have been employed for formalizing non-Euclidean distances between points, their additional structural properties, such as smoothness and infinitesimal angles, impose substantial limitations, rendering the demonstration of Riemannian manifolds with closed-form distance functions challenging.Quasimetric spaces, isolate the relevant properties of Riemannian distance functions without requiring any of their additional structure for graph embedding.A quasi-metric space is a set X with a distance function d :\nX \u00d7 X \u2192 [0, \u221e) satisfying for every x, y, z \u2208 X: i) d(x, y) = 0 if and only if x = y, ii) d(x, y) = d(y, x), iii) d(x, y) \u2264 C d(x, z) + d(z, y) , for some constant C \u2265 1.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      222140827,
      260926483,
      18356386
    ]
  },
  {
    "index": 2509,
    "source_corpus_id": 9226593,
    "ref_id": "b34",
    "citation_corpus_id": 14124313,
    "start": 5147,
    "end": 5175,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "We explore whether the usefulness of such features extends to visual servoing.",
    "curr": "To answer this question, we propose a visual servoing method that uses pre-trained features, in our case obtained from the VGG network (Simonyan & Zisserman, 2015) trained for ImageNet classification.",
    "next": "Besides the visual features, our method uses an estimate of the feature dynamics in visual space by means of a bilinear model.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      14008641,
      53776053,
      16213870
    ]
  },
  {
    "index": 2512,
    "source_corpus_id": 259164552,
    "ref_id": "b66",
    "citation_corpus_id": 215717103,
    "start": 18081,
    "end": 18085,
    "title": "Collecting Highly Parallel Data for Paraphrase Evaluation",
    "abstract": "A lack of standard datasets and evaluation metrics has prevented the field of paraphrasing from making the kind of rapid progress enjoyed by the machine translation community over the last 15 years. We address both problems by presenting a novel data collection framework that produces highly parallel text data relatively inexpensively and on a large scale. The highly parallel nature of this data allows us to use simple n-gram comparisons to measure both the semantic adequacy and lexical dissimilarity of paraphrase candidates. In addition to being simple and efficient to compute, experiments show that these metrics correlate highly with human judgments.",
    "prev": "Video Captioning.",
    "curr": "We evaluate video captioning on five benchmarks, including MSRVTT [60], MSVD [67], VATEX [68], YouCook2 [69], and TVC [70].",
    "next": "The GM objective is used, and captions are autoregressively generated during inference.",
    "hard_negative": [
      837398,
      11652247,
      9842595,
      1963942,
      11728052,
      8431414,
      1302329,
      13043395,
      16019656,
      2755801,
      11888861,
      7489770,
      6387310,
      10181753
    ],
    "easy_negative": [
      12848012,
      220835624,
      219530980
    ]
  },
  {
    "index": 2514,
    "source_corpus_id": 52909749,
    "ref_id": "b44",
    "citation_corpus_id": 1918428,
    "start": 1827,
    "end": 1846,
    "title": "A Neural Attention Model for Sentence Summarization",
    "abstract": "Summarization based on text extraction is inherently limited, but generation-style abstractive methods have proven challenging to build. In this work, we propose a fully data-driven approach to abstractive sentence summarization. Our method utilizes a local attention-based model that generates each word of the summary conditioned on the input sentence. While the model is structurally simple, it can easily be trained end-to-end and scales to a large amount of training data. The model shows significant performance gains on the DUC-2004 shared task compared with several strong baselines.",
    "prev": "Such encoder-decoder architectures are adopted in both machine translation (Bahdanau et al., 2015;Hassan et al., 2018) and speech recognition systems (Chan et al., 2016;Bahdanau et al., 2016a;Chiu et al., 2017) to achieve impressive performance beyond traditional multi-stage pipelines (Koehn et al., 2007;Povey et al., 2011).",
    "curr": "Improving the building blocks of seq2seq models can fundamentally advance machine translation and speech recognition, and positively impact other domains such as image captioning (Xu et al., 2015), parsing , summarization (Rush et al., 2015), and program synthesis (Zhong et al., 2017).",
    "next": "To improve the key components of seq2seq models, one can either design better architectures, or develop better learning algorithms.",
    "hard_negative": [
      14068874,
      9952653,
      1729177,
      12639289,
      964287,
      9586240,
      189898,
      2411338,
      9751546,
      8928636
    ],
    "easy_negative": [
      231839638,
      18776034,
      237372057
    ]
  },
  {
    "index": 2521,
    "source_corpus_id": 247451183,
    "ref_id": "b14",
    "citation_corpus_id": 13046179,
    "start": 3436,
    "end": 3461,
    "title": "A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS",
    "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.Published as a conference paper at ICLR 2017 one method which outperforms the baseline on some (but not all) tasks. This new method evaluates the quality of a neural network's input reconstruction to determine if an example is abnormal.",
    "prev": "The baseline approach for OOD detection relies on the predictive uncertainty of DNNs.",
    "curr": "Hendrycks & Gimpel (2017) demonstrated that OOD samples, in general, induce DNN classifiers to output less confident softmax scores, while existing state-of-the-art methods on classification problems still output high accuracy even under dataset shift.",
    "next": "For instance, Ovadia et al.",
    "hard_negative": [
      6628106,
      7105713,
      2879445,
      1428702
    ],
    "easy_negative": [
      7650859,
      227230639,
      254877347
    ]
  },
  {
    "index": 2522,
    "source_corpus_id": 263622464,
    "ref_id": "b29",
    "citation_corpus_id": 232290577,
    "start": 18145,
    "end": 18162,
    "title": "MARS: MARKOV MOLECULAR SAMPLING FOR MULTI-OBJECTIVE DRUG DISCOVERY",
    "abstract": "Searching for novel molecules with desired chemical properties is crucial in drug discovery. Existing work focuses on developing neural models to generate either molecular sequences or chemical graphs. However, it remains a big challenge to find novel and diverse compounds satisfying several properties. In this paper, we propose MARS, a method for multi-objective drug molecule discovery. MARS is based on the idea of generating the chemical candidates by iteratively editing fragments of molecular graphs. To search for high-quality candidates, it employs Markov chain Monte Carlo sampling (MCMC) on molecules with an annealing scheme and an adaptive proposal. To further improve sample efficiency, MARS uses a graph neural network (GNN) to represent and select candidate edits, where the GNN is trained on-the-fly with samples from MCMC. Experiments show that MARS achieves state-of-the-art performance in various multi-objective settings where molecular bio-activity, drug-likeness, and synthesizability are considered. Remarkably, in the most challenging setting where all four objectives are simultaneously optimized, our approach outperforms previous methods significantly in comprehensive evaluations. The code is available at",
    "prev": "(2020).",
    "curr": "RNA-Binding\n\n\nBASELINES\n\nWe consider prior GFlowNet (GFN) methods and reward-maximization methods as our baselines.Prior GFN methods include detailed balance (DB, Bengio et al., 2023), maximum entropy GFN (MaxEnt, Malkin et al., 2022), trajectory balance (TB, Malkin et al., 2022), sub-trajectory balance (SubTB, Madan et al., 2023), and substructure-guided trajectory balance (GTB, Shen et al., 2023).For reward-maximization methods, we consider Markov Molecular Sampling (MARS, Xie et al., 2020), which is a sampling-based method known to work well in the molecule domain, and RL-based methods which include advantage actor-critic (A2C) with entropy regularization (Mnih et al., 2016), Soft Q-Learning (SQL, Haarnoja et al., 2018), and proximal policy optimization (PPO, Schulman et al., 2017).",
    "next": "IMPLEMENTATIONS AND HYPERPARAMETERS\n\nFor GFN implementations, we strictly follow implementations from Shen et al.",
    "hard_negative": [
      54444711,
      210920362,
      213085920,
      202537332,
      196183669
    ],
    "easy_negative": [
      203691203,
      16088818,
      8027990
    ]
  },
  {
    "index": 2524,
    "source_corpus_id": 260704723,
    "ref_id": "b29",
    "citation_corpus_id": 201646309,
    "start": 20966,
    "end": 20991,
    "title": "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    "abstract": "BERT(Devlin et al., 2018)and RoBERTa (Liu  et al., 2019)  has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (~65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT.We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods. 1",
    "prev": "While well-formated options are provided, we empirically observe that many MLLMs struggle to strictly follow instructions to output the option indexes but generate free-form text.",
    "curr": "Thus, when models do not exactly output the required options, we match their outputs to one of the given options based on the TF-IDF distance, which we find is more robust than model-based methods (OpenAI,  2023a; Reimers & Gurevych, 2019).",
    "next": "Since we explore a large number of tasks, we take a maximum of 500 instances per task for evaluation efficiency and exclude several datasets that are difficult to obtain and are subject to strict copyright restrictions (referred to as DEMON-Core).",
    "hard_negative": [
      388,
      2937095,
      28971531,
      5033484,
      10241043,
      990233,
      195345563,
      3432876,
      12549805,
      1957433,
      11650107,
      646594,
      18283203,
      3264224,
      5394019,
      4421747,
      10181753
    ],
    "easy_negative": [
      236459897,
      256461208,
      237416431
    ]
  },
  {
    "index": 2527,
    "source_corpus_id": 251765079,
    "ref_id": "b28",
    "citation_corpus_id": 204960716,
    "start": 11733,
    "end": 11753,
    "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    "abstract": "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new stateof-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance. 1",
    "prev": "RetMol is agnostic to the choice of the underlying encoder and decoder architectures, enabling it to work with a variety of generative models and molecule representations.",
    "curr": "In this work, we consider the SMILES string (Weininger, 1988) representation of molecules and the ChemFormer model (Irwin et al., 2022), which a variant of BART (Lewis et al., 2020) trained on the billion-scale ZINC dataset (Irwin and Shoichet, 2004) and achieves state-of-the-art generation performance.",
    "next": "Retrieval database.",
    "hard_negative": [
      16639476,
      990233
    ],
    "easy_negative": [
      5090230,
      724244,
      215513848
    ]
  },
  {
    "index": 2532,
    "source_corpus_id": 239016943,
    "ref_id": "b8",
    "citation_corpus_id": 213152193,
    "start": 25070,
    "end": 25090,
    "title": "ELECTRA: PRE-TRAINING TEXT ENCODERS AS DISCRIMINATORS RATHER THAN GENERATORS",
    "abstract": "Masked language modeling (MLM) pre-training methods such as BERT corrupt the input by replacing some tokens with [MASK]  and then train a model to reconstruct the original tokens. While they produce good results when transferred to downstream NLP tasks, they generally require large amounts of compute to be effective. As an alternative, we propose a more sample-efficient pre-training task called replaced token detection. Instead of masking the input, our approach corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, we train a discriminative model that predicts whether each token in the corrupted input was replaced by a generator sample or not. Thorough experiments demonstrate this new pre-training task is more efficient than MLM because the task is defined over all input tokens rather than just the small subset that was masked out. As a result, the contextual representations learned by our approach substantially outperform the ones learned by BERT given the same model size, data, and compute. The gains are particularly strong for small models; for example, we train a model on one GPU for 4 days that outperforms GPT (trained using 30x more compute) on the GLUE natural language understanding benchmark. Our approach also works well at scale, where it performs comparably to RoBERTa and XLNet while using less than 1/4 of their compute and outperforms them when using the same amount of compute.",
    "prev": "BERT (Devlin et al., 2018) proposed the Masked Language Modeling (MLM) pretraining paradigm to train a deep bidirectional Transformer model; RoBERTa  removed the Next Sentence Prediction (NSP) task in BERT; XLNet  generalized BERT pretraining to the autoregressive manner; Span-level BERTs Song et al., 2019;Joshi et al., 2020) introduced span-level masks rather than just relying on token-level masks.",
    "curr": "ELECTRA (Clark et al., 2020) proposed to detect token replacement as opposed to token generation, improving both the efficiency and effectiveness of pretraining.",
    "next": "extends BERT to accommodate glyph information.",
    "hard_negative": [
      3655946,
      990233,
      53113638,
      3432876,
      1957433,
      5959482,
      3626819,
      259144,
      5034059,
      11816014,
      40100965,
      52967399,
      11758569,
      85464175,
      4421747,
      16639476
    ],
    "easy_negative": [
      18126734,
      14797130,
      18544112
    ]
  },
  {
    "index": 2533,
    "source_corpus_id": 12713052,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 3186,
    "end": 3208,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "curr": "INTRODUCTION\n\nThe last few years have seen much success of deep neural networks in many challenging applications, such as speech recognition , image recognition (LeCun et al., 1998;Krizhevsky et al., 2012) and machine translation (Sutskever et al., 2014;Bahdanau et al., 2015;.",
    "next": "Along with this success is a paradigm shift from feature designing to architecture designing, i.e., from SIFT (Lowe, 1999), and HOG (Dalal & Triggs, 2005), to AlexNet (Krizhevsky et al., 2012), VGGNet (Simonyan & Zisserman, 2014), GoogleNet , and ResNet (He et al., 2016a).",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      52182989,
      45893629,
      259367730
    ]
  },
  {
    "index": 2534,
    "source_corpus_id": 263609190,
    "ref_id": "b6",
    "citation_corpus_id": 67855286,
    "start": 2927,
    "end": 2929,
    "title": "ANTISYMMETRICRNN: A DYNAMICAL SYSTEM VIEW ON RECURRENT NEURAL NETWORKS",
    "abstract": "Recurrent neural networks have gained widespread use in modeling sequential data. Learning long-term dependencies using these models remains difficult though, due to exploding or vanishing gradients. In this paper, we draw connections between recurrent networks and ordinary differential equations. A special form of recurrent networks called the AntisymmetricRNN is proposed under this theoretical framework, which is able to capture long-term dependencies thanks to the stability property of its underlying differential equation. Existing approaches to improving RNN trainability often incur significant computation overhead. In comparison, AntisymmetricRNN achieves the same goal by design. We showcase the advantage of this new architecture through extensive simulations and experiments. AntisymmetricRNN exhibits much more predictable dynamics. It outperforms regular LSTM models on tasks requiring long-term memory and matches the performance on tasks where short-term dependencies dominate despite being much simpler. advocate going beyond initialization and forcing the weight matrices to be orthogonal throughout the entire learning process. However, some of these approaches come with significant computational overhead and reportedly hinder representation power of these models(Vorontsov et al., 2017). Moreover, orthogonal weight matrices alone do not prevent exploding and vanishing gradients, due to the nonlinear nature of deep neural networks as shown in(Pennington et al., 2017).Here we offer a new perspective on the trainability of RNNs from the dynamical system viewpoint. While exploding gradient is a manifestation of the instability of the underlying dynamical system, vanishing gradient results from a lossy system, properties that have been widely studied in the dynamical system literature(Haber & Ruthotto, 2017;Laurent & von Brecht, 2017). The main contributions of the work are:\u2022 We draw connections between RNNs and the ordinary differential equation theory and design new recurrent architectures by discretizing ODEs.",
    "prev": "ramework, while the S4D/S5 initialization only achieves weak convergences.As a result, our new models show resilience to Fourier-mode noise-perturbed inputs, a crucial property not achieved by the S4D/S5 models.In addition to improved robustness, our S5-PTD model averages 87.6% accuracy on the Long-Range Arena benchmark, demonstrating that the PTD methodology helps to improve the accuracy of deep learning models.",
    "curr": "Introduction\n\nSequential data are pervasive across a wide range of fields, including natural language processing, speech recognition, robotics and autonomous systems, as well as scientific machine learning and financial time-series analysis, among others.Given that many of these applications produce exceedingly long sequences, sequential models need to capture long-range temporal dependencies in order to yield accurate predictions.To this end, many specialized deep learning methods have been developed to deal with long sequences, including recurrent neural networks (RNNs) [2,7,13,30,14,28], convolutional neural networks (CNNs) [4,29], continuous-time models (CTMs) [18,37], and transformers [21,8,23,39,26].",
    "next": "Over the past few years, the new class of state-space models (SSMs) gained vast popularity for sequential modeling due to their outstanding performance on the Long-Range Arena (LRA) dataset [33].An SSM is built upon a continuous-time linear time-invariant (LTI) dynamical system \u03a3 = (A, B, C, D), which is a system of linear ODEs given by x \u2032 (t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t), (1) where A \u2208 C n\u00d7n , B \u2208 C n\u00d7m , C \u2208 C p\u00d7n , D \u2208 C p\u00d7m are the state, input, output and feedthrough matrices; and u(t) \u2208 C m , x(t) \u2208 C n , y(t) \u2208 C p are the inputs, states, and outputs of the system, respectively.The system can be discretized at time steps j\u2206t, where \u2206t > 0 and j = 1, .",
    "hard_negative": [
      3532296,
      3005102,
      5590763,
      35673326
    ],
    "easy_negative": [
      12564904,
      208267761,
      10254261
    ]
  },
  {
    "index": 2536,
    "source_corpus_id": 3538865,
    "ref_id": "b5",
    "citation_corpus_id": 5590763,
    "start": 1252,
    "end": 1269,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "* Equal contribution.",
    "curr": "INTRODUCTION\n\nSequence-to-sequence models (Sutskever et al., 2014;Cho et al., 2014) with a soft attention mechanism  have been successfully applied to a plethora of sequence transduction problems (Luong et al., 2015;Xu et al., 2015;Chorowski et al., 2015;Wang et al., 2017;See et al., 2017).",
    "next": "In their most familiar form, these models process an input sequence with an encoder recurrent neural network (RNN) to produce a sequence of hidden states, referred to as a memory.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      219310365,
      23316954,
      36515726
    ]
  },
  {
    "index": 2538,
    "source_corpus_id": 227746078,
    "ref_id": "b1",
    "citation_corpus_id": 3618568,
    "start": 3533,
    "end": 3552,
    "title": "Reading Wikipedia to Answer Open-Domain Questions",
    "abstract": "This paper proposes to tackle opendomain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval (finding the relevant articles) with that of machine comprehension of text (identifying the answer spans from those articles). Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.",
    "prev": "In this paper, we propose a procedure to learn retriever systems without strong supervision in the form of pairs of queries and documents.",
    "curr": "Following previous work (Chen et al., 2017), our approach uses two models: the first one retrieves documents from a large source of knowledge (the retriever), the second one processes the support documents to solve the task (the reader).",
    "next": "Our method is inspired by knowledge distillation (Hinton et al., 2015), and uses the reader model to obtain synthetic labels to train the retriever model.",
    "hard_negative": [
      6360322,
      14068874,
      12384779,
      6401679,
      1957433,
      10910955,
      5541486,
      216034672,
      11212020,
      14915449,
      2711679
    ],
    "easy_negative": [
      236460201,
      220326925,
      257985178
    ]
  },
  {
    "index": 2540,
    "source_corpus_id": 211146411,
    "ref_id": "b25",
    "citation_corpus_id": 196210081,
    "start": 2253,
    "end": 2270,
    "title": "Incremental Transformer with Deliberation Decoder for Document Grounded Conversations",
    "abstract": "Document Grounded Conversations is a task to generate dialogue responses when chatting about the content of a given document. Obviously, document knowledge plays a critical role in Document Grounded Conversations, while existing dialogue models do not exploit this kind of knowledge effectively enough. In this paper, we propose a novel Transformerbased architecture for multi-turn document grounded conversations. In particular, we devise an Incremental Transformer to encode multi-turn utterances along with knowledge in related documents. Motivated by the human cognitive process, we design a two-pass decoder (Deliberation Decoder) to improve context coherence and knowledge correctness. Our empirical study on a real-world Document Grounded Dataset proves that responses generated by our model significantly outperform competitive baselines on both context coherence and knowledge relevance. * * Fandong Meng is the corresponding author of the paper. This work was done when Zekang Li was interning at Pattern Recognition Center, WeChat AI, Tencent.",
    "prev": ".",
    "curr": "As it has been one of the key milestone tasks in conversational research (Zhang et al., 2018), a majority of previous works have studied how to effectively combine given knowledge and dialogue context to generate an utterance (Zhang et al., 2018;Li et al., 2019b;Parthasarathi & Pineau, 2018;Madotto et al., 2018;Gopalakrishnan et al., 2019).",
    "next": "Recently,  proposed to tackle the knowledge-grounded dialogue by decomposing it into two sub-problems: first selecting knowledge from a large pool of candidates and generating a response based on the selected knowledge and context.",
    "hard_negative": [
      7356547,
      1998416,
      47018994,
      7287895
    ],
    "easy_negative": [
      219309700,
      53097114,
      263830786
    ]
  },
  {
    "index": 2542,
    "source_corpus_id": 3285020,
    "ref_id": "b48",
    "citation_corpus_id": 3047732,
    "start": 1601,
    "end": 1627,
    "title": "Deep Multi-task Representation Learning: A Tensor Factorisation Approach",
    "abstract": "Most contemporary multi-task learning methods assume linear models. This setting is considered shallow in the era of deep learning. In this paper, we present a new deep multi-task representation learning framework that learns cross-task sharing structure at every layer in a deep network. Our approach is based on generalising the matrix factorisation techniques explicitly or implicitly used by many conventional MTL algorithms to tensor factorisation, to realise automatic learning of end-to-end knowledge sharing in deep networks. This is in contrast to existing deep learning approaches that need a user-defined multi-task sharing strategy. Our approach applies to both homogeneous and heterogeneous MTL, as well as multi-domain learning (MDL). Experiments demonstrate the efficacy of our deep multi-task representation learning in terms of both higher accuracy and fewer design choices.",
    "prev": "As deep learning has yielded state-ofthe-art systems across a range of domains, there has been increased focus on developing deep MTL techniques.",
    "curr": "Such techniques have been applied across settings such as vision (Bilen and Vedaldi, 2016;Jou and Chang, 2016;Misra et al., 2016;Ranjan et al., 2016;Yang and Hospedales, 2017;Zhang et al., 2014), natural language (Collobert and Weston, 2008;Dong et al., 2015;Hashimoto et al., 2016;Liu et al., 2015a;Luong et al., 2016), speech (Huang et al., 2013;2015;Seltzer and Droppo, 2013;, and reinforcement learning (Devin et al., 2016;Fernando et al., 2017;Jaderberg et al., 2017;Rusu et al., 2016).",
    "next": "Although they improve performance over single-task learning in these settings, these approaches have generally been constrained to joint training of relatively few and/or closely-related tasks.",
    "hard_negative": [
      275330,
      3281198,
      15002492
    ],
    "easy_negative": [
      227230633,
      9088468,
      11393064
    ]
  },
  {
    "index": 2543,
    "source_corpus_id": 3700344,
    "ref_id": "b26",
    "citation_corpus_id": 8535316,
    "start": 4180,
    "end": 4199,
    "title": "BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION",
    "abstract": "Machine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bidirectional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test.",
    "prev": "Thus SearchQA tests the ability of AQA to reformulate questions such that the QA system has the best chance of returning the correct answer.",
    "curr": "AQA outperforms a deep network built for QA, BiDAF [Seo et al., 2017a], which has produced state-of-the-art results on multiple tasks, by 11% absolute F1, a 32% relative F1 improvement.",
    "next": "We conclude by proposing AQA as a general framework for stateful, iterative information seeking tasks.",
    "hard_negative": [
      711424,
      10239453,
      6360322,
      2926851,
      9672033,
      11022639,
      14915449,
      2100831
    ],
    "easy_negative": [
      720511,
      247762223,
      263831484
    ]
  },
  {
    "index": 2547,
    "source_corpus_id": 209315300,
    "ref_id": "b14",
    "citation_corpus_id": 13751870,
    "start": 32389,
    "end": 32401,
    "title": "A Call for Clarity in Reporting BLEU Scores",
    "abstract": "The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to \"the\" BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for usersupplied reference processing, and provide a new tool, SACREBLEU, 1 to facilitate this. . 2016. Google's neural machine translation system: Bridging the gap between human and machine translation. ArXiv eprints, abs/1609.08144.",
    "prev": "Table 4 :\n4BLEU scores on newstest2014 for WMT English-German (EnDe).",
    "curr": "We additionally report detokenized BLEU scores as computed by sacreBLEU(Post, 2018).sacreBLEU \n\nhttps://github.com/google/trax/tree/master/trax/models/reformer 3 BLEU+case.lc+lang.en-de+numrefs.1+smooth.exp+test.wmt14/full+tok.intl+version.1.4.3 4 BLEU+case.mixed+lang.en-de+numrefs.1+smooth.exp+test.wmt14/full+tok.intl+version.1.4.3\n\nCharacter-level language modeling with deeper self-attention.",
    "next": "Rami Al-Rfou, Dokook Choe, Noah Constant, Mandy Guo, Llion Jones, abs/1808.04444CoRRRami Al-Rfou, Dokook Choe, Noah Constant, Mandy Guo, and Llion Jones.",
    "hard_negative": [
      512833,
      384994,
      2863491,
      16794216,
      49742509,
      2531955,
      7647892,
      17643319,
      1245593,
      21675165,
      252796,
      905565
    ],
    "easy_negative": [
      102354561,
      259370819,
      49567968
    ]
  },
  {
    "index": 2548,
    "source_corpus_id": 264172720,
    "ref_id": "b28",
    "citation_corpus_id": 257505014,
    "start": 10782,
    "end": 10800,
    "title": "Published as a conference paper at ICLR 2023 MESHDIFFUSION: SCORE-BASED GENERATIVE 3D MESH MODELING",
    "abstract": "We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parametrization. We demonstrate the effectiveness of our model on multiple generative tasks.Published as a conference paper at ICLR 2023 for computers, both voxels and point clouds are relatively hard for artists to edit, especially when the generated 3D shapes are complex and of low quality. Moreover, modern graphics pipelines are built and optimized for explicit geometry representations like meshes, making meshes one of the most desirable final 3D shape representations. While it is still possible to use methods like Poisson reconstruction to obtain surfaces from voxels and points clouds, the resulted surfaces are generally noisy and contain many topological artifacts, even with carefully tuned hyperparameters.To improve the representation flexibility, sign distance fields (SDFs) have been adopted to model shape surfaces, which enables us to use marching cubes [29] to extract the zero-surfaces and thus 3D meshes. However, SDFs are typically harder to learn as it requires a carefully designed sampling strategy and regularization. Because SDFs are usually parameterized with multi-layer perceptrons (MLPs) in which a smoothness prior is implicitly embedded, the generated shapes tend to be so smooth that sharp edges and important (and potentially semantic) details are lost. Moreover, SDFs are costly to render and therefore less suitable for downstream tasks like conditional generation with RGB images, which require an efficient differentiable renderer during inference.We instead aim to generate 3D shapes by directly producing 3D meshes, where surfaces are represented as a graph of triangular or polygon faces. With 3D meshes, all local surface information is completely included in the mesh vertices (along with the vertex connectivity), because the surface normal of any point on the shape surface is simply a nearest neighbor or some local linear combination of vertex normals. Such a regular structure with rich geometric details enables us to better model the data distribution and learn generative models that are more geometry-aware. In light of recent advances in score-based generative modeling[16,47]where powerful generative performance and effortless training are demonstrated, we propose to train diffusion models on these vertices to generate meshes. However, it is by no means a trivial task and poses two critical problems: (1) the numbers of vertices and faces are indefinite for general object categories, and (2) the underlying topology varies wildly and edges have to be generated at the same time.",
    "prev": "3D Generation with Diffusion Models.",
    "curr": "Drawing inspiration from 2D generation, recent endeavours have been made to train generative models on 3D datasets conditioned on text or images (Cheng et al., 2023;Liu et al., 2023d;Gupta et al., 2023;Zheng et al., 2023).",
    "next": "However, they are usually confined to specific categories with unsatisfactory generation results.",
    "hard_negative": [
      222179041,
      52889459,
      222140788,
      227209335
    ],
    "easy_negative": [
      245838278,
      11450322,
      541539
    ]
  },
  {
    "index": 2550,
    "source_corpus_id": 252846166,
    "ref_id": "b21",
    "citation_corpus_id": 3529936,
    "start": 4728,
    "end": 4746,
    "title": "Gradient Estimators for Implicit Models",
    "abstract": "Implicit models, which allow for the generation of samples but not for point-wise evaluation of probabilities, are omnipresent in real world problems tackled by machine learning and a hot topic of current research. Some examples include data simulators that are widely used in engineering and scientific research, generative adversarial networks (GANs) for image synthesis, and hot-off-the-press approximate inference techniques relying on implicit distributions. The majority of existing approaches to learning implicit models rely on approximating the intractable distribution or optimisation objective for gradient-based optimisation, which is liable to produce inaccurate updates and thus poor models. This paper alleviates the need for such approximations by proposing the Stein gradient estimator, which directly estimates the score function of the implicitly defined distribution. The efficacy of the proposed estimator is empirically demonstrated by examples that include meta-learning for approximate inference, and entropy regularised GANs that provide improved sample diversities.",
    "prev": "Rolland et al.",
    "curr": "(2022) estimate the Hessian point-wise with a second-order Stein gradient estimator (Li & Turner, 2018) over a radial basis function (RBF) kernel.",
    "next": "However, point-wise estimation with kernels scales poorly to datasets with large number of samples n because it requires inverting a n \u00d7 n kernel matrix.",
    "hard_negative": [
      6628106,
      11758569
    ],
    "easy_negative": [
      1269384,
      44179423,
      6057840
    ]
  },
  {
    "index": 2555,
    "source_corpus_id": 215737267,
    "ref_id": "b46",
    "citation_corpus_id": 3687922,
    "start": 7549,
    "end": 7571,
    "title": "SEMI-PARAMETRIC TOPOLOGICAL MEMORY FOR NAVIGATION",
    "abstract": "We introduce a new memory architecture for navigation in previously unseen environments, inspired by landmark-based navigation in animals. The proposed semiparametric topological memory (SPTM) consists of a (non-parametric) graph with nodes corresponding to locations in the environment and a (parametric) deep network capable of retrieving nodes from the graph based on observations. The graph stores no metric information, only connectivity of locations corresponding to the nodes. We use SPTM as a planning module in a navigation system. Given only 5 minutes of footage of a previously unseen maze, an SPTM-based navigation agent can build a topological map of the environment and use it to confidently navigate towards goals. The average success rate of the SPTM agent in goal-directed navigation across test environments is higher than the best-performing baseline by a factor of three.",
    "prev": "These classical methods have inspired recent learning-based techniques.",
    "curr": "Researchers have designed neural network policies that reason via spatial representations Henriques and Vedaldi, 2018;Gordon et al., 2018), topological representations (Savinov et al., 2018;, or use differentiable and trainable planners (Tamar et al., 2016;Lee et al., 2018;Khan et al., 2017).",
    "next": "Our work furthers this research, and we study a hierarchical and modular decomposition of the problem and employ learning inside these components instead of end-to-end learning.",
    "hard_negative": [
      6628106,
      534043,
      13298214,
      16134629
    ],
    "easy_negative": [
      218487272,
      15641974,
      18611199
    ]
  },
  {
    "index": 2556,
    "source_corpus_id": 11245315,
    "ref_id": "b19",
    "citation_corpus_id": 10489017,
    "start": 3806,
    "end": 3822,
    "title": "End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF",
    "abstract": "State-of-the-art sequence labeling systems traditionally require large amounts of taskspecific knowledge in the form of handcrafted features and data pre-processing. In this paper, we introduce a novel neutral network architecture that benefits from both word-and character-level representations automatically, by using combination of bidirectional LSTM, CNN and CRF. Our system is truly end-to-end, requiring no feature engineering or data preprocessing, thus making it applicable to a wide range of sequence labeling tasks. We evaluate our system on two data sets for two sequence labeling tasks -Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003 corpus for named entity recognition (NER). We obtain state-of-the-art performance on both datasets -97.55% accuracy for POS tagging and 91.21% F1 for NER.",
    "prev": "In a nutshell, dropout randomly \"drops\" neural units during training as a means to prevent feature co-adaptation-a sign of overfitting (Hinton et al., 2012).",
    "curr": "Simple as it appears to be, dropout has led to several record-breaking performances (Hinton et al., 2012;Ma & Hovy, 2016), and thus spawned a lot of recent interests in analyzing and justifying dropout from the theoretical perspective, and also in further improving dropout from the algorithmic and practical perspective.",
    "next": "In their pioneering work, Hinton et al.",
    "hard_negative": [
      7973006,
      14584850,
      11336213,
      793886,
      9150889,
      8148140,
      306227,
      12926517,
      1957433,
      643522,
      825928,
      15876808,
      12675146,
      1689426,
      10242516,
      11616343,
      28873816,
      7663461,
      1845735,
      1862889,
      6042994,
      252796
    ],
    "easy_negative": [
      62737067,
      2238974,
      173990567
    ]
  },
  {
    "index": 2557,
    "source_corpus_id": 238419331,
    "ref_id": "b2",
    "citation_corpus_id": 215737187,
    "start": 3212,
    "end": 3235,
    "title": "Dense Passage Retrieval for Open-Domain Question Answering",
    "abstract": "Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dualencoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks. 1",
    "prev": "In NAACL-HLT, 2021.",
    "curr": "INTRODUCTION\n\nDense text retrieval Karpukhin et al., 2020) has achieved great successes in a wide variety of both research and industrial areas, such as search engines (Brickley et al., 2019;Shen et al., 2014), recommendation system (Hu et al., 2020), open-domain question answering (Guo et al., 2018;, etc.",
    "next": "A typical dense retrieval model adopts a dual-encoder (Huang et al., 2013) architecture to encode queries and documents into low-dimensional embedding vectors, with the relevance between query and document being measured by the similarity between embeddings.",
    "hard_negative": [
      3618568,
      59604492,
      6401679,
      208267807,
      189762341,
      26501419,
      201307832,
      51875405,
      11816014,
      1965270,
      202558815,
      52967399,
      5541486,
      202660724
    ],
    "easy_negative": [
      5687975,
      218973998,
      304957
    ]
  },
  {
    "index": 2559,
    "source_corpus_id": 223953594,
    "ref_id": "b19",
    "citation_corpus_id": 8394195,
    "start": 2633,
    "end": 2653,
    "title": "LOSSY IMAGE COMPRESSION WITH COMPRESSIVE AUTOENCODERS",
    "abstract": "We propose a new approach to the problem of optimizing autoencoders for lossy image compression. New media formats, changing hardware technology, as well as diverse requirements and content types create a need for compression algorithms which are more flexible than existing codecs. Autoencoders have the potential to address this need, but are difficult to optimize directly due to the inherent non-differentiabilty of the compression loss. We here show that minimal changes to the loss are sufficient to train deep autoencoders competitive with JPEG 2000 and outperforming recently proposed approaches based on RNNs. Our network is furthermore computationally efficient thanks to a sub-pixel architecture, which makes it suitable for high-resolution images. This is in contrast to previous work on autoencoders for compression using coarser approximations, shallower architectures, computationally expensive methods, or focusing on small images.",
    "prev": "Any further improvement is expected to be even more difficult.",
    "curr": "Inspired by the successful stories of deep learning in many vision tasks, several pioneer works [Toderici et al., 2016, Agustsson et al., 2017, Theis et al., 2017, Ball\u00e9 et al., 2017, Ball\u00e9 et al., 2018, Mentzer et al., 2018, Lee et al., 2019, Minnen et al., 2018a demonstrate that the image compression task can be effectively solved by deep learning too.",
    "next": "This breakthrough allows us to use data-driven learning system to design novel compression algorithms automatically.",
    "hard_negative": [
      6628106,
      2187805
    ],
    "easy_negative": [
      2468769,
      14749549,
      237433853
    ]
  },
  {
    "index": 2561,
    "source_corpus_id": 600040,
    "ref_id": "b4",
    "citation_corpus_id": 11212020,
    "start": 2813,
    "end": 2816,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "Some previous work propose to adapt phrase-based statistical machine translation (SMT) for code migration [26,20,27].",
    "curr": "Recently, neural network approaches, such as sequence-to-sequencebased models, have achieved the state-of-the-art performance on machine translation [5,10,14,15,36].",
    "next": "In this work, we study neural machine translation methods to handle the program translation problem.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      18996812,
      259376912,
      249204425
    ]
  },
  {
    "index": 2564,
    "source_corpus_id": 256697328,
    "ref_id": "b3",
    "citation_corpus_id": 231918471,
    "start": 4182,
    "end": 4210,
    "title": "SCALABLE BAYESIAN INVERSE REINFORCEMENT LEARNING",
    "abstract": "Bayesian inference over the reward presents an ideal solution to the ill-posed nature of the inverse reinforcement learning problem. Unfortunately current methods generally do not scale well beyond the small tabular setting due to the need for an inner-loop MDP solver, and even non-Bayesian methods that do themselves scale often require extensive interaction with the environment to perform well, being inappropriate for high stakes or costly applications such as healthcare. In this paper we introduce our method, Approximate Variational Reward Imitation Learning (AVRIL), that addresses both of these issues by jointly learning an approximate posterior distribution over the reward that scales to arbitrarily complicated state spaces alongside an appropriate policy in a completely offline manner through a variational approach to said latent reward. Applying our method to real medical data alongside classic control simulations, we demonstrate Bayesian reward inference in environments beyond the scope of current methods, as well as task performance competitive with focused offline imitation learning algorithms.",
    "prev": "(2020;.",
    "curr": "Unfortunately, to the best of our knowledge, this challenge remains not well understood in offline IRL, albeit there is some recent progress (Zolna et al., 2020;Garg et al., 2021;Chan & van der Schaar, 2021).",
    "next": "Thus motivated, the key question this paper seeks to answer is: \"How to devise offline IRL algorithms that can ameliorate the reward extrapolation error effectively?\"",
    "hard_negative": [
      108304275,
      209202457,
      208857409
    ],
    "easy_negative": [
      222177356,
      12226252,
      251307710
    ]
  },
  {
    "index": 2567,
    "source_corpus_id": 263311025,
    "ref_id": "b42",
    "citation_corpus_id": 202539551,
    "start": 2893,
    "end": 2915,
    "title": "Language Models as Knowledge Bases?",
    "abstract": "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as \"fillin-the-blank\" cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-theart pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https: //github.com/facebookresearch/LAMA.",
    "prev": "1 Our code is available at: https://github.com/Vaidehi99/InfoDeletionAttacks arXiv:2309.17410v1 [cs.CL] 29 Sep 2023\u2022 How can we \"delete\" specific sensitive information from language models when we do not want models to know or express this information?\u2022 How do we test whether that specific information was successfully deleted?Language ModelLanguage Model\n\nINTRODUCTION\n\nLarge language models (LLMs) now possess much factual knowledge about the world.",
    "curr": "This knowledge can be extracted from models using natural language prompts (Petroni et al., 2019), or models can be finetuned to answer user questions within a dialogue (Ouyang et al., 2022).",
    "next": "Notably, these models sometimes possess knowledge that we do not wish them to, including memorized personal information (Carlini et al., 2021), knowledge that could be used to harm people (e.g.",
    "hard_negative": [
      3226120,
      53296520,
      2924682,
      52113185,
      108300988,
      3626819,
      5034059,
      11816014,
      85205,
      8781666,
      4612975
    ],
    "easy_negative": [
      225062648,
      15238040,
      248834196
    ]
  },
  {
    "index": 2571,
    "source_corpus_id": 53483457,
    "ref_id": "b1",
    "citation_corpus_id": 11212020,
    "start": 2347,
    "end": 2370,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "However, learning vanilla RNNs over long distance proves to be difficult due to the vanishing gradient problem (Bengio et al., 1994;Pascanu et al., 2013).",
    "curr": "One alleviation is to introduce skip-connections along the execution path, in the forms of dilated layers (Van Den Oord et al., 2016;Chang et al., 2017), attention mechanisms (Bahdanau et al., 2015;Vaswani et al., 2017) and external memory (Graves et al., 2014;2016).",
    "next": "Amongst all, using external memory most resembles human cognitive architecture where we perceive the world sequentially and make decision by consulting our memory.",
    "hard_negative": [
      1274371,
      13805769,
      5590763,
      8884845,
      10766958,
      1870512,
      8608051,
      11336213,
      12639289
    ],
    "easy_negative": [
      248392030,
      227231518,
      216051399
    ]
  },
  {
    "index": 2572,
    "source_corpus_id": 238634219,
    "ref_id": "b21",
    "citation_corpus_id": 68167178,
    "start": 29445,
    "end": 29462,
    "title": "Neural Approaches to Conversational AI",
    "abstract": "This tutorial surveys neural approaches to conversational AI that were developed in the last few years. We group conversational systems into three categories: (1) question answering agents, (2) task-oriented dialogue agents, and (3) social bots. For each category, we present a review of state-of-the-art neural approaches, draw the connection between neural approaches and traditional symbolic approaches, and discuss the progress we have made and challenges we are facing, using specific systems and models as case studies.",
    "prev": "We stress-test full fine-tuning under DP on the task of chit-chat dialog generation.",
    "curr": "This task has the distinct challenge that the response space is intrinsically diverse (Li et al., 2015;Gao et al., 2018) since human conversations can be informal and noisy (Zhang et al., 2019).",
    "next": "Moreover, dialog datasets are usually formed with user data which may contain sensitive information.",
    "hard_negative": [
      12633363,
      7287895,
      2955580
    ],
    "easy_negative": [
      15380259,
      244713935,
      202539208
    ]
  },
  {
    "index": 2573,
    "source_corpus_id": 264306111,
    "ref_id": "b27",
    "citation_corpus_id": 56657912,
    "start": 14150,
    "end": 14180,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "IMAGE CLASSIFICATION\n\nTask statement.Image classification is the most common challenge for representation learning.",
    "curr": "We conduct experiments on ImageNet1k (Deng et al., 2009) for accuracy, and additionally evaluate on robustness benchmarks: corrupted images from ImageNet-C (Hendrycks & Dietterich, 2018), natural adversarial images from ImageNet-A (Hendrycks et al., 2021b), and out-of-distribution images from ImageNet-SK (Wang et al., 2019) and ImageNet-R (Hendrycks et al., 2021a).",
    "next": "Design.Without loss of generality, we select ViT (Dosovitskiy et al., 2021) due to its wide use and native support for transformers.Following the notation in Eqn.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      220444937,
      31188530,
      15179147
    ]
  },
  {
    "index": 2581,
    "source_corpus_id": 252668622,
    "ref_id": "b7",
    "citation_corpus_id": 232076011,
    "start": 3754,
    "end": 3757,
    "title": "Published as a conference paper at ICLR 2021 GRADIENT DESCENT ON NEURAL NETWORKS TYPI- CALLY OCCURS AT THE EDGE OF STABILITY",
    "abstract": "We empirically demonstrate that full-batch gradient descent on neural network training objectives typically operates in a regime we call the Edge of Stability. In this regime, the maximum eigenvalue of the training loss Hessian hovers just above the value 2/(step size), and the training loss behaves non-monotonically over short timescales, yet consistently decreases over long timescales. Since this behavior is inconsistent with several widespread presumptions in the field of optimization, our findings raise questions as to whether these presumptions are relevant to neural network training. We hope that our findings will inspire future efforts aimed at rigorously understanding optimization at the Edge of Stability.arXiv:2103.00065v3 [cs.LG] 23 Nov 2022Published as a conference paper at ICLR 2021 this happens, gradient descent does not diverge entirely or stall. Instead, it enters a regime we call the Edge of Stability 1 ( \u00a73.2), in which (1) the sharpness hovers right at, or just above, the value 2/\u03b7; and (2) the train loss behaves non-monotonically, yet consistently decreases over long timescales. In this regime, gradient descent is constantly \"trying\" to increase the sharpness, but is constantly restrained from doing so. The net effect is that gradient descent continues to successfully optimize the training objective, but in such a way as to avoid further increasing the sharpness. 2",
    "prev": "Recently, Cohen et al.",
    "curr": "[8] observed two important phenomena for gradient descent, which made more precise similar observations in Jastrz\u0119bski et al.",
    "next": "[15,16] for SGD:\n\nProgressive Sharpening Throughout most of the optimization trajectory, the gradient of the loss is negatively aligned with the gradient of sharpness, i.e.",
    "hard_negative": [
      16299141,
      211678094,
      204734206
    ],
    "easy_negative": [
      247476096,
      247446906,
      222378161
    ]
  },
  {
    "index": 2582,
    "source_corpus_id": 67856213,
    "ref_id": "b16",
    "citation_corpus_id": 3568073,
    "start": 2865,
    "end": 2886,
    "title": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024 2 . We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.",
    "prev": "Furthermore, since these large models operate at a fine timescale, their autoencoder variants are restricted to only modeling local latent structure due to memory constraints (Engel et al., 2017).",
    "curr": "On the other end of the spectrum, Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) have seen great recent success at generating high resolution images Berthelot et al., 2017;Kodali et al., 2017;Karras et al., 2018a;Miyato et al., 2018).",
    "next": "Typical GANs achieve both efficient parallel sampling and global latent control by conditioning a stack of transposed convolutions on a latent vector, The potential for audio GANs extends further, as adversarial costs have unlocked intriguing domain transformations for images that could possibly have analogues in audio Wolf et al., 2017;Jin et al., 2017).",
    "hard_negative": [
      18828233,
      6628106
    ],
    "easy_negative": [
      905565,
      16868700,
      14110756
    ]
  },
  {
    "index": 2585,
    "source_corpus_id": 12933888,
    "ref_id": "b6",
    "citation_corpus_id": 5590763,
    "start": 2711,
    "end": 2729,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "Generating a naturallanguage description of a video, termed video captioning, is an important component of video analysis.",
    "curr": "Inspired by the successful encoder-decoder framework used in machine translation (Cho et al., 2014;Bahdanau et al., 2015; and image caption generation (Kiros et al., 2014;Vinyals et al., 2015;Karpathy & Li, 2015;Mao et al., 2015), most recent work on video captioning (Donahue et al., 2015;Venugopalan et al., 2015a;Pan et al., 2016b;Yu et al., 2016) employs a twodimensional (2D) or three-dimensional (3D) Convolutional Neural Network (CNN) as an encoder, mapping an input video to a compact feature-vector representation.",
    "next": "A Recurrent Neural Network (RNN) is typically employed as a decoder, unrolling the feature vector to generate a sequence of words of arbitrary length.",
    "hard_negative": [
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      7417943,
      38407095,
      5552894
    ],
    "easy_negative": [
      9431510,
      7823468,
      253080870
    ]
  },
  {
    "index": 2586,
    "source_corpus_id": 56657912,
    "ref_id": "b23",
    "citation_corpus_id": 13046179,
    "start": 2201,
    "end": 2227,
    "title": "A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS",
    "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.Published as a conference paper at ICLR 2017 one method which outperforms the baseline on some (but not all) tasks. This new method evaluates the quality of a neural network's input reconstruction to determine if an example is abnormal.",
    "prev": "It is also essential for creating deep learning systems that can be deployed in safety-critical applications.",
    "curr": "Most work on robustness in deep learning methods for vision has focused on the important challenges of robustness to adversarial examples (Szegedy et al., 2014;Carlini & Wagner, 2017;, unknown unknowns (Hendrycks et al., 2019;Hendrycks & Gimpel, 2017b;Liu et al., 2018), and model or data poisoning (Steinhardt et al., 2017;.",
    "next": "In contrast, we develop and validate datasets for two other forms of robustness.",
    "hard_negative": [
      6628106,
      7105713,
      2879445,
      1428702,
      6706414
    ],
    "easy_negative": [
      251518354,
      8282858,
      237420508
    ]
  },
  {
    "index": 2589,
    "source_corpus_id": 6039192,
    "ref_id": "b20",
    "citation_corpus_id": 252796,
    "start": 17651,
    "end": 17672,
    "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
    "abstract": "There is a growing consensus that significant, rapid progress can be made in both text understanding and spoken language understanding by investigating those phenomena that occur most centrally in naturally occurring unconstrained materials and by attempting to automatically extract information about language from very large corpora. Such corpora are beginning to serve as important research tools for investigators in natural language processing, speech recognition, and integrated spoken language systems, as well as in theoretical linguistics. Annotated corpora promise to be valuable for enterprises as diverse as the automatic construction of statistical models for the grammar of the written and the colloquial spoken language, the development of explicit formal theories of the differing grammars of writing and speech, the investigation of prosodic phenomena in speech, and the evaluation and comparison of the adequacy of parsing models.In this paper, we review our experience with constructing one such large annotated corpus--the Penn Treebank, a corpus 1 consisting of over 4.5 million words of American English. During the first three-year phase of the Penn Treebank Project (1989)(1990)(1991)(1992), this corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure. These materials are available to members of the Linguistic Data Consortium; for details, see Section 5.1.The paper is organized as follows. Section 2 discusses the POS tagging task. After outlining the considerations that informed the design of our POS tagset and presenting the tagset itself, we describe our two-stage tagging process, in which text is first assigned POS tags automatically and then corrected by human annotators. Section 3 briefly presents the results of a comparison between entirely manual and semi-automated tagging, with the latter being shown to be superior on three counts: speed, consistency, and accuracy. In Section 4, we turn to the bracketing task. Just as with the tagging task, we have partially automated the bracketing task: the output of",
    "prev": "EXPERIMENTS\n\nWe assess the performance of our proposed TopicRNN model on word prediction and sentiment analysis 5 .",
    "curr": "For word prediction we use the Penn TreeBank dataset, a standard benchmark for assessing new language models (Marcus et al., 1993).",
    "next": "For sentiment analysis we use the IMDB 100k dataset (Maas et al., 2011), also a common benchmark dataset for this application 6 .",
    "hard_negative": [
      696805,
      3166885,
      2369736,
      12951757,
      5153623,
      2769726
    ],
    "easy_negative": [
      221949407,
      102353391,
      2042393
    ]
  },
  {
    "index": 2592,
    "source_corpus_id": 3904215,
    "ref_id": "b30",
    "citation_corpus_id": 252796,
    "start": 10125,
    "end": 10129,
    "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
    "abstract": "There is a growing consensus that significant, rapid progress can be made in both text understanding and spoken language understanding by investigating those phenomena that occur most centrally in naturally occurring unconstrained materials and by attempting to automatically extract information about language from very large corpora. Such corpora are beginning to serve as important research tools for investigators in natural language processing, speech recognition, and integrated spoken language systems, as well as in theoretical linguistics. Annotated corpora promise to be valuable for enterprises as diverse as the automatic construction of statistical models for the grammar of the written and the colloquial spoken language, the development of explicit formal theories of the differing grammars of writing and speech, the investigation of prosodic phenomena in speech, and the evaluation and comparison of the adequacy of parsing models.In this paper, we review our experience with constructing one such large annotated corpus--the Penn Treebank, a corpus 1 consisting of over 4.5 million words of American English. During the first three-year phase of the Penn Treebank Project (1989)(1990)(1991)(1992), this corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure. These materials are available to members of the Linguistic Data Consortium; for details, see Section 5.1.The paper is organized as follows. Section 2 discusses the POS tagging task. After outlining the considerations that informed the design of our POS tagset and presenting the tagset itself, we describe our two-stage tagging process, in which text is first assigned POS tags automatically and then corrected by human annotators. Section 3 briefly presents the results of a comparison between entirely manual and semi-automated tagging, with the latter being shown to be superior on three counts: speed, consistency, and accuracy. In Section 4, we turn to the bracketing task. Just as with the tagging task, we have partially automated the bracketing task: the output of",
    "prev": "To avoid this effect, we scale down the skip connection slightly, setting \u03b1 = 0.99.",
    "curr": "Experiments\n\n\nCharacter-level Penn Treebank\n\nWe train character level RNN language models on Penn Treebank [31], a 6MB text corpus with a vocabulary of 54 characters.",
    "next": "Because of the small size of the dataset, proper regularization is key to getting good performance.",
    "hard_negative": [
      696805,
      3166885,
      2369736,
      12951757,
      5153623,
      2769726
    ],
    "easy_negative": [
      9581267,
      252683604,
      238638481
    ]
  },
  {
    "index": 2594,
    "source_corpus_id": 228063930,
    "ref_id": "b2",
    "citation_corpus_id": 52889459,
    "start": 3886,
    "end": 3905,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "In contrast, our model can synthesize diverse and high-quality images while only using an adversarial loss, without any external supervision.",
    "curr": "INTRODUCTION\n\nConditional generative adversarial networks (GANs) (Mirza & Osindero, 2014) synthesize images conditioned on class labels Brock et al., 2019), text (Reed et al., 2016;Zhang et al., 2018a), other images (Isola et al., 2017;Huang et al., 2018), or semantic label maps (Wang et al., 2018;Park et al., 2019).",
    "next": "In this work, we focus on the latter, addressing semantic image synthesis.",
    "hard_negative": [
      17272965,
      3398677,
      5687613
    ],
    "easy_negative": [
      237329472,
      227231068,
      10570679
    ]
  },
  {
    "index": 2599,
    "source_corpus_id": 252762386,
    "ref_id": "b3",
    "citation_corpus_id": 213488539,
    "start": 7351,
    "end": 7373,
    "title": "Published as a conference paper at ICLR 2020 LEARNING FROM RULES GENERALIZING LABELED EXEMPLARS",
    "abstract": "In many applications labeled data is not readily available, and needs to be collected via pain-staking human supervision. We propose a rule-exemplar method for collecting human supervision to combine the efficiency of rules with the quality of instance labels. The supervision is coupled such that it is both natural for humans and synergistic for learning. We propose a training algorithm that jointly denoises rules via latent coverage variables, and trains the model through a soft implication loss over the coverage and label variables. The denoised rules and trained model are used jointly for inference. Empirical evaluation on five different tasks shows that (1) our algorithm is more accurate than several existing methods of learning from a mix of clean and noisy supervision, and (2) the coupled rule-exemplar supervision is effective in denoising rules.",
    "prev": "One recent line of work has considered constraining the space of possible pseudolabels via weak labeler accuracies (Arachie & Huang, 2019;Mazzetto et al., 2021a;b;Arachie & Huang, 2021;2022).",
    "curr": "Other works improve the aggregation scheme (Xu et al., 2021) or the weak labelers (Awasthi et al., 2020).",
    "next": "We note that only one method incorporates any notion of smoothness into the weakly supervised pipeline (Chen et al., 2022).",
    "hard_negative": [
      3300937,
      44122339,
      7663461
    ],
    "easy_negative": [
      10919306,
      7930242,
      60119001
    ]
  },
  {
    "index": 2601,
    "source_corpus_id": 247741267,
    "ref_id": "b41",
    "citation_corpus_id": 207878944,
    "start": 6178,
    "end": 6199,
    "title": "EXPLANATION BY PROGRESSIVE EXAGGERATION",
    "abstract": "As machine learning methods see greater adoption and implementation in high stakes applications such as medical image diagnosis, the need for model interpretability and explanation has become more critical.Classical approaches that assess feature importance (e.g., saliency maps) do not explain how and why a particular region of an image is relevant to the prediction.We propose a method that explains the outcome of a classification black-box by gradually exaggerating the semantic effect of a given class.Given a query input to a classifier, our method produces a progressive set of plausible variations of that query, which gradually changes the posterior probability from its original class to its negation.These counter-factually generated samples preserve features unrelated to the classification decision, such that a user can employ our method as a \"tuning knob\" to traverse a data manifold while crossing the decision boundary.Our method is model agnostic and only requires the output value and gradient of the predictor with respect to its input.",
    "prev": "It is suitable for lay-users and includes several measures to ensure high-quality crowd-sourced responses, \u2022 A strong and simple baseline explanation technique using only the model output, which we propose as a benchmark for future studies, \u2022 We open-source our dataset, explanation techniques, model, study design, including instructions and videos to support replicating our results as well as adapting our design to other explanation techniques.",
    "curr": "RELATED WORK\n\nInterpretable ML for Vision Different explanation approaches have been proposed: saliency maps (Bach et al., 2015;Ancona et al., 2018;Sundararajan et al., 2017), example-based explanations (Cai et al., 2019), counterfactual examples (Singla et al., 2020), activation-concept approaches (Kim et al., 2018), or models with built-in interpretability (Chen et al., 2019;Brendel & Bethge, 2018).",
    "next": "For a detailed review about the field, we refer to (Gilpin et al., 2018;Molnar et al., 2020).",
    "hard_negative": [
      12998557,
      1450294,
      3633127,
      52889459,
      8217340
    ],
    "easy_negative": [
      1412569,
      261341854,
      198977064
    ]
  },
  {
    "index": 2605,
    "source_corpus_id": 238634210,
    "ref_id": "b6",
    "citation_corpus_id": 56657912,
    "start": 25768,
    "end": 25771,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "Real data\n\nIn deep learning, out-of-distribution robustness is often assessed based on a model performance gap between the original data (used for training) and data to which various perturbations are applied.",
    "curr": "We focus on two image classification datasets with induced corruptions: MNIST-C [13] and CIFAR-10-C [7,11].",
    "next": "We illustrate an example of a clean MNIST image on Figure 5a along with its corrupted versions after applying motion blur, blur along a random direction (Figure 5b), translate, affine transformation along a random direction (Figure 5c), and zigzag, randomly oriented zigzag over an image (Figure 5d).",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      245838344,
      14465500,
      15267314
    ]
  },
  {
    "index": 2608,
    "source_corpus_id": 221340643,
    "ref_id": "b21",
    "citation_corpus_id": 6488690,
    "start": 2475,
    "end": 2500,
    "title": "Injecting Logical Background Knowledge into Embeddings for Relation Extraction",
    "abstract": "Matrix factorization approaches to relation extraction provide several attractive features: they support distant supervision, handle open schemas, and leverage unlabeled data. Unfortunately, these methods share a shortcoming with all other distantly supervised approaches: they cannot learn to extract target relations without existing data in the knowledge base, and likewise, these models are inaccurate for relations with sparse data. Rule-based extractors, on the other hand, can be easily extended to novel relations and improved for existing but inaccurate relations, through first-order formulae that capture auxiliary domain knowledge. However, usually a large set of such formulae is necessary to achieve generalization.In this paper, we introduce a paradigm for learning low-dimensional embeddings of entity-pairs and relations that combine the advantages of matrix factorization with first-order logic domain knowledge. We introduce simple approaches for estimating such embeddings, as well as a novel training algorithm to jointly optimize over factual and first-order logic information. Our results show that this method is able to learn accurate extractors with little or no distant supervision alignments, while at the same time generalizing to textual patterns that do not appear in the formulae.",
    "prev": "Introduction\n\nNeural networks have become the de-facto standard for solving perceptual tasks over low level representations, such as pixels in an image or audio signals.",
    "curr": "Recent research has also explored their application for solving symbolic reasoning tasks, requiring higher level inferences, such as neural theorem proving [Rockt\u00e4schel et al., 2015, Evans and Grefenstette, 2018, Minervini et al., 2020, and playing blocks world [Dong et al., 2019].",
    "next": "The advantage of neural models for these tasks is that it will create a unified, end-to-end trainable representation for integrated AI systems that combine perceptual and high level reasoning.",
    "hard_negative": [
      11825156,
      1729543,
      10202504,
      17526435,
      4408231,
      2687019,
      15075376,
      2158386,
      5869747,
      16483125,
      2238015,
      2816192,
      25845573,
      3179848,
      18597583,
      17981782,
      6745820,
      370914,
      9676646,
      10910955,
      11296630
    ],
    "easy_negative": [
      67855269,
      227231567,
      248780431
    ]
  },
  {
    "index": 2611,
    "source_corpus_id": 240354406,
    "ref_id": "b24",
    "citation_corpus_id": 3292002,
    "start": 2695,
    "end": 2719,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "INTRODUCTION\n\nThe ubiquity of graph-structured data and its importance in solving various real-world problems such as node and graph classification have made graph-centered machine learning an important research area (L\u00fc & Zhou, 2011;Shervashidze et al., 2011;Zhu, 2005).",
    "curr": "Graph neural networks (GNNs) offer state-of-the-art performance on many graph learning tasks and have by now become a standard methodology in the field (Kipf & Welling, 2017;Hamilton et al., 2017;Velickovic et al., 2018;Chien et al., 2020).",
    "next": "In most such studies, GNNs take graphs with numerical node attributes as inputs and train them with task-specific labels.",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      222310307,
      15168504,
      5209622
    ]
  },
  {
    "index": 2616,
    "source_corpus_id": 260164542,
    "ref_id": "b55",
    "citation_corpus_id": 247595075,
    "start": 1841,
    "end": 1844,
    "title": "CROSSBEAM: LEARNING TO SEARCH IN BOTTOM-UP PROGRAM SYNTHESIS",
    "abstract": "Many approaches to program synthesis perform a search within an enormous space of programs to find one that satisfies a given specification. Prior works have used neural models to guide combinatorial search algorithms, but such approaches still explore a huge portion of the search space and quickly become intractable as the size of the desired program increases. To tame the search space blowup, we propose training a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm. Our approach, called CROSSBEAM, uses the neural model to choose how to combine previouslyexplored programs into new programs, taking into account the search history and partial program executions. Motivated by work in structured prediction on learning to search, CROSSBEAM is trained on-policy using data extracted from its own bottom-up searches on training tasks. We evaluate CROSSBEAM in two very different domains, string manipulation and logic programming. We observe that CROSSBEAM learns to search efficiently, exploring much smaller portions of the program space compared to the state-of-the-art. * Equal contribution. \u2020 Equal contribution.",
    "prev": "Introduction\n\nProgram synthesis aims to assist programmers by automatically producing code according to a user's specification of what the code should do [26].",
    "curr": "Program synthesis systems, such as programming by example (PBE) systems, have been effective for tasks such as string manipulation [27,19,55], writing short Java functions [53], and tensor manipulation [54].",
    "next": "Neural program synthesizers, especially those based on large language models [11,3,38], have been particularly successful at generating code functions and blocks across a variety of general-purpose programming languages.",
    "hard_negative": [
      225062282,
      4606753
    ],
    "easy_negative": [
      249712518,
      229365664,
      9687923
    ]
  },
  {
    "index": 2621,
    "source_corpus_id": 3687922,
    "ref_id": "b31",
    "citation_corpus_id": 13298214,
    "start": 1538,
    "end": 1560,
    "title": "LEARNING TO NAVIGATE IN COMPLEX ENVIRONMENTS",
    "abstract": "Learning to navigate in complex environments with dynamic elements is an important milestone in developing AI agents. In this work we formulate the navigation question as a reinforcement learning problem and show that data efficiency and task performance can be dramatically improved by relying on additional auxiliary tasks leveraging multimodal sensory inputs. In particular we consider jointly learning the goal-driven reinforcement learning problem with auxiliary depth prediction and loop closure classification tasks. This approach can learn to navigate from raw sensory input in complicated 3D mazes, approaching human-level performance even under conditions where the goal location changes frequently. We provide detailed analysis of the agent behaviour 1 , its ability to localise, and its network activity dynamics, showing that the agent implicitly learns key navigation abilities.",
    "prev": "INTRODUCTION\n\nDeep learning (DL) has recently been used as an efficient approach to learning navigation in complex three-dimensional environments.",
    "curr": "DL-based approaches to navigation can be broadly divided into three classes: purely reactive Zhu et al., 2017), based on unstructured general-purpose memory such as LSTM (Mnih et al., 2016;Mirowski et al., 2017), and employing a navigation-specific memory structure based on a metric map (Parisotto & Salakhutdinov, 2018;.",
    "next": "However, extensive evidence from psychology suggests that when traversing environments, animals do not rely strongly on metric representations (Gillner & Mallot, 1998;Wang & Spelke, 2002;Foo et al., 2005).",
    "hard_negative": [
      14717992,
      8395799
    ],
    "easy_negative": [
      35851458,
      165163819,
      245855931
    ]
  },
  {
    "index": 2623,
    "source_corpus_id": 220363813,
    "ref_id": "b10",
    "citation_corpus_id": 46928091,
    "start": 2253,
    "end": 2256,
    "title": "GAMEPAD: A LEARNING ENVIRONMENT FOR THEO- REM PROVING",
    "abstract": "In this paper, we introduce a system called GamePad that can be used to explore the application of machine learning methods to theorem proving in the Coq proof assistant. Interactive theorem provers such as Coq enable users to construct machine-checkable proofs in a step-by-step manner. Hence, they provide an opportunity to explore theorem proving with human supervision. We use GamePad to synthesize proofs for a simple algebraic rewrite problem and train baseline models for a formalization of the Feit-Thompson theorem. We address position evaluation (i.e., predict the number of proof steps left) and tactic prediction (i.e., predict the next proof step) tasks, which arise naturally in tactic-based theorem proving.",
    "prev": "Introduction\n\nAdvances in theorem proving can catalyze developments in fields including formal mathematics [22], software verification [5], and hardware design [16].",
    "curr": "Following its recent success across other application domains, machine learning has significantly improved the performance of theorem proving agents [1,3,9,11,12,15,20,21,30,32,37].",
    "next": "One factor that makes theorem proving an especially challenging domain for ML is data sparsity.",
    "hard_negative": [
      5590763,
      5144625
    ],
    "easy_negative": [
      51874605,
      6071441,
      219302697
    ]
  },
  {
    "index": 2624,
    "source_corpus_id": 247618909,
    "ref_id": "b27",
    "citation_corpus_id": 202888986,
    "start": 8977,
    "end": 8995,
    "title": "Published as a conference paper at ICLR 2020 ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS",
    "abstract": "Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameterreduction techniques to lower memory consumption and increase the training speed of BERT (Devlin et al., 2019). Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT.Published as a conference paper at ICLR 2020 These solutions address the memory limitation problem, but not the communication overhead. In this paper, we address all of the aforementioned problems, by designing A Lite BERT (ALBERT) architecture that has significantly fewer parameters than a traditional BERT architecture.ALBERT incorporates two parameter reduction techniques that lift the major obstacles in scaling pre-trained models. The first one is a factorized embedding parameterization. By decomposing the large vocabulary embedding matrix into two small matrices, we separate the size of the hidden layers from the size of vocabulary embedding. This separation makes it easier to grow the hidden size without significantly increasing the parameter size of the vocabulary embeddings. The second technique is cross-layer parameter sharing. This technique prevents the parameter from growing with the depth of the network. Both techniques significantly reduce the number of parameters for BERT without seriously hurting performance, thus improving parameter-efficiency. An ALBERT configuration similar to BERT-large has 18x fewer parameters and can be trained about 1.7x faster. The parameter reduction techniques also act as a form of regularization that stabilizes the training and helps with generalization.To further improve the performance of ALBERT, we also introduce a self-supervised loss for sentence-order prediction (SOP). SOP primary focuses on inter-sentence coherence and is designed to address the ineffectiveness  of the next sentence prediction (NSP) loss proposed in the original BERT.As a result of these design decisions, we are able to scale up to much larger ALBERT configurations that still have fewer parameters than BERT-large but achieve significantly better performance. We establish new state-of-the-art results on the well-known GLUE, SQuAD, and RACE benchmarks for natural language understanding. Specifically, we push the RACE accuracy to 89.4%, the GLUE benchmark to 89.4, and the F1 score of SQuAD 2.0 to 92.2.",
    "prev": "In the field of natural language processing (NLP), two dominant self-supervised language modeling paradigms are Masked Language Modeling, such as BERT (Devlin et al., 2018), and GPT-style autoregressive pre-training (Brown et al., 2020;Radford & Narasimhan, 2018;Radford et al., 2019).",
    "curr": "Given a sentence, BERT and its variants (Lan et al., 2020;Liu et al., 2019) pre-train transformer encoders by predicting randomly masked out input words, referred to as tokens.",
    "next": "Such frameworks model the bidirectional (contextual) dependencies between the visible tokens and the corrupted/masked tokens.",
    "hard_negative": [
      2937095,
      990233,
      3432876,
      102350771,
      1957433,
      3626819,
      5034059,
      11816014,
      52967399,
      47018994,
      4421747,
      16639476
    ],
    "easy_negative": [
      252819468,
      6479514,
      475726
    ]
  },
  {
    "index": 2640,
    "source_corpus_id": 263605817,
    "ref_id": "b48",
    "citation_corpus_id": 244117525,
    "start": 2519,
    "end": 2537,
    "title": "FILIP: FINE-GRAINED INTERACTIVE LANGUAGE- IMAGE PRE-TRAINING",
    "abstract": "Unsupervised large-scale vision-language pre-training has shown promising advances on various downstream tasks. Existing methods often model the crossmodal interaction either via the similarity of the global feature of each modality which misses sufficient information, or finer-grained interactions using cross/selfattention upon visual and textual tokens. However, cross/self-attention suffers from inferior efficiency in both training and inference. In this paper, we introduce a large-scale Fine-grained Interactive Language-Image Pre-training (FILIP) to achieve finer-level alignment through a cross-modal late interaction mechanism, which uses a token-wise maximum similarity between visual and textual tokens to guide the contrastive objective. FILIP successfully leverages the finergrained expressiveness between image patches and textual words by modifying only contrastive loss, while simultaneously gaining the ability to pre-compute image and text representations offline at inference, keeping both large-scale training and inference efficient. Furthermore, we construct a new large-scale image-text pair dataset called FILIP300M for pre-training. Experiments show that FILIP achieves state-of-the-art performance on multiple downstream vision-language tasks including zero-shot image classification and image-text retrieval. The visualization on word-patch alignment further shows that FILIP can learn meaningful fine-grained features with promising localization ability. * Equal contribution \u2020 Corresponding authors: xu.hang@huawei.com,",
    "prev": "r state-of-the-art methods on benchmark datasets.",
    "curr": "Introduction\n\nMulti-modal learning (Ngiam et al., 2011) integrates information from a variety of data types, resulting in AI systems that are both robust and precise.Recently, CLIP (Radford et al., 2021) emerged as a milestone work that leverages vision-language contrastive pretraining to jointly learn image and text embeddings, using the vast amounts of image-text data available on the web.During the training process, CLIP considers image-text data that appear together as positive pairs and other combinations as negative pairs.The goal is to maximize the embedding similarity for the positive pairs while minimizing it for the negative pairs.Remarkably, this approach has achieved significant success in zero-shot transfer (Lei Ba et al., 2015), indicating the model's ability to handle a great variety of tasks without prior exposure to any of their training data.Inspired by CLIP's groundbreaking zero-shot capabilities, subsequent studies (Yao et al., 2022;Li et al., 2022;Mu et al., 2022;Goel et al., 2022;Zhai et al., 2022;Alayrac et al., 2022) emerged with the primary objective of further enhancing CLIP's zero-shot performance.Despite the empirical success of CLIP in zero-shot transfer, the theoretical understanding of how it works remains elusive.An intriguing inquiry is thus: How does CLIP learn representations that are transferable to the various downstream tasks?",
    "next": "\u23df\n\n\nShared Features Self Standing Features\n\nThe stop sign is located on the street corner.",
    "hard_negative": [
      225039882,
      229924402,
      165163737,
      52967399,
      14337532
    ],
    "easy_negative": [
      16478940,
      5930893,
      226262329
    ]
  },
  {
    "index": 2641,
    "source_corpus_id": 258352594,
    "ref_id": "b16",
    "citation_corpus_id": 227746078,
    "start": 29608,
    "end": 29630,
    "title": "DISTILLING KNOWLEDGE FROM READER TO RETRIEVER FOR QUESTION ANSWERING",
    "abstract": "The task of information retrieval is an important component of many natural language processing systems, such as open domain question answering. While traditional methods were based on hand-crafted features, continuous representations based on neural networks recently obtained competitive results. A challenge of using such methods is to obtain supervised data to train the retriever model, corresponding to pairs of query and support documents. In this paper, we propose a technique to learn retriever models for downstream tasks, inspired by knowledge distillation, and which does not require annotated pairs of query and documents. Our approach leverages attention scores of a reader model, used to solve the task based on retrieved documents, to obtain synthetic labels for the retriever. We evaluate our method on question answering, obtaining state-of-the-art results.",
    "prev": "Sub-object part-centric memory representations would permit fine-grained retrieval of visual memory scenes.",
    "curr": "We further plan to explore alternative supervision for the retriever module inspired by works in the language domain (Izacard et al., 2022;Izacard & Grave, 2021).",
    "next": "(ii) Scaling Analogical Networks to segmentation of complete, multi-object 3D scenes in realistic home environments requires scaling up the size of memory collection.",
    "hard_negative": [
      173990818,
      52967399,
      3618568,
      26501419,
      59604492,
      11816014
    ],
    "easy_negative": [
      2946085,
      14291660,
      218487684
    ]
  },
  {
    "index": 2642,
    "source_corpus_id": 53113673,
    "ref_id": "b20",
    "citation_corpus_id": 8535316,
    "start": 4483,
    "end": 4502,
    "title": "BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION",
    "abstract": "Machine comprehension (MC), answering a query about a given context paragraph, requires modeling complex interactions between the context and the query. Recently, attention mechanisms have been successfully extended to MC. Typically these methods use attention to focus on a small portion of the context and summarize it with a fixed-size vector, couple attentions temporally, and/or often form a uni-directional attention. In this paper we introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage hierarchical process that represents the context at different levels of granularity and uses bidirectional attention flow mechanism to obtain a query-aware context representation without early summarization. Our experimental evaluations show that our model achieves the state-of-the-art results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze test.",
    "prev": "The three participant entities also get destroyed in the process, which is captured in the graph by pointing to a special Nowhere node.",
    "curr": "(MRC) mechanism (Seo et al., 2017a;Xiong et al., 2017;Chen et al., 2017;Yu et al., 2018, inter alia), which queries for entities and their states at each time step.",
    "next": "We leverage MRC mechanisms because they have proven adept at extracting text spans that answer entity-centric questions (Levy et al., 2017).",
    "hard_negative": [
      711424,
      10239453,
      6360322,
      2926851,
      9672033,
      14915449,
      11816014,
      11022639,
      1957433,
      2100831
    ],
    "easy_negative": [
      16497823,
      256846523,
      1843738
    ]
  },
  {
    "index": 2643,
    "source_corpus_id": 253018859,
    "ref_id": "b20",
    "citation_corpus_id": 56657912,
    "start": 2473,
    "end": 2502,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "Intuitively, fine-tuning more parameters on a small target dataset can cause information learned during pre-training to be forgotten, and the relevant information depends on the type of shift.",
    "curr": "INTRODUCTION\n\nWhile deep neural networks have achieved impressive results in many domains, they are often brittle to even small distribution shifts between the source and target domains (Recht et al., 2019;Hendrycks & Dietterich, 2019;.",
    "next": "While many approaches to robustness attempt to directly generalize to the target distribution after training on source data (Peters et al., 2016;Arjovsky et al., 2019), an alternative approach is to fine-tune on a small amount of labeled target datapoints.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      7471769,
      11933190,
      51883097
    ]
  },
  {
    "index": 2652,
    "source_corpus_id": 254044324,
    "ref_id": "b36",
    "citation_corpus_id": 227209335,
    "start": 1788,
    "end": 1807,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "Extensive experiments indicate that our proposed method can perform comparably to the state-of-the-art solutions in various generation tasks.",
    "curr": "INTRODUCTION\n\nDiffusion models (Ho et al., 2020;Song et al., 2021b) have garnered significant interest on various high quality conditional image generation tasks, such as image super-resolution (Rombach et al., 2022), image inpainting (Lugmayr et al., 2022), image editing (Avrahami et al., 2022), image translation (Saharia et al., 2022a), among others.",
    "next": "Concurrently, the Vector Quantized (VQ) models have also achieved rapid advances in image generations, especially on cross-modal tasks, examples in- clude text-to-image , sketch-to-image (Esser et al., 2021b), image-to-video .",
    "hard_negative": [
      52908831,
      52889459
    ],
    "easy_negative": [
      252595668,
      13077531,
      34188490
    ]
  },
  {
    "index": 2653,
    "source_corpus_id": 235624202,
    "ref_id": "b40",
    "citation_corpus_id": 3626819,
    "start": 1906,
    "end": 1926,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "We believe this work paves the way for highly performant token-free models that are trained completely end-to-end.",
    "curr": "INTRODUCTION\n\nNeural networks have achieved tremendous success in natural language processing (NLP) by replacing feature-engineered models with stacks of functions that are learned end-to-end from vast amounts of data (Mikolov et al., 2013;Peters et al., 2018;Howard and Ruder, 2018).",
    "next": "The single component of the traditional NLP pipeline (Manning and Sch\u00fctze, 1999) that has so far resisted gradient-based learning is tokenization, which is commonly applied as a pre-processing step.",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      8535316,
      11336213,
      9917468,
      20472740,
      34032948,
      1957433,
      10489017,
      1222212,
      12688069,
      15026764,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      215745312,
      260449054,
      6447400
    ]
  },
  {
    "index": 2657,
    "source_corpus_id": 250526649,
    "ref_id": "b7",
    "citation_corpus_id": 215828350,
    "start": 3221,
    "end": 3242,
    "title": "The State and Fate of Linguistic Diversity and Inclusion in the NLP World",
    "abstract": "Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the \"language agnostic\" status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind. * Authors contributed equally to the work. https://microsoft.github.io/linguisticdiversity",
    "prev": "pretrained language models (PLMs) like BERT (Devlin et al., 2019), GPT-3 (Brown et al., 2020), and XLM-R (Conneau et al., 2020); large unlabelled datasets; such as C4 (Raffel et al., 2020), The Pile (Gao et al., 2020); and large-scale computing power (Hirschberg & Manning, 2015).",
    "curr": "Despite this progress, these models only cover a fraction of the world's languages, with large inequalities in performance (Pires et al., 2019;Lauscher et al., 2020), and the majority of languages are falling behind English (Joshi et al., 2020b;Bugliarello et al., 2022).",
    "next": "Even within English, these models struggle when tasked with processing noisy inputs (Sun et al., 2020;Eger & Benz, 2020).",
    "hard_negative": [
      67855815,
      52967399,
      11816014,
      8822680,
      174798142
    ],
    "easy_negative": [
      992326,
      218974490,
      236460191
    ]
  },
  {
    "index": 2663,
    "source_corpus_id": 235742951,
    "ref_id": "b0",
    "citation_corpus_id": 231592776,
    "start": 32456,
    "end": 32479,
    "title": "CONTRASTIVE BEHAVIORAL SIMILARITY EMBEDDINGS FOR GENERALIZATION IN REINFORCEMENT LEARNING",
    "abstract": "Reinforcement learning methods trained on few environments rarely learn policies that generalize to unseen environments. To improve generalization, we incorporate the inherent sequential structure in reinforcement learning into the representation learning process. This approach is orthogonal to recent approaches, which rarely exploit this structure explicitly. Specifically, we introduce a theoretically motivated policy similarity metric (PSM) for measuring behavioral similarity between states. PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. We also present a contrastive representation learning procedure to embed any state similarity metric, which we instantiate with PSM to obtain policy similarity embeddings (PSEs 1 ). We demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite. Source code would be made available at agarwl.github.io/pse.",
    "prev": "Baselines In the MDP setting, we compare AdaRL with CAVIA (Zintgraf et al., 2019) and PEARL (Rakelly et al., 2019).",
    "curr": "In the POMDP setting, we compare with PNN (Rusu et al., 2016), PSM (Agarwal et al., 2021a) and MQL (Fakoor et al., 2020).",
    "next": "We also compare with AdaRL*, a version of AdaRL that does not learn the binary masks c \u00b7 )\u00b7 and therefore does not use any structural information.",
    "hard_negative": [
      208857488,
      3280568,
      213597045
    ],
    "easy_negative": [
      9093102,
      1541597,
      20737041
    ]
  },
  {
    "index": 2667,
    "source_corpus_id": 7451980,
    "ref_id": "b8",
    "citation_corpus_id": 84591,
    "start": 13600,
    "end": 13603,
    "title": "Adversarial Feature Learning",
    "abstract": "The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing generators learn to \"linearize semantics\" in the latent space of such models. Intuitively, such latent spaces may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.",
    "prev": "However they see image as a cause of the neural net weights, and do not use labels.",
    "curr": "BiGAN [9] and ALI [10] improve the standard GAN framework to provide the functionality of learning the mapping from image space to latent space.",
    "next": "In CoGAN [22] the authors learn a joint distribution given samples from marginals by enforcing weight sharing between generators.",
    "hard_negative": [
      6628106,
      9665723,
      11758569,
      11212020
    ],
    "easy_negative": [
      216641734,
      11479759,
      14746785
    ]
  },
  {
    "index": 2671,
    "source_corpus_id": 243832613,
    "ref_id": "b94",
    "citation_corpus_id": 231632937,
    "start": 8443,
    "end": 8463,
    "title": "HIERARCHICAL REINFORCEMENT LEARNING BY DISCOVERING INTRINSIC OPTIONS",
    "abstract": "We propose a hierarchical reinforcement learning method, HIDIO, that can learn task-agnostic options in a self-supervised manner while jointly learning to utilize them to solve sparse-reward tasks. Unlike current hierarchical RL approaches that tend to formulate goal-reaching low-level tasks or pre-define ad hoc lowerlevel policies, HIDIO encourages lower-level option learning that is independent of the task at hand, requiring few assumptions or little knowledge about the task structure. These options are learned through an intrinsic entropy minimization objective conditioned on the option sub-trajectories. The learned options are diverse and task-agnostic. In experiments on sparse-reward robotic manipulation and navigation tasks, HIDIO achieves higher success rates with greater sample efficiency than regular RL baselines and two state-of-the-art hierarchical RL methods. Code available at https://www.github.com/jesbu1/hidio. * Denotes equal contribution.",
    "prev": "In this work, we explore the efficacy of learned skills operating on highdimensional observations for long-horizon control in realistic environments.",
    "curr": "To improve the quality of lower-level policies, recent work in HRL has studied various facets of the problem, including discovery of skills (Konidaris & Barto, 2009;Zhang et al., 2021b;Florensa et al., 2017;Warde-Farley et al., 2018), end-to-end training of both levels (Kulkarni et al., 2016;Tessler et al., 2017) and integrating goal-conditioned behaviors (Ghosh et al., 2019;Nachum et al., 2019).",
    "next": "In this work, we assume that the low-level skills are given, and do not focus on discovering them.",
    "hard_negative": [
      13022595,
      3521071,
      28202810,
      52911937,
      53792719,
      16326763,
      53841789
    ],
    "easy_negative": [
      236460346,
      44065,
      18446213
    ]
  },
  {
    "index": 2675,
    "source_corpus_id": 249191498,
    "ref_id": "b15",
    "citation_corpus_id": 238583615,
    "start": 2628,
    "end": 2650,
    "title": "AB-INITIO POTENTIAL ENERGY SURFACES BY PAIRING GNNS WITH NEURAL WAVE FUNCTIONS",
    "abstract": "Solving the Schr\u00f6dinger equation is key to many quantum mechanical properties. However, an analytical solution is only tractable for single-electron systems. Recently, neural networks succeeded at modeling wave functions of many-electron systems. Together with the variational Monte-Carlo (VMC) framework, this led to solutions on par with the best known classical methods. Still, these neural methods require tremendous amounts of computational resources as one has to train a separate model for each molecular geometry. In this work, we combine a Graph Neural Network (GNN) with a neural wave function to simultaneously solve the Schr\u00f6dinger equation for multiple geometries via VMC. This enables us to model continuous subsets of the potential energy surface with a single training pass. Compared to existing state-of-the-art networks, our Potential Energy Surface Network (PESNet) speeds up training for multiple geometries by up to 40 times while matching or surpassing their accuracy. This may open the path to accurate and orders of magnitude cheaper quantum mechanical calculations.",
    "prev": "Although they lead to accurate energies, training such neural wave functions proved to be computationally intensive .",
    "curr": "To reduce the computational burden, Gao & G\u00fcnnemann (2022) proposed the potential energy surface network (PESNet) to simultaneously solve many Schr\u00f6dinger equations, i.e., for different spatial arrangements of the nuclei in R 3 .",
    "next": "They use a GNN to reparametrize the wave function model based on the molecular structure.",
    "hard_negative": [
      6628106,
      165163737
    ],
    "easy_negative": [
      252819375,
      13746789,
      235313510
    ]
  },
  {
    "index": 2699,
    "source_corpus_id": 211020709,
    "ref_id": "b4",
    "citation_corpus_id": 52898806,
    "start": 4734,
    "end": 4759,
    "title": "RIEMANNIAN ADAPTIVE OPTIMIZATION METHODS",
    "abstract": "Several first order stochastic optimization methods commonly used in the Euclidean domain such as stochastic gradient descent (SGD), accelerated gradient descent or variance reduced methods have already been adapted to certain Riemannian settings. However, some of the most popular of these optimization tools \u2212 namely ADAM, ADAGRAD and the more recent AMSGRAD \u2212 remain to be generalized to Riemannian manifolds. We discuss the difficulty of generalizing such adaptive schemes to the most agnostic Riemannian setting, and then provide algorithms and convergence proofs for geodesically convex objectives in the particular case of a product of Riemannian manifolds, in which adaptivity is implemented across manifolds in the cartesian product. Our generalization is tight in the sense that choosing the Euclidean space as Riemannian manifold yields the same algorithms and regret bounds as those that were already known for the standard algorithms. Experimentally, we show faster convergence and to a lower train loss value for Riemannian adaptive methods over their corresponding baselines on the realistic task of embedding the WordNet taxonomy in the Poincar\u00e9 ball.arXiv:1810.00760v1 [cs.LG] 1 Oct 2018Under review as a conference paper at ICLR 2019Our contributions. In this work we (i) explain why generalizing these adaptive schemes to the most agnostic Riemannian setting in an intrinsic manner is compromised, and (ii) propose generalizations of the algorithms together with their convergence analysis in the particular case of a product of manifolds where each manifold represents one \"coordinate\" of the adaptive scheme. Finally, we (iii) empirically support our claims on the realistic task of hyperbolic taxonomy embedding.Our initial motivation. The particular application that motivated us in developing Riemannian versions of ADAGRAD and ADAM was the learning of symbolic embeddings in non-Euclidean spaces. As an example, the GloVe algorithm(Pennington et al., 2014)\u2212 an unsupervised method for learning Euclidean word embeddings capturing semantic/syntactic relationships \u2212 benefits significantly from optimizing with ADAGRAD compared to using SGD, presumably because different words are sampled at different frequencies. Hence the absence of Riemannian adaptive algorithms could constitute a significant obstacle to the development of competitive optimization-based Riemannian embedding methods. In particular, we believe that the recent rise of embedding methods in hyperbolic spaces",
    "prev": "A theoretical analysis of the convergence of Cayley SGD is presented.",
    "curr": "Similar analysis for Cayley ADAM is omitted, since it is very similar to the analysis presented in (Becigneul & Ganea, 2019).",
    "next": "Cayley SGD and Cayley ADAM are empirically evaluated on image classification using VGG and Wide ResNet on the CIFAR-10 and CIFAR-100 datasets (Krizhevsky & Hinton, 2009).",
    "hard_negative": [
      6628106,
      1957433
    ],
    "easy_negative": [
      225067799,
      8227522,
      18505916
    ]
  },
  {
    "index": 2703,
    "source_corpus_id": 218487073,
    "ref_id": "b5",
    "citation_corpus_id": 3531856,
    "start": 18295,
    "end": 18298,
    "title": "Published as a conference paper at ICLR 2018 DEMYSTIFYING MMD GANS",
    "abstract": "We investigate the training and performance of generative adversarial networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs. As our main theoretical contribution, we clarify the situation with bias in GAN loss functions raised by recent work: we show that gradient estimators used in the optimization process for both MMD GANs and Wasserstein GANs are unbiased, but learning a discriminator based on samples leads to biased gradients for the generator parameters. We also discuss the issue of kernel choice for the MMD critic, and characterize the kernel corresponding to the energy distance used for the Cram\u00e9r GAN critic. Being an integral probability metric, the MMD benefits from training strategies recently developed for Wasserstein GANs. In experiments, the MMD GAN is able to employ a smaller critic network than the Wasserstein GAN, resulting in a simpler and faster-training algorithm with matching performance. We also propose an improved measure of GAN convergence, the Kernel Inception Distance, and show how to use it to dynamically adapt learning rates during GAN training. * These authors contributed equally.Published as a conference paper at ICLR 2018 are infinite, meaning that they provide no useful gradient for the generator to follow. This helps to explain some of the instability of GAN training.The lack of sensitivity to distance, meaning that nearby but non-overlapping regions of high probability mass are not considered similar, is a long-recognized problem for KL divergence-based discrepancy measures (e.g. Gneiting & Raftery, 2007, Section 4.2). It is natural to address this problem using Integral Probability Metrics (IPMs; M\u00fcller, 1997): these measure the distance between probability measures via the largest discrepancy in expectation over a class of \"well behaved\" witness functions. Thus, IPMs are able to signal proximity in the probability mass of the generator and reference distributions. (Section 2 describes this framework in more detail.)  proposed to use the Wasserstein distance between distributions as the discriminator, which is an integral probability metric constructed from the witness class of 1-Lipschitz functions. To implement the Wasserstein critic, Arjovsky et al. originally proposed weight clipping of the discriminator network, to enforce k-Lipschitz smoothness. Gulrajani et al. (2017)  improved on this result by directly constraining the gradient of the discriminator network at points between the generator and reference samples. This new Wasserstein GAN implementation, called WGAN-GP, is more stable and easier to train.A second integral probability metric used in GAN variants is the maximum mean discrepancy (MMD), for which the witness function class is a unit ball in a reproducing kernel Hilbert space (RKHS). Generative adversarial models based on minimizing the MMD were first considered by Li et al. (2015)  and Dziugaite et al. (2015). These works optimized a generator to minimize the MMD with a fixed kernel, either using a generic kernel on image pixels or by modeling autoencoder representations instead of images directly. Sutherland et al.(2017)instead minimized the statistical power of an MMD-based test with a fixed kernel. Such approaches struggle with complex natural images, where pixel distances are of little value, and fixed representations can easily be tricked, as in the adversarial examples of Szegedy et al. (2014). A. Krizhevsky. Learning multiple layers of features from tiny images, 2009. Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition.",
    "prev": "We use features derived from the final pooling layer of the p4-CNN defined in [14] to replace Inception-featurization.",
    "curr": "An analogous approach was taken in [6] in their MNIST experiments.",
    "next": "Fr\u00e9chet distance of synthesized samples to the test set is calculated at every thousand generator iterations.",
    "hard_negative": [
      18828233,
      2263947,
      604334,
      2187805
    ],
    "easy_negative": [
      252624490,
      14902521,
      21729459
    ]
  },
  {
    "index": 2708,
    "source_corpus_id": 3480671,
    "ref_id": "b0",
    "citation_corpus_id": 11212020,
    "start": 1554,
    "end": 1577,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "By sampling fertilities in parallel at inference time, our non-autoregressive model achieves near-state-of-the-art performance of 29.8 BLEU on WMT 2016 English-Romanian.",
    "curr": "INTRODUCTION\n\nNeural network based models outperform traditional statistical models for machine translation (MT) (Bahdanau et al., 2015;Luong et al., 2015).",
    "next": "However, state-of-the-art neural models are much slower than statistical MT approaches at inference time (Wu et al., 2016).",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      260537993,
      246702335,
      201739018
    ]
  },
  {
    "index": 2712,
    "source_corpus_id": 7443908,
    "ref_id": "b22",
    "citation_corpus_id": 1957433,
    "start": 2242,
    "end": 2266,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "Despite the overwhelming success achieved by recurrent neural networks in modeling long range dependencies between words, current recurrent neural network language models (RNNLM) are based on the conventional classification framework, which has two major drawbacks: First, there is no assumed metric on the output classes, whereas there is evidence suggesting that learning is improved when one can define a natural metric on the output space (Frogner et al., 2015).",
    "curr": "In language modeling, there is a well established metric space for the outputs (words in the language) based on word embeddings, with meaningful distances between words (Mikolov et al., 2013;Pennington et al., 2014).",
    "next": "Second, in the classical framework, inputs and outputs are considered as isolated entities with no semantic link between them.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      10810207,
      198159868,
      46925714
    ]
  },
  {
    "index": 2714,
    "source_corpus_id": 233219849,
    "ref_id": "b35",
    "citation_corpus_id": 3986974,
    "start": 2878,
    "end": 2900,
    "title": "The Web as a Knowledge-base for Answering Complex Questions",
    "abstract": "Answering complex questions is a timeconsuming activity for humans that requires reasoning and integration of information. Recent work on reading comprehension made headway in answering simple questions, but tackling complex questions is still an ongoing research challenge. Conversely, semantic parsers have been successful at handling compositionality, but only when the information resides in a target knowledge-base. In this paper, we present a novel framework for answering broad and complex questions, assuming answering simple questions is possible using a search engine and a reading comprehension model. We propose to decompose complex questions into a sequence of simple questions, and compute the final answer from the sequence of answers. To illustrate the viability of our approach, we create a new dataset of complex questions, COMPLEXWEBQUES-TIONS, and present a model that decomposes questions and interacts with the web to compute an answer. We empirically demonstrate that question decomposition improves performance from 20.8 precision@1 to 27.5 preci-sion@1 on this new dataset.",
    "prev": "Answering this question is made possible by integrating information across both the textual and visual modalities.",
    "curr": "Recently, there has been substantial interest in question answering (QA) models that reason over multiple pieces of evidence (multi-hop questions (Yang et al., 2018;Talmor & Berant, 2018;Welbl et al., 2017)).",
    "next": "In most prior work, the question is phrased in natural language and the answer is in a context, which may be a paragraph (Rajpurkar, 2016), a table (Pasupat & Liang, 2015), or an image (Antol et al., 2015).",
    "hard_negative": [
      14472576,
      6360322,
      7218315,
      6401679,
      7228830,
      9963298,
      13905064,
      26501419,
      1957433,
      9268430,
      11816014,
      1373518,
      5633240,
      18549358,
      340852,
      5761781,
      12501880,
      14915449
    ],
    "easy_negative": [
      237581301,
      260534404,
      14118135
    ]
  },
  {
    "index": 2716,
    "source_corpus_id": 258832501,
    "ref_id": "b9",
    "citation_corpus_id": 231815627,
    "start": 9279,
    "end": 9282,
    "title": "RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering",
    "abstract": "In open-domain question answering, dense passage retrieval has become a new paradigm to retrieve relevant passages for finding answers. Typically, the dual-encoder architecture is adopted to learn dense representations of questions and passages for semantic matching. However, it is difficult to effectively train a dual-encoder due to the challenges including the discrepancy between training and inference, the existence of unlabeled positives and limited training data. To address these challenges, we propose an optimized training approach, called RocketQA, to improving dense passage retrieval. We make three major technical contributions in RocketQA, namely crossbatch negatives, denoised hard negatives and data augmentation. The experiment results show that RocketQA significantly outperforms previous state-of-the-art models on both MS-MARCO and Natural Questions. We also conduct extensive experiments to examine the effectiveness of the three strategies in RocketQA. Besides, we demonstrate that the performance of end-to-end QA can be improved based on our RocketQA retriever 1 .",
    "prev": "The retrieve-then-read model [40] utilizes retrievers, such as BM25 [41] and DPR [42], to identify relevant documents within a knowledge corpus.",
    "curr": "Subsequently, a reader, like FiD [34], analyzes the retrieved documents to enhance NLP tasks [39,43,44,45].",
    "next": "Some studies retrieve subgraphs from knowledge graphs to provide additional input for question-answering tasks [35,46].",
    "hard_negative": [
      3618568,
      208267807,
      173990818,
      222205492,
      201307832,
      204823992,
      211068995,
      86611921,
      202558815,
      215737187,
      5541486
    ],
    "easy_negative": [
      201687957,
      588327,
      15594774
    ]
  },
  {
    "index": 2717,
    "source_corpus_id": 225076232,
    "ref_id": "b28",
    "citation_corpus_id": 14124313,
    "start": 1633,
    "end": 1660,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "Our code is available at https://github.com/utsaslab/MONeT.",
    "curr": "INTRODUCTION\n\nDeep networks are widely used in domains ranging from image classification (Krizhevsky et al., 2012;Simonyan & Zisserman, 2015;He et al., 2016a) to video recognition (Wu et al., 2019; or natural language processing (Devlin et al., 2019;.",
    "next": "However, training deep networks is resource-intensive.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      211082896,
      220118082,
      258486936
    ]
  },
  {
    "index": 2719,
    "source_corpus_id": 259164846,
    "ref_id": "b40",
    "citation_corpus_id": 49868626,
    "start": 1354,
    "end": 1357,
    "title": "META-LEARNING WITH LATENT EMBEDDING OPTIMIZATION",
    "abstract": "Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems. However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes. We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this lowdimensional latent space. The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters. Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks. Further analysis indicates LEO is able to capture uncertainty in the data, and can perform adaptation more effectively by optimizing in latent space. arXiv:1807.05960v3 [cs.LG]",
    "prev": "Introduction\n\nFew-shot recognition [23,33,51] aims to learn novel concepts from few examples, often by rapid adaptation of a model trained on a disjoint set of labels.",
    "curr": "Many solutions adopt a meta-learning perspective [16,25,38,41,43], or train a powerful feature extractor on the source classes [44,50] -both of which assume that the training and testing classes are drawn from the same underlying distribution e.g., handwritten characters [24], or ImageNet categories [48].",
    "next": "Later work considers a more realistic and challenging problem variant where a classifier should perform few-shot adaptation not only across visual categories, but also across diverse visual domains [46,47].",
    "hard_negative": [
      3484654,
      3507990
    ],
    "easy_negative": [
      245385814,
      35229587,
      1820591
    ]
  },
  {
    "index": 2721,
    "source_corpus_id": 255340454,
    "ref_id": "b24",
    "citation_corpus_id": 240354066,
    "start": 3433,
    "end": 3437,
    "title": "Efficiently Modeling Long Sequences with Structured State Spaces",
    "abstract": "A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies. Although conventional models including RNNs, CNNs, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of 10000 or more steps. A promising recent approach proposed modeling sequences by simulating the fundamental state space model, and showed that for appropriate choices of the state matrix A, this system could handle long-range dependencies mathematically and empirically. However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution. We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths. Our technique involves conditioning A with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel. S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91% accuracy on sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation 60\u00d7 faster (iii) SoTA on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors. 1",
    "prev": "Order determined by coin flip.",
    "curr": "Introduction\n\nState space models (SSMs) have achieved state-of-the-art sequence modeling performance in domains ranging from time series analysis [25] to audio generation [22].",
    "next": "However, they have yet to match the performance of Transformers on language modeling, often underperforming Transformers by multiple points in perplexity [25].",
    "hard_negative": [
      239009958,
      59310641,
      52890982,
      219965819
    ],
    "easy_negative": [
      1006472,
      7399546,
      59868529
    ]
  },
  {
    "index": 2727,
    "source_corpus_id": 44129557,
    "ref_id": "b3",
    "citation_corpus_id": 5590763,
    "start": 1806,
    "end": 1824,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "INTRODUCTION\n\nNeural response generation has been a long interest of natural language research.",
    "curr": "Most of the recent approaches to data-driven conversation modeling primarily build upon sequence-to-sequence learning (Cho et al., 2014;Sutskever et al., 2014).",
    "next": "Previous research has demonstrated that sequenceto-sequence conversation models often suffer from the safe response problem and fail to generate meaningful, diverse on-topic responses (Li et al., 2015;Sato et al., 2017).",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      11688166,
      233004538,
      173990671
    ]
  },
  {
    "index": 2728,
    "source_corpus_id": 259108266,
    "ref_id": "b10",
    "citation_corpus_id": 86611921,
    "start": 2549,
    "end": 2551,
    "title": "Natural Questions: A Benchmark for Question Answering Research",
    "abstract": "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.453",
    "prev": "Yidong did this work during his internship at Westlake University.",
    "curr": "\u2020 Corresponding to\n\nIntroduction\n\nLarge language models (LLMs) have attracted increasing attention in the field of artificial intelligence [1,2,3,4,5,6], with various applications from question answering [7,8], machine translation [9,10] to content creation [11,12].",
    "next": "The Alpaca project [13] has been a pioneering effort in instruction tuning of LLaMA [14], setting a precedent for instruction tuning LLMs, followed by Vicunna [15].",
    "hard_negative": [
      3618568,
      7228830,
      52057510,
      26501419,
      3432876,
      52183757,
      11816014,
      1373518,
      2381275,
      2100831,
      3662564,
      2593903,
      47018994,
      5761781,
      14915449
    ],
    "easy_negative": [
      11688166,
      46406105,
      140117323
    ]
  },
  {
    "index": 2729,
    "source_corpus_id": 231955136,
    "ref_id": "b14",
    "citation_corpus_id": 49667762,
    "start": 2045,
    "end": 2067,
    "title": "UNIVERSAL TRANSFORMERS",
    "abstract": "Recurrent neural networks (RNNs) sequentially process data by updating their state with each new data point, and have long been the de facto choice for sequence modeling tasks. However, their inherently sequential computation makes them slow to train. Feed-forward and convolutional architectures have recently been shown to achieve superior results on some sequence modeling tasks such as machine translation, with the added advantage that they concurrently process all inputs in the sequence, leading to easy parallelization and faster training times. Despite these successes, however, popular feed-forward sequence models like the Transformer fail to generalize in many simple tasks that recurrent models handle with ease, e.g. copying strings or even simple logical inference when the string or formula lengths exceed those observed at training time. We propose the Universal Transformer (UT), a parallel-in-time self-attentive recurrent sequence model which can be cast as a generalization of the Transformer model and which addresses these issues. UTs combine the parallelizability and global receptive field of feed-forward sequence models like the Transformer with the recurrent inductive bias of RNNs. We also add a dynamic per-position halting mechanism and find that it improves accuracy on several tasks. In contrast to the standard Transformer, under certain assumptions UTs can be shown to be Turing-complete. Our experiments show that UTs outperform standard Transformers on a wide range of algorithmic and language understanding tasks, including the challenging LAMBADA language modeling task where UTs achieve a new state of the art, and machine translation where UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De dataset. * Equal contribution, alphabetically by last name. \u2020 Work performed while at Google Brain.",
    "prev": "Each layer computes some transformation of the output of the previous layer.",
    "curr": "Surprisingly, several recent studies achieved results competitive with the state-ofthe-art performances by using the same transformation for each layer with weight tying (Dabre & Fujita, 2019;Bai et al., 2019b;Dehghani et al., 2019).",
    "next": "In general terms, the output of the l-th layer with weight tying can be written by z (l) = h(z (l\u22121) ; x, \u03b8) for l = 1, 2, .",
    "hard_negative": [
      14091969,
      3785155,
      2009318,
      14091946,
      2381275
    ],
    "easy_negative": [
      14330405,
      10669626,
      37962359
    ]
  },
  {
    "index": 2734,
    "source_corpus_id": 247292561,
    "ref_id": "b40",
    "citation_corpus_id": 222208633,
    "start": 3641,
    "end": 3645,
    "title": "DEFORMABLE DETR: DEFORMABLE TRANSFORMERS FOR END-TO-END OBJECT DETECTION",
    "abstract": "DETR has been recently proposed to eliminate the need for many hand-designed components in object detection while demonstrating good performance. However, it suffers from slow convergence and limited feature spatial resolution, due to the limitation of Transformer attention modules in processing image feature maps. To mitigate these issues, we proposed Deformable DETR, whose attention modules only attend to a small set of key sampling points around a reference. Deformable DETR can achieve better performance than DETR (especially on small objects) with 10\u00d7 less training epochs. Extensive experiments on the COCO benchmark demonstrate the effectiveness of our approach. Code shall be released. * Equal contribution. \u2020 This work is done when Weijie Su is an intern at SenseTime Research.",
    "prev": "Despite its promising performance, the training convergence of DETR is slow and the meaning of queries is unclear.",
    "curr": "To address such problems, many methods have been proposed, such as introducing deformable attention [41], decoupling positional and content information [25], providing spatial priors [11,39,37], etc.",
    "next": "Recently, DAB-DETR [21] proposes to formulate DETR queries as dynamic anchor boxes (DAB), which bridges the gap between classical anchor-based detectors and DETR-like ones.",
    "hard_negative": [
      6628106,
      3608234,
      59310641,
      209315300
    ],
    "easy_negative": [
      6789063,
      243865428,
      226238689
    ]
  },
  {
    "index": 2735,
    "source_corpus_id": 85469987,
    "ref_id": "b5",
    "citation_corpus_id": 16209268,
    "start": 1764,
    "end": 1788,
    "title": "Published as a conference paper at ICLR 2015 QUALITATIVELY CHARACTERIZING NEURAL NETWORK OPTIMIZATION PROBLEMS",
    "abstract": "Training neural networks involves solving large-scale non-convex optimization problems. This task has long been believed to be extremely difficult, with fear of local minima and other obstacles motivating a variety of schemes to improve optimization, such as unsupervised pretraining. However, modern neural networks are able to achieve negligible training error on complex tasks, using only direct training with stochastic gradient descent. We introduce a simple analysis technique to look for evidence that such networks are overcoming local optima. We find that, in fact, on a straight path from initialization to solution, a variety of state of the art neural networks never encounter any significant obstacles.",
    "prev": "INTRODUCTION\n\nIt is well known that the optimization problem for training neural networks can have exponentially many local minima (Auer et al., 1996;Safran & Shamir, 2016) and NP-hardness has been shown in many cases (Blum & Rivest., 1989;Sima, 2002;Livni et al., 2014;Shamir, 2017;Shalev-Shwartz et al., 2017).",
    "curr": "However, it has been empirically observed (Dauphin et al., 2014;Goodfellow et al., 2015) that the training of state-of-the-art deep CNNs (LeCun et al., 1990;Krizhevsky et al., 2012), which are often overparameterized, is not hampered by suboptimal local minima.",
    "next": "In order to explain the apparent gap between hardness results and practical performance, many interesting theoretical results have been recently developed (Andoni et al., 2014;Sedghi & Anandkumar, 2015;Janzamin et al., 2016;Haeffele & Vidal, 2015;Gautier et al., 2016;Brutzkus & Globerson, 2017;Soltanolkotabi, 2017;Soudry & Hoffer, 2017;Goel & Klivans, 2017;Du et al., 2017;Zhong et al., 2017;Tian, 2017;Li & Yuan, 2017) in order to identify conditions under which one can guarantee that local search algorithms like gradient descent converge to the globally optimal solution.",
    "hard_negative": [
      17272965,
      252796
    ],
    "easy_negative": [
      189683,
      7527531,
      208541377
    ]
  },
  {
    "index": 2742,
    "source_corpus_id": 247594476,
    "ref_id": "b37",
    "citation_corpus_id": 7478738,
    "start": 4095,
    "end": 4117,
    "title": "Linguistic Regularities in Continuous Space Word Representations",
    "abstract": "Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, \"King -Man + Woman\" results in a vector very close to \"Queen.\" We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems.",
    "prev": "The practice in Natural Language Processing (NLP) and Data Mining (DM) might shed some light on this issue.",
    "curr": "Word embeddings (Mikolov et al., 2013;Pennington et al., 2014) is proposed very early in NLP to map words into an embedding space using embedding layers, which work as lookup tables that are indexed by the one-hot encoding of words.",
    "next": "The word embeddings retrieved from embedding layers have similar values for words with similar meanings.",
    "hard_negative": [
      5278106,
      15637201,
      629094,
      252796
    ],
    "easy_negative": [
      257767700,
      857232,
      12767961
    ]
  },
  {
    "index": 2746,
    "source_corpus_id": 238583615,
    "ref_id": "b22",
    "citation_corpus_id": 211842237,
    "start": 2267,
    "end": 2289,
    "title": "Published as a conference paper at ICLR 2020 DIRECTIONAL MESSAGE PASSING FOR MOLECULAR GRAPHS",
    "abstract": "Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes). They do not, however, consider the spatial direction from one atom to another, despite directional information playing a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions and spherical harmonics to construct theoretically well-founded, orthogonal representations that achieve better performance than the currently prevalent Gaussian radial basis representations while using fewer than 1 /4 of the parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 76 % on MD17 and by 31 % on QM9. Our implementation is available online. 1 1 https://www.daml.in.tum.de/dimenet arXiv:2003.03123v2 [cs.LG] 5 Apr 2022Published as a conference paper at ICLR 2020 embeddings are equivariant with respect to the above transformations since the directions move with the molecule. Hence, they preserve the relative directional information between neighboring atoms. We propose to let message embeddings interact based on the distance between atoms and the angle between directions. Both distances and angles are invariant to translation, rotation, and inversion of the molecule, as required. Additionally, we show that the distance and angle can be jointly represented in a principled and effective manner by using spherical Bessel functions and spherical harmonics. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet can learn both molecular properties and atomic forces. It is twice continuously differentiable and solely based on the atom types and coordinates, which are essential properties for performing molecular dynamics simulations. DimeNet outperforms previous GNNs on average by 76 % on MD17 and by 31 % on QM9. Our paper's main contributions are:",
    "prev": "In particular, a lot of work has gone into building surrogate models to reproduce QM properties, e.g., energies.",
    "curr": "These models learn from datasets created using classical techniques such as density functional theory (DFT) (Ramakrishnan et al., 2014;Klicpera et al., 2019) or coupled clusters (CCSD) (Chmiela et al., 2018).",
    "next": "While this approach has shown great success in recovering the baseline calculations, it suffers from several disadvantages.",
    "hard_negative": [
      65455367,
      3144218,
      85457862,
      21731691,
      7060599
    ],
    "easy_negative": [
      203902359,
      234336760,
      7646419
    ]
  },
  {
    "index": 2750,
    "source_corpus_id": 263830334,
    "ref_id": "b21",
    "citation_corpus_id": 254247299,
    "start": 2098,
    "end": 2115,
    "title": "EXPLORING THE LIMITS OF DIFFERENTIALLY PRI- VATE DEEP LEARNING WITH GROUP-WISE CLIPPING",
    "abstract": "Differentially private deep learning has recently witnessed advances in computational efficiency and privacy-utility trade-off. We explore whether further improvements along the two axes are possible and provide affirmative answers leveraging two instantiations of group-wise clipping. To reduce the compute time overhead of private learning, we show that per-layer clipping, where the gradient of each neural network layer is clipped separately, allows clipping to be performed in conjunction with backpropagation in differentially private optimization. This results in private learning that is as memory-efficient and almost as fast per training update as non-private learning for many workflows of interest. While per-layer clipping with constant thresholds tends to underperform standard flat clipping, per-layer clipping with adaptive thresholds matches or outperforms flat clipping under given training epoch constraints, hence attaining similar or better task performance within less wall time. To explore the limits of scaling (pretrained) models in differentially private deep learning, we privately fine-tune the 175 billion-parameter GPT-3. We bypass scaling challenges associated with clipping gradients that are distributed across multiple devices with per-device clipping that clips the gradient of each model piece separately on its host device. Privately fine-tuning GPT-3 with perdevice clipping achieves a task performance at = 1 better than what is attainable by non-privately fine-tuning the largest GPT-2 on a summarization task. arXiv:2212.01539v1 [cs.LG] 3 Dec 2022 mechanism for large scale NLU models. Deep models under the gan: information leakage from collaborative deep learning. In , et al. Learning and evaluating a differentially private pre-trained language model. In",
    "prev": "The workhorse of private learning, a differentially private variant of stochastic gradient descent called DP-SGD (Song et al., 2013;Bassily et al., 2014;Abadi et al., 2016), clips per-example gradients to some \u2113 2 norm and adds independent Gaussian noise.",
    "curr": "DP-SGD has been used in a range of applications from learning with medical images (Adnan et al., 2022) to finetuning large language models with O(100B) parameters (He et al., 2023).",
    "next": "A recent line of work instead proposes to add correlated Gaussian noise to each clipped gradient (Smith & Thakurta, 2013;Kairouz et al., 2021a;Denisov et al., 2022;Choquette-Choo et al., 2023b).",
    "hard_negative": [
      238743879,
      232046284,
      220404588,
      227152280
    ],
    "easy_negative": [
      12294387,
      17703143,
      204912182
    ]
  },
  {
    "index": 2754,
    "source_corpus_id": 211092198,
    "ref_id": "b7",
    "citation_corpus_id": 53218829,
    "start": 6499,
    "end": 6518,
    "title": "OF WIKIPEDIA: KNOWLEDGE-POWERED CONVERSATIONAL AGENTS",
    "abstract": "In open-domain dialogue intelligent agents should exhibit the use of knowledge, however there are few convincing demonstrations of this to date. The most popular sequence to sequence models typically \"generate and hope\" generic utterances that can be memorized in the weights of the model when mapping from input utterance(s) to output, rather than employing recalled knowledge as context. Use of knowledge has so far proved difficult, in part because of the lack of a supervised learning benchmark task which exhibits knowledgeable open dialogue with clear grounding. To that end we collect and release a large dataset with conversations directly grounded with knowledge retrieved from Wikipedia. We then design architectures capable of retrieving knowledge, reading and conditioning on it, and finally generating natural responses. Our best performing dialogue models are able to conduct knowledgeable discussions on open-domain topics as evaluated by automatic metrics and human evaluations, while our new benchmark allows for measuring further improvements in this important research direction. * Joint first authors.",
    "prev": "While documents are abundant on the Web, it is difficult to obtain large scale dialogues that are naturally grounded on the documents for learning of a neural generation model.",
    "curr": "To overcome the challenge, some recent work (Zhou et al., 2018b;Dinan et al., 2019) resorts to crowd-sourcing and builds benchmarks with the source of Wikipedia.",
    "next": "On the one hand, the datasets pave the way to the recent research on knowledge-grounded response generation/selection Lian et al., 2019;Li et al., 2019); on the other hand, we argue that there still a long way to go for application of the existing models in real scenarios, since (1) the models, especially those achieve state-of-the-art performance via sophisticated neural architectures, just overfit to the small training data (e.g., \u223c 18k dialogues).",
    "hard_negative": [
      2129889,
      52057510,
      3618568,
      2239496,
      52281610,
      11816014,
      22716243,
      52167799,
      1294169
    ],
    "easy_negative": [
      237635411,
      45066633,
      251741028
    ]
  },
  {
    "index": 2759,
    "source_corpus_id": 258564452,
    "ref_id": "b93",
    "citation_corpus_id": 220968978,
    "start": 2911,
    "end": 2934,
    "title": "Hopfield Networks is All You Need",
    "abstract": "The transformer and BERT models pushed the performance on NLP tasks to new levels via their attention mechanism. We show that this attention mechanism is the update rule of a modern Hopfield network with continuous states. This new Hopfield network can store exponentially (with the dimension) many patterns, converges with one update, and has exponentially small retrieval errors. The number of stored patterns must be traded off against convergence speed and retrieval error. The new Hopfield network has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. Transformers learn an attention mechanism by constructing an embedding of patterns and queries into an associative space. Transformer and BERT models operate in their first layers preferably in the global averaging regime, while they operate in higher layers in metastable states. The gradient in transformers is maximal in the regime of metastable states, is uniformly distributed when averaging globally, and vanishes when a fixed point is near a stored pattern. Based on the Hopfield network interpretation, we analyzed learning of transformer and BERT architectures. Learning starts with attention heads that average and then most of them switch to metastable states. However, the majority of heads in the first layers still averages and can be replaced by averaging operations like the Gaussian weighting that we propose. In contrast, heads in the last layers steadily learn and seem to use metastable states to collect information created in lower layers. These heads seem to be a promising target for improving transformers. Neural networks that integrate Hopfield networks, that are equivalent to attention heads, outperform other methods on immune repertoire classification, where the Hopfield net stores several hundreds of thousands of patterns. We provide a new PyTorch layer called \"Hopfield\" which allows to equip deep learning architectures with modern Hopfield networks as new powerful concept comprising pooling, memory, and attention. The implementation is available at: https://github.com/ml-jku/ hopfield-layers arXiv:2008.02217v1 [cs.NE] 16 Jul 2020The update rule converges after one update for well separated patterns: Theorem 4. With query \u03be, after one update the distance of the new point f (\u03be) to the fixed point x * i is exponentially small in the separation \u2206 i . The precise bounds using the Jacobian J = \u2202f (\u03be) \u2202\u03be and its value J m in the mean value theorem are:",
    "prev": "Since its introduction, the Hopfield network has been extended and studied widely by neuroscientists (Griniasty et al., 1993;Schneidman et al., 2006;Sridhar et al., 2021;Burns et al., 2022), physicists (Amit et al., 1985;Agliari et al., 2013;Leonetti et al., 2021), and computer scientists (Widrich et al., 2020;Millidge et al., 2022).",
    "curr": "Of particular interest to the machine learning community is the recent development of modern Hopfield networks (Krotov & Hopfield, 2016) and their close correspondence (Ramsauer et al., 2021) to the attention mechanism of Transformers (Vaswani et al., 2017).",
    "next": "An early (Amit et al., 1985;McEliece et al., 1987) and ongoing (Hillar & Tran, 2018) theme in the study of Hopfield networks has been their memory storage capacity, i.e., determining the number of memory patterns which can be reliably stored and later recalled via the dynamics.",
    "hard_negative": [
      52967399,
      5590763,
      210942708
    ],
    "easy_negative": [
      253420743,
      14048239,
      7142721
    ]
  },
  {
    "index": 2762,
    "source_corpus_id": 247922520,
    "ref_id": "b34",
    "citation_corpus_id": 1957433,
    "start": 7592,
    "end": 7595,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "Pretraining weights is a dominant paradigm for transfer learning with deep models, in which pretrained model weights (from surrogate tasks) are used to initialize some subset of parameters in the model for the target task, which are then either (a) left frozen, or (b) finetuned.",
    "curr": "Pretraining deep models has been studied extensively in the unsupervised setting [24,25,26,27,28], and in the supervised setting was perhaps most popularized by ImageNet [29] pretraining [30,31,32,33], Various forms of pretraining have been ubiquitous in NLP [34,35,36,37,38,1,2].",
    "next": "For each target task, model architectures and/or training procedures may need to be developed that are composed of these pretrained parameters, for which domain expertise may be advantageous.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      9832697,
      235258265,
      19286820
    ]
  },
  {
    "index": 2764,
    "source_corpus_id": 259203582,
    "ref_id": "b31",
    "citation_corpus_id": 257039062,
    "start": 10245,
    "end": 10249,
    "title": "Published as a conference paper at ICLR 2023 SEMANTIC UNCERTAINTY: LINGUISTIC INVARIANCES FOR UNCERTAINTY ESTIMATION IN NATURAL LANGUAGE GENERATION",
    "abstract": "We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of 'semantic equivalence'-different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy-an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to 'off-the-shelf' language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines.",
    "prev": "Our methods are model agnostic and provide rigorous guarantees.",
    "curr": "Our conformal component selection ( \u00a74.4) also relates to recent selfconsistency work that builds on the empirical observation that repeated similar samples are more likely to be correct [45; 72], and cross-sample entailment can approximate uncertainty [32].",
    "next": "Unlike previous work that uses a fixed number of re-samples and compares full outputs, we (1) introduce a dynamic stopping rule to reduce the number of samples, (2) extend this concept to semantically compare sub-components of long text outputs, and (3) conformalize the process to provide proper guarantees.",
    "hard_negative": [
      44104104,
      248780252,
      52055325
    ],
    "easy_negative": [
      258557287,
      363867,
      15681845
    ]
  },
  {
    "index": 2767,
    "source_corpus_id": 58028789,
    "ref_id": "b32",
    "citation_corpus_id": 7147309,
    "start": 1694,
    "end": 1715,
    "title": "SEQUENCE LEVEL TRAINING WITH RECURRENT NEURAL NETWORKS",
    "abstract": "Many natural language processing applications use language models to generate text. These models are typically trained to predict the next word in a sequence, given the previous words and some context such as an image. However, at test time the model is expected to generate the entire sequence from scratch. This discrepancy makes generation brittle, as errors may accumulate along the way. We address this issue by proposing a novel sequence level training algorithm that directly optimizes the metric used at test time, such as BLEU or ROUGE. On three different tasks, our approach outperforms several strong baselines for greedy generation. The method is also competitive when these baselines employ beam search, while being several times faster.",
    "prev": "Extensive experiments are conducted to validate the utility of the proposed approach, showing consistent improvements over a wide variety of NLP tasks, including machine translation, abstractive text summarization, and image captioning.",
    "curr": "INTRODUCTION\n\nSequence-to-sequence (Seq2Seq) models are widely used in various natural language processing tasks, such as machine translation (Bahdanau et al., 2015;Cho et al., 2014;Sutskever et al., 2014), text summarization (Chopra et al., 2016;Rush et al., 2015) and image captioning (Vinyals et al., 2015;Xu et al., 2015).",
    "next": "Typically, Seq2Seq models are based on an encoder-decoder architecture, with an encoder mapping a source sequence into a latent vector, and a decoder translating the latent vector into a target sequence.",
    "hard_negative": [
      1391785,
      5467830,
      1318875,
      11212020
    ],
    "easy_negative": [
      198232757,
      257496586,
      226239345
    ]
  },
  {
    "index": 2773,
    "source_corpus_id": 231951553,
    "ref_id": "b23",
    "citation_corpus_id": 3633127,
    "start": 2380,
    "end": 2403,
    "title": "Published as a conference paper at ICLR 2018 CGANS WITH PROJECTION DISCRIMINATOR",
    "abstract": "We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. This approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. With this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (Im-ageNet) 1000-class image dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. We were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. This new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_projection.",
    "prev": "The conditional information in cGANs is used to drive the generation and to enforce the correspondence between condition and sample.",
    "curr": "Various alternatives have been proposed for how the condition should be included in the discriminator (Miyato & Koyama, 2018;Reed et al., 2016) but the majority of frameworks provide it as an input, hoping that the sample's correlation with the condition will play a role in distinguishing between synthesized and genuine samples.",
    "next": "The main drawback of this approach is that it does not encourage the use of the conditional information and therefore its contribution can be diminished or even ignored.",
    "hard_negative": [
      3366315,
      5687613,
      6104263,
      11758569
    ],
    "easy_negative": [
      252624427,
      2313543,
      53105955
    ]
  },
  {
    "index": 2776,
    "source_corpus_id": 204512445,
    "ref_id": "b28",
    "citation_corpus_id": 44131019,
    "start": 14631,
    "end": 14649,
    "title": "Scaling Neural Machine Translation",
    "abstract": "Sequence to sequence learning models still require several days to reach state of the art performance on large benchmark datasets using a single machine. This paper shows that reduced precision and large batch training can speedup training by nearly 5x on a single 8-GPU machine with careful tuning and implementation. 1 On WMT'14 English-German translation, we match the accuracy ofVaswani et al. (2017)in under 5 hours when training on 8 GPUs and we obtain a new state of the art of 29.3 BLEU after training for 85 minutes on 128 GPUs. We further improve these results to 29.8 BLEU by training on the much larger Paracrawl dataset. On the WMT'14 English-French task, we obtain a state-of-the-art BLEU of 43.2 in 8.5 hours on 128 GPUs.",
    "prev": "The learning rate is warmed up over the first 10,000 updates to a peak value of 1 \u00d7 10 \u22125 , and then linearly decayed over a total of 250k updates.",
    "curr": "We train on 128 GPUs with a batch size of 3072 tokens per GPU giving a total batch size of 393k tokens (Ott et al., 2018).",
    "next": "Each token represents 10ms of audio data.",
    "hard_negative": [
      6628106,
      3297437,
      9545399,
      21850704,
      3516266,
      11212020,
      6380915,
      3725815
    ],
    "easy_negative": [
      15383868,
      6612964,
      13788863
    ]
  },
  {
    "index": 2781,
    "source_corpus_id": 228372368,
    "ref_id": "b13",
    "citation_corpus_id": 1428702,
    "start": 37034,
    "end": 37053,
    "title": "Learning Word Vectors for Sentiment Analysis",
    "abstract": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term-document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.",
    "prev": "We use a subset of the Amazon Review Data (He & McAuley, 2016) for sentiment classification, aggregating all categories with more than 100k reviews from which we sample 200k reviews and split them into 160k training points and 40k test points.",
    "curr": "We use the IMDB Movie Review Sentiment dataset (Maas et al., 2011) which has 25k training samples and 25k test samples.",
    "next": "In addition, we use the Bias in Bios (De-Arteaga et al., 2019) dataset from which we create binary classification tasks to distinguish difficult pairs among frequently occurring occupations.",
    "hard_negative": [
      1260035,
      388,
      2279432,
      10473638,
      7105713,
      2787775,
      218515777,
      3264224,
      629094,
      469886
    ],
    "easy_negative": [
      2970201,
      18732516,
      184483331
    ]
  },
  {
    "index": 2793,
    "source_corpus_id": 263831633,
    "ref_id": "b36",
    "citation_corpus_id": 237416585,
    "start": 9084,
    "end": 9101,
    "title": "Published as a conference paper at ICLR 2022 FINETUNED LANGUAGE MODELS ARE ZERO-SHOT LEARNERS",
    "abstract": "This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning-finetuning language models on a collection of datasets described via instructions-substantially improves zeroshot performance on unseen tasks.",
    "prev": "Scalable Oversight & Self-Alignment AI alignment traditionally relies heavily on extensive human annotations.",
    "curr": "Primary Supervised Fine-Tuning (SFT) sources for response demonstrations include those curated from existing NLP datasets (Sanh et al., 2021;Wei et al., 2021;Chung et al., 2022b;Wang et al., 2022b) and those specifically crafted by humans for instruction tuning (Databricks, 2023;K\u00f6pf et al., 2023;Zhou et al., 2023;Ouyang et al., 2022 Touvron et al.",
    "next": "(2023b)), online human preferences are collected to train a reward model to further fine-tune the SFT-trained model (Leike et al., 2018).",
    "hard_negative": [
      210838924,
      102353817,
      220045465,
      52055325,
      52057510,
      202540839,
      3432876,
      195218742,
      9586240,
      182953152,
      3626819,
      220364230,
      11816014,
      207756753,
      165163607,
      233231453,
      10766958,
      85464175,
      47018994,
      215768182,
      219165306,
      85504763
    ],
    "easy_negative": [
      1367004,
      1024399,
      2474505
    ]
  },
  {
    "index": 2811,
    "source_corpus_id": 49654320,
    "ref_id": "b45",
    "citation_corpus_id": 4043645,
    "start": 10346,
    "end": 10362,
    "title": "Published as a conference paper at ICLR 2018 VARIANCE REDUCTION FOR POLICY GRADIENT WITH ACTION-DEPENDENT FACTORIZED BASELINES",
    "abstract": "Policy gradient methods have enjoyed great success in deep reinforcement learning but suffer from high variance of gradient estimates. The high variance problem is particularly exasperated in problems with long horizons or high-dimensional action spaces. To mitigate this issue, we derive a bias-free action-dependent baseline for variance reduction which fully exploits the structural form of the stochastic policy itself and does not make any additional assumptions about the MDP. We demonstrate and quantify the benefit of the action-dependent baseline through both theoretical analysis as well as numerical results, including an analysis of the suboptimality of the optimal state-dependent baseline. The result is a computationally efficient policy gradient algorithm, which scales to high-dimensional control problems, as demonstrated by a synthetic 2000-dimensional target matching task. Our experimental results indicate that action-dependent baselines allow for faster learning on standard reinforcement learning benchmarks and highdimensional hand manipulation and synthetic tasks. Finally, we show that the general idea of including additional information in baselines for improved variance reduction can be extended to partially observed and multi-agent tasks.Published as a conference paper at ICLR 2018 removing the influence of future actions from the total reward. A better baseline, which predicts the average performance more accurately, will lead to lower variance of the gradient estimator.",
    "prev": "(1) becomes E \u03c1\u03c0,\u03c0 \u03b8 [\u2207 \u03b8 log \u03c0 \u03b8 (a|s) (Q \u03c0 \u03b8 (s, a) \u2212 b(s))].",
    "curr": "While an optimal baseline exists (Greensmith et al., 2004;Wu et al., 2018), it is hard to estimate and often replaced by the value function b(s t ) = V \u03c0 (s t ) (Sutton & Barto, 1998;Mnih et al., 2016).",
    "next": "Stochastic gradient descent using Eq.",
    "hard_negative": [
      16326763,
      14048239,
      3075448
    ],
    "easy_negative": [
      236459829,
      235729183,
      52088192
    ]
  },
  {
    "index": 2812,
    "source_corpus_id": 57761150,
    "ref_id": "b12",
    "citation_corpus_id": 8348149,
    "start": 10556,
    "end": 10577,
    "title": "Learning Effective and Interpretable Semantic Models using Non-Negative Sparse Embedding",
    "abstract": "In this paper, we introduce an application of matrix factorization to produce corpus-derived, distributional models of semantics that demonstrate cognitive plausibility. We find that word representations learned by Non-Negative Sparse Embedding (NNSE), a variant of matrix factorization, are sparse, effective, and highly interpretable. To the best of our knowledge, this is the first approach which yields semantic representation of words satisfying these three desirable properties. Though extensive experimental evaluations on multiple real-world tasks and datasets, we demonstrate the superiority of semantic models learned by NNSE over other state-of-the-art baselines.",
    "prev": "We estimate semantic features from behavioral data alone, using the probabilistic model described in the next section.",
    "curr": "In our model, each feature/dimension x if in the vector x i is real and non-negative, so as to make it interpretable as the degree to which the aspect of meaning it represents is present and influences subject behavior (Murphy et al., 2012).",
    "next": "Further, we expect features/dimensions to be sparse McRae et al.",
    "hard_negative": [
      5584134,
      7747235,
      380201,
      9460276,
      15698938,
      629094
    ],
    "easy_negative": [
      51878811,
      6105163,
      238582653
    ]
  },
  {
    "index": 2816,
    "source_corpus_id": 257039062,
    "ref_id": "b5",
    "citation_corpus_id": 212747810,
    "start": 21667,
    "end": 21688,
    "title": "Calibration of Pre-trained Transformers",
    "abstract": "Pre-trained Transformers are now ubiquitous in natural language processing, but despite their high end-task performance, little is known empirically about whether they are calibrated. Specifically, do these models' posterior probabilities provide an accurate empirical measure of how likely the model is to be correct on a given example? We focus on BERT (Devlin et al., 2019)  and RoBERTa  (Liu et al., 2019)  in this work, and analyze their calibration across three tasks: natural language inference, paraphrase detection, and commonsense reasoning. For each task, we consider in-domain as well as challenging outof-domain settings, where models face more examples they should be uncertain about. We show that: (1) when used out-of-the-box, pretrained models are calibrated in-domain, and compared to baselines, their calibration error out-of-domain can be as much as 3.5\u00d7 lower;(2) temperature scaling is effective at further reducing calibration error in-domain, and using label smoothing to deliberately increase empirical uncertainty helps calibrate posteriors out-of-domain. 1",
    "prev": "We address the challenges of sampling and variable-length generation using specific details of our sampling procedure in Section 4.",
    "curr": "RELATED WORK\n\nPrior work on uncertainty in foundation models for NLP has largely focused on the calibration of classifiers (Jiang et al., 2021;Desai & Durrett, 2020) and text regressors (Glushkova et al., 2021;Wang et al., 2022).",
    "next": "These settings, are analogous to classification or regression settings in other modalities like vision, and conventional uncertainty measures like MC dropout or Deep Ensembles can be applied without modification (see Section 2 for a discussion of uncertainty in deep learning in general).",
    "hard_negative": [
      8495258,
      202888986,
      51879969,
      13046179,
      3432876,
      34032948,
      52019251,
      1957433,
      213152193,
      9387600,
      2879445,
      201645145,
      184486746,
      3464416,
      52967399,
      3994096,
      3526391
    ],
    "easy_negative": [
      250391066,
      6401679,
      12063711
    ]
  },
  {
    "index": 2828,
    "source_corpus_id": 251929437,
    "ref_id": "b9",
    "citation_corpus_id": 1729543,
    "start": 28247,
    "end": 28267,
    "title": "Guiding Semi-Supervision with Constraint-Driven Learning",
    "abstract": "Over the last few years, two of the main research directions in machine learning of natural language processing have been the study of semi-supervised learning algorithms as a way to train classifiers when the labeled data is scarce, and the study of ways to exploit knowledge and global information in structured learning tasks. In this paper, we suggest a method for incorporating domain knowledge in semi-supervised learning algorithms. Our novel framework unifies and can exploit several kinds of task specific constraints. The experimental results presented in the information extraction domain demonstrate that applying constraints helps the model to generate better feedback during learning, and hence the framework allows for high performance learning with significantly less training data than was possible before on these tasks.",
    "prev": "Regularization in probabilistic models.",
    "curr": "Extensive regularization approaches have been developed in traditional Bayesian inference (Zhu et al., 2014) and probabilistic modeling (Chang et al., 2007;Liang et al., 2009;Ganchev et al., 2010 \n\n\nETHICS STATEMENT\n\nThis work presents a framework to train deep generative models on small data.",
    "next": "By improving the data efficiency, it can potentially benefit real-world applications like medicine analysis and automatic drive.",
    "hard_negative": [
      9044768,
      137155,
      628455,
      259144,
      10432514,
      859162
    ],
    "easy_negative": [
      7193856,
      9674799,
      10576017
    ]
  },
  {
    "index": 2849,
    "source_corpus_id": 254044293,
    "ref_id": "b49",
    "citation_corpus_id": 243756979,
    "start": 3128,
    "end": 3149,
    "title": "LARGE-SCALE REPRESENTATION LEARNING ON GRAPHS VIA BOOTSTRAPPING",
    "abstract": "Self-supervised learning provides a promising path towards eliminating the need for costly label information in representation learning on graphs. However, to achieve state-of-the-art performance, methods often need large numbers of negative examples and rely on complex augmentations. This can be prohibitively expensive, especially for large graphs. To address these challenges, we introduce Bootstrapped Graph Latents (BGRL) -a graph representation learning method that learns by predicting alternative augmentations of the input. BGRL uses only simple augmentations and alleviates the need for contrasting with negative examples, and is thus scalable by design. BGRL outperforms or matches prior methods on several established benchmarks, while achieving a 2-10x reduction in memory costs. Furthermore, we show that BGRL can be scaled up to extremely large graphs with hundreds of millions of nodes in the semi-supervised regime -achieving state-ofthe-art performance and improving over supervised baselines where representations are shaped only through label information. In particular, our solution centered on BGRL constituted one of the winning entries to the Open Graph Benchmark -Large Scale Challenge at KDD Cup 2021, on a graph orders of magnitudes larger than all previously available benchmarks, thus demonstrating the scalability and effectiveness of our approach.",
    "prev": "INTRODUCTION\n\nGraph neural networks (GNNs) are ubiquitously used modeling tools for relational graph data, with widespread applications in chemistry , forecasting and traffic prediction (Derrow-Pinion et al., 2021;, recommendation systems (Ying et al., 2018b;He et al., 2020;Sankar et al., 2021;Fan et al., 2022), graph generation (You et al., 2018;Fan & Huang, 2019;Shiao & Papalexakis, 2021), and more.",
    "curr": "Given significant challenges in obtaining labeled data, one particularly exciting recent direction is the advent of graph self-supervised learning (SSL), which aims to learn representations useful for various downstream tasks without using explicit supervision besides available graph structure and node features Jin et al., 2021;Thakoor et al., 2022;Bielak et al., 2022).",
    "next": "One prominent class of graph SSL approaches are contrastive methods (Jin et al., 2020).",
    "hard_negative": [
      6628106,
      52877454,
      4630420,
      235614234,
      1957433,
      5959482,
      199441876,
      52055130,
      213085920,
      212859361,
      3292002,
      52967399,
      5273326
    ],
    "easy_negative": [
      226283756,
      9351405,
      219303199
    ]
  },
  {
    "index": 2858,
    "source_corpus_id": 256697430,
    "ref_id": "b34",
    "citation_corpus_id": 170078913,
    "start": 3420,
    "end": 3437,
    "title": "Published as a conference paper at ICLR 2020 WHAT CAN NEURAL NETWORKS REASON ABOUT?",
    "abstract": "Neural networks have succeeded in many reasoning tasks. Empirically, these tasks require specialized network structures, e.g., Graph Neural Networks (GNNs) perform well on many such tasks, but less structured networks fail. Theoretically, there is limited understanding of why and when a network structure generalizes better than others, although they have equal expressive power. In this paper, we develop a framework to characterize which reasoning tasks a network can learn well, by studying how well its computation structure aligns with the algorithmic structure of the relevant reasoning process. We formally define this algorithmic alignment and derive a sample complexity bound that decreases with better alignment. This framework offers an explanation for the empirical success of popular reasoning models, and suggests their limitations. As an example, we unify seemingly different reasoning tasks, such as intuitive physics, visual question answering, and shortest paths, via the lens of a powerful algorithmic paradigm, dynamic programming (DP). We show that GNNs align with DP and thus are expected to solve these tasks. On several reasoning tasks, our theory is supported by empirical results.However, there is limited understanding of the relation between the generalization ability and network structure for reasoning. What tasks can a neural network (sample efficiently) learn to reason about? Answering this question is crucial for understanding the empirical success and limitations of existing models, and for designing better models for new reasoning tasks.This paper is an initial work towards answering this fundamental question, by developing a theoretical framework to characterize what tasks a neural network can reason about. We build on a simple observation that reasoning processes resemble algorithms. Hence, we study how well a reasoning algorithm aligns with the computation graph of the network. Intuitively, if they align well, the network only needs to learn simple algorithm steps to simulate the reasoning process, which leads to better sample efficiency. We formalize this intuition with a numeric measure of algorithmic alignment, 1",
    "prev": "by learning an input-output mapping, or through the lens of reinforcement learning (Kool et al., 2019).",
    "curr": "However, more recent works build upon the notion of algorithmic alignment (Xu et al., 2020) stating that there must be an \"alignment\" between the learning model structure and the target algorithm in order to ease optimisation.",
    "next": "Much focus has been placed on Graph Neural Networks (GNNs) (Bacciu et al., 2020) learning graph algorithms, i.e Bellman-Ford (Bellman, 1958).",
    "hard_negative": [
      6981893,
      49667227,
      57825721,
      203736530,
      1803861,
      52920808,
      108296442,
      85504763
    ],
    "easy_negative": [
      259376752,
      17204537,
      6255830
    ]
  },
  {
    "index": 2860,
    "source_corpus_id": 248798499,
    "ref_id": "b13",
    "citation_corpus_id": 108306725,
    "start": 2178,
    "end": 2196,
    "title": "NEURAL LOGIC MACHINES",
    "abstract": "We propose the Neural Logic Machine (NLM), a neural-symbolic architecture for both inductive learning and logic reasoning. NLMs exploit the power of both neural networks-as function approximators, and logic programming-as a symbolic processor for objects with properties, relations, logic connectives, and quantifiers. After being trained on small-scale tasks (such as sorting short arrays), NLMs can recover lifted rules, and generalize to large-scale tasks (such as sorting longer arrays). In our experiments, NLMs achieve perfect generalization in a number of tasks, from relational reasoning tasks on the family tree and general graphs, to decision making tasks including sorting arrays, finding shortest paths, and playing the blocks world. Most of these tasks are hard to accomplish for neural networks or inductive logic programming alone.",
    "prev": "* Equal contribution.",
    "curr": "INTRODUCTION\n\nWhile deep learning has achieved great success in various applications, it was pointed out that there is a debate over the problem of systematicity in connectionist models (Fodor & Pylyshyn, 1988;Fodor & McLaughlin, 1990;Hadley, 1994;Jansen & Watter, 2012;Dong et al., 2018).",
    "next": "To concretely explain systematicity (Hupkes et al., 2020), let us consider the kinship problem shown in Figure 1.",
    "hard_negative": [
      7034786,
      6715185
    ],
    "easy_negative": [
      3329316,
      10059432,
      14087839
    ]
  },
  {
    "index": 2865,
    "source_corpus_id": 9747411,
    "ref_id": "b14",
    "citation_corpus_id": 16496273,
    "start": 3931,
    "end": 3934,
    "title": "Efficient Learning of Domain-invariant Image Representations",
    "abstract": "We present an algorithm that learns representations which explicitly compensate for domain mismatch and which can be efficiently realized as linear classifiers. Specifically, we form a linear transformation that maps features from the target (test) domain to the source (training) domain as part of training the classifier. We optimize both the transformation and classifier parameters jointly, and introduce an efficient cost function based on misclassification loss. Our method combines several features previously unavailable in a single algorithm: multi-class adaptation through representation learning, ability to map across heterogeneous feature spaces, and scalability to large datasets. We present experiments on several image datasets that demonstrate improved accuracy and computational advantages compared to previous approaches.",
    "prev": "Theoretical [2,4] and practical results from [20,21] have shown that supervised methods' test error increases in proportion to the difference between the test and training input distribution.",
    "curr": "Many visual domain adaptation methods have been put forth to compensate for dataset bias [7,22,1,20,18,16,13,12,14,15], but are limited to shallow models.",
    "next": "Evaluation for image category classification across visually distinct domains has focused on the Office dataset, which contains 31 image categories and 3 domains [20].",
    "hard_negative": [
      15036406,
      15978939
    ],
    "easy_negative": [
      233365322,
      9457590,
      2431311
    ]
  },
  {
    "index": 2872,
    "source_corpus_id": 52912118,
    "ref_id": "b14",
    "citation_corpus_id": 3568073,
    "start": 1532,
    "end": 1552,
    "title": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024 2 . We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.",
    "prev": "Selfmodulation is a simple architectural change that requires no additional parameter tuning, which suggests that it can be applied readily to any GAN.",
    "curr": "INTRODUCTION\n\nGenerative Adversarial Networks (GANs) are a powerful class of generative models successfully applied to a variety of tasks such as image generation (Zhang et al., 2017;Miyato et al., 2018;Karras et al., 2017), learned compression (Tschannen et al., 2018), super-resolution (Ledig et al., 2017), inpainting (Pathak et al., 2016), and domain transfer (Isola et al., 2016;Zhu et al., 2017).",
    "next": "Training GANs is a notoriously challenging task (Goodfellow et al., 2014;Lucic et al., 2018) as one is searching in a high-dimensional parameter space for a Nash equilibrium of a non-convex game.",
    "hard_negative": [
      18828233,
      6628106
    ],
    "easy_negative": [
      232021925,
      44159345,
      219308999
    ]
  },
  {
    "index": 2891,
    "source_corpus_id": 231573479,
    "ref_id": "b44",
    "citation_corpus_id": 12713052,
    "start": 6560,
    "end": 6576,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "More recently, AutoML (Hutter et al., 2018) aims to automate the machine learning training process.",
    "curr": "Automated neural network architecture search (Stanley & Miikkulainen, 2002;Real et al., 2017;Liu et al., 2017;Zoph & Le, 2016;Elsken et al., 2018;Pham et al., 2018) has made large improvements in image classification.",
    "next": "Instead of learning the architecture, AutoML-Zero (Real et al., 2020) learns the algorithm from scratch using basic mathematical operations.",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      258298024,
      216869183,
      222180042
    ]
  },
  {
    "index": 2893,
    "source_corpus_id": 52876166,
    "ref_id": "b19",
    "citation_corpus_id": 17272965,
    "start": 3339,
    "end": 3359,
    "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
    "abstract": "Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.Deep learning methods have realized impressive performance in a range of applications, from visual object classification [1, 2, 3] to speech recognition [4] and natural language processing[5,6]. These successes have been achieved despite the noted difficulty of training such deep architectures[7,8,9,10,11]. Indeed, many explanations for the difficulty of deep learning have been advanced in the literature, including the presence of many local minima, low curvature regions due to saturating nonlinearities, and exponential growth or decay of back-propagated gradients[12,13,14,15]. Furthermore, many neural network simulations have observed 1 arXiv:1312.6120v3 [cs.NE]",
    "prev": "In the absence of any such tight and computable theory of deep network generalization error, we develop an analytic theory of generalization error for deep linear networks.",
    "curr": "Such networks exhibit highly nonlinear learning dynamics (Saxe et al., 2013a;b) including many prominent phenomena like learning plateaus, saddle points, and sudden drops in training error.",
    "next": "Moreover, theory developed for the learning dynamics of deep linear networks directly inspired better initialization schemes for nonlinear networks (Schoenholz et al., 2016;Pennington et al., 2017;.",
    "hard_negative": [
      14228101,
      14687186
    ],
    "easy_negative": [
      248987294,
      5925661,
      7658188
    ]
  },
  {
    "index": 2897,
    "source_corpus_id": 15075376,
    "ref_id": "b1",
    "citation_corpus_id": 3116311,
    "start": 1218,
    "end": 1220,
    "title": "Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions",
    "abstract": "We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model's ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.",
    "prev": "This model learns representations that generalize well to new types of reasoning pattern in all but a few cases, a result which is promising for the ability of learned representation models to capture logical reasoning.",
    "curr": "Introduction\n\nDeep learning methods in NLP which learn vector representations for words have seen successful uses in recent years on increasingly sophisticated tasks [1,2,3,4].",
    "next": "Given the still modest performance of semantically rich NLP systems in many domains-question answering and machine translation, for instance-it is worth exploring the degree to which learned vectors can serve as general purpose semantic representations.",
    "hard_negative": [
      388,
      2279432,
      6684426,
      9656604,
      866726,
      7105713,
      1688003,
      6627923,
      3264224,
      629094,
      2527473
    ],
    "easy_negative": [
      14316240,
      227230349,
      8624752
    ]
  },
  {
    "index": 2899,
    "source_corpus_id": 248811447,
    "ref_id": "b71",
    "citation_corpus_id": 14124313,
    "start": 3224,
    "end": 3252,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "Provided with multimodality input of an RGB image and its depth map, the task of RGB-D SOD is to effectively identify and segment the most distinctive objects in a scene.",
    "curr": "The state-of-the-art RGB-D SOD approaches Ji et al., 2020b;2021b) typically entail an image-to-mask mapping pipeline that is based on the powerful deep learning paradigms of e.g., VGG16 (Simonyan & Zisserman, 2015) or ResNet50 .",
    "next": "This strategy has led to excellent performance.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      1253903,
      236486297,
      174800105
    ]
  },
  {
    "index": 2900,
    "source_corpus_id": 182953182,
    "ref_id": "b35",
    "citation_corpus_id": 14124313,
    "start": 2649,
    "end": 2677,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "A key component of many neural networks is the use of normalization layers such as Batch Normalization (Ioffe & Szegedy, 2015), Group Normalization (Wu & He, 2018), or Layer Normalization (Ba et al., 2016), with Batch Normalization the most commonly used for vision-based tasks.",
    "curr": "While the true reason why these methods work is still an active area of research (Santurkar et al., 2018), normalization techniques typically serve the purpose of making neural networks more amenable to optimization, allowing the training of very deep networks without the use of careful initialization schemes (Simonyan & Zisserman, 2015;, custom nonlinearities (Klambauer et al., 2017), or other more complicated techniques (Xiao et al., 2018).",
    "next": "Even in situations where training without normalization layers is possible, their usage can still aid generalization .",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      32496083,
      8048647,
      165163737
    ]
  },
  {
    "index": 2902,
    "source_corpus_id": 244130146,
    "ref_id": "b29",
    "citation_corpus_id": 227209335,
    "start": 4330,
    "end": 4348,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "Our main idea is to learn the prior distribution of medical images with a generative model in order to infer the lost information due to partial measurements.",
    "curr": "Specifically, we propose to train a score-based generative model (Song & Ermon, 2019;2020;Song et al., 2021) on medical images as the data prior, due to its strong performance in image generation (Ho et al., 2020;Dhariwal & Nichol, 2021).",
    "next": "Given a trained score-based generative model, we provide a family of sampling algorithms to create image samples that are consistent with the observed measurements and the estimated data prior, leveraging the physical measurement process.",
    "hard_negative": [
      52889459,
      52908831
    ],
    "easy_negative": [
      227231083,
      441908,
      29152969
    ]
  },
  {
    "index": 2907,
    "source_corpus_id": 249151922,
    "ref_id": "b5",
    "citation_corpus_id": 235254358,
    "start": 13511,
    "end": 13530,
    "title": "HOW ATTENTIVE ARE GRAPH ATTENTION NETWORKS?",
    "abstract": "Graph Attention Networks (GATs) are one of the most popular GNN architectures and are considered as the state-of-the-art architecture for representation learning with graphs. In GAT, every node attends to its neighbors given its own representation as the query. However, in this paper we show that GAT computes a very limited kind of attention: the ranking of the attention scores is unconditioned on the query node. We formally define this restricted kind of attention as static attention and distinguish it from a strictly more expressive dynamic attention. Because GATs use a static attention mechanism, there are simple graph problems that GAT cannot express: in a controlled problem, we show that static attention hinders GAT from even fitting the training data. To remove this limitation, we introduce a simple fix by modifying the order of operations and propose GATv2: a dynamic graph attention variant that is strictly more expressive than GAT. We perform an extensive evaluation and show that GATv2 outperforms GAT across 12 OGB and other benchmarks while we match their parametric costs. Our code is available at https://github.com/tech-srl/how_attentive_are_ gats.",
    "prev": "GNN ensembles Ho (1998) and Breiman (2001) showed that training an ensemble of shallow learners on random subspaces could exploit variance in the feature space and improve performance, and Dietterich (2000) demonstrated that these ensembles are most potent when the predictions of their base classifiers are accurate and diverse.",
    "curr": "Deep ensembles have typically been used with random weight initializations to improve uncertainty estimation and robustness (Lakshminarayanan et al., 2017;Fort et al., 2019;Wasay & Idreos, 2020), which has benefited GNNs via mechanisms like multi-head attention (Veli\u010dkovi\u0107 et al., 2018;Brody et al., 2022;Hou et al., 2021), but very few works have directly explored ensembles of GNNs.",
    "next": "Some recent exceptions have suggested that ensembling subgraphs could benefit GNNs (Zeng et al., 2021;Tang et al., 2021;Lin et al., 2022).",
    "hard_negative": [
      202538897,
      3144218,
      225075866,
      235614234,
      3495200,
      220047268,
      174797737,
      44115640,
      8393918,
      202888772,
      219708742,
      1998416,
      212859361,
      3292002,
      52895589
    ],
    "easy_negative": [
      164019,
      248512748,
      17432480
    ]
  },
  {
    "index": 2910,
    "source_corpus_id": 211021032,
    "ref_id": "b4",
    "citation_corpus_id": 14711954,
    "start": 25713,
    "end": 25735,
    "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
    "abstract": "We describe a framework for multitask deep reinforcement learning guided by policy sketches. Sketches annotate tasks with sequences of named subtasks, providing information about high-level structural relationships among tasks but not how to implement them-specifically not providing the detailed guidance used by much previous work on learning policy abstractions for RL (e.g. intermediate rewards, subtask completion signals, or intrinsic motivations). To learn from sketches, we present a model that associates every subtask with a modular subpolicy, and jointly maximizes reward over full task-specific policies by tying parameters across shared subpolicies. Optimization is accomplished via a decoupled actor-critic training objective that facilitates learning common behaviors from multiple dissimilar reward functions. We evaluate the effectiveness of our approach in three environments featuring both discrete and continuous control, and with sparse rewards that can be obtained only after completing a number of high-level subgoals. Experiments show that using our approach to learn policies guided by sketches gives better performance than existing techniques for learning task-specific or shared policies, while naturally inducing a library of interpretable primitive behaviors that can be recombined to rapidly adapt to new tasks.",
    "prev": "Language can provide a form of supervision for how to break down the world and/or learned behaviours into meaningful sub-parts, which in turn might stimulate systematicity and generalisation.",
    "curr": "Indeed, prior work has found that language can serve to promote compositional behaviour in deep RL agents (Andreas et al., 2017).",
    "next": "To explore this hypothesis, we devised a simple task in the grid world that can be solved either with or without relying on language.",
    "hard_negative": [
      9963298,
      806709,
      3130692,
      216034672,
      5249151
    ],
    "easy_negative": [
      14899593,
      16847124,
      9093102
    ]
  },
  {
    "index": 2917,
    "source_corpus_id": 2926851,
    "ref_id": "b3",
    "citation_corpus_id": 8893912,
    "start": 11226,
    "end": 11229,
    "title": "Paraphrase-Driven Learning for Open Question Answering",
    "abstract": "We study question answering as a machine learning problem, and induce a function that maps open-domain questions to queries over a database of web extractions. Given a large, community-authored, question-paraphrase corpus, we demonstrate that it is possible to learn a semantic lexicon and linear ranking function without manually annotating questions. Our approach automatically generalizes a seed lexicon and includes a scalable, parallelized perceptron parameter estimation scheme. Experiments show that our approach more than quadruples the recall of the seed lexicon, with only an 8% loss in precision.",
    "prev": "This then gives a feature space of D = 8|W |.",
    "curr": "Experiments\n\n\nLarge-scale QA\n\nWe perform experiments on the QA dataset introduced in [4].",
    "next": "It consists of 14M statements, stored as (subject, relation, object) triples, which are stored as memories in the MemNN model.",
    "hard_negative": [
      4895939,
      1942340,
      13043395,
      5667590,
      7747592,
      2755801,
      10318045,
      9842595,
      10910955,
      8884845,
      5541486,
      6387310,
      5284722,
      340852,
      16483125,
      16639862
    ],
    "easy_negative": [
      16681321,
      41708129,
      13746581
    ]
  },
  {
    "index": 2920,
    "source_corpus_id": 8895303,
    "ref_id": "b33",
    "citation_corpus_id": 14124313,
    "start": 3751,
    "end": 3779,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "In this paper we demonstrate that, for a speech recognition task, it is possible to train very accurate CNN models, outperforming LSTMs.",
    "curr": "This is thanks to CNN architectures inspired by recent devel-opments in computer vision (Simonyan & Zisserman, 2014), which were not previously considered for this task.",
    "next": "Moreover, the experiments suggest that LSTMs and CNNs learn different functions when trained on the same data.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      234487247,
      550498,
      250390617
    ]
  },
  {
    "index": 2927,
    "source_corpus_id": 257482853,
    "ref_id": "b16",
    "citation_corpus_id": 5590763,
    "start": 10821,
    "end": 10839,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "(2021).",
    "curr": "EVENT-BASED GRU\n\n3.1 TIME-SPARSE GRU FORMULATION We base our model on the GRU (Cho et al., 2014), illustrated for convenience in Fig.",
    "next": "1A.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      3062078,
      252386222,
      550145
    ]
  },
  {
    "index": 2928,
    "source_corpus_id": 257102428,
    "ref_id": "b45",
    "citation_corpus_id": 222179041,
    "start": 3338,
    "end": 3357,
    "title": "LEARNING MESH-BASED SIMULATION WITH GRAPH NETWORKS",
    "abstract": "Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efficiency. However, highdimensional scientific simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied. Here we introduce MESHGRAPHNETS, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model's adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efficient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efficiency of complex, scientific modeling tasks. * equal contribution Videos of all our experiments can be found at https",
    "prev": "Applications include structural mechanics (Zienkiewicz & Taylor, 2005;Stanova et al., 2015), electromagnetics (Jin, 2015;Xiao et al., 2022;Coggon, 1971), fluid dynamics (Chung, 1978;Zawawi et al., 2018;Long et al., 2021) and biomedical engineering (Van Staden et al., 2006;Soro et al., 2018), most of which traditionally depend on highly specialized task-dependent simulators.",
    "curr": "Recent advancements in deep learning brought rise to more general learned dynamic models such as Graph Network Simulators (GNSs) Pfaff et al., 2021).",
    "next": "GNSs learn to predict the dynamics of a system from data by encoding the system state as a graph and then iteratively computing the dynamics for every node in the graph with a Graph Neural Network (GNN) (Scarselli et al., 2009;Wu et al., 2020b).",
    "hard_negative": [
      3144218,
      2808403
    ],
    "easy_negative": [
      233476543,
      256662499,
      59800482
    ]
  },
  {
    "index": 2931,
    "source_corpus_id": 208637407,
    "ref_id": "b30",
    "citation_corpus_id": 2879445,
    "start": 5520,
    "end": 5544,
    "title": "Posterior calibration and exploratory analysis for natural language processing models",
    "abstract": "Many models in natural language processing define probabilistic distributions over linguistic structures. We argue that (1) the quality of a model's posterior distribution can and should be directly evaluated, as to whether probabilities correspond to empirical frequencies; and (2) NLP uncertainty can be projected not only to pipeline components, but also to exploratory data analysis, telling a user when to trust and not trust the NLP analysis. We present a method to analyze calibration, and apply it to compare the miscalibration of several commonly used models. We also contribute a coreference sampling algorithm that can create confidence intervals for a political event extraction task. 1",
    "prev": "Guo et al.",
    "curr": "(2017);Nguyen & O'Connor (2015) propose metrics for determining the calibration of machine learning models.",
    "next": "Lakshminarayanan et al.",
    "hard_negative": [
      7245829,
      1258901,
      5563288,
      15625129,
      11706155,
      11898554,
      12596803,
      4989386,
      7499734,
      10914266,
      16039645,
      2029665,
      4986998,
      2243454
    ],
    "easy_negative": [
      252460914,
      251385383,
      248779963
    ]
  },
  {
    "index": 2933,
    "source_corpus_id": 53116133,
    "ref_id": "b32",
    "citation_corpus_id": 1957433,
    "start": 1865,
    "end": 1890,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "They are essential in order to move from the discrete word space to the continuous space where differentiable loss functions can be optimized.",
    "curr": "The popular models of Glove (Pennington et al., 2014), Word2Vec (Mikolov et al., 2013b) or FastText (Bojanowski et al., 2016), provide efficient ways to learn word vectors fully unsupervised from raw text corpora, solely based on word co-occurrence statistics.",
    "next": "These models are then successfully applied to word similarity and other downstream tasks and, surprisingly (or not (Arora et al., 2016)), exhibit a linear algebraic structure that is also useful to solve word analogy.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      102352338,
      226262248,
      243865674
    ]
  },
  {
    "index": 2935,
    "source_corpus_id": 256697616,
    "ref_id": "b28",
    "citation_corpus_id": 232105052,
    "start": 1460,
    "end": 1479,
    "title": "RANDOM FEATURE ATTENTION",
    "abstract": "Transformers are state-of-the-art models for a variety of sequence modeling tasks.At their core is an attention function which models pairwise interactions between the inputs at every timestep.While attention is powerful, it does not scale efficiently to long sequences due to its quadratic time and space complexity in the sequence length.We propose RFA, a linear time and space attention that uses random feature methods to approximate the softmax function, and explore its application in transformers.RFA can be used as a drop-in replacement for conventional softmax attention and offers a straightforward way of learning with recency bias through an optional gating mechanism.Experiments on language modeling and machine translation demonstrate that RFA achieves similar or better performance compared to strong transformer baselines.In the machine translation experiment, RFA decodes twice as fast as a vanilla transformer.Compared to existing efficient transformer variants, RFA is competitive in terms of both accuracy and efficiency on three long text classification datasets.Our analysis shows that RFA's efficiency gains are especially notable on long sequences, suggesting that RFA will be particularly useful in tasks that require working with large inputs, fast decoding speed, or low memory footprints.",
    "prev": "1 Our code and models are available at this link.",
    "curr": "INTRODUCTION\n\nRandom-feature-based attention (RFA, also known as Performer; Choromanski et al., 2021;Peng et al., 2021b) is an established fast approximation to the conventional softmax attention mechanism (Bahdanau et al., 2014;Vaswani et al., 2017), which successfully scales Transformer models to processing much longer sequences (Choromanski et al., 2021).",
    "next": "At its core is the usage of random features (RF; Rahimi & Recht, 2008) to linearize the exponential kernel in softmax attention, which reduces the computational cost from quadratic to linear runtime and space complexity.",
    "hard_negative": [
      260440449,
      16299141,
      6628106,
      212756,
      52114454,
      218487704,
      52044834,
      49667762,
      102350771,
      59310641,
      201698358,
      222067132,
      212996548,
      3718988,
      208144205,
      44131019,
      159041867,
      207847640,
      1428702,
      52967399,
      5590763,
      5273326,
      11212020,
      204896246,
      4942335
    ],
    "easy_negative": [
      258865225,
      52012878,
      256461179
    ]
  },
  {
    "index": 2946,
    "source_corpus_id": 10278413,
    "ref_id": "b25",
    "citation_corpus_id": 7185434,
    "start": 2290,
    "end": 2312,
    "title": "Learning Bilingual Lexicons from Monolingual Corpora",
    "abstract": "We present a method for learning bilingual translation lexicons from monolingual corpora. Word types in each language are characterized by purely monolingual features, such as context counts and orthographic substrings. Translations are induced using a generative model based on canonical correlation analysis, which explains the monolingual lexicons in terms of latent matchings. We show that high-precision lexicons can be learned in a variety of language pairs and from a range of corpus types.",
    "prev": "This approach allows us to run approximate KCCA on a speech dataset with 1.4 million training samples and a random feature space of dimensionality M = 100000 on a typical workstation.",
    "curr": "INTRODUCTION\n\nCanonical correlation analysis (CCA, Hotelling, 1936) and its extensions are ubiquitous techniques in scientific research areas for revealing the common sources of variability in multiple views of the same phenomenon, including meteorology (Anderson, 2003), chemometrics (Montanarella et al., 1995), genomics (Witten et al., 2009), computer vision (Kim et al., 2007;Socher & Li, 2010), speech recognition (Rudzicz, 2010;Wang et al., 2015a), and natural language processing (Vinokourov et al., 2003;Haghighi et al., 2008;Dhillon et al., 2011;Hodosh et al., 2013;Faruqui & Dyer, 2014;Lu et al., 2015a).",
    "next": "CCA seeks linear projections of two random vectors (views), such that the resulting low-dimensional vectors are maximally correlated.",
    "hard_negative": [
      7822594,
      765547,
      15202196,
      38407095,
      1487550
    ],
    "easy_negative": [
      258999499,
      52158121,
      233029474
    ]
  },
  {
    "index": 2947,
    "source_corpus_id": 252907554,
    "ref_id": "b23",
    "citation_corpus_id": 221150562,
    "start": 3736,
    "end": 3755,
    "title": "Glancing Transformer for Non-Autoregressive Neural Machine Translation",
    "abstract": "Recent work on non-autoregressive neural machine translation (NAT) aims at improving the efficiency by parallel decoding without sacrificing the quality. However, existing NAT methods are either inferior to Transformer or require multiple decoding passes, leading to reduced speedup. We propose the Glancing Language Model (GLM) for single-pass parallel generation models. With GLM, we develop Glancing Transformer (GLAT) for machine translation. With only single-pass parallel decoding, GLAT is able to generate high-quality translation with 8\u00d7-15\u00d7 speedup. Note that GLAT does not modify the network architecture, which is a training method to learn word interdependency. Experiments on multiple WMT language directions show that GLAT outperforms all previous single pass non-autoregressive methods, and is nearly comparable to Transformer, reducing the gap to 0.25-0.9 BLEU points.",
    "prev": "Connectionist Temporal Classification (CTC) (Graves et al., 2006) is a fundamental criterion for seq2seq tasks.",
    "curr": "The CTC criterion was initially proposed Published as a conference paper at ICLR 2023 for automatic speech recognition (ASR) but its usage has been extended to many other tasks like machine translation (MT) (Qian et al., 2021;Gu & Kong, 2020;Huang et al., 2022), speech translation (ST) (Yan et al., 2022;Chuang et al., 2021;Liu et al., 2020), sign language translation (Wang et al., 2018;Guo et al., 2019;Camgoz et al., 2020), optical character recognition (OCR) (Graves & Schmidhuber, 2008), lip reading (Assael et al., 2017), hand gesture detection (Molchanov et al., 2016) and even robot control (Shiarlis et al., 2018).",
    "next": "Research on CTC is of wide interest, as many advanced systems for seq2seq tasks are based on CTC (Yao et al., 2021), its extensions (Graves, 2012;Sak et al., 2017;Higuchi et al., 2020;Qian et al., 2021) and its hybrid with attention-based architectures (Watanabe et al., 2017;Yan et al., 2022).",
    "hard_negative": [
      232307330,
      215786391,
      3438497,
      202539063,
      189999553,
      220046693,
      202538740
    ],
    "easy_negative": [
      19145711,
      12998021,
      258765287
    ]
  },
  {
    "index": 2948,
    "source_corpus_id": 257404839,
    "ref_id": "b32",
    "citation_corpus_id": 3292002,
    "start": 4715,
    "end": 4740,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "One particular example is in graph representation learning.",
    "curr": "Message Passing Graph Neural Networks (MP-GNNs) are the prevailing designs in modern Graph Neural Networks (GNNs), including numerous variants like GCN (Kipf & Welling, 2017), GAT (Veli\u010dkovi\u0107 et al., 2018), and even the Transformers (Vaswani et al., 2017).",
    "next": "There is a vast literature studying its diffusion dynamics and representation power Oono & Suzuki, 2020;Wang et al., 2021b;Li et al., 2022;Dong et al., 2021;Xu et al., 2019;Chen et al., 2022).",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      245855915,
      253098734,
      236965823
    ]
  },
  {
    "index": 2953,
    "source_corpus_id": 233231739,
    "ref_id": "b1",
    "citation_corpus_id": 9128667,
    "start": 2821,
    "end": 2846,
    "title": "STOCHASTIC VARIATIONAL VIDEO PREDICTION",
    "abstract": "Predicting the future in real-world settings, particularly from raw sensory observations such as images, is exceptionally challenging. Real-world events can be stochastic and unpredictable, and the high dimensionality and complexity of natural images require the predictive model to build an intricate understanding of the natural world. Many existing methods tackle this problem by making simplifying assumptions about the environment. One common assumption is that the outcome is deterministic and there is only one plausible future. This can lead to low-quality predictions in real-world settings with stochastic dynamics. In this paper, we develop a stochastic variational video prediction (SV2P) method that predicts a different possible future for each sample of its latent variables. To the best of our knowledge, our model is the first to provide effective stochastic multi-frame prediction for real-world videos. We demonstrate the capability of the proposed method in predicting detailed future frames of videos on multiple real-world datasets, both action-free and action-conditioned. We find that our proposed method produces substantially improved video predictions when compared to the same model without stochasticity, and to other stochastic video prediction methods. Our SV2P implementation will be open sourced upon publication.",
    "prev": "To make it truly beneficial for these applications, video prediction should be capable of forecasting long-term future.",
    "curr": "Many previous approaches have formulated video prediction as a conditional generation task by recursively synthesizing future frames conditioned on the previous frames (Vondrick et al., 2016;Tulyakov et al., 2018;Denton & Fergus, 2018;Babaeizadeh et al., 2018;Castrejon et al., 2019;.",
    "next": "Despite their success in short-term forecasting, however, none of these approaches have been successful in synthesizing convincing long-term future, due to the challenges in modeling complex dynamics and extrapolating from short sequences to much longer future.",
    "hard_negative": [
      205514,
      71638
    ],
    "easy_negative": [
      33914228,
      201646137,
      1583396
    ]
  },
  {
    "index": 2956,
    "source_corpus_id": 3517962,
    "ref_id": "b5",
    "citation_corpus_id": 3463260,
    "start": 5939,
    "end": 5960,
    "title": "Published as a conference paper at ICLR 2018 DISTRIBUTED PRIORITIZED EXPERIENCE REPLAY",
    "abstract": "We propose a distributed architecture for deep reinforcement learning at scale, that enables agents to learn effectively from orders of magnitude more data than previously possible. The algorithm decouples acting from learning: the actors interact with their own instances of the environment by selecting actions according to a shared neural network, and accumulate the resulting experience in a shared experience replay memory; the learner replays samples of experience and updates the neural network. The architecture relies on prioritized experience replay to focus only on the most significant data generated by the actors. Our architecture substantially improves the state of the art on the Arcade Learning Environment, achieving better final performance in a fraction of the wall-clock training time.",
    "prev": "Most interestingly, there have also been recent attempts to distribute updates for the DDPG algorithm, (e.g.",
    "curr": "Popov et al., 2017) and more generally in this work we build on work of (Horgan et al., 2018) for implementing distributed actors.",
    "next": "Recently, Bellemare et al.",
    "hard_negative": [
      1163588,
      14717992
    ],
    "easy_negative": [
      90247557,
      2511956,
      15856096
    ]
  },
  {
    "index": 2957,
    "source_corpus_id": 245123899,
    "ref_id": "b28",
    "citation_corpus_id": 226262285,
    "start": 3087,
    "end": 3098,
    "title": "Gradient-guided Unsupervised Lexically Constrained Text Generation",
    "abstract": "Lexically-constrained generation requires the target sentence to satisfy some lexical constraints, such as containing some specific words or being the paraphrase to a given sentence, which is very important in many real-world natural language generation applications. Previous works usually apply beamsearch-based methods or stochastic searching methods to lexically-constrained generation. However, when the search space is too large, beam-search-based methods always fail to find the constrained optimal solution. At the same time, stochastic search methods always cost too many steps to find the correct optimization direction. In this paper, we propose a novel method G2LC to solve the lexically-constrained generation as an unsupervised gradient-guided optimization problem. We propose a differentiable objective function and use the gradient to help determine which position in the sequence should be changed (deleted or inserted/replaced by another word). The word updating process of the inserted/replaced word also benefits from the guidance of gradient. Besides, our method is free of parallel data training, which is flexible to be used in the inference stage of any pre-trained generation model. We apply G2LC to two generation tasks: keyword-to-sentence generation and unsupervised paraphrase generation. The experiment results show that our method achieves state-of-the-art compared to previous lexically-constrained methods.",
    "prev": "For example, given concept words {dog, frisbee, catch, throw}, a machine is expected to generate a plausible description, e.g., \"A man throws a frisbee and his dog catches it in the air\".",
    "curr": "Machines with GCSR skills would communicate fluidly with humans, e.g., when summarizing a document by preserving its key details (Sha, 2020), composing a creative story according to a set of clues (Yao et al., 2019), and generating a conversation reply that includes specified keywords (Mou et al., 2016).",
    "next": "GCSR poses three unique challenges for automatic text generation methods.",
    "hard_negative": [
      8313873,
      9385494,
      4936344,
      7921947,
      92327,
      9662636,
      13663540,
      921404,
      15281983,
      2617281,
      174800071,
      5165773,
      7287895,
      8014052,
      1979237
    ],
    "easy_negative": [
      58774356,
      259376713,
      2036954
    ]
  },
  {
    "index": 2960,
    "source_corpus_id": 11212020,
    "ref_id": "b17",
    "citation_corpus_id": 12639289,
    "start": 1610,
    "end": 1641,
    "title": "Recurrent Continuous Translation Models",
    "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
    "prev": "Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "curr": "INTRODUCTION\n\nNeural machine translation is a newly emerging approach to machine translation, recently proposed by Kalchbrenner and Blunsom (2013), Sutskever et al.",
    "next": "(2014) and Cho et al.",
    "hard_negative": [
      10691183,
      16391184,
      8476273,
      806709
    ],
    "easy_negative": [
      252624732,
      5466972,
      6181272
    ]
  },
  {
    "index": 2961,
    "source_corpus_id": 247582435,
    "ref_id": "b2",
    "citation_corpus_id": 227905681,
    "start": 9164,
    "end": 9187,
    "title": "Compressing Pre-trained Language Models by Matrix Decomposition",
    "abstract": "Large pre-trained language models reach stateof-the-art results on many different NLP tasks when fine-tuned individually; They also come with a significant memory and computational requirements, calling for methods to reduce model sizes (green AI). We propose a twostage model-compression method to reduce a model's inference time cost. We first decompose the matrices in the model into smaller matrices and then perform feature distillation on the internal representation to recover from the decomposition. This approach has the benefit of reducing the number of parameters while preserving much of the information within the model. We experimented on BERTbase model with the GLUE benchmark dataset and show that we can reduce the number of parameters by a factor of 0.4x, and increase inference speed by a factor of 1.45x, while maintaining a minimal loss in metric performance.",
    "prev": "Those works inspire us to explore in depth extreme parameter compression for large-scale PLMs.",
    "curr": "We argue that compression ratio of existing work using matrix/tensor decomposition (Ma et al., 2019;Liu et al., 2021;Noach & Goldberg, 2020) for PLMs is relatively-small; most of them do not have speedup effect, limiting their applications in large-scale PLMs.",
    "next": "The potential to compress PLMs with matrix/tensor decomposition is under-investigated.",
    "hard_negative": [
      40100965,
      52967399,
      5034059,
      162183964
    ],
    "easy_negative": [
      15251438,
      33780956,
      226284017
    ]
  },
  {
    "index": 2971,
    "source_corpus_id": 222125277,
    "ref_id": "b18",
    "citation_corpus_id": 6216506,
    "start": 3275,
    "end": 3296,
    "title": "Robust Disambiguation of Named Entities in Text",
    "abstract": "Disambiguating named entities in naturallanguage text maps mentions of ambiguous names onto canonical entities like people or places, registered in a knowledge base such as DBpedia or YAGO. This paper presents a robust method for collective disambiguation, by harnessing context from knowledge bases and using a new form of coherence graph. It unifies prior approaches into a comprehensive framework that combines three measures: the prior probability of an entity being mentioned, the similarity between the contexts of a mention and a candidate entity, as well as the coherence among candidate entities for all mentions together. The method builds a weighted graph of mentions and candidate entities, and computes a dense subgraph that approximates the best joint mention-entity mapping. Experiments show that the new method significantly outperforms prior methods in terms of accuracy, with robust behavior across a variety of inputs.",
    "prev": "Although there has been extensive previous work on entity retrieval (e.g.",
    "curr": "Hoffart et al., 2011;Piccinno & Ferragina, 2014;Huang et al., 2015;Le & Titov, 2018;Logeswaran et al., 2019;Broscheit, 2019;, to name just a few) there is a common design choice to most current solutions: entities are associated with a unique atomic label and the retrieval problem can be interpreted as multi-class classification across these labels.",
    "next": "The match between input and label is calculated through a bi-encoder : a dot product between dense vector encodings of the input and the entity's meta information (such as title and description).",
    "hard_negative": [
      5540599,
      10977241
    ],
    "easy_negative": [
      199379445,
      1484762,
      247250765
    ]
  },
  {
    "index": 2981,
    "source_corpus_id": 257482844,
    "ref_id": "b15",
    "citation_corpus_id": 203593909,
    "start": 6587,
    "end": 6605,
    "title": "REVISITING SELF-TRAINING FOR NEURAL SEQUENCE GENERATION",
    "abstract": "Self-training is one of the earliest and simplest semi-supervised methods. The key idea is to augment the original labeled dataset with unlabeled data paired with the model's prediction (i.e. the pseudo-parallel data). While self-training has been extensively studied on classification problems, in complex sequence generation tasks (e.g. machine translation) it is still unclear how self-training works due to the compositionality of the target space. In this work, we first empirically show that selftraining is able to decently improve the supervised baseline on neural sequence generation tasks. Through careful examination of the performance gains, we find that the perturbation on the hidden states (i.e. dropout) is critical for self-training to benefit from the pseudo-parallel data, which acts as a regularizer and forces the model to yield close predictions for similar unlabeled inputs. Such effect helps the model correct some incorrect predictions on unlabeled data. To further encourage this mechanism, we propose to inject noise to the input space, resulting in a \"noisy\" version of self-training. Empirical study on standard machine translation and text summarization benchmarks shows that noisy self-training is able to effectively utilize unlabeled data and improve the performance of the supervised baseline by a large margin.",
    "prev": "Our method is also orthogonal to CLIP-like research in model pre-training and can be applied to other image classification models (Jia et al., 2021;Li et al., 2022;Yao et al., 2022;, such as LiT (Zhai et al., 2022) which performs two-stage pre-training.",
    "curr": "Self-training has shown promising progress in many domains including vision Xie et al., 2020;Sahito et al., 2022), NLP (He et al., 2020a), and speech (Kahn et al., 2020).",
    "next": "Our method is more closely related to the self-training approaches proposed for semi-supervised learning (Tarvainen & Valpola, 2017;, where pseudo-labels on unlabeled data are used as training targets.",
    "hard_negative": [
      91184134,
      12167053,
      5033497,
      49325612,
      52113461,
      1487550,
      964287,
      447315,
      1918428,
      10480989,
      628455
    ],
    "easy_negative": [
      9473484,
      6506243,
      52044834
    ]
  },
  {
    "index": 2985,
    "source_corpus_id": 2239496,
    "ref_id": "b30",
    "citation_corpus_id": 780171,
    "start": 2344,
    "end": 2365,
    "title": "Data-Driven Response Generation in Social Media",
    "abstract": "We present a data-driven approach to generating responses to Twitter status posts, based on phrase-based Statistical Machine Translation. We find that mapping conversational stimuli onto responses is more difficult than translating between languages, due to the wider range of possible responses, the larger fraction of unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed. After addressing these challenges, we compare approaches based on SMT and Information Retrieval in a human evaluation. We show that SMT outperforms IR on this task, and its output is preferred over actual human responses in 15% of cases. As far as we are aware, this is the first work to investigate the use of phrase-based SMT to directly translate a linguistic stimulus into an appropriate response.",
    "prev": "INTRODUCTION\n\nWith the recent employment of Recurrent Neural Networks (RNNs) and the large quantities of conversational data available on websites like Twitter or Reddit, a new type of dialog system is emerging.",
    "curr": "Such end-to-end dialog systems (Ritter et al., 2011;Shang et al., 2015;Vinyals & Le, 2015;Sordoni et al., 2015) directly generate a response given the last user utterance and (potentially) the context from previous dialog turns without relying on the intermediate use of a dialog state tracking component like in traditional dialog systems (e.g.",
    "next": "in Henderson (2015)).",
    "hard_negative": [
      14386564,
      12305296,
      1060508,
      59940,
      1963942,
      10534951,
      12131372,
      2713391,
      5219389,
      17309374,
      9482302,
      13043395,
      6990165,
      11169623,
      1922162,
      10181753,
      7785983
    ],
    "easy_negative": [
      67855494,
      15821152,
      6763105
    ]
  },
  {
    "index": 2989,
    "source_corpus_id": 231800078,
    "ref_id": "b52",
    "citation_corpus_id": 174801567,
    "start": 3028,
    "end": 3045,
    "title": "Published as a conference paper at ICLR 2020 PLAYING THE LOTTERY WITH REWARDS AND MULTIPLE LANGUAGES: LOTTERY TICKETS IN RL AND NLP",
    "abstract": "The lottery ticket hypothesis proposes that over-parameterization of deep neural networks (DNNs) aids training by increasing the probability of a \"lucky\" sub-network initialization being present rather than by helping the optimization process (Frankle & Carbin, 2019). Intriguingly, this phenomenon suggests that initialization strategies for DNNs can be improved substantially, but the lottery ticket hypothesis has only previously been tested in the context of supervised learning for natural image tasks. Here, we evaluate whether \"winning ticket\" initializations exist in two different domains: natural language processing (NLP) and reinforcement learning (RL). For NLP, we examined both recurrent LSTM models and large-scale Transformer models(Vaswani et al., 2017). For RL, we analyzed a number of discrete-action space tasks, including both classic control and pixel control. Consistent with work in supervised image classification, we confirm that winning ticket initializations generally outperform parameter-matched random initializations, even at extreme pruning rates for both NLP and RL. Notably, we are able to find winning ticket initializations for Transformers which enable models one-third the size to achieve nearly equivalent performance. Together, these results suggest that the lottery ticket hypothesis is not restricted to supervised learning of natural images, but rather represents a broader phenomenon in DNNs.",
    "prev": "It states that there exist matching subnetworks in dense models that can be trained to reach a comparable test accuracy to the full model within similar training iterations.",
    "curr": "The hypothesis has successfully shown its success in various fields (Yu et al., 2020;Renda et al., 2020;Chen et al., 2020b;Gan et al., 2021), and its property has been studied widely (Malach et al., 2020;Pensia et al., 2020;Elesedy et al., 2020;Chen et al., 2021a).",
    "next": "However, it is never introduced to GANs, and therefore the presence of matching subnetworks in generative adversarial networks still remains mysterious.",
    "hard_negative": [
      16299141,
      91184134,
      3334304,
      6021932,
      44131019,
      52920808
    ],
    "easy_negative": [
      218613673,
      17135444,
      51874519
    ]
  },
  {
    "index": 2993,
    "source_corpus_id": 259298566,
    "ref_id": "b20",
    "citation_corpus_id": 211146562,
    "start": 3337,
    "end": 3353,
    "title": "Published as a conference paper at ICLR 2020 DIVIDEMIX: LEARNING WITH NOISY LABELS AS SEMI-SUPERVISED LEARNING",
    "abstract": "Deep neural networks are known to be annotation-hungry. Numerous efforts have been devoted to reducing the annotation cost when learning with deep networks. Two prominent directions include learning with noisy labels and semi-supervised learning by exploiting unlabeled data. In this work, we propose DivideMix, a novel framework for learning with noisy labels by leveraging semi-supervised learning techniques. In particular, DivideMix models the per-sample loss distribution with a mixture model to dynamically divide the training data into a labeled set with clean samples and an unlabeled set with noisy samples, and trains the model on both the labeled and unlabeled data in a semi-supervised manner. To avoid confirmation bias, we simultaneously train two diverged networks where each network uses the dataset division from the other network. During the semi-supervised training phase, we improve the MixMatch strategy by performing label co-refinement and label co-guessing on labeled and unlabeled samples, respectively. Experiments on multiple benchmark datasets demonstrate substantial improvements over state-of-the-art methods. Code is available at",
    "prev": "Therefore, it is important to develop robust training methods against segmentation label noise.",
    "curr": "However, despite many existing methods addressing label noise in classification tasks (Patrini et al., 2017;Yu et al., 2019;Zhang & Sabuncu, 2018;Li et al., 2020;Zhang et al., 2021;Xia et al., 2021), limited progress has been made in the context of image segmentation.",
    "next": "A few existing segmentation label noise approaches (Zhu et al., 2019;Zhang et al., 2020b;a) directly apply methods in classification label noise.",
    "hard_negative": [
      13123084,
      9545399,
      3162051,
      2181703
    ],
    "easy_negative": [
      258686320,
      235097282,
      21686891
    ]
  },
  {
    "index": 2995,
    "source_corpus_id": 209516262,
    "ref_id": "b30",
    "citation_corpus_id": 1957433,
    "start": 20054,
    "end": 20078,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "B and App.",
    "curr": "C.\n\nOur embedding generally has 3 \u00d7 D \u00d7 |W| parameters with D-dimensional word vectors and |W| words, while previous work (Mikolov et al., 2013b;Pennington et al., 2014) usually employs only D \u00d7 |W| parameters for embedding lookup tables.",
    "next": "To increase efficiency and facilitate fair comparison with previous work we set initial phases \u03b8 j = [\u03b8 j,1 , ..., \u03b8 j,D ] to a shared constant value (such as zero).",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      9012785,
      16416003,
      14674200
    ]
  },
  {
    "index": 2998,
    "source_corpus_id": 252918484,
    "ref_id": "b7",
    "citation_corpus_id": 211132990,
    "start": 11865,
    "end": 11883,
    "title": "BATCHENSEMBLE: AN ALTERNATIVE APPROACH TO EFFICIENT ENSEMBLE AND LIFELONG LEARNING",
    "abstract": "Ensembles, where multiple neural networks are trained individually and their predictions are averaged, have been shown to be widely successful for improving both the accuracy and predictive uncertainty of single neural networks. However, an ensemble's cost for both training and testing increases linearly with the number of networks, which quickly becomes untenable. In this paper, we propose BatchEnsemble 1 , an ensemble method whose computational and memory costs are significantly lower than typical ensembles. BatchEnsemble achieves this by defining each weight matrix to be the Hadamard product of a shared weight among all ensemble members and a rank-one matrix per member. Unlike ensembles, BatchEnsemble is not only parallelizable across devices, where one device trains one member, but also parallelizable within a device, where multiple ensemble members are updated simultaneously for a given mini-batch. Across CIFAR-10, CIFAR-100, WMT14 EN-DE/EN-FR translation, and out-of-distribution tasks, BatchEnsemble yields competitive accuracy and uncertainties as typical ensembles; the speedup at test time is 3X and memory reduction is 3X at an ensemble of size 4. We also apply BatchEnsemble to lifelong learning, where on Split-CIFAR-100, BatchEnsemble yields comparable performance to progressive neural networks while having a much lower computational and memory costs. We further show that BatchEnsemble can easily scale up to lifelong learning on Split-ImageNet which involves 100 sequential learning tasks. * Partial work done as part of the Google Student Researcher Program.",
    "prev": "As we propose to replace a single model architecture with several subnetworks, we study the behavior of PE on various sizes architectures: ResNet-18, ResNet-50 (He et al., 2016), and Wide ResNet28-10 (Zagoruyko & Komodakis, 2016).",
    "curr": "We compare it against Deep Ensembles (Lakshminarayanan et al., 2017) and three other approximated ensembles from the literature: BatchEnsemble (Wen et al., 2019), MIMO (Havasi et al., 2021), andMasksembles (Durasov et al., 2021).",
    "next": "Second, we report our results for Packed-Ensembles on ImageNet (Deng et al., 2009), which we compare against all baselines.",
    "hard_negative": [
      3861760,
      53100211,
      3536221,
      54443381,
      56657912,
      53033211
    ],
    "easy_negative": [
      235258253,
      5050185,
      227231572
    ]
  },
  {
    "index": 2999,
    "source_corpus_id": 247447572,
    "ref_id": "b19",
    "citation_corpus_id": 225094135,
    "start": 32219,
    "end": 32242,
    "title": "Published as a conference paper at ICLR 2021 LEARNING TO REPRESENT ACTION VALUES AS A HYPERGRAPH ON THE ACTION VERTICES",
    "abstract": "Action-value estimation is a critical component of many reinforcement learning (RL) methods whereby sample complexity relies heavily on how fast a good estimator for action value can be learned. By viewing this problem through the lens of representation learning, good representations of both state and action can facilitate action-value estimation. While advances in deep learning have seamlessly driven progress in learning state representations, given the specificity of the notion of agency to RL, little attention has been paid to learning action representations. We conjecture that leveraging the combinatorial structure of multi-dimensional action spaces is a key ingredient for learning good representations of action. To test this, we set forth the action hypergraph networks framework-a class of functions for learning action representations in multi-dimensional discrete action spaces with a structural inductive bias. Using this framework we realise an agent class based on a combination with deep Q-networks, which we dub hypergraph Q-networks. We show the effectiveness of our approach on a myriad of domains: illustrative prediction problems under minimal confounding effects, Atari 2600 games, and discretised physical control benchmarks.Published as a conference paper at ICLR 2021Our results advocate for the general usefulness of leveraging the combinatorial structure of multidimensional discrete action spaces, especially in problems with larger action spaces.",
    "prev": "Finally, we contemplate research on numerous special instances as future work, following our theoretical foundation.",
    "curr": "Also, we believe that studying the combination of our general value mapping ideas with value decomposition (Tavakoli et al., 2021), instead of the the reward decomposition paradigm studied in this paper, could prove to be a fruitful direction for future research.",
    "next": "REPRODUCIBILITY STATEMENT\n\nWe release a generic codebase, built upon the Dopamine framework (Castro et al., 2018), with the option of using arbitrary compositions of mapping functions and reward decomposition schemes as easy-to-code modules.",
    "hard_negative": [
      13022595,
      6628106,
      5176587,
      222133333,
      16326763
    ],
    "easy_negative": [
      259376755,
      14748840,
      237490430
    ]
  },
  {
    "index": 3003,
    "source_corpus_id": 257102348,
    "ref_id": "b19",
    "citation_corpus_id": 108300988,
    "start": 8862,
    "end": 8882,
    "title": "WHAT DO YOU LEARN FROM CONTEXT? PROBING FOR SENTENCE STRUCTURE IN CONTEXTUALIZED WORD REPRESENTATIONS",
    "abstract": "Contextualized representation models such as ELMo(Peters et al., 2018a)andBERT (Devlin et al., 2018)have recently achieved state-of-the-art results on a diverse array of downstream NLP tasks. Building on recent token-level probing work, we introduce a novel edge probing task design and construct a broad suite of sub-sentence tasks derived from the traditional structured NLP pipeline. We probe word-level contextual representations from four recent models and investigate how they encode sentence structure across a range of syntactic, semantic, local, and long-range phenomena. We find that existing models trained on language modeling and translation produce strong representations for syntactic phenomena, but only offer comparably small improvements on semantic tasks over a non-contextual baseline.",
    "prev": "RELATED WORK\n\nProbing deep learning models.",
    "curr": "To explore whether deep learning models have certain capabilities, there has been much work examining these black-box models in some specially designed settings, called probes (Petroni et al., 2019;Tenney et al., 2018;Warstadt et al., 2019;Lin et al., 2019;Hewitt & Manning, 2019;Vuli\u0107 et al., 2020).",
    "next": "The key challenge in designing probes is to exclude superficial correlations.",
    "hard_negative": [
      49363457,
      6628106,
      28971531,
      5112203,
      44152851,
      24544277,
      7197724,
      24461982,
      52113185,
      14091946,
      436023,
      1957433,
      11162815,
      3626819,
      1222212,
      5034059,
      7100502,
      52123220,
      7645153,
      40100965,
      4891749,
      13888490,
      19206893,
      3994096,
      21663989,
      6771196,
      4460159
    ],
    "easy_negative": [
      220446097,
      193561415,
      235652017
    ]
  },
  {
    "index": 3004,
    "source_corpus_id": 246431036,
    "ref_id": "b1",
    "citation_corpus_id": 5509327,
    "start": 5417,
    "end": 5449,
    "title": "A causal framework for explaining the predictions of black-box sequence-to-sequence models",
    "abstract": "We interpret the predictions of any blackbox structured input-structured output model around a specific input-output pair. Our method returns an \"explanation\" consisting of groups of input-output tokens that are causally related. These dependencies are inferred by querying the black-box model with perturbed inputs, generating a graph over tokens from the responses, and solving a partitioning problem to select the most relevant components. We focus the general approach on sequence-tosequence problems, adopting a variational autoencoder to yield meaningful input perturbations. We test our method across several NLP sequence generation tasks.",
    "prev": "Unfortunately, when facing with out-of-distribution (OOD) data, such methods generalize poorly since the shortcuts are changed.",
    "curr": "Hence, such shortcut-involved rationales hardly reveal the truly critical subgraphs for the predicted labels, being at odds with the true reasoning process that underlies the task of interest (Teney et al., 2020) and human cognition (Alvarez-Melis & Jaakkola, 2017).",
    "next": "Here we ascribe the failure on OOD data to the inability to identify causal patterns, which are stable to distribution shift.",
    "hard_negative": [
      7205805,
      1918428
    ],
    "easy_negative": [
      257913267,
      246473294,
      3516767
    ]
  },
  {
    "index": 3005,
    "source_corpus_id": 220871147,
    "ref_id": "b53",
    "citation_corpus_id": 14124313,
    "start": 1832,
    "end": 1859,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "Experiments across CIFAR, ImageNet, PASCAL VOC, and Penn Treebank, with convolutional networks for image classification and semantic segmentation, and recurrent networks for language modeling, demonstrate that we both train faster and produce more efficient networks than competing architecture pruning or search methods.",
    "curr": "INTRODUCTION\n\nDeep neural networks are the dominant approach to a variety of machine learning tasks, including image classification (Krizhevsky et al., 2012;Simonyan & Zisserman, 2015), object detection (Girshick, 2015;, semantic segmentation (Long et al., 2015; and language modeling (Zaremba et al., 2014;Vaswani et al., 2017;Devlin et al., 2019).",
    "next": "Modern neural networks are overparameterized and training larger networks usually yields improved generalization accuracy.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      14667350,
      232021496,
      232021663
    ]
  },
  {
    "index": 3018,
    "source_corpus_id": 258967945,
    "ref_id": "b35",
    "citation_corpus_id": 3626819,
    "start": 1905,
    "end": 1926,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "* Corresponding authors.",
    "curr": "INTRODUCTION\n\nFine-tuning pre-trained language models (PLMs) is a dominating paradigm for natural language understanding (NLU) with state-of-the-art results for a variety of NLU tasks (Peters et al., 2018;Devlin et al., 2019;He et al., 2021a).",
    "next": "The powerful fine-tuned language models have been experimented with for decision-making in real-world applications such as the healthcare domain (He et al., 2020) and safety-critical domain (Sandagiri et al., 2020), where the classification networks need to be highly accurate and provide calibrated confidence for their predictions to improve the safety and trustiness of the models (Guo et al., 2017).",
    "hard_negative": [
      6300165,
      41479182,
      8535316,
      11336213,
      990233,
      9917468,
      20472740,
      34032948,
      10489017,
      1957433,
      1222212,
      12688069,
      15026764,
      11816014,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      35320832,
      14403330,
      51918770
    ]
  },
  {
    "index": 3025,
    "source_corpus_id": 219531210,
    "ref_id": "b27",
    "citation_corpus_id": 59523594,
    "start": 3406,
    "end": 3425,
    "title": "Multi-Task Deep Neural Networks for Natural Language Understanding",
    "abstract": "In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. MT-DNN extends the model proposed inLiu et al. (2015)by incorporating a pre-trained bidirectional transformer language model, known as BERT(Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.2% (1.8% absolute improvement). We also demonstrate using the SNLI and Sc-iTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. Our code and pre-trained models will be made publicly available.",
    "prev": "Since 2018, we have seen the rise of a set of large-scale Transformer-based Pre-trained Language Models (PLMs), such as GPT Brown et al., 2020), BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019c), XLNet , UniLM (Dong et al., 2019), ELECTRA (Clark et al., 2020), T5 (Raffel et al., 2020), ALUM , StructBERT (Wang et al., 2019c) and ERINE (Sun et al., 2019) .",
    "curr": "These PLMs have been fine-tuned using task-specific labels and created new state of the art in many downstream natural language processing (NLP) tasks (Liu et al., 2019b;Minaee et al., 2020;Jiang et al., 2020;Shen et al., 2020).",
    "next": "In this paper, we propose a new Transformer-based neural language model DeBERTa (Decodingenhanced BERT with disentangled attention), which improves previous state-of-the-art PLMs using two novel techniques: a disentangled attention mechanism, and an enhanced mask decoder.",
    "hard_negative": [
      11754890,
      30758763
    ],
    "easy_negative": [
      245219268,
      7303263,
      35016477
    ]
  },
  {
    "index": 3035,
    "source_corpus_id": 225075866,
    "ref_id": "b22",
    "citation_corpus_id": 3144218,
    "start": 2680,
    "end": 2702,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "These models have had much success and sit atop leaderboards such as the Open Graph Benchmark (Hu et al., 2020).",
    "curr": "Often, the methodological developments for GNNs revolve around creating strictly more expressive architectures than basic variants such as the Graph Convolutional Network (GCN) (Kipf & Welling, 2017) or GraphSAGE (Hamilton et al., 2017a); examples include Graph Attention Networks (Veli\u010dkovi\u0107 et al., 2018), Graph Isomorphism Networks (Xu et al., 2018), and various deep models (Li et al., 2019;Rong et al., 2019;.",
    "next": "Many ideas for new GNN architectures are adapted from new architectures in models for language (e.g., attention) or vision (e.g., deep CNNs) with the hopes that success will translate to graphs.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      257254835,
      196172757,
      1712903
    ]
  },
  {
    "index": 3039,
    "source_corpus_id": 249605546,
    "ref_id": "b26",
    "citation_corpus_id": 222310549,
    "start": 16684,
    "end": 16700,
    "title": "SHAPE-TEXTURE DEBIASED NEURAL NETWORK TRAINING",
    "abstract": "Shape and texture are two prominent and complementary cues for recognizing objects. Nonetheless, Convolutional Neural Networks are often biased towards either texture or shape, depending on the training dataset. Our ablation shows that such bias degenerates model performance. Motivated by this observation, we develop a simple algorithm for shape-texture debiased learning. To prevent models from exclusively attending on a single cue in representation learning, we augment training data with images with conflicting shape and texture information (e.g., an image of chimpanzee shape but with lemon texture) and, most importantly, provide the corresponding supervisions from shape and texture simultaneously. Experiments show that our method successfully improves model performance on several image recognition benchmarks and adversarial robustness. For example, by training on ImageNet, it helps ResNet-152 achieve substantial improvements on ImageNet (+1.2%), ImageNet-A (+5.2%), ImageNet-C (+8.3%) and Stylized-ImageNet (+11.1%), and on defending against FGSM adversarial attacker on ImageNet (+14.4%). Our method also claims to be compatible to other advanced data augmentation strategies, e.g., Mixup and Cut-Mix. The code is available here: https://github.com/LiYingwei/ ShapeTextureDebiasedTraining.",
    "prev": "RELATIVE DISTANCE SUPERVISION\n\nPredicting the target distance from the target embedding is more straightforward than from other indirect cues such as reference embeddings.",
    "curr": "To encourage the model to learn the pairwise relationships between target and reference objects, instead of shortcut cues (Geirhos et al., 2020;Li et al., 2021;Wang et al., 2020), we provide additional supervision.",
    "next": "The design of this additional supervision is akin to the residual representation, which is widely used for computer vision to help the optimization procedure (Briggs et al., 2000;He et al., 2016;Szeliski, 1990;2006).",
    "hard_negative": [
      14124313,
      3162051,
      6706414,
      54101493,
      56657912,
      1996665
    ],
    "easy_negative": [
      7952407,
      58779058,
      51818591
    ]
  },
  {
    "index": 3049,
    "source_corpus_id": 235358191,
    "ref_id": "b11",
    "citation_corpus_id": 202538740,
    "start": 5375,
    "end": 5403,
    "title": "Mask-Predict: Parallel Decoding of Conditional Masked Language Models",
    "abstract": "Most machine translation systems generate text autoregressively from left to right. We, instead, use a masked language modeling objective to train a model to predict any subset of the target words, conditioned on both the input text and a partially masked target translation. This approach allows for efficient iterative decoding, where we first predict all of the target words non-autoregressively, and then repeatedly mask out and regenerate the subset of words that the model is least confident about. By applying this strategy for a constant number of iterations, our model improves state-of-the-art performance levels for nonautoregressive and parallel decoding translation models by over 4 BLEU on average. It is also able to reach within about 1 BLEU point of a typical left-to-right transformer model, while decoding significantly faster.",
    "prev": "We study the behavior of our sampling approach extensively with different proposal distributions.",
    "curr": "We also verify the soundness of our approach by sampling from regions around the mode by annealing the target distribution and finding our samples to be competitive with a prominent undirected (and non-probablistic) generation approach (Ghazvininejad et al., 2019) on MT performance.",
    "next": "Moreover, human evaluation of the open ended generation samples further corroborates the effectiveness of our approach.",
    "hard_negative": [
      3438497,
      3480671,
      60441316,
      6628106,
      3297437,
      13751870
    ],
    "easy_negative": [
      15664170,
      14474596,
      6048544
    ]
  },
  {
    "index": 3055,
    "source_corpus_id": 209439505,
    "ref_id": "b40",
    "citation_corpus_id": 2768038,
    "start": 4883,
    "end": 4902,
    "title": "Under review as conference paper at ICLR 2015 EMBEDDING ENTITIES AND RELATIONS FOR LEARN- ING AND INFERENCE IN KNOWLEDGE BASES",
    "abstract": "We consider learning representations of entities and relations in KBs using the neural-embedding approach. We show that most existing models, including NTN (Socher et al., 2013)  and TransE (Bordes et al., 2013b), can be generalized under a unified learning framework, where entities are low-dimensional vectors learned from a neural network and relations are bilinear and/or linear mapping functions. Under this framework, we compare a variety of embedding models on the link prediction task. We show that a simple bilinear formulation achieves new state-of-the-art results for the task (achieving a top-10 accuracy of 73.2% vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules such as BornInCitypa, bq^CityInCountrypb, cq \u00f9\u00f1 N ationalitypa, cq. We find that embeddings learned from the bilinear objective are particularly good at capturing relational semantics, and that the composition of relations is characterized by matrix multiplication. More interestingly, we demonstrate that our embedding-based rule extraction approach successfully outperforms a state-ofthe-art confidence-based rule mining approach in mining horn rules that involve compositional reasoning.",
    "prev": "TransE (Bordes et al., 2013) is the forerunner of distance-based methods, and spun a number of models commonly referred to as TransX.",
    "curr": "The intuition behind the symmetric bilinear-diagonal model DistMult (Yang et al., 2015) paved the way for its asymmetric evolutions in the complex space, RotatE (Sun et al., 2019) and ComplEx (Trouillon et al., 2016) (a generalization of which uses hypercomplex representations (Zhang et al., 2019)).",
    "next": "HolE relies instead on circular correlation (Nickel et al., 2016b).",
    "hard_negative": [
      1077128,
      6343829,
      2141094,
      806709,
      370914,
      9676646
    ],
    "easy_negative": [
      34359113,
      11256128,
      4380496
    ]
  },
  {
    "index": 3062,
    "source_corpus_id": 17225395,
    "ref_id": "b31",
    "citation_corpus_id": 806709,
    "start": 30594,
    "end": 30598,
    "title": "Semantic Compositionality through Recursive Matrix-Vector Spaces",
    "abstract": "Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them.",
    "prev": "\u2022 Recursive Networks.",
    "curr": "Recursive networks have been successfully used for tasks such as sentiment classification and compositional modeling of natural language from word embeddings [32].",
    "next": "These architectures are usually trained using L-BFGS.",
    "hard_negative": [
      5584134,
      3116311,
      7747235,
      17121460,
      436023,
      2678583,
      15698938,
      8360910,
      6430811,
      3264224
    ],
    "easy_negative": [
      213987212,
      62159671,
      46939269
    ]
  },
  {
    "index": 3069,
    "source_corpus_id": 2135897,
    "ref_id": "b14",
    "citation_corpus_id": 10421567,
    "start": 2695,
    "end": 2721,
    "title": "Illinois-LH: A Denotational and Distributional Approach to Semantics",
    "abstract": "This paper describes and analyzes our Se-mEval 2014 Task 1 system. Its features are based on distributional and denotational similarities; word alignment; negation; and hypernym/hyponym, synonym, and antonym relations.",
    "prev": "State-of-the-art systems for RTE so far relied heavily on engineered NLP pipelines, extensive manual creation of features, as well as various external resources and specialized subcomponents such as negation detection (e.g.",
    "curr": "Lai and Hockenmaier, 2014;Jimenez et al., 2014;Zhao et al., 2014;Beltagy et al., 2015).",
    "next": "Despite the success of neural networks for paraphrase detection (e.g.",
    "hard_negative": [
      16404002,
      8360910,
      806709,
      3104920,
      15430366
    ],
    "easy_negative": [
      11358089,
      5754132,
      7513738
    ]
  },
  {
    "index": 3075,
    "source_corpus_id": 246485648,
    "ref_id": "b8",
    "citation_corpus_id": 5079983,
    "start": 2441,
    "end": 2463,
    "title": "Very Deep Convolutional Networks for Text Classification",
    "abstract": "The dominant approach for many NLP tasks are recurrent neural networks, in particular LSTMs, and convolutional neural networks. However, these architectures are rather shallow in comparison to the deep convolutional networks which have pushed the state-of-the-art in computer vision. We present a new architecture (VD-CNN) for text processing which operates directly at the character level and uses only small convolutions and pooling operations. We are able to show that the performance of this model increases with the depth: using up to 29 convolutional layers, we report improvements over the state-ofthe-art on several public text classification tasks. To the best of our knowledge, this is the first time that very deep convolutional nets have been applied to text processing.",
    "prev": "We show how this regularization allows trading off accuracy for efficiency on ImageNet.",
    "curr": "INTRODUCTION\n\nConvolutional neural networks (CNNs) (Fukushima, 1980;LeCun et al., 1989) have been the most widely used neural architecture across a wide range of tasks, including image classification (Krizhevsky et al., 2012;He et al., 2016a;Bello et al., 2021), audio pattern recognition (Kong et al., 2020), text classification (Conneau et al., 2017), machine translation (Gehring et al., 2017) and speech recognition (Amodei et al., 2016;Sercu et al., 2016;Zeghidour et al., 2018).",
    "next": "Convolution layers, which are the building block of CNNs, project input features to a higher-level representation while preserving their resolution.",
    "hard_negative": [
      9672033,
      1306065,
      3116311,
      15874232,
      14124313,
      6857205
    ],
    "easy_negative": [
      8804578,
      219303088,
      804244
    ]
  },
  {
    "index": 3077,
    "source_corpus_id": 53216389,
    "ref_id": "b27",
    "citation_corpus_id": 22421874,
    "start": 3664,
    "end": 3692,
    "title": "Knowledge Distillation for Bilingual Dictionary Induction",
    "abstract": "Leveraging zero-shot learning to learn mapping functions between vector spaces of different languages is a promising approach to bilingual dictionary induction. However, methods using this approach have not yet achieved high accuracy on the task. In this paper, we propose a bridging approach, where our main contribution is a knowledge distillation training objective. As teachers, rich resource translation paths are exploited in this role. And as learners, translation paths involving low resource languages learn from the teachers. Our training objective allows seamless addition of teacher translation paths for any given low resource pair. Since our approach relies on the quality of monolingual word embeddings, we also propose to enhance vector representations of both the source and target language with linguistic information. Our experiments on various languages show large performance gains from our distillation training objective, obtaining as high as 17% accuracy improvements.",
    "prev": "Our method relies on constraining word translations to be coherent between languages when mapped to the common space.",
    "curr": "Nakashole and Flauger (2017) has recently shown that similar constraints over a well chosen triplet of languages improve supervised bilingual alignment.",
    "next": "Our work extends their conclusions to the unsupervised case.",
    "hard_negative": [
      6758088,
      12187767,
      891605,
      8030425,
      7185434,
      18634877,
      719133,
      14183678
    ],
    "easy_negative": [
      7934449,
      18648201,
      2980252
    ]
  },
  {
    "index": 3079,
    "source_corpus_id": 231632854,
    "ref_id": "b52",
    "citation_corpus_id": 1487550,
    "start": 7958,
    "end": 7974,
    "title": "UNSUPERVISED WORD SENSE DISAMBIGUATION RIVALING SUPERVISED METHODS",
    "abstract": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints -that words tend to have one sense per discourse and one sense per collocation -exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%.",
    "prev": "For a general overview of SSL, we point to (Chapelle et al., 2010;Zhu, 2005).",
    "curr": "Pseudo-labeling\n\nThe goal of pseudo-labeling (Lee, 2013;Shi et al., 2018) and self-training (Yarowsky, 1995;McClosky et al., 2006) is to generate pseudo-labels for unlabeled samples with a model trained on labeled data.",
    "next": "In (Lee, 2013), pseudo-labels are created from the predictions of a trained neural network.",
    "hard_negative": [
      11329942,
      1693468,
      3166885,
      1580335,
      5458997,
      2946526,
      9537399
    ],
    "easy_negative": [
      52847675,
      18537180,
      15784619
    ]
  },
  {
    "index": 3082,
    "source_corpus_id": 252815535,
    "ref_id": "b51",
    "citation_corpus_id": 202539551,
    "start": 2592,
    "end": 2614,
    "title": "Language Models as Knowledge Bases?",
    "abstract": "Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as \"fillin-the-blank\" cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-theart pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https: //github.com/facebookresearch/LAMA.",
    "prev": "To tackle these problems, existing remedies include using improved prompting techniques, such as inserting hand-written decomposed reasoning steps in few-shot demonstrations .",
    "curr": "These methods are inherently limited as their reasoning ability completely relies on the knowledge perpetuated in the LM-their performance could suffer if the knowledge learnt by the LM is incorrect (Petroni et al., 2019) or outdated (Dhingra et al., 2022).",
    "next": "To incorporate external knowledge, retrieval-augmented LMs such as REALM (Guu et al., 2020), RAG (Lewis et al., 2020) and RETRO (Borgeaud et al., 2022), retrieve relevant documents as additional evidence for given questions, and may also fine-tune the LM on the question-document-answer triplets.",
    "hard_negative": [
      3226120,
      53296520,
      2924682,
      52113185,
      108300988,
      3626819,
      5034059,
      11816014,
      85205,
      8781666,
      4612975
    ],
    "easy_negative": [
      226283846,
      208108034,
      1934565
    ]
  },
  {
    "index": 3085,
    "source_corpus_id": 3532489,
    "ref_id": "b12",
    "citation_corpus_id": 990233,
    "start": 23235,
    "end": 23256,
    "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
    "prev": "Based on the same set of training data, we evaluate the dynamic embeddings trained with the three network models and compare them with the syntax-based program embeddings (on the same error prediction task) on the same testing data.",
    "curr": "The syntax-based models include (1) one trained with a RNN that encodes the run-time syntactic traces of programs (Reed & De Freitas, 2015;Cai et al., 2017); (2) another trained with a RNN that encodes token sequences of programs; (3) the third trained with a RNN on abstract syntax trees of programs (Socher et al., 2013).",
    "next": "All models are implemented in TensorFlow.",
    "hard_negative": [
      5584134,
      2279432,
      3116311,
      7747235,
      15659560,
      1588782,
      806709,
      2678583,
      3264224,
      15616495,
      2091504
    ],
    "easy_negative": [
      6186855,
      1075182,
      15779728
    ]
  },
  {
    "index": 3086,
    "source_corpus_id": 256598360,
    "ref_id": "b2",
    "citation_corpus_id": 212877887,
    "start": 9923,
    "end": 9941,
    "title": "THE INGREDIENTS OF REAL-WORLD ROBOTIC REINFORCEMENT LEARNING",
    "abstract": "The success of reinforcement learning for real world robotics has been, in many cases limited to instrumented laboratory scenarios, often requiring arduous human effort and oversight to enable continuous learning. In this work, we discuss the elements that are needed for a robotic learning system that can continually and autonomously improve with data collected in the real world. We propose a particular instantiation of such a system, using dexterous manipulation as our case study. Subsequently, we investigate a number of challenges that come up when learning without instrumentation. In such settings, learning must be feasible without manually designed resets, using only on-board perception, and without hand-engineered reward functions. We propose simple and scalable solutions to these challenges, and then demonstrate the efficacy of our proposed system on a set of dexterous robotic manipulation tasks, providing an in-depth analysis of the challenges associated with this learning paradigm. We demonstrate that our complete system can learn without any human intervention, acquiring a variety of vision-based skills with a real-world three-fingered hand. Results and videos can be found at https://sites.google.com/view/realworld-rl/.",
    "prev": "Hence, great efforts have been made to model human biases, such as irrationality (Selten, 1990;Bobu et al., 2020;Laidlaw & Dragan, 2022), risk aversion (Pratt, 1978;Barberis, 2013), and myopia (Evans et al., 2016).",
    "curr": "Many popular models further assume humans have hidden subject utility functions (Nguyen et al., 2013;Hadfield-Menell et al., 2016;Eckersley, 2019;Shah et al., 2019).",
    "next": "Conventional methods for human-AI collaboration require an accurate behavior model over human data (Ajoudani et al., 2018;Kwon et al., 2020;Kress-Gazit et al., 2021;Wang et al., 2022), while we consider the setting of no human data.",
    "hard_negative": [
      3162051,
      52055130,
      12256925,
      27254961,
      28202810
    ],
    "easy_negative": [
      227230662,
      15057877,
      8030425
    ]
  },
  {
    "index": 3089,
    "source_corpus_id": 250334377,
    "ref_id": "b18",
    "citation_corpus_id": 248003131,
    "start": 3046,
    "end": 3070,
    "title": "A Multi-Level Optimization Framework for End-to-End Text Augmentation",
    "abstract": "Text augmentation is an effective technique in alleviating overfitting in NLP tasks. In existing methods, text augmentation and downstream tasks are mostly performed separately. As a result, the augmented texts may not be optimal to train the downstream model. To address this problem, we propose a three-level optimization framework to perform text augmentation and the downstream task end-toend. The augmentation model is trained in a way tailored to the downstream task. Our framework consists of three learning stages. A text summarization model is trained to perform data augmentation at the first stage. Each summarization example is associated with a weight to account for its domain difference with the text classification data. At the second stage, we use the model trained at the first stage to perform text augmentation and train a text classification model on the augmented texts. At the third stage, we evaluate the text classification model trained at the second stage and update weights of summarization examples by minimizing the validation loss. These three stages are performed end-to-end. We evaluate our method on several text classification datasets where the results demonstrate the effectiveness of our method. Code is available at https://github.com/Sai-Ashish /End-to-End-Text-Augmentation.",
    "prev": "For example, (Raghu et al., 2021) proposed trilevel optimization that combines hyperparameter optimization with two-level pretraining and finetuning.",
    "curr": "More generally, conducting joint optimization over machine learning pipelines consisting of multiple models and hyperparameter sets can be approached as deeper instances of MLO (Garg et al., 2022;Raghu et al., 2021;Somayajula et al., 2022;.",
    "next": "Following its increasing popularity, a multitude of optimization algorithms have been proposed to solve MLO.",
    "hard_negative": [
      1428702,
      3257353,
      16639476,
      7186165,
      2058777,
      22162396,
      990233
    ],
    "easy_negative": [
      244773609,
      225062646,
      33353746
    ]
  },
  {
    "index": 3094,
    "source_corpus_id": 232146022,
    "ref_id": "b14",
    "citation_corpus_id": 51942590,
    "start": 3220,
    "end": 3239,
    "title": "L-Shapley and C-Shapley: Efficient Model Interpretation for Structured Data",
    "abstract": "We study instancewise feature importance scoring as a method for model interpretation. Any such method yields, for each predicted instance, a vector of importance scores associated with the feature vector. Methods based on the Shapley score have been proposed as a fair way of computing feature attributions of this kind, but incur an exponential complexity in the number of features. This combinatorial explosion arises from the definition of the Shapley value and prevents these methods from being scalable to large data sets and complex models. We focus on settings in which the data have a graph structure, and the contribution of features to the target variable is well-approximated by a graph-structured factorization. In such settings, we develop two algorithms with linear complexity for instancewise feature importance scoring. We establish the relationship of our methods to the Shapley value and another closely related concept known as the Myerson value from cooperative game theory. We demonstrate on both language and image data that our algorithms compare favorably with other methods for model interpretation.",
    "prev": "Despite these elegant theoretically-grounded properties, exact Shapley value computation has exponential time complexity in the general case.",
    "curr": "To alleviate the computational issue, several methods have been proposed to approximate Shapley values via sampling (Strumbelj & Kononenko, 2010) and weighted regression (Kernel SHAP), a modified backpropagation step (Deep SHAP) (Lundberg & Lee, 2017), utilization of the expectation of summations (Ancona et al., 2019), or making assumptions on underlying data structures (Chen et al., 2019).",
    "next": "To avoid approximation, the model class could be restricted to allow for simpler computation.",
    "hard_negative": [
      9672033,
      1428702
    ],
    "easy_negative": [
      14748840,
      10046354,
      5903592
    ]
  },
  {
    "index": 3097,
    "source_corpus_id": 246276212,
    "ref_id": "b3",
    "citation_corpus_id": 204512445,
    "start": 3994,
    "end": 4016,
    "title": "VQ-WAV2VEC: SELF-SUPERVISED LEARNING OF DISCRETE SPEECH REPRESENTATIONS",
    "abstract": "We propose vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task. The algorithm uses either a Gumbel-Softmax or online k-means clustering to quantize the dense representations. Discretization enables the direct application of algorithms from the NLP community which require discrete inputs. Experiments show that BERT pre-training achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition. 1 * Equal contribution. \u2020 Work done during a Facebook AI residency. 1 The code will be made available at",
    "prev": "In this paper, we introduce a new speech pre-training method which works by learning denoising representation of perturbed data with the teacher-student framework, named as Self-supervised Perturbation-Invariant Representation Learning (SPIRAL).",
    "curr": "Compared to state-of-the-art speech pretraining methods such as wav2vec 2.0 (Baevski et al., 2020b) and HuBERT (Hsu et al., 2021), our method allows end-to-end training with a single contrastive loss, and without relying on discrete unit discovery techniques such as vector quantization (J\u00e9gou et al., 2011;Baevski et al., 2020a;b) or iterative clustering process (Hsu et al., 2021).",
    "next": "We apply multi-condition training with SPIRAL (Seltzer et al., 2013;Ko et al., 2015) to improve noise-robustness for the downstream speech tasks.",
    "hard_negative": [
      91184134,
      44131019,
      2561041
    ],
    "easy_negative": [
      216641773,
      237347189,
      5195887
    ]
  },
  {
    "index": 3102,
    "source_corpus_id": 219708602,
    "ref_id": "b8",
    "citation_corpus_id": 3531856,
    "start": 3700,
    "end": 3723,
    "title": "Published as a conference paper at ICLR 2018 DEMYSTIFYING MMD GANS",
    "abstract": "We investigate the training and performance of generative adversarial networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs. As our main theoretical contribution, we clarify the situation with bias in GAN loss functions raised by recent work: we show that gradient estimators used in the optimization process for both MMD GANs and Wasserstein GANs are unbiased, but learning a discriminator based on samples leads to biased gradients for the generator parameters. We also discuss the issue of kernel choice for the MMD critic, and characterize the kernel corresponding to the energy distance used for the Cram\u00e9r GAN critic. Being an integral probability metric, the MMD benefits from training strategies recently developed for Wasserstein GANs. In experiments, the MMD GAN is able to employ a smaller critic network than the Wasserstein GAN, resulting in a simpler and faster-training algorithm with matching performance. We also propose an improved measure of GAN convergence, the Kernel Inception Distance, and show how to use it to dynamically adapt learning rates during GAN training. * These authors contributed equally.Published as a conference paper at ICLR 2018 are infinite, meaning that they provide no useful gradient for the generator to follow. This helps to explain some of the instability of GAN training.The lack of sensitivity to distance, meaning that nearby but non-overlapping regions of high probability mass are not considered similar, is a long-recognized problem for KL divergence-based discrepancy measures (e.g. Gneiting & Raftery, 2007, Section 4.2). It is natural to address this problem using Integral Probability Metrics (IPMs; M\u00fcller, 1997): these measure the distance between probability measures via the largest discrepancy in expectation over a class of \"well behaved\" witness functions. Thus, IPMs are able to signal proximity in the probability mass of the generator and reference distributions. (Section 2 describes this framework in more detail.)  proposed to use the Wasserstein distance between distributions as the discriminator, which is an integral probability metric constructed from the witness class of 1-Lipschitz functions. To implement the Wasserstein critic, Arjovsky et al. originally proposed weight clipping of the discriminator network, to enforce k-Lipschitz smoothness. Gulrajani et al. (2017)  improved on this result by directly constraining the gradient of the discriminator network at points between the generator and reference samples. This new Wasserstein GAN implementation, called WGAN-GP, is more stable and easier to train.A second integral probability metric used in GAN variants is the maximum mean discrepancy (MMD), for which the witness function class is a unit ball in a reproducing kernel Hilbert space (RKHS). Generative adversarial models based on minimizing the MMD were first considered by Li et al. (2015)  and Dziugaite et al. (2015). These works optimized a generator to minimize the MMD with a fixed kernel, either using a generic kernel on image pixels or by modeling autoencoder representations instead of images directly. Sutherland et al.(2017)instead minimized the statistical power of an MMD-based test with a fixed kernel. Such approaches struggle with complex natural images, where pixel distances are of little value, and fixed representations can easily be tricked, as in the adversarial examples of Szegedy et al. (2014). A. Krizhevsky. Learning multiple layers of features from tiny images, 2009. Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition.",
    "prev": "The generator is trained adversarially against a discriminator network whose goal is to distinguish samples produced by the generator from the target data.",
    "curr": "This has inspired further research to extend the training procedure to more general losses (Nowozin et al., 2016;Arjovsky et al., 2017;Li et al., 2017;Bi\u0144kowski et al., 2018; and to improve its stability (Miyato et al., 2018;Gulrajani et al., 2017;Nagarajan and Kolter, 2017;Kodali et al., 2017).",
    "next": "While the generator of a GAN has effectively a low-dimensional support, it remains challenging to refine the distribution of mass on that support using pre-defined latent noise.",
    "hard_negative": [
      18828233,
      2263947,
      604334,
      2187805
    ],
    "easy_negative": [
      19416742,
      218977391,
      243865323
    ]
  },
  {
    "index": 3108,
    "source_corpus_id": 235795569,
    "ref_id": "b1",
    "citation_corpus_id": 231592776,
    "start": 48581,
    "end": 48603,
    "title": "CONTRASTIVE BEHAVIORAL SIMILARITY EMBEDDINGS FOR GENERALIZATION IN REINFORCEMENT LEARNING",
    "abstract": "Reinforcement learning methods trained on few environments rarely learn policies that generalize to unseen environments. To improve generalization, we incorporate the inherent sequential structure in reinforcement learning into the representation learning process. This approach is orthogonal to recent approaches, which rarely exploit this structure explicitly. Specifically, we introduce a theoretically motivated policy similarity metric (PSM) for measuring behavioral similarity between states. PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. We also present a contrastive representation learning procedure to embed any state similarity metric, which we instantiate with PSM to obtain policy similarity embeddings (PSEs 1 ). We demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite. Source code would be made available at agarwl.github.io/pse.",
    "prev": "Apart from MRA (Fortunato et al., 2019) mentioned above, one of the early examples of this is CURL(Srinivas et al., 2020a) which combines Q-Learning with a separate encoder used for representation learning with the InfoNCE loss from CPC(Oord et al., 2018).",
    "curr": "More recent examples use contrastive learning for predicting future latent states(Schwarzer et al., 2020;  Mazoure et al., 2020), defining a policy similarity embeddings(Agarwal et al., 2021) and learning abstract representations of state-action pairs(Liu et al., 2021).",
    "next": "The closest work to our is M-CURL(Zhu et al., 2020).",
    "hard_negative": [
      208857488,
      3280568,
      213597045
    ],
    "easy_negative": [
      17575738,
      252568221,
      202778086
    ]
  },
  {
    "index": 3114,
    "source_corpus_id": 226965048,
    "ref_id": "b51",
    "citation_corpus_id": 2926851,
    "start": 6015,
    "end": 6037,
    "title": "Memory Networks",
    "abstract": "We describe a new class of learning models called memory networks. Memory networks reason with inference components combined with a long-term memory component; they learn how to use these jointly. The long-term memory can be read and written to, with the goal of using it for prediction. We investigate these models in the context of question answering (QA) where the long-term memory effectively acts as a (dynamic) knowledge base, and the output is a textual response. We evaluate them on a large-scale QA task, and a smaller, but more complex, toy task generated from a simulated world. In the latter, we show the reasoning power of such models by chaining multiple supporting sentences to answer questions that require understanding the intension of verbs.",
    "prev": "Early work addressed this issue through the use of additional memory (Das et al., 1992;Mozer & Das, 1993) and differentiable fast weights (Schmidhuber, 1992;1993).",
    "curr": "Recently, memory-augmented NNs have solved algorithmic toy problems (Graves et al., 2014; as well as reasoning and inference problems in synthetic and natural language (Weston et al., 2015b;Xiong et al., 2016).",
    "next": "Inspired by the random-access memory of computer architectures, a common approach is to incorporate a soft and differentiable lookup table into the NN model.",
    "hard_negative": [
      8893912,
      2100831
    ],
    "easy_negative": [
      258960565,
      218973828,
      198165578
    ]
  },
  {
    "index": 3116,
    "source_corpus_id": 253080510,
    "ref_id": "b12",
    "citation_corpus_id": 226226888,
    "start": 2729,
    "end": 2749,
    "title": "Pre-print MIXKD: TOWARDS EFFICIENT DISTILLATION OF LARGE-SCALE LANGUAGE MODELS",
    "abstract": "Large-scale language models have recently demonstrated impressive empirical performance. Nevertheless, the improved results are attained at the price of bigger models, more power consumption, and slower inference, which hinder their applicability to low-resource (memory and computation) platforms. Knowledge distillation (KD) has been demonstrated as an effective framework for compressing such big models. However, large-scale neural network systems are prone to memorize training instances, and thus tend to make inconsistent predictions when the data distribution is altered slightly. Moreover, the student model has few opportunities to request useful information from the teacher model when there is limited task-specific data available. To address these issues, we propose MixKD, a data-agnostic distillation framework that leverages mixup, a simple yet efficient data augmentation approach, to endow the resulting model with stronger generalization ability. Concretely, in addition to the original training examples, the student model is encouraged to mimic the teacher's behavior on the linear interpolation of example pairs as well. We prove, from a theoretical perspective, that under reasonable conditions MixKD gives rise to a smaller gap between the generalization error and the empirical error. To verify its effectiveness, we conduct experiments on the GLUE benchmark, where MixKD consistently leads to significant gains over the standard KD training, and outperforms several competitive baselines. Experiments under a limited-data setting and ablation studies further demonstrate the advantages of the proposed approach. * Equal contribution 1 arXiv:2011.00593v1 [cs.CL] 1 Nov 2020",
    "prev": "This method, however, usually requires a large amount of data to guarantee the transfer quality, which may not be easily obtained in real-world applications.",
    "curr": "To this end, data augmentation methods are applied (Liang et al., 2020;Wang & Yang, 2020;Zhang et al., 2022b) to improve the distillation performance.",
    "next": "There are three major types of data augmentation methods: (1) Representation interpolation.",
    "hard_negative": [
      174799713,
      3432876,
      11816014
    ],
    "easy_negative": [
      9225825,
      201646280,
      236778562
    ]
  },
  {
    "index": 3124,
    "source_corpus_id": 257353677,
    "ref_id": "b24",
    "citation_corpus_id": 220047252,
    "start": 2654,
    "end": 2672,
    "title": "Unsupervised FAQ Retrieval with Question Generation and BERT",
    "abstract": "We focus on the task of Frequently Asked Questions (FAQ) retrieval. A given user query can be matched against the questions and/or the answers in the FAQ. We present a fully unsupervised method that exploits the FAQ pairs to train two BERT models. The two models match user queries to FAQ answers and questions, respectively. We alleviate the missing labeled data of the latter by automatically generating high-quality question paraphrases. We show that our model is on par and even outperforms supervised models on existing datasets.",
    "prev": "These works leverage task-adaptive training and focus on pre-training a model on a large open-domain dialogue corpus and fine-tuning it for ID classification (Mehri et al., 2020;Wu et al., 2020a;Casanueva et al., 2020;Zhang et al., 2021a).",
    "curr": "Alternative approaches tried to learn query representation based on query-to-query matching (henceforth, Match-QQ systems) Mass et al., 2020;Mehri et al., 2021).",
    "next": "; Mass et al.",
    "hard_negative": [
      52967399,
      904973,
      5541486
    ],
    "easy_negative": [
      12847003,
      56538189,
      36920300
    ]
  },
  {
    "index": 3125,
    "source_corpus_id": 207852415,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 3452,
    "end": 3475,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "The key difference between transformers and previous methods, such as recurrent neural networks (Hochreiter & Schmidhuber, 1997) and convolutional neural networks (CNN), is that the former can simultaneously attend to every word of their input sequence.",
    "curr": "This is made possible thanks to the attention mechanism-originally introduced in Neural Machine Translation to better handle long-range dependencies (Bahdanau et al., 2015).",
    "next": "With self-attention in particular, the similarity of two words in a sequence is captured by an attention score measuring the distance of their representations.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      14106458,
      1105972,
      8140866
    ]
  },
  {
    "index": 3129,
    "source_corpus_id": 252907242,
    "ref_id": "b20",
    "citation_corpus_id": 245704504,
    "start": 9120,
    "end": 9138,
    "title": "SDEDIT: GUIDED IMAGE SYNTHESIS AND EDITING WITH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Guided image synthesis enables everyday users to create and edit photo-realistic images with minimum effort. The key challenge is balancing faithfulness to the user inputs (e.g., hand-drawn colored strokes) and realism of the synthesized images. Existing GAN-based methods attempt to achieve such balance using either conditional GANs or GAN inversions, which are challenging and often require additional training data or loss functions for individual applications. To address these issues, we introduce a new image synthesis and editing method, Stochastic Differential Editing (SDEdit), based on a diffusion model generative prior, which synthesizes realistic images by iteratively denoising through a stochastic differential equation (SDE). Given an input image with user guide in a form of manipulating RGB pixels, SDEdit first adds noise to the input, then subsequently denoises the resulting image through the SDE prior to increase its realism. SDEdit does not require task-specific training or inversions and can naturally achieve the balance between realism and faithfulness. SDEdit outperforms state-of-the-art GAN-based methods by up to 98.09% on realism and 91.72% on overall satisfaction scores, according to a human perception study, on multiple tasks, including stroke-based image synthesis and editing as well as image compositing.",
    "prev": "As a likelihood-based model, the diffusion model matches the underlying data distribution q(x 0 ) by learning to reverse a noising process, and thus novel images can be sampled from a prior Gaussian distribution via the learned reverse path.",
    "curr": "Because of the high sample quality, good mode coverage and promising training stability, diffusion models are quickly becoming a new trend in both unconditional (Ho et al., 2020;Ho et al., 2022) and conditional Rombach et al., 2022;Lugmayr et al., 2022;Saharia et al., 2022a;Meng et al., 2021;Saharia et al., 2022c) image synthesis fields.",
    "next": "In particular, text-to-image generation can be treated as a conditional image generation task that requires the sampled image to match the given natural language description.",
    "hard_negative": [
      13890001,
      227209335
    ],
    "easy_negative": [
      250391049,
      185024671,
      253018703
    ]
  },
  {
    "index": 3137,
    "source_corpus_id": 252780503,
    "ref_id": "b17",
    "citation_corpus_id": 204960716,
    "start": 2777,
    "end": 2796,
    "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    "abstract": "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new stateof-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance. 1",
    "prev": "* Work done during an internship at MSRA.",
    "curr": "yangzh20@mails.tsinghua.edu.cn \u2020 Corresponding authors: P. Li\n\nINTRODUCTION\n\nTransformer (Vaswani et al., 2017) based Pre-trained Language Models (PLMs) (Radford et al., 2019;Raffel et al., 2019;Lewis et al., 2020) could produce quite fluent text and have empowered a wide range of downstream Natural Language Generation (NLG) tasks (See et al., 2019;Zhang et al., 2020;Lewis et al., 2020).",
    "next": "However, these PLMs are observed to internalize, propagate, and even amplify problematic contents that exist in crawled unclean corpora, typically toxic language (e.g., offensive text) (Gehman et al., 2020) and social biases (e.g., stereotypes or different model predictions) towards particular demographic groups (e.g., gender and race) (Sheng et al., 2019), as shown in Figure 1-(a).",
    "hard_negative": [
      52967399,
      16639476,
      990233
    ],
    "easy_negative": [
      218900756,
      6602395,
      52862016
    ]
  },
  {
    "index": 3144,
    "source_corpus_id": 3649804,
    "ref_id": "b6",
    "citation_corpus_id": 11212020,
    "start": 12226,
    "end": 12249,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "We address both isssues in this paper.",
    "curr": "For generalization beyond a pre-specified graph size, we follow the approach of (Vinyals et al., 2015b), which makes use of a set of non-parameteric softmax modules, resembling the attention mechanism from (Bahdanau et al., 2015).",
    "next": "This approach, named pointer network, allows the model to effectively point to a specific position in the input sequence rather than predicting an index value from a fixed-size vocabulary.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      8360741,
      15491080,
      257427641
    ]
  },
  {
    "index": 3145,
    "source_corpus_id": 212859361,
    "ref_id": "b14",
    "citation_corpus_id": 3144218,
    "start": 2477,
    "end": 2499,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "In other words, GCNs have been becoming one of the most crucial tools for graph representation learning.",
    "curr": "Yet, when we revisit typical GCNs on node classification (Kipf & Welling, 2017), they are usually shallow (e.g.",
    "next": "the number of the layers is 2 1 ).",
    "hard_negative": [
      6628106,
      8393918
    ],
    "easy_negative": [
      470570,
      248780379,
      227746856
    ]
  },
  {
    "index": 3150,
    "source_corpus_id": 257496463,
    "ref_id": "b7",
    "citation_corpus_id": 3480671,
    "start": 2213,
    "end": 2230,
    "title": "NON-AUTOREGRESSIVE NEURAL MACHINE TRANSLATION",
    "abstract": "Existing approaches to neural machine translation condition each output word on previously generated outputs. We introduce a model that avoids this autoregressive property and produces its outputs in parallel, allowing an order of magnitude lower latency during inference. Through knowledge distillation, the use of input token fertilities as a latent variable, and policy gradient fine-tuning, we achieve this at a cost of as little as 2.0 BLEU points relative to the autoregressive Transformer network used as a teacher. We demonstrate substantial cumulative improvements associated with each of the three aspects of our training strategy, and validate our approach on IWSLT 2016 English-German and two WMT language pairs. By sampling fertilities in parallel at inference time, our non-autoregressive model achieves near-state-of-the-art performance of 29.8 BLEU on WMT 2016 English-Romanian.",
    "prev": "Extensive experiments on major WMT benchmarks show that our method substantially improves translation performance and increases prediction confidence, setting a new state of the art for NAT on the raw training data.",
    "curr": "1\n\nINTRODUCTION\n\nNon-autoregressive translation (NAT) (Gu et al., 2018) reduces the decoding latency by generating all target tokens in parallel.",
    "next": "Compared with the autoregressive counterpart (Vaswani et al., 2017), NAT often suffers from performance degradation due to the severe multi-modality problem (Gu et al., 2018), which refers to the fact that one source sentence may have multiple translations in the target language.",
    "hard_negative": [
      8476273,
      11212020
    ],
    "easy_negative": [
      251104701,
      14922761,
      13959470
    ]
  },
  {
    "index": 3156,
    "source_corpus_id": 3714278,
    "ref_id": "b1",
    "citation_corpus_id": 8471750,
    "start": 1460,
    "end": 1481,
    "title": "Modeling Biological Processes for Reading Comprehension",
    "abstract": "Machine reading calls for programs that read and understand text, but most current work only attempts to extract facts from redundant web-scale corpora. In this paper, we focus on a new reading comprehension task that requires complex reasoning over a single document. The input is a paragraph describing a biological process, and the goal is to answer questions that require an understanding of the relations between entities and events in the process. To answer the questions, we first predict a rich structure representing the process in the paragraph. Then, we map the question to a formal query, which is executed against the predicted structure. We demonstrate that answering questions via predicted structures substantially improves accuracy over baselines that use shallower representations.",
    "prev": "INTRODUCTION\n\nQuestion answering (QA) is a crucial task in natural language processing that requires both natural language understanding and world knowledge.",
    "curr": "Previous QA datasets tend to be high in quality due to human annotation, but small in size (Berant et al., 2014;Richardson et al., 2013).",
    "next": "Hence, they did not allow for training data-intensive, expressive models such as deep neural networks.",
    "hard_negative": [
      5667590,
      6401679,
      991005,
      13273377,
      18198203,
      11162815,
      16714688,
      2199359,
      34491971,
      13856836,
      7359050,
      12451537,
      10250712,
      8893912,
      10318045,
      10048734,
      2486369,
      13494886,
      15197674,
      6945139,
      2065400,
      7785983
    ],
    "easy_negative": [
      16134775,
      1556206,
      235417501
    ]
  },
  {
    "index": 3158,
    "source_corpus_id": 252595924,
    "ref_id": "b14",
    "citation_corpus_id": 13046179,
    "start": 30909,
    "end": 30935,
    "title": "A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS",
    "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.Published as a conference paper at ICLR 2017 one method which outperforms the baseline on some (but not all) tasks. This new method evaluates the quality of a neural network's input reconstruction to determine if an example is abnormal.",
    "prev": "1-4.",
    "curr": "We used the maximum softmax probability (Hendrycks & Gimpel, 2017) of the (ensembled) predictive distribution as the score and we used AUROC and FPR95 as the performance metric.",
    "next": "We found that HMC and ShiftMatch always perform better than ensembles and SGD (Tab.",
    "hard_negative": [
      6628106,
      7105713,
      2879445,
      1428702,
      6706414
    ],
    "easy_negative": [
      17910420,
      252818942,
      5599802
    ]
  },
  {
    "index": 3162,
    "source_corpus_id": 259212405,
    "ref_id": "b0",
    "citation_corpus_id": 235614375,
    "start": 8918,
    "end": 8936,
    "title": "FEDMIX: APPROXIMATION OF MIXUP UNDER MEAN AUGMENTED FEDERATED LEARNING",
    "abstract": "Federated learning (FL) allows edge devices to collectively learn a model without directly sharing data within each device, thus preserving privacy and eliminating the need to store data globally. While there are promising results under the assumption of independent and identically distributed (iid) local data, current state-of-the-art algorithms suffer from performance degradation as the heterogeneity of local data across clients increases. To resolve this issue, we propose a simple framework, Mean Augmented Federated Learning (MAFL), where clients send and receive averaged local data, subject to the privacy requirements of target applications. Under our framework, we propose a new augmentation algorithm, named FedMix, which is inspired by a phenomenal yet simple data augmentation method, Mixup, but does not require local raw data to be directly shared among devices. Our method shows greatly improved performance in the standard benchmark datasets of FL, under highly non-iid federated settings, compared to conventional algorithms. arXiv:2107.00233v1 [cs.LG] 1 Jul 2021Published as a conference paper at ICLR 2021",
    "prev": "Class-balanced data re-sampling and loss re-weighting methods can improve the training performance when clients have imbalanced local data (Hsu et al., 2020;Wang et al., 2021;Chen & Chao, 2021).",
    "curr": "Besides, data sharing mechanisms and data augmentation methods are also investigated to mitigate the non-IID data challenges (Zhao et al., 2018;Yoon et al., 2021).",
    "next": "From the model aggregation perspective, selecting clients with more contribution to global model performance can also speed up the convergence and mitigate the influence of non-IID data (Wang et al., 2020;Tang et al., 2021;Wu & Wang, 2021;Fraboni et al., 2021).",
    "hard_negative": [
      208076137,
      211132598
    ],
    "easy_negative": [
      15432507,
      14909180,
      2289859
    ]
  },
  {
    "index": 3164,
    "source_corpus_id": 226226934,
    "ref_id": "b1",
    "citation_corpus_id": 14711954,
    "start": 2618,
    "end": 2640,
    "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
    "abstract": "We describe a framework for multitask deep reinforcement learning guided by policy sketches. Sketches annotate tasks with sequences of named subtasks, providing information about high-level structural relationships among tasks but not how to implement them-specifically not providing the detailed guidance used by much previous work on learning policy abstractions for RL (e.g. intermediate rewards, subtask completion signals, or intrinsic motivations). To learn from sketches, we present a model that associates every subtask with a modular subpolicy, and jointly maximizes reward over full task-specific policies by tying parameters across shared subpolicies. Optimization is accomplished via a decoupled actor-critic training objective that facilitates learning common behaviors from multiple dissimilar reward functions. We evaluate the effectiveness of our approach in three environments featuring both discrete and continuous control, and with sparse rewards that can be obtained only after completing a number of high-level subgoals. Experiments show that using our approach to learn policies guided by sketches gives better performance than existing techniques for learning task-specific or shared policies, while naturally inducing a library of interpretable primitive behaviors that can be recombined to rapidly adapt to new tasks.",
    "prev": "However, the ability to adapt to new environments and tasks remains a distant dream.",
    "curr": "Previous work have considered using language as a high-level representation for RL (Andreas et al., 2017;Jiang et al., 2019).",
    "next": "However, these approaches typically use language generated from templates that are hard-coded into the simulators the agents are tested in, allowing the agents to receive virtually unlimited training data to learn language abstractions.",
    "hard_negative": [
      9963298,
      806709,
      3130692,
      216034672,
      5249151
    ],
    "easy_negative": [
      14792899,
      222125320,
      6452962
    ]
  },
  {
    "index": 3165,
    "source_corpus_id": 338016,
    "ref_id": "b1",
    "citation_corpus_id": 1282393,
    "start": 3924,
    "end": 3942,
    "title": "Learning New Facts From Knowledge Bases With Neural Tensor Networks and Semantic Word Vectors",
    "abstract": "Knowledge bases provide applications with the benefit of easily accessible, systematic relational knowledge but often suffer in practice from their incompleteness and lack of knowledge of new entities and relations. Much work has focused on building or extending them by finding patterns in large unannotated text corpora. In contrast, here we mainly aim to complete a knowledge base by predicting additional true relationships between entities, based on generalizations that can be discerned in the given knowledgebase. We introduce a neural tensor network (NTN) model which predicts new relationship entries that can be added to the database. This model can be improved by initializing entity representations with word vectors learned in an unsupervised fashion from text, and when doing this, existing relations can even be queried for entities that were not present in the database. Our model generalizes and outperforms existing models for this problem, and can classify unseen relationships in WordNet with an accuracy of 75.8%.",
    "prev": "(2013).",
    "curr": "Even more general setups with arbitrary collections of matrices that share some sets of entities have been proposed several times by different authors, under names such as co-factorization or multi-relational matrix factorization, and most end up being either a variant of tensor factorization of knowledge bases (Nickel et al., 2011;Chen et al., 2013) or a special case of Collective Matrix Factorization (CMF; Singh and Gordon, 2008).",
    "next": "In this paper, we concentrate on the CMF model, i.e.",
    "hard_negative": [
      1671874,
      629094,
      1189640,
      806709,
      10318045
    ],
    "easy_negative": [
      10267128,
      14810326,
      33191382
    ]
  },
  {
    "index": 3170,
    "source_corpus_id": 253098700,
    "ref_id": "b38",
    "citation_corpus_id": 52183757,
    "start": 8565,
    "end": 8588,
    "title": "Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering",
    "abstract": "We present a new kind of question answering dataset, OpenBookQA, modeled after open book exams for assessing human understanding of a subject. The open book that comes with our questions is a set of 1326 elementary level science facts. Roughly 6000 questions probe an understanding of these facts and their application to novel situations. This requires combining an open book fact (e.g., metals conduct electricity) with broad common knowledge (e.g., a suit of armor is made of metal) obtained from other sources. While existing QA datasets over documents or knowledge bases, being generally self-contained, focus on linguistic understanding, OpenBookQA probes a deeper understanding of both the topic-in the context of common knowledge-and the language it is expressed in. Human performance on OpenBookQA is close to 92%, but many state-of-the-art pre-trained QA methods perform surprisingly poorly, worse than several simple neural baselines we develop. Our oracle experiments designed to circumvent the knowledge retrieval bottleneck demonstrate the value of both the open book and additional facts. We leave it as a challenge to solve the retrieval problem in this multi-hop setting and to close the large gap to human performance. 1  The dataset and the code for the models are available at http://data.allenai.org/OpenBookQA.",
    "prev": "Given the same raw data (question and candidate answers) the answer selected when using CP depends on choice of normalization strategy.",
    "curr": "Question taken from OpenBookQA (Mihaylov et al., 2018) with slight modification.",
    "next": "We are not the first to notice prompting's impact on LLM performance.",
    "hard_negative": [
      6360322,
      2592133,
      3618568,
      957320,
      6628106,
      28971531,
      2498076,
      8078497,
      5019682,
      26501419,
      34032948,
      1957433,
      1671874,
      3626819,
      3623373,
      11816014,
      2100831,
      21067620,
      1167588,
      5761781,
      14915449
    ],
    "easy_negative": [
      221373817,
      216050683,
      219300338
    ]
  },
  {
    "index": 3172,
    "source_corpus_id": 9864100,
    "ref_id": "b21",
    "citation_corpus_id": 5959482,
    "start": 19356,
    "end": 19378,
    "title": "Efficient Estimation of Word Representations in Vector Space",
    "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities. arXiv:1301.3781v3 [cs.CL] 7 Sep 2013 1 The test set is available at www.fit.vutbr.cz/\u02dcimikolov/rnnlm/word-test.v1.txt 2",
    "prev": "We combine the models by averaging the predicted softmax distributions of the models at every timestep.",
    "curr": "While it is generally believed that neural network models require a large number of training examples compared to simpler linear models to get good performance, our model  We did not get better results either by using pre-trained word vectors (Mikolov et al., 2013) or by pre-training the question RNN with a language modeling objective (Dai & Le, 2015).",
    "next": "A possible explanation is that the word vectors obtained from unsupervised learning may not be suitable to the task under consideration.",
    "hard_negative": [
      633992,
      5278106,
      1428702,
      629094
    ],
    "easy_negative": [
      15975555,
      1144118,
      227231852
    ]
  },
  {
    "index": 3178,
    "source_corpus_id": 224470441,
    "ref_id": "b23",
    "citation_corpus_id": 1957433,
    "start": 13641,
    "end": 13666,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "The embeddings are expected to capture the semantic information of the topics and words.",
    "curr": "Instead of learning the word embeddings, we propose to feed them with pretrained word embeddings such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014).",
    "next": "This not only reduces the parameter space to make the learning of M more stable but also enables us to leverage the rich semantic information in pretrained word embeddings, which is beneficial for short documents.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      227231585,
      2016873,
      5873462
    ]
  },
  {
    "index": 3180,
    "source_corpus_id": 204960946,
    "ref_id": "b20",
    "citation_corpus_id": 52917394,
    "start": 3958,
    "end": 3984,
    "title": "Learning to Segment Inputs for NMT Favors Character-Level Processing",
    "abstract": "Most modern neural machine translation (NMT) systems rely on presegmented inputs. Segmentation granularity importantly determines the input and output sequence lengths, hence the modeling depth, and source and target vocabularies, which in turn determine model size, computational costs of softmax normalization, and handling of out-ofvocabulary words. However, the current practice is to use static, heuristic-based segmentations that are fixed before NMT training. This begs the question whether the chosen segmentation is optimal for the translation task. To overcome suboptimal segmentation choices, we present an algorithm for dynamic segmentation, that is trainable end-to-end and driven by the NMT objective. In an evaluation on four translation tasks we found that, given the freedom to navigate between different segmentation levels, the model prefers to operate on (almost) character level, providing support for purely character-level NMT models from a novel angle.",
    "prev": "Moreover, in this approach, a word form is then generated by prediction of multiple subword units, which makes generalizing to unseen word forms more difficult due to the possibility that a subword unit necessary to reconstruct a given word form may be unlikely in a given context.",
    "curr": "To alleviate the sub-optimal effects of using explicit segmentation and generalize better to new morphological forms, recent studies explored the idea of extending NMT to model translation directly at the level of characters (Kreutzer & Sokolov, 2018;Cherry et al., 2018), which, in turn, have demonstrated the requirement of using comparably deeper networks, as the network would then need to learn longer distance grammatical dependencies (Sennrich, 2017).",
    "next": "In this paper, we explore the benefits of explicitly modeling variation in surface forms of words using techniques from deep latent variable modeling in order to improve translation accuracy for low-resource and morphologically-rich languages.",
    "hard_negative": [
      6628106,
      4109354,
      5590763,
      11212020,
      13495961,
      10509498,
      14421595
    ],
    "easy_negative": [
      197908565,
      219307482,
      1138220
    ]
  },
  {
    "index": 3181,
    "source_corpus_id": 258833259,
    "ref_id": "b59",
    "citation_corpus_id": 211003696,
    "start": 4062,
    "end": 4082,
    "title": "EFFICIENT PROBABILISTIC LOGIC REASONING WITH GRAPH NEURAL NETWORKS",
    "abstract": "Markov Logic Networks (MLNs), which elegantly combine logic rules and probabilistic graphical models, can be used to address many knowledge graph problems. However, inference in MLN is computationally intensive, making the industrialscale application of MLN very difficult. In recent years, graph neural networks (GNNs) have emerged as efficient and effective tools for large-scale graph problems. Nevertheless, GNNs do not explicitly incorporate prior logic rules into the models, and may require many labeled examples for a target task. In this paper, we explore the combination of MLNs and GNNs, and use graph neural networks for variational inference in MLN. We propose a GNN variant, named ExpressGNN, which strikes a nice balance between the representation power and the simplicity of the model. Our extensive experiments on several benchmark datasets demonstrate that ExpressGNN leads to effective and efficient probabilistic logic reasoning.Published as a conference paper at ICLR 2020 Variational EM Posterior Encoding Likelihood Decoding GNN MLN Knowledge Graph \" (\u22c5) formula potential predicate posterior Figure 1: Overview of our method for combining MLN and GNN using the variational EM framework.\u2022 Efficient inference and learning: ExpressGNN can be viewed as the inference network for MLN, which scales up MLN inference to much larger knowledge graph problems.\u2022 Combining logic rules and data supervision: ExpressGNN can leverage the prior knowledge encoded in logic rules, as well as the supervision from graph structured data.\u2022 Compact and expressive model: ExpressGNN may have small number of parameters, yet it is sufficient to represent mean-field distributions in MLN.\u2022 Capability of zero-shot learning: ExpressGNN can deal with the zero-shot learning problem where the target predicate has few or zero labeled instances.",
    "prev": "Recent deep neural network models based on Graph Neural Networks (GNNs) (Teru et al., 2020;Mai et al., 2021) have utilized local sub-graphs as an important inductive bias in knowledge graph completion.",
    "curr": "Although GNNs can efficiently incorporate neighboring information via messagepassing mechanisms to improve prediction performance (Zhang et al., 2019;Lin et al., 2022), they are not capable of discovering explicit logical rules, and the reasoning process of GNNs is largely unexplainable.",
    "next": "In this paper, we propose Logical Entity RePresentation (LERP) to incorporate information from local sub-graphs into probabilistic logic rule learning.",
    "hard_negative": [
      5378837,
      3144218,
      8393918
    ],
    "easy_negative": [
      21723087,
      13080665,
      235196067
    ]
  },
  {
    "index": 3183,
    "source_corpus_id": 254018220,
    "ref_id": "b11",
    "citation_corpus_id": 247596648,
    "start": 4949,
    "end": 4967,
    "title": "METAMORPH: LEARNING UNIVERSAL CONTROLLERS WITH TRANSFORMERS",
    "abstract": "Multiple domains like vision, natural language, and audio are witnessing tremendous progress by leveraging Transformers for large scale pre-training followed by task specific fine tuning. In contrast, in robotics we primarily train a single robot for a single task. However, modular robot systems now allow for the flexible combination of general-purpose building blocks into task optimized morphologies. However, given the exponentially large number of possible robot morphologies, training a controller for each new design is impractical. In this work, we propose MetaMorph, a Transformer based approach to learn a universal controller over a modular robot design space. MetaMorph is based on the insight that robot morphology is just another modality on which we can condition the output of a Transformer. Through extensive experiments we demonstrate that large scale pretraining on a variety of robot morphologies results in policies with combinatorial generalization capabilities, including zero shot generalization to unseen robot morphologies. We further demonstrate that our pre-trained policy can be used for sample-efficient transfer to completely new robot morphologies and tasks. . Neural graph evolution: Automatic robot design. In ICLR, 2019.Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine learning, 8(3-4):229-256, 1992.",
    "prev": "many robots in different simulators (Freeman et al., 2021;Todorov et al., 2012;Coumans & Bai, 2016) as possible.",
    "curr": "Most prior works (Mendonca et al., 2021;Gupta et al., 2022) only address either the task or morphology axis separately, and achieving broad generalization over task and morphology jointly remains a long-standing problem 2 .",
    "next": "This paper first proposes MxT-Bench 3 , the first multi-morphology and multi-task benchmarking environments, as a step toward building the massive diverse dataset for continuous control.",
    "hard_negative": [
      225039882,
      3352260
    ],
    "easy_negative": [
      857427,
      244119739,
      18358623
    ]
  },
  {
    "index": 3184,
    "source_corpus_id": 209501080,
    "ref_id": "b11",
    "citation_corpus_id": 68222714,
    "start": 7763,
    "end": 7788,
    "title": "APPROXIMATING CNNS WITH BAG-OF-LOCAL- FEATURES MODELS WORKS SURPRISINGLY WELL ON IMAGENET",
    "abstract": "Deep Neural Networks (DNNs) excel on many complex perceptual tasks but it has proven notoriously difficult to understand how they reach their decisions. We here introduce a high-performance DNN architecture on ImageNet whose decisions are considerably easier to explain. Our model, a simple variant of the ResNet-50 architecture called BagNet, classifies an image based on the occurrences of small local image features without taking into account their spatial ordering. This strategy is closely related to the bag-of-feature (BoF) models popular before the onset of deep learning and reaches a surprisingly high accuracy on ImageNet (87.6% top-5 for 33 \u00d7 33 px features and Alexnet performance for 17 \u00d7 17 px features). The constraint on local features makes it straight-forward to analyse how exactly each part of the image influences the classification. Furthermore, the BagNets behave similar to state-of-the art deep neural networks such as VGG-16, ResNet-152 or DenseNet-169 in terms of feature sensitivity, error distribution and interactions between image parts. This suggests that the improvements of DNNs over previous bag-of-feature classifiers in the last few years is mostly achieved by better fine-tuning rather than by qualitatively different decision strategies.",
    "prev": "Formally, f (x) \u2208 R is compositional if it can be expressed as a combination of the elements of {g(p)|p \u2208 D(x)}.",
    "curr": "The combination operator used is commonly a weighted sum (Brendel & Bethge, 2019b), although some works learn more complex combinations (Higgins et al., 2017b).",
    "next": "As we consider representations that are implicitly compositional, the above formalism might be approximately true which motivates our later use of the TRE metric.",
    "hard_negative": [
      2103669,
      32654687
    ],
    "easy_negative": [
      202540345,
      15154323,
      1307208
    ]
  },
  {
    "index": 3186,
    "source_corpus_id": 250425754,
    "ref_id": "b25",
    "citation_corpus_id": 239616181,
    "start": 11180,
    "end": 11200,
    "title": "ILLITERATE DALL-E LEARNS TO COMPOSE",
    "abstract": "Although DALL\u00b7E has shown an impressive ability of composition-based systematic generalization in image generation, it requires the dataset of text-image pairs and the compositionality is provided by the text. In contrast, object-centric representation models like the Slot Attention model learn composable representations without the text prompt. However, unlike DALL\u00b7E its ability to systematically generalize for zero-shot generation is significantly limited. In this paper, we propose a simple but novel slot-based autoencoding architecture, called SLATE 1 , for combining the best of both worlds: learning object-centric representations that allows systematic generalization in zero-shot image generation without text. As such, this model can also be seen as an illiterate DALL\u00b7E model. Unlike the pixel-mixture decoders of existing object-centric representation models, we propose to use the Image GPT decoder conditioned on the slots for capturing complex interactions among the slots and pixels. In experiments, we show that this simple and easy-to-implement architecture not requiring a text prompt achieves significant improvement in in-distribution and out-of-distribution (zero-shot) image generation and qualitatively comparable or better slot-attention structure than the models based on mixture decoders. https://sites.google.com/view/slate-autoencoder",
    "prev": "Unsupervised Object-centric Representation Learning Object centric learning assumes that scenes are composed of different objects and aims to learn sets of feature vectors, where each of them binding to one object.",
    "curr": "Unsupervised methods based on single images (Burgess et al., 2019;Greff et al., 2019;Engelcke et al., 2020;Locatello et al., 2020;Singh et al., 2022a) suffer from singleview ambiguities, which one tries to overcome by exploiting the information in multiple views of a static scene (Chen et al., 2021), in a single view of a dynamic scene (i.e., a video) (Hsieh et al., 2021;Kipf et al., 2021;Singh et al., 2022b) or multiple views of a dynamic scene (Nanbo et al., 2021).",
    "next": "In contrast to previous methods and similar to DINOSAUR method (Seitzer et al., 2023), our method exploits unlabeled object-centric datasets to extract object masks and representations.",
    "hard_negative": [
      212414722,
      20827927,
      2428314,
      232269768,
      210064473
    ],
    "easy_negative": [
      10695055,
      16742116,
      12810977
    ]
  },
  {
    "index": 3187,
    "source_corpus_id": 26100519,
    "ref_id": "b6",
    "citation_corpus_id": 5590763,
    "start": 5914,
    "end": 5930,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "Nonetheless, to the best of our knowledge, Deep Voice 3 is the first TTS system to scale to thousands of speakers.",
    "curr": "Sequence-to-sequence models (Sutskever et al., 2014;Cho et al., 2014) encode a variable-length input to hidden states, and which are then processed at the decoder to generate the target sequence.",
    "next": "An attention mechanism allows the decoder to adaptively choose which hidden states in encoder to focus on while generating the target sequence .",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      6674497,
      264172710,
      5151805
    ]
  },
  {
    "index": 3198,
    "source_corpus_id": 250280065,
    "ref_id": "b15",
    "citation_corpus_id": 44115640,
    "start": 9640,
    "end": 9659,
    "title": "On the Practical Computational Power of Finite Precision RNNs for Language Recognition",
    "abstract": "While Recurrent Neural Networks (RNNs) are famously known to be Turing complete, this relies on infinite precision in the states and unbounded computation time. We consider the case of RNNs with finite precision whose computation time is linear in the input length. Under these limitations, we show that different RNN variants have different computational power. In particular, we show that the LSTM and the Elman-RNN with ReLU activation are strictly stronger than the RNN with a squashing activation and the GRU. This is achieved because LSTMs and ReLU-RNNs can easily implement counting behavior. We show empirically that the LSTM does indeed learn to effectively use the counting mechanism.",
    "prev": "However, these results are impractical as they rely on an unbounded number of recurrent steps and on arbitrary numerical precision.",
    "curr": "Thus, more recent work (Ackerman & Cybenko, 2020;Bhattamishra et al., 2020;Hahn, 2020;Hao et al., 2022;Korsky & Berwick, 2019;Merrill, 2019;Merrill et al., 2020;Merrill & Sabharwal, 2022;Weiss et al., 2018) has refined these theoretical analyses by considering linear computation steps and logarithmic precision, showing that: (i) RNNs and GRUs can, in theory, recognize regular languages, and (ii) LSTMs are strictly more powerful since they can learn a counting mechanism (i.e., are k-counter machines).",
    "next": "Moreover, it was theoretically shown that Transformers are not well-aligned with the Chomsky hierarchy since they cannot recognize certain regular languages (e.g., periodic finite-state languages), while being able to learn some counter languages (e.g., Shuffle-Dyck and n-ary Boolean expressions).",
    "hard_negative": [
      8078153,
      5590763
    ],
    "easy_negative": [
      45438237,
      220445592,
      241583497
    ]
  },
  {
    "index": 3200,
    "source_corpus_id": 232222444,
    "ref_id": "b14",
    "citation_corpus_id": 3463260,
    "start": 7987,
    "end": 8007,
    "title": "Published as a conference paper at ICLR 2018 DISTRIBUTED PRIORITIZED EXPERIENCE REPLAY",
    "abstract": "We propose a distributed architecture for deep reinforcement learning at scale, that enables agents to learn effectively from orders of magnitude more data than previously possible. The algorithm decouples acting from learning: the actors interact with their own instances of the environment by selecting actions according to a shared neural network, and accumulate the resulting experience in a shared experience replay memory; the learner replays samples of experience and updates the neural network. The architecture relies on prioritized experience replay to focus only on the most significant data generated by the actors. Our architecture substantially improves the state of the art on the Arcade Learning Environment, achieving better final performance in a fraction of the wall-clock training time.",
    "prev": "Existing systems for high-performance RL have primarily focused on improving the efficiency of DNN components of the workload (policy inference and optimization) and use a simulator designed for efficient single agent simulation as a black box.",
    "curr": "For example, Impala and Ape-X used multiple worker processes to asynchronously collect experience for a centralized learner (Espeholt et al., 2018;Horgan et al., 2018).",
    "next": "SEED RL and Sample Factory built upon this idea and introduced inference workers that centralize network inference, thereby allowing it to be accelerated by GPUs or TPUs (Espeholt et al., 2020;Petrenko et al., 2020).",
    "hard_negative": [
      1163588,
      14717992
    ],
    "easy_negative": [
      2940623,
      14958345,
      258999730
    ]
  },
  {
    "index": 3209,
    "source_corpus_id": 257232537,
    "ref_id": "b23",
    "citation_corpus_id": 240288835,
    "start": 2476,
    "end": 2493,
    "title": "MetaICL: Learning to Learn In Context",
    "abstract": "We introduce MetaICL (Meta-training for In-Context Learning), a new meta-training framework for few-shot learning where a pretrained language model is tuned to do in-context learning on a large set of training tasks. This metatraining enables the model to more effectively learn a new task in context at test time, by simply conditioning on a few training examples with no parameter updates or task-specific templates. We experiment on a large, diverse collection of tasks consisting of 142 NLP datasets including classification, question answering, natural language inference, paraphrase detection and more, across seven different metatraining/target splits. MetaICL outperforms a range of baselines including in-context learning without meta-training and multi-task learning followed by zero-shot transfer. We find that the gains are particularly significant for target tasks that have domain shifts from the meta-training tasks, and that using a diverse set of the meta-training tasks is key to improvements. We also show that MetaICL approaches (and sometimes beats) the performance of models fully finetuned on the target task, and outperforms much bigger models with nearly 8x parameters. Finally, we show that MetaICL is complementary to human-written instructions, and the best performance can be achieved by combining both approaches. Tom Brown, Dawn Song, Ulfar Erlingsson, et al. 2021. Extracting training data from large language models. In 30th USENIX Security Symposium (USENIX Security 21). .2018. Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization. In EMNLP.",
    "prev": "Yet, it is quite challenging for current vision and language models to deal with a limited labeled space, when performing multimodal few-shot learning (Tsimpoukelli et al., 2021;Alayrac et al., 2022).",
    "curr": "On the contrary, language-only models have already flourished over the past years, especially when being transferred to a limited labeled space (Brown et al., 2020;Perez et al., 2021;Min et al., 2022), as a result of the large-scale pre-training and huge model capacity.",
    "next": "Such advances in natural language processing inspired similar efforts in the vision domain, yielding large vision models with impressive few-shot and zero-shot image classification capabilities (Radford et al., 2021;Jia et al., 2021).",
    "hard_negative": [
      237416585,
      1553193,
      5034059,
      1373518,
      196174735,
      52019251
    ],
    "easy_negative": [
      247793148,
      229365728,
      259370883
    ]
  },
  {
    "index": 3213,
    "source_corpus_id": 258212652,
    "ref_id": "b1",
    "citation_corpus_id": 108297336,
    "start": 4650,
    "end": 4677,
    "title": "THERE ARE MANY CONSISTENT EXPLANATIONS OF UNLABELED DATA: WHY YOU SHOULD AVERAGE",
    "abstract": "Presently the most successful approaches to semi-supervised learning are based on consistency regularization, whereby a model is trained to be robust to small perturbations of its inputs and parameters. To understand consistency regularization, we conceptually explore how loss geometry interacts with training procedures. The consistency loss dramatically improves generalization performance over supervisedonly training; however, we show that SGD struggles to converge on the consistency loss and continues to make large steps that lead to changes in predictions on the test data. Motivated by these observations, we propose to train consistencybased methods with Stochastic Weight Averaging (SWA), a recent approach which averages weights along the trajectory of SGD with a modified learning rate schedule. We also propose fast-SWA, which further accelerates convergence by averaging multiple points within each cycle of a cyclical learning rate schedule. With weight averaging, we achieve the best known semi-supervised results on CIFAR-10 and CIFAR-100, over many different quantities of labeled training data. For example, we achieve 5.0% error on CIFAR-10 with only 4000 labels, compared to the previous best result in the literature of 6.3%.Izmailov et al., 2018). Interpolating between the weights corresponding to different epochs of training we demonstrate that the solutions of \u03a0 and Mean Teacher models are indeed flatter along these directions(Figure 1b).",
    "prev": "To this end, we first investigate Stochastic Weight Averaging (SWA;Izmailov et al., 2018), which improves the generalization performance of deep neural networks by seeking flat minima in loss surfaces.",
    "curr": "Although SWA has been successful for various tasks involving deep neural networks (for instance, supervised learning (Izmailov et al., 2018), semisupervised learning (Athiwaratkun et al., 2019) and domain generalization (Cha et al., 2021)), to the best of our knowledge, it has never been explored for long-tailed classification problems.",
    "next": "In Section 3, we empirically show that a na\u00efve application of SWA for long-tailed classification would fail due to a similar bottleneck issue, but when combined with decoupling, SWA significantly improves the classification performance due to its property to obtain generalizable representations.",
    "hard_negative": [
      3461223,
      13123084,
      16209268
    ],
    "easy_negative": [
      14225680,
      216036179,
      212725580
    ]
  },
  {
    "index": 3215,
    "source_corpus_id": 256615635,
    "ref_id": "b3",
    "citation_corpus_id": 231672601,
    "start": 3323,
    "end": 3346,
    "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models",
    "abstract": "We introduce BitFit, a sparse-finetuning method where only the bias-terms of the model (or a subset of them) are being modified. We show that with small-to-medium training data, applying BitFit on pre-trained BERT models is competitive with (and sometimes better than) fine-tuning the entire model. For larger data, the method is competitive with other sparse fine-tuning methods. Besides their practical utility, these findings are relevant for the question of understanding the commonly-used process of finetuning: they support the hypothesis that finetuning is mainly about exposing knowledge induced by language-modeling training, rather than learning new task-specific linguistic knowledge.",
    "prev": "An inadequate finetuning on downstream data might destroy the well generalized representations from such foundation models.",
    "curr": "To overcome the drawbacks, a research direction termed parameter-efficient transfer learning has been trending in natural language processing (NLP) (Houlsby et al., 2019;Lester et al., 2021;Ben Zaken et al., 2022;.",
    "next": "The goal is to only finetune a small number of (extra) parameters while keeping large pre-trained language models (Devlin et al., 2018;Brown et al., 2020) frozen to attain strong performance.",
    "hard_negative": [
      208117506,
      19247366,
      990233,
      218487454,
      216553665,
      53388625,
      16639476
    ],
    "easy_negative": [
      236460092,
      19226723,
      238419359
    ]
  },
  {
    "index": 3219,
    "source_corpus_id": 211011309,
    "ref_id": "b35",
    "citation_corpus_id": 12130431,
    "start": 7424,
    "end": 7442,
    "title": "INCREMENTAL NETWORK QUANTIZATION: TOWARDS LOSSLESS CNNS WITH LOW-PRECISION WEIGHTS",
    "abstract": "This paper presents incremental network quantization (INQ), a novel method, targeting to efficiently convert any pre-trained full-precision convolutional neural network (CNN) model into a low-precision version whose weights are constrained to be either powers of two or zero. Unlike existing methods which are struggled in noticeable accuracy loss, our INQ has the potential to resolve this issue, as benefiting from two innovations. On one hand, we introduce three interdependent operations, namely weight partition, group-wise quantization and re-training. A wellproven measure is employed to divide the weights in each layer of a pre-trained CNN model into two disjoint groups. The weights in the first group are responsible to form a low-precision base, thus they are quantized by a variable-length encoding method. The weights in the other group are responsible to compensate for the accuracy loss from the quantization, thus they are the ones to be re-trained. On the other hand, these three operations are repeated on the latest re-trained group in an iterative manner until all the weights are converted into low-precision ones, acting as an incremental network quantization and accuracy enhancement procedure. Extensive experiments on the ImageNet classification task using almost all known deep CNN architectures including AlexNet, VGG-16, GoogleNet and ResNets well testify the efficacy of the proposed method. Specifically, at 5-bit quantization (a variable-length encoding: 1 bit for representing zero value, and the remaining 4 bits represent at most 16 different values for the powers of two) 1 , our models have improved accuracy than the 32-bit floating-point references. Taking ResNet-18 as an example, we further show that our quantized models with 4-bit, 3-bit and 2-bit ternary weights have improved or very similar accuracy against its 32-bit floating-point baseline. Besides, impressive results with the combination of network pruning and INQ are also reported. We believe that our method sheds new insights on how to make deep CNNs to be applicable on mobile or embedded devices. The code is available at https://github.com",
    "prev": "BACKGROUND AND RELATED WORK\n\nQuantization.",
    "curr": "Recent works (Lin et al., 2016;Zhou et al., 2017;Jacob et al., 2018;McKinstry et al., 2018;Zhang et al., 2018) quantize the real-valued weights and activations to fixed-point representations, so that the model size is reduced and inferences can use low-cost fixed-point MAC operations.",
    "next": "To further reduce inference computing overhead, prior works (Kim & Smaragdis, 2016;Tang et al., 2017;Rastegari et al., 2016; quantize weights and activations into multi-bit binary codes of {-1, +1}s. Rather than real-valued MACs, inferences of these quantized models depend on bit-wise logic operations, i.e., XNORs and popcounts.",
    "hard_negative": [
      14124313,
      2134321,
      1996665
    ],
    "easy_negative": [
      222378211,
      259847777,
      196209097
    ]
  },
  {
    "index": 3221,
    "source_corpus_id": 252780278,
    "ref_id": "b1",
    "citation_corpus_id": 14711954,
    "start": 7650,
    "end": 7672,
    "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
    "abstract": "We describe a framework for multitask deep reinforcement learning guided by policy sketches. Sketches annotate tasks with sequences of named subtasks, providing information about high-level structural relationships among tasks but not how to implement them-specifically not providing the detailed guidance used by much previous work on learning policy abstractions for RL (e.g. intermediate rewards, subtask completion signals, or intrinsic motivations). To learn from sketches, we present a model that associates every subtask with a modular subpolicy, and jointly maximizes reward over full task-specific policies by tying parameters across shared subpolicies. Optimization is accomplished via a decoupled actor-critic training objective that facilitates learning common behaviors from multiple dissimilar reward functions. We evaluate the effectiveness of our approach in three environments featuring both discrete and continuous control, and with sparse rewards that can be obtained only after completing a number of high-level subgoals. Experiments show that using our approach to learn policies guided by sketches gives better performance than existing techniques for learning task-specific or shared policies, while naturally inducing a library of interpretable primitive behaviors that can be recombined to rapidly adapt to new tasks.",
    "prev": "We instead use embed-ding spaces that are shaped with pretrained language models so that semantically similar tasks are encoded in similar regions of the embedding space, which helps improve generalization.",
    "curr": "Multi-task robotic policies have also been studied in other settings and contexts that do not fall under the class of approaches we take in this paper, such as hierarchical goal-conditioned policies , probabilistic modeling techniques (Wilson et al., 2007), distillation and transfer learning (Parisotto et al., 2015;Teh et al., 2017;Xu et al., 2020;Rusu et al., 2015), data sharing (Espeholt et al., 2018;Hessel et al., 2019), gradient-based techniques (Yu et al., 2020), policy modularization (Andreas et al., 2017;Devin et al., 2017) and task modularization (Yang et al., 2020).",
    "next": "LEARNING WITH LANGUAGE AND DEMONSTRATIONS\n\nConditioning Multitask Policies on Language or Demonstrations.",
    "hard_negative": [
      9963298,
      806709,
      3130692,
      216034672,
      5249151
    ],
    "easy_negative": [
      1157610,
      76656665,
      15070938
    ]
  },
  {
    "index": 3223,
    "source_corpus_id": 256598058,
    "ref_id": "b1",
    "citation_corpus_id": 219558760,
    "start": 22935,
    "end": 22955,
    "title": "On the Bottleneck of Graph Neural Networks and its Practical Implications",
    "abstract": "Graph neural networks (GNNs) were shown to effectively learn from highly structured data containing elements (nodes) with relationships (edges) between them. GNN variants differ in how each node in the graph absorbs the information flowing from its neighbor nodes. In this paper, we highlight an inherent problem in GNNs: the mechanism of propagating information between neighbors creates a bottleneck when every node aggregates messages from its neighbors. This bottleneck causes the over-squashing of exponentially-growing information into fixed-size vectors. As a result, the graph fails to propagate messages flowing from distant nodes and performs poorly when the prediction task depends on long-range information. We demonstrate that the bottleneck hinders popular GNNs from fitting the training data. We show that GNNs that absorb incoming edges equally, like GCN and GIN, are more susceptible to over-squashing than other GNN types. We further show that existing, extensively-tuned, GNN-based models suffer from over-squashing and that breaking the bottleneck improves state-of-the-art results without any hyperparameter tuning or additional weights.Preprint. Under review.",
    "prev": "However, GCNII performs worse on heterophilous datasets, leaving a gap of more than 20 percents on Squirrel dataset.",
    "curr": "The amazing performance on this dataset might related to the \"over-squashing\" problem (Alon & Yahav, 2020;Topping et al., 2021) (see Appendix B.3).",
    "next": "We also achieve SOTA on the heterophilous datasets and consistently outperform baselines across all datasets.",
    "hard_negative": [
      11336213,
      3144218,
      3495200,
      8393918,
      13697606,
      202888772,
      209439835,
      212859361,
      3292002,
      52895589
    ],
    "easy_negative": [
      236460087,
      234762955,
      2109203
    ]
  },
  {
    "index": 3229,
    "source_corpus_id": 252596292,
    "ref_id": "b20",
    "citation_corpus_id": 198986015,
    "start": 5415,
    "end": 5437,
    "title": "GENESIS: Generative Scene Inference and Sampling with Object-Centric Latent Representations",
    "abstract": "Generative models are emerging as promising tools in robotics and reinforcement learning. Yet, even though tasks in these domains typically involve distinct objects, most state-of-the-art methods do not explicitly capture the compositional nature of visual scenes. Two exceptions, MONet and IODINE, decompose scenes into objects in an unsupervised fashion via a set of latent variables. Their underlying generative processes, however, do not account for component interactions. Hence, neither of them allows for principled sampling of coherent scenes. Here we present GENESIS, the first object-centric generative model of visual scenes capable of both decomposing and generating complete scenes by explicitly capturing relationships between scene components. GENESIS parameterises a spatial GMM over pixels which is encoded by component-wise latent variables that are inferred sequentially or sampled from an autoregressive prior. We train GENESIS on two publicly available datasets and probe the information in the latent representations through a set of classification tasks, outperforming several baselines.",
    "prev": "Like color, motion and depth act as grouping signals when objects move or stand-out in 3D-space.",
    "curr": "Unfortunately, this precludes training on most real-world 2 RELATED WORK Our research follows a body of work studying the emergence of object-centric representations in neural networks trained end-to-end with certain architectural biases (Eslami et al., 2016;Greff et al., 2019;Lin et al., 2020;Engelcke et al., 2020;Locatello et al., 2020;Singh et al., 2022a).",
    "next": "These approaches implicitly define objects as repeating patterns across a closed-world dataset that can be discovered e.g.",
    "hard_negative": [
      6628106,
      5273326
    ],
    "easy_negative": [
      8950336,
      45723107,
      248779965
    ]
  },
  {
    "index": 3238,
    "source_corpus_id": 38796293,
    "ref_id": "b20",
    "citation_corpus_id": 252796,
    "start": 17578,
    "end": 17599,
    "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
    "abstract": "There is a growing consensus that significant, rapid progress can be made in both text understanding and spoken language understanding by investigating those phenomena that occur most centrally in naturally occurring unconstrained materials and by attempting to automatically extract information about language from very large corpora. Such corpora are beginning to serve as important research tools for investigators in natural language processing, speech recognition, and integrated spoken language systems, as well as in theoretical linguistics. Annotated corpora promise to be valuable for enterprises as diverse as the automatic construction of statistical models for the grammar of the written and the colloquial spoken language, the development of explicit formal theories of the differing grammars of writing and speech, the investigation of prosodic phenomena in speech, and the evaluation and comparison of the adequacy of parsing models.In this paper, we review our experience with constructing one such large annotated corpus--the Penn Treebank, a corpus 1 consisting of over 4.5 million words of American English. During the first three-year phase of the Penn Treebank Project (1989)(1990)(1991)(1992), this corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure. These materials are available to members of the Linguistic Data Consortium; for details, see Section 5.1.The paper is organized as follows. Section 2 discusses the POS tagging task. After outlining the considerations that informed the design of our POS tagset and presenting the tagset itself, we describe our two-stage tagging process, in which text is first assigned POS tags automatically and then corrected by human annotators. Section 3 briefly presents the results of a comparison between entirely manual and semi-automated tagging, with the latter being shown to be superior on three counts: speed, consistency, and accuracy. In Section 4, we turn to the bracketing task. Just as with the tagging task, we have partially automated the bracketing task: the output of",
    "prev": "The warm-up period for DGC is 4 epochs out of164 epochs for Cifar10 and 4 epochs out of 90 epochs for ImageNet Dataset.",
    "curr": "Language Modeling The Penn Treebank corpus (PTB) dataset consists of 923,000 training, 73,000 validation and 82,000 test words (Marcus et al., 1993).",
    "next": "The vocabulary we select is the same as the one in Mikolov et al.",
    "hard_negative": [
      696805,
      3166885,
      2369736,
      12951757,
      5153623,
      2769726
    ],
    "easy_negative": [
      60467791,
      2664856,
      218470167
    ]
  },
  {
    "index": 3239,
    "source_corpus_id": 257279837,
    "ref_id": "b31",
    "citation_corpus_id": 3292002,
    "start": 5717,
    "end": 5742,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "Spatial GNNs.",
    "curr": "Spatial GNNs like GAT (Velickovic et al., 2018) and MPNN (Gilmer et al., 2017) leverage message passing to aggregate local information from neighborhoods.",
    "next": "By stacking multiple layers, spatial GNNs can possibly learn long-range dependencies but suffer from over-smoothing (Oono & Suzuki, 2020) and over-squashing (Topping et al., 2022).",
    "hard_negative": [
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      235097418,
      794463,
      15243221
    ]
  },
  {
    "index": 3240,
    "source_corpus_id": 237490346,
    "ref_id": "b58",
    "citation_corpus_id": 173990158,
    "start": 3950,
    "end": 3969,
    "title": "Multimodal Transformer for Unaligned Multimodal Language Sequences",
    "abstract": "Human language is often multimodal, which comprehends a mixture of natural language, facial gestures, and acoustic behaviors. However, two major challenges in modeling such multimodal human language time-series data exist: 1) inherent data non-alignment due to variable sampling rates for the sequences from each modality; and 2) long-range dependencies between elements across modalities. In this paper, we introduce the Multimodal Transformer (MulT) to generically address the above issues in an end-to-end manner without explicitly aligning the data. At the heart of our model is the directional pairwise crossmodal attention, which attends to interactions between multimodal sequences across distinct time steps and latently adapt streams from one modality to another. Comprehensive experiments on both aligned and non-aligned multimodal time-series show that our model outperforms state-of-the-art methods by a large margin. In addition, empirical analysis suggests that correlated crossmodal signals are able to be captured by the proposed crossmodal attention mechanism in MulT.",
    "prev": "However, the current CNNs-based methods are not robust to the generated noisy pseudo labels for accurate domain alignment (Morerio et al., 2020;Jiang et al., 2020).",
    "curr": "With the success of Transformer in natural language processing (NLP) (Vaswani et al., 2017;Devlin et al., 2018) and vision tasks (Dosovitskiy et al., 2020;He et al., 2021;Khan et al., 2021), it is found that cross-attention in Transformer is good at aligning different distributions, even from different modalities e.g., vision-to-vision (Li et al., 2021e), vision-to-text (Tsai et al., 2019;Hu & Singh, 2021) and text-to-speech .",
    "next": "And we find that it is robust to noise in pseudo labels to some extent.",
    "hard_negative": [
      13747425,
      51868869,
      51991738,
      14068874,
      46895984,
      5068376,
      1957433,
      23583643,
      52892477
    ],
    "easy_negative": [
      202542870,
      9768072,
      2111612
    ]
  },
  {
    "index": 3242,
    "source_corpus_id": 3457087,
    "ref_id": "b17",
    "citation_corpus_id": 14911774,
    "start": 3293,
    "end": 3316,
    "title": "MULTI-AGENT COOPERATION AND THE EMERGENCE OF (NATURAL) LANGUAGE",
    "abstract": "The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the \"word meanings\" induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents' code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively. * Work done while at Facebook AI Research.The central problem of our program, then, is the following: How do we design environments that foster the development of a language that is portable to new situations and to new communication partners (in particular humans)?We start from the most basic challenge of using a language in order to refer to things in the context of a two-agent game. We focus on two questions. First, whether tabula rasa agents succeed in communication. Second, what features of the environment lead to the development of codes resembling human language.We assess this latter question in two ways. First, we consider whether the agents associate general conceptual properties, such as broad object categories (as opposed to low-level visual properties), to the symbols they learn to use. Second, we examine whether the agents' \"word usage\" is partially interpretable by humans in an online experiment.Other researchers have proposed communication-based environments for the development of coordination-capable AI. Work in multi-agent systems has focused on the design of pre-programmed communication systems to solve specific tasks (e.g., robot soccer, Stone & Veloso 1998). Most related to our work,Sukhbaatar et al. (2016) andFoerster et al. (2016)show that neural networks can evolve communication in the context of games without a pre-coded protocol. We pursue the same question, but further ask how we can change our environment to make the emergent language more interpretable.Others (e.g., the SHRLDU program of Winograd 1971 or the game inWang et al. 2016)propose building a communicating AI by putting humans in the loop from the very beginning. This approach has benefits but faces serious scalability issues, as active human intervention is required at each step. An attractive component of our game-based paradigm is that humans may be added as players, but do not need to be there all the time.",
    "prev": "Recently, there have been several notable works that demonstrated the emergence of communication between neural network agents.",
    "curr": "Even though each work produced very interesting results of its own, in all cases, communication was either achieved with a single discrete symbol (as opposed to a sequence of discrete symbols) (Foerster et al., 2016;Lazaridou et al., 2017) or via a continuous value (Sukhbaatar et al., 2016;Jorge et al., 2016).",
    "next": "Not only is human communication un-differentiable, but also using a single discrete symbol is quite far from natural language communication.",
    "hard_negative": [
      6308361,
      2705742
    ],
    "easy_negative": [
      210813,
      227230317,
      3076637
    ]
  },
  {
    "index": 3244,
    "source_corpus_id": 211133221,
    "ref_id": "b1",
    "citation_corpus_id": 5076191,
    "start": 9958,
    "end": 9980,
    "title": "Generating Natural Language Adversarial Examples",
    "abstract": "Deep neural networks (DNNs) are vulnerable to adversarial examples, perturbations to correctly classified examples which can cause the model to misclassify. In the image domain, these perturbations are often virtually indistinguishable to human perception, causing humans and state-of-the-art models to disagree. However, in the natural language domain, small perturbations are clearly perceptible, and the replacement of a single word can drastically alter the semantics of the document. Given these challenges, we use a black-box population-based optimization algorithm to generate semantically and syntactically similar adversarial examples that fool well-trained sentiment analysis and textual entailment models with success rates of 97% and 70%, respectively. We additionally demonstrate that 92.3% of the successful sentiment analysis adversarial examples are classified to their original label by 20 human annotators, and that the examples are perceptibly quite similar. Finally, we discuss an attempt to use adversarial training as a defense, but fail to yield improvement, demonstrating the strength and diversity of our adversarial examples. We hope our findings encourage researchers to pursue improving the robustness of DNNs in the natural language domain.",
    "prev": "Self-attentive models are also useful beyond NLP, including VisualBERT on vision and language applications (Li et al., 2019b;Su et al., 2019), image transformer for image generation (Parmar et al., 2018), acoustic models for speech recognition, sequential recommendation (Kang & McAuley, 2018) and graph embedding (Li et al., 2019a).",
    "curr": "The robustness of NLP models has been studied, especially many methods have been proposed to generate adversarial examples (Papernot et al., 2016;Jia & Liang, 2017;Zhao et al., 2017;Alzantot et al., 2018;Ebrahimi et al., 2018;Shi et al., 2019).",
    "next": "In particular,  showed that Transformers are more robust than LSTMs.",
    "hard_negative": [
      9059612,
      7228830,
      604334,
      3488815,
      34032948,
      4302773,
      1957433,
      4956100,
      3513418,
      1428702,
      6706414
    ],
    "easy_negative": [
      203905467,
      2884642,
      259370790
    ]
  },
  {
    "index": 3245,
    "source_corpus_id": 224726548,
    "ref_id": "b30",
    "citation_corpus_id": 13123084,
    "start": 2428,
    "end": 2448,
    "title": "Published as a conference paper at ICLR 2017 TEMPORAL ENSEMBLING FOR SEMI-SUPERVISED LEARNING",
    "abstract": "In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels.",
    "prev": "1 To name a few, BERT (Devlin et al., 2019): 340M parameters, T5 (Raffel et al., 2019): 11B parameters, GPT-3 (Brown et al., 2020): 175B parameters.",
    "curr": "INTRODUCTION\n\nData augmentation approaches have successfully improved large-scale neural-network-based models, (Laine & Aila, 2017;Xie et al., 2019;Berthelot et al., 2019;Sohn et al., 2020;Khosla et al., 2020;Chen et al., 2020b), however, the majority of existing research is geared towards computer vision tasks.",
    "next": "The discrete nature of natural language makes it challenging to design effective label-preserving transformations for text sequences that can help improve model generalization Xie et al., 2019).",
    "hard_negative": [
      1965764,
      2780493,
      6230637,
      9398766,
      1487550
    ],
    "easy_negative": [
      3176110,
      252819431,
      12292453
    ]
  },
  {
    "index": 3246,
    "source_corpus_id": 211107043,
    "ref_id": "b36",
    "citation_corpus_id": 15603670,
    "start": 2208,
    "end": 2231,
    "title": "Learning Text Similarity with Siamese Recurrent Networks",
    "abstract": "This paper presents a deep architecture for learning a similarity metric on variablelength character sequences. The model combines a stack of character-level bidirectional LSTM's with a Siamese architecture. It learns to project variablelength strings into a fixed-dimensional embedding space by using only information about the similarity between pairs of strings. This model is applied to the task of job title normalization based on a manually annotated taxonomy. A small data set is incrementally expanded and augmented with new sources of variance. The model learns a representation that is selective to differences in the input that reflect semantic differences (e.g., \"Java developer\" vs. \"HR manager\") but also invariant to nonsemantic string differences (e.g., \"Java developer\" vs. \"Java programmer\").",
    "prev": "Our experiments show that our approach is competitive to the other baselines and yields a similar or better speed-vs-accuracy tradeoff on practical datasets 1 .",
    "curr": "INTRODUCTION\n\nLearning semantic representations using deep neural networks (DNN) is now a fundamental facet of applications ranging from visual search (Jing et al., 2015;Hadi Kiapour et al., 2015), semantic text matching (Neculoiu et al., 2016), oneshot classification (Koch et al., 2015), clustering (Oh Song et al., 2017), and recommendation (Shankar et al., 2017).",
    "next": "The high-dimensional dense embeddings generated from DNNs however pose a computational challenge for performing nearest neighbor search in large-scale problems with millions of instances.",
    "hard_negative": [
      17560995,
      15874232,
      1957433,
      931054
    ],
    "easy_negative": [
      12627600,
      17472619,
      164849551
    ]
  },
  {
    "index": 3249,
    "source_corpus_id": 17267607,
    "ref_id": "b23",
    "citation_corpus_id": 14124313,
    "start": 13296,
    "end": 13324,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "The code necessary for generating EEG images and building and training the networks discussed in this paper is available online 2 .",
    "curr": "CONVNET ARCHITECTURE\n\nWe adopted an architecture mimicking the VGG network used in Imagenet classification challenge (Simonyan & Zisserman, 2015).",
    "next": "This network enjoys a highly scalable architecture which uses stacked convolutional layers with small receptive fields.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      235097588,
      21706240,
      11808
    ]
  },
  {
    "index": 3253,
    "source_corpus_id": 256662685,
    "ref_id": "b20",
    "citation_corpus_id": 14124313,
    "start": 13118,
    "end": 13146,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "The AUROC reflects the distinction quality of two uncertainty distributions.",
    "curr": "We adopt VGG13 (Simonyan & Zisserman, 2015) and ResNet50 (He et al., 2016) as the network backbone in the image domain and TSM (Lin et al., 2019) and I3D (Carreira & Zisserman, 2017) in the video domain.",
    "next": "More experiment settings are in Appendix E.\n\nResults.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      235390569,
      16914752,
      15089521
    ]
  },
  {
    "index": 3254,
    "source_corpus_id": 232013680,
    "ref_id": "b60",
    "citation_corpus_id": 214184365,
    "start": 4208,
    "end": 4224,
    "title": "Published as a conference paper at ICLR 2020 PC-DARTS: PARTIAL CHANNEL CONNECTIONS FOR MEMORY-EFFICIENT ARCHITECTURE SEARCH",
    "abstract": "Differentiable architecture search (DARTS) provided a fast solution in finding effective network architectures, but suffered from large memory and computing overheads in jointly training a super-network and searching for an optimal architecture. In this paper, we present a novel approach, namely, Partially-Connected DARTS, by sampling a small part of super-network to reduce the redundancy in exploring the network space, thereby performing a more efficient search without comprising the performance. In particular, we perform operation search in a subset of channels while bypassing the held out part in a shortcut. This strategy may suffer from an undesired inconsistency on selecting the edges of super-net caused by sampling different channels. We alleviate it using edge normalization, which adds a new set of edge-level parameters to reduce uncertainty in search. Thanks to the reduced memory cost, PC-DARTS can be trained with a larger batch size and, consequently, enjoys both faster speed and higher training stability. Experimental results demonstrate the effectiveness of the proposed method. Specifically, we achieve an error rate of 2.57% on CIFAR10 with merely 0.1 GPU-days for architecture search, and a state-of-the-art top-1 error rate of 24.2% on ImageNet (under the mobile setting) using 3.8 GPU-days for search. Our code has been made available at https://github.com/yuhuixu1993/PC-DARTS.",
    "prev": "However, these NAS algorithms suffer from heavy consumption of both time and GPU resources.",
    "curr": "Training a supernet till convergence is extremely slow, even with many effective heuristics for sampling or channel approximations (Dong & Yang, 2019;Xu et al., 2019).",
    "next": "Approximated proxy inference such as truncated training/early stopping can accelerate the search, but is well known to introduce search bias to the inaccurate results obtained (Pham et al., 2018;.",
    "hard_negative": [
      49411844,
      6628106,
      14124313,
      23873820,
      56895416,
      54438210,
      50773706,
      12713052,
      3489117
    ],
    "easy_negative": [
      9297900,
      7793139,
      234335834
    ]
  },
  {
    "index": 3262,
    "source_corpus_id": 53218829,
    "ref_id": "b9",
    "citation_corpus_id": 1294169,
    "start": 5456,
    "end": 5480,
    "title": "The Second Dialog State Tracking Challenge",
    "abstract": "A spoken dialog system, while communicating with a user, must keep track of what the user wants from the system at each step. This process, termed dialog state tracking, is essential for a successful dialog system as it directly informs the system's actions. The first Dialog State Tracking Challenge allowed for evaluation of different dialog state tracking techniques, providing common testbeds and evaluation suites. This paper presents a second challenge, which continues this tradition and introduces some additional features -a new domain, changing user goals and a richer dialog state. The challenge received 31 entries from 9 research groups. The results suggest that while large improvements on a competitive baseline are possible, trackers are still prone to degradation in mismatched conditions. An investigation into ensemble learning demonstrates the most accurate tracking can be achieved by combining multiple trackers.",
    "prev": "For example, popular chit-chat datasets such as Open-Subtitles (Vinyals & Le, 2015), Persona-Chat (Zhang et al., 2018) and Twitter (Sordoni et al., 2015) have tested the ability of sequence-to-sequence models that attend over the recent dialogue history, but do not attempt to recall long-term knowledge beyond encoding it directly into the weights of the feed-forward network.",
    "curr": "In the area of goal-directed dialogue, separate from open domain chit-chat, such as airline (El Asri et al., 2017) or restaurant booking (Henderson et al., 2014;, knowledge conditioning is typically employed by allowing access to a database through API calls or otherwise.",
    "next": "In contrast, our work investigates unstructured knowledge across a large, diverse set of topics potentially spanning all of Wikipedia.",
    "hard_negative": [
      10250499,
      10079468,
      8109232
    ],
    "easy_negative": [
      249192211,
      259075202,
      41769338
    ]
  },
  {
    "index": 3266,
    "source_corpus_id": 235254386,
    "ref_id": "b29",
    "citation_corpus_id": 67855860,
    "start": 3205,
    "end": 3208,
    "title": "Attention is not Explanation",
    "abstract": "Attention mechanisms have seen wide adoption in neural NLP models. In addition to improving predictive performance, these are often touted as affording transparency: models equipped with attention provide a distribution over attended-to input units, and this is often presented (at least implicitly) as communicating the relative importance of inputs. However, it is unclear what relationship exists between attention weights and model outputs. In this work we perform extensive experiments across a variety of NLP tasks that aim to assess the degree to which attention weights provide meaningful \"explanations\" for predictions. We find that they largely do not. For example, learned attention weights are frequently uncorrelated with gradient-based measures of feature importance, and one can identify very different attention distributions that nonetheless yield equivalent predictions. Our findings show that standard attention modules do not provide meaningful explanations and should not be treated as though they do. Code to reproduce all experiments is available at https://github.com/successar/ AttentionExplanation.",
    "prev": "There has been active research into the shortcomings of explainability methods (e.g.",
    "curr": "[1,30,61,70,84]) and determining when attention can be used as an explanation [84].",
    "next": "While these methods focus on information that already exists in the data, either by weighting features or concepts in training examples or by selecting important training examples, recent progress in generative models [12,29,36,40,45] has lead to another family of explainability methods that provide explanations by generating new examples or features [14,32,68,73].",
    "hard_negative": [
      990233,
      8495258,
      12664997,
      7205805,
      51979567,
      52113465,
      5509327,
      1428702,
      982761
    ],
    "easy_negative": [
      5555941,
      257378449,
      202774000
    ]
  },
  {
    "index": 3271,
    "source_corpus_id": 232273772,
    "ref_id": "b3",
    "citation_corpus_id": 54203451,
    "start": 2017,
    "end": 2041,
    "title": "SYSTEMATIC GENERALIZATION: WHAT IS REQUIRED AND CAN IT BE LEARNED?",
    "abstract": "Numerous models for grounded language understanding have been recently proposed, including (i) generic models that can be easily adapted to any given task with little adaptation and (ii) intuitively appealing modular models that require background knowledge to be instantiated. We compare both types of models in how much they lend themselves to a particular form of systematic generalization. Using a synthetic VQA test, we evaluate which models are capable of reasoning about all possible object pairs after training on only a small subset of them. Our findings show that the generalization of modular models is much more systematic and that it is highly sensitive to the module layout, i.e. to how exactly the modules are connected. We furthermore investigate if modular models that generalize well could be made more end-to-end by learning their layout and parametrization. We find that end-to-end methods from prior work often learn a wrong layout and a spurious parametrization that do not facilitate systematic generalization. Our results suggest that, in addition to modularity, systematic generalization in language understanding may require explicit regularizers or priors.",
    "prev": "We demonstrate superior performance in recovering ground-truth compositional program structure with limited supervision on both SHAPES-SyGeT and CLEVR.",
    "curr": "INTRODUCTION\n\nAlthough great progress has been made in visual question-answering (VQA), recent methods still struggle to generalize systematically to inputs coming from a distribution different from that seen during training (Bahdanau et al., 2019b;a).",
    "next": "Neural module networks (NMNs) present a natural solution to improve generalization in VQA, using a symbolic layout or program to arrange neural computational modules into computation graphs.",
    "hard_negative": [
      52116963,
      20472740,
      12304778,
      4537113,
      7228830
    ],
    "easy_negative": [
      257280201,
      5357119,
      17479603
    ]
  },
  {
    "index": 3277,
    "source_corpus_id": 3000562,
    "ref_id": "b12",
    "citation_corpus_id": 2922805,
    "start": 9221,
    "end": 9237,
    "title": "BLACKOUT: SPEEDING UP RECURRENT NEURAL NET- WORK LANGUAGE MODELS WITH VERY LARGE VO- CABULARIES",
    "abstract": "We propose BlackOut, an approximation algorithm to efficiently train massive recurrent neural network language models (RNNLMs) with million word vocabularies. BlackOut is motivated by using a discriminative loss, and we describe a weighted sampling strategy which significantly reduces computation while improving stability, sample efficiency, and rate of convergence. One way to understand BlackOut is to view it as an extension of the DropOut strategy to the output layer, wherein we use a discriminative training loss and a weighted sampling scheme. We also establish close connections between BlackOut, importance sampling, and noise contrastive estimation (NCE). Our experiments, on the recently released one billion word language modeling benchmark, demonstrate scalability and accuracy of BlackOut; we outperform the state-of-the art, and achieve the lowest perplexity scores on this dataset. Moreover, unlike other established methods which typically require GPUs or CPU clusters, we show that a carefully implemented version of BlackOut requires only 1-10 days on a single machine to train a RNNLM with a million word vocabulary and billions of parameters on one billion words. Although we describe BlackOut in the context of RNNLM training, it can be used to any networks with large softmax output layers.",
    "prev": "Consequently, the dimensions of k t , v t and p t are 100 for a hidden dimension of 300.",
    "curr": "N -GRAM RECURRENT NEURAL NETWORK\n\nNeural language models often work best in combination with traditional N -gram models (Mikolov et al., 2011;Chelba et al., 2013;Williams et al., 2015;Ji et al., 2016;Shazeer et al., 2015), since the former excel at generalization while the latter ensure memorization.",
    "next": "In addition, from initial experiments with memory-augmented neural language models, we found that usually only the previous five output representations are utilized.",
    "hard_negative": [
      2863491,
      289313,
      7417943,
      12469208
    ],
    "easy_negative": [
      219304584,
      222133374,
      216144503
    ]
  },
  {
    "index": 3282,
    "source_corpus_id": 207870430,
    "ref_id": "b0",
    "citation_corpus_id": 52892477,
    "start": 4219,
    "end": 4240,
    "title": "ADAPTIVE INPUT REPRESENTATIONS FOR NEURAL LANGUAGE MODELING",
    "abstract": "We introduce adaptive input representations for neural language modeling which extend the adaptive softmax ofGrave et al. (2017)to input representations of variable capacity. There are several choices on how to factorize the input and output layers, and whether to model words, characters or sub-word units. We perform a systematic comparison of popular choices for a self-attentional architecture. Our experiments show that models equipped with adaptive embeddings are more than twice as fast to train than the popular character input CNN while having a lower number of parameters. On the WIKITEXT-103 benchmark we achieve 18.7 perplexity, an improvement of 10.5 perplexity compared to the previously best published result and on the BILLION WORD benchmark, we achieve 23.02 perplexity. 1",
    "prev": "To better measure these effects, we conduct an extensive empirical evaluation.",
    "curr": "Applying our kNN augmentation to a strong WIKITEXT-103 LM using only the original dataset achieves a new stateof-the-art perplexity of 15.79 -a 2.86 point improvement over the base model (Baevski & Auli, 2019) -with no additional training.",
    "next": "We also show that the approach has implications for efficiently scaling up to larger training sets and allows for effective domain adaptation, by simply varying the nearest neighbor datastore.",
    "hard_negative": [
      3065236,
      6035643,
      900029,
      44131019,
      3834706,
      15095390,
      836219
    ],
    "easy_negative": [
      774866,
      28178914,
      5608910
    ]
  },
  {
    "index": 3284,
    "source_corpus_id": 252683782,
    "ref_id": "b3",
    "citation_corpus_id": 53216818,
    "start": 10595,
    "end": 10615,
    "title": "Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control",
    "abstract": "We propose a \"plan online and learn offline\" framework for the setting where an agent, with an internal model, needs to continually act and learn in the world. Our work builds on the synergistic relationship between local model-based control, global value function learning, and exploration. We study how local trajectory optimization can cope with approximation errors in the value function, and can stabilize and accelerate value function learning. Conversely, we also study how approximate value functions can help reduce the planning horizon and allow for better policies beyond local solutions. Finally, we also demonstrate how trajectory optimization can be used to perform temporally coordinated exploration in conjunction with estimating uncertainty in value function approximation. This exploration is critical for fast and stable learning of the value function. Combining these components enable solutions to complex control tasks, like humanoid locomotion and dexterous in-hand manipulation, in the equivalent of a few minutes of experience in the real world.",
    "prev": "Competence-based methods learn an explicit skill vector by maximizing the mutual information between the observation and skills (Campos et al., 2020;Eysenbach et al., 2019;Gregor et al., 2017).",
    "curr": "Model-based reinforcement learning (MBRL) leverages a learned dynamic model of the environment to plan a sequence of actions in advance which augment the data (Sutton, 1991;Janner et al., 2019;Pan et al., 2020;Mu et al., 2020;Peng et al., 2021) or obtain the desired behavior through planning (Chua et al., 2018;Hafner et al., 2019;Lowrey et al., 2019;Chen et al., 2022).",
    "next": "However, training the world model requires a large number of samples (Polydoros & Nalpantidis, 2017;Plaat et al., 2021), and an imprecise model can lead to low-quality decisions for imaginary planning (Freeman et al., 2019).",
    "hard_negative": [
      997870,
      3075448
    ],
    "easy_negative": [
      256460982,
      6275358,
      256461322
    ]
  },
  {
    "index": 3288,
    "source_corpus_id": 248300043,
    "ref_id": "b8",
    "citation_corpus_id": 54101493,
    "start": 2368,
    "end": 2390,
    "title": "IMAGENET-TRAINED CNNS ARE BIASED TOWARDS TEXTURE; INCREASING SHAPE BIAS IMPROVES ACCURACY AND ROBUSTNESS",
    "abstract": "Convolutional Neural Networks (CNNs) are commonly thought to recognise objects by learning increasingly complex representations of object shapes. Some recent studies suggest a more important role of image textures. We here put these conflicting hypotheses to a quantitative test by evaluating CNNs and human observers on images with a texture-shape cue conflict. We show that ImageNettrained CNNs are strongly biased towards recognising textures rather than shapes, which is in stark contrast to human behavioural evidence and reveals fundamentally different classification strategies. We then demonstrate that the same standard architecture (ResNet-50) that learns a texture-based representation on ImageNet is able to learn a shape-based representation instead when trained on 'Stylized-ImageNet', a stylized version of ImageNet. This provides a much better fit for human behavioural performance in our well-controlled psychophysical lab setting (nine experiments totalling 48,560 psychophysical trials across 97 observers) and comes with a number of unexpected emergent benefits such as improved object detection performance and previously unseen robustness towards a wide range of image distortions, highlighting advantages of a shape-based representation. de Beeck. Deep neural networks as a computational model for human shape sensitivity. DiCarlo. Performance-optimized hierarchical models predict neural responses in higher visual cortex.",
    "prev": "As fueled by powerful computational resources and massive amounts of data, deep networks achieve compelling, sometimes even superhuman, performance on a wide range of visual benchmarks.",
    "curr": "However, when testing out of the box, these exemplary models are usually get criticized for lacking generalization/robustness-an increasing amount of works point out that deep neural networks are brittle at handling out-of-domain situations like natural image corruptions (Hendrycks & Dietterich, 2018), images with shifted styles (Geirhos et al., 2018;Hendrycks et al., 2020), etc.",
    "next": "Adversarial propagation (AdvProp) , which additionally feeds networks with adversarial examples during training, emerged as one of the most effective ways to train not only accurate but also robust deep neural networks.",
    "hard_negative": [
      56657912,
      68222714
    ],
    "easy_negative": [
      252433181,
      186768247,
      235417102
    ]
  },
  {
    "index": 3294,
    "source_corpus_id": 248218711,
    "ref_id": "b17",
    "citation_corpus_id": 3144218,
    "start": 1849,
    "end": 1871,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "This paper studies node classification, a fundamental problem in the machine learning community.",
    "curr": "Most existing efforts focus on the transductive setting (Kipf & Welling, 2017;Veli\u010dkovi\u0107 et al., 2018), i.e., using a small set of labeled nodes in a graph to classify the rest of nodes.",
    "next": "In this paper, we study node classification in the inductive setting (Hamilton et al., 2017), which is receiving growing interest.",
    "hard_negative": [
      8393918,
      17682909
    ],
    "easy_negative": [
      244067281,
      220047076,
      212644640
    ]
  },
  {
    "index": 3298,
    "source_corpus_id": 247411040,
    "ref_id": "b13",
    "citation_corpus_id": 3292002,
    "start": 11688,
    "end": 11712,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "See Appendix B.1 for a proof.",
    "curr": "Theorem 1 also reveals that no matter how attention is computed inside the softmax function, including dot product (Vaswani et al., 2017), linear combination (Veli\u010dkovi\u0107 et al., 2018), or L2 distance (Kim et al., 2021, the resulting attention matrix is always a low-pass filter.",
    "next": "One can see consecutively applying self-attention matrix simulates the process of ViT's forward propagation.",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      59608662,
      7754497,
      2777329
    ]
  },
  {
    "index": 3303,
    "source_corpus_id": 4535830,
    "ref_id": "b14",
    "citation_corpus_id": 15412473,
    "start": 2554,
    "end": 2575,
    "title": "Language to Logical Form with Neural Attention",
    "abstract": "Semantic parsing aims at mapping natural language to machine interpretable meaning representations. Traditional approaches rely on high-quality lexicons, manually-built templates, and linguistic features which are either domainor representation-specific. In this paper we present a general method based on an attention-enhanced encoder-decoder model. We encode input utterances into vector representations, and generate their logical forms by conditioning the output sequences or trees on the encoding vectors. Experimental results on four datasets show that our approach performs competitively without using hand-engineered features and is easy to adapt across domains and meaning representations.",
    "prev": "The system we present here illustrates how end-to-end learning and scalability can be made possible through a symbolic knowledge storage.",
    "curr": "INTRODUCTION\n\nAlthough there is a great deal of recent research on extracting structured knowledge from text (Dong et al., 2014;Mitchell et al., 2015) and answering questions from structured knowledge stores (Dong & Lapata, 2016;Jia & Liang, 2016;, much less progress has been made on either the problem of unifying these approaches in an end-to-end model or the problem of removing the bottleneck of relying on human experts to design the schema and annotate examples for information extraction.",
    "next": "In particular, traditional natural language processing and information extraction approaches are too labor-intensive and brittle for answering open domain questions from large corpus, and existing end-to-end deep QA models (e.g., (Miller et al., 2016;Weston et al., 2014)) lack scalability and the ability to integrate domain knowledge.",
    "hard_negative": [
      2863491,
      5667590,
      15324422,
      8674440,
      2046600,
      1140108,
      1964946,
      1245593,
      146843,
      12728987,
      9337134,
      12639289,
      2916543,
      6228816,
      245587,
      8597719,
      5633240,
      2036954,
      1918428,
      5590763,
      10983275,
      16088818,
      11212020,
      8045822,
      7785983
    ],
    "easy_negative": [
      555420,
      43390,
      225076222
    ]
  },
  {
    "index": 3305,
    "source_corpus_id": 257102959,
    "ref_id": "b6",
    "citation_corpus_id": 44157913,
    "start": 2438,
    "end": 2455,
    "title": "A Survey of Domain Adaptation for Neural Machine Translation",
    "abstract": "Neural machine translation (NMT) is a deep learning based approach for machine translation, which yields the state-of-the-art translation performance in scenarios where large-scale parallel corpora are available. Although the high-quality and domain-specific translation is crucial in the real world, domain-specific corpora are usually scarce or nonexistent, and thus vanilla NMT performs poorly in such scenarios. Domain adaptation that leverages both out-of-domain parallel corpora as well as monolingual corpora for in-domain translation, is very important for domainspecific translation. In this paper, we give a comprehensive survey of the state-of-the-art domain adaptation techniques for NMT.",
    "prev": "INTRODUCTION\n\nDomain adaptation is one of the fundamental challenges in machine learning which aspires to cope with the discrepancy across domain distributions and improve the generality of the trained models.",
    "curr": "It has attracted wide attention in the neural machine translation (NMT) area (Britz et al., 2017;Chu & Wang, 2018;Wei et al., 2020).",
    "next": "Recently, kNN-MT and its variants (Khandelwal et al., 2021;Zheng et al., 2021a;b;Wang et al., 2022a) provide a new paradigm and have achieved remarkable performance for fast domain adaptation by retrieval pipelines.",
    "hard_negative": [
      7930242,
      2863491,
      948101,
      10086161,
      7921428,
      1245593,
      14565147,
      35167387,
      7026589,
      35290014,
      33854118,
      37405481,
      630188,
      9990193,
      19164342,
      256189,
      928331,
      6996688,
      16406099,
      6359641,
      61274,
      22006749,
      6053988,
      46719720,
      5590763,
      8793195,
      10766958,
      61947758,
      16631020,
      8170227,
      15036406
    ],
    "easy_negative": [
      10899851,
      16052100,
      196096
    ]
  },
  {
    "index": 3307,
    "source_corpus_id": 202888986,
    "ref_id": "b40",
    "citation_corpus_id": 3626819,
    "start": 5793,
    "end": 5813,
    "title": "Deep contextualized word representations",
    "abstract": "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pretrained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
    "prev": "Existing solutions to the aforementioned problems include model parallelization (Shazeer et al., 2018;Shoeybi et al., 2019) and clever memory management (Chen et al., 2016;.",
    "curr": "RELATED WORK\n\n\nSCALING UP REPRESENTATION LEARNING FOR NATURAL LANGUAGE\n\nLearning representations of natural language has been shown to be useful for a wide range of NLP tasks and has been widely adopted (Mikolov et al., 2013;Le & Mikolov, 2014;Dai & Le, 2015;Peters et al., 2018;Radford et al., 2018;.",
    "next": "One of the most significant changes in the last two years is the shift from pre-training word embeddings, whether standard (Mikolov et al., 2013;Pennington et al., 2014) or contextualized (McCann et al., 2017;Peters et al., 2018), to full-network pre-training followed by task-specific fine-tuning (Dai & Le, 2015;Radford et al., 2018;.",
    "hard_negative": [
      6300165,
      6628106,
      41479182,
      8535316,
      11336213,
      9917468,
      20472740,
      34032948,
      10489017,
      1222212,
      12688069,
      15026764,
      1689426,
      7100502,
      16039645,
      2486369,
      207556454,
      33626727,
      629094,
      9163756,
      15251438,
      3202289,
      6042994,
      12501880,
      252796
    ],
    "easy_negative": [
      209319301,
      5674153,
      752623
    ]
  },
  {
    "index": 3310,
    "source_corpus_id": 17732879,
    "ref_id": "b3",
    "citation_corpus_id": 806709,
    "start": 8864,
    "end": 8884,
    "title": "Semantic Compositionality through Recursive Matrix-Vector Spaces",
    "abstract": "Single-word vector space models have been very successful at learning lexical information. However, they cannot capture the compositional meaning of longer phrases, preventing them from a deeper understanding of language. We introduce a recursive neural network (RNN) model that learns compositional vector representations for phrases and sentences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to every node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the meaning of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying sentiment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syntactic path between them.",
    "prev": "To the best of our knowledge, our work is the first to learn embeddings for discontinuous linguistic units.",
    "curr": "An alternative to learning an embedding for a linguistic unit is to calculate its distributed representation from the distributed representations of its parts; the best known work along those lines is (Socher et al., 2012(Socher et al., , 2010(Socher et al., , 2011.",
    "next": "This approach is superior for units that are compositional, i.e., whose properties are systematically predictable from their parts.",
    "hard_negative": [
      5584134,
      7747235,
      17121460,
      436023,
      2678583,
      8360910,
      6430811,
      3264224,
      15698938
    ],
    "easy_negative": [
      15386883,
      6353943,
      30451912
    ]
  },
  {
    "index": 3312,
    "source_corpus_id": 211092828,
    "ref_id": "b2",
    "citation_corpus_id": 51979536,
    "start": 8036,
    "end": 8055,
    "title": "Large-Scale Study of Curiosity-Driven Learning",
    "abstract": "Reinforcement learning algorithms rely on carefully engineering environment rewards that are extrinsic to the agent. However, annotating each environment with hand-designed, dense rewards is not scalable, motivating the need for developing reward functions that are intrinsic to the agent. Curiosity is a type of intrinsic reward function which uses prediction error as reward signal. In this paper: (a) We perform the first large-scale study of purely curiosity-driven learning, i.e. without any extrinsic rewards, across 54 standard benchmark environments, including the Atari game suite. Our results show surprisingly good performance, and a high degree of alignment between the intrinsic curiosity objective and the handdesigned extrinsic rewards of many game environments. (b) We investigate the effect of using different feature spaces for computing prediction error and show that random features are sufficient for many popular RL game benchmarks, but learned features appear to generalize better (e.g. to novel game levels in Super Mario Bros.). (c) We demonstrate limitations of the prediction-based rewards in stochastic setups. Game-play videos and code are at https://pathak22.github. io/large-scale-curiosity/. * Alphabetical ordering; the first three authors contributed equally.Preprint. Work in progress.",
    "prev": "the difference between the predicted and actual value of some function computed on the current state, the taken action, etc.",
    "curr": "(Barto, 2013;Oudeyer et al., 2007;Bellemare et al., 2016); intrinsic motivation can even be used on its own when no extrinsic reward is provided (Pathak et al., 2017;Burda et al., 2019;Haber et al., 2018).",
    "next": "A separate line of work studies how agents can synthesize a library of skills via intrinsic motivation in the absence of extrinsic rewards (Eysenbach et al., 2019).",
    "hard_negative": [
      12256925,
      5037032
    ],
    "easy_negative": [
      246607791,
      257154220,
      14558172
    ]
  },
  {
    "index": 3314,
    "source_corpus_id": 14016036,
    "ref_id": "b13",
    "citation_corpus_id": 7478738,
    "start": 1311,
    "end": 1334,
    "title": "Linguistic Regularities in Continuous Space Word Representations",
    "abstract": "Continuous space language models have recently demonstrated outstanding results across a variety of tasks. In this paper, we examine the vector-space word representations that are implicitly learned by the input-layer weights. We find that these representations are surprisingly good at capturing syntactic and semantic regularities in language, and that each relationship is characterized by a relation-specific vector offset. This allows vector-oriented reasoning based on the offsets between words. For example, the male/female relationship is automatically learned, and with the induced vector representations, \"King -Man + Woman\" results in a vector very close to \"Queen.\" We demonstrate that the word vectors capture syntactic regularities by means of syntactic analogy questions (provided with this paper), and are able to correctly answer almost 40% of the questions. We demonstrate that the word vectors capture semantic regularities by using the vector offset method to answer SemEval-2012 Task 2 questions. Remarkably, this method outperforms the best previous systems.",
    "prev": "INTRODUCTION\n\nWe are interested in algorithms for learning vector representations of words.",
    "curr": "Recent work has shown that such representations, also known as word embeddings, can successfully capture the semantic and syntactic regularities of words (Mikolov et al., 2013a) and improve the performance of various Natural Language Processing systems, including information extraction (Turian et al., 2010;Wang & Manning, 2013), parsing (Socher et al., 2013a), and semantic role labeling (Collobert et al., 2011).",
    "next": "Although many kinds of representation learning algorithms have been proposed so far, they are all essentially based on the same premise of distributional semantics (Harris, 1954), embodied by J. R. Firth's dictum: \"You shall know a word by the company it keeps.\"",
    "hard_negative": [
      252796,
      15637201
    ],
    "easy_negative": [
      195428710,
      239009574,
      33563145
    ]
  },
  {
    "index": 3316,
    "source_corpus_id": 255186085,
    "ref_id": "b47",
    "citation_corpus_id": 238215257,
    "start": 2329,
    "end": 2356,
    "title": "VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding",
    "abstract": "We present VideoCLIP, a contrastive approach to pre-train a unified model for zeroshot video and text understanding, without using any labels on downstream tasks. VideoCLIP trains a transformer for video and text by contrasting temporally overlapping positive video-text pairs with hard negatives from nearest neighbor retrieval. Our experiments on a diverse series of downstream tasks, including sequence-level text-video retrieval, VideoQA, token-level action localization, and action segmentation reveal state-ofthe-art performance, surpassing prior work, and in some cases even outperforming supervised approaches. Code is made available at https://github.com/pytorch/ fairseq/tree/main/examples/MMPT.",
    "prev": "\u2020 Equal contribution.",
    "curr": "Code Link: https://github.com/yyuncong/TempCLR\n\nINTRODUCTION\n\nRepresentation learning on videos has achieved success (Goroshin et al., 2015;Feichtenhofer et al., 2021) in detecting actions in short periods.",
    "next": "Recent work has extended it on video-text data (Miech et al., 2019;Radford et al., 2021) to learn a common feature space for zero-shot transfer.",
    "hard_negative": [
      222142276,
      204960716,
      232240219,
      215737187,
      207556454,
      52967399,
      235125628
    ],
    "easy_negative": [
      1036881,
      17822486,
      227231621
    ]
  },
  {
    "index": 3319,
    "source_corpus_id": 56895485,
    "ref_id": "b8",
    "citation_corpus_id": 3515219,
    "start": 4027,
    "end": 4049,
    "title": "UNSUPERVISED NEURAL MACHINE TRANSLATION",
    "abstract": "In spite of the recent success of neural machine translation (NMT) in standard benchmarks, the lack of large parallel corpora poses a major practical problem for many language pairs. There have been several proposals to alleviate this issue with, for instance, triangulation and semi-supervised learning techniques, but they still require a strong cross-lingual signal. In this work, we completely remove the need of parallel data and propose a novel method to train an NMT system in a completely unsupervised manner, relying on nothing but monolingual corpora. Our model builds upon the recent work on unsupervised embedding mappings, and consists of a slightly modified attentional encoder-decoder model that can be trained on monolingual corpora alone using a combination of denoising and backtranslation. Despite the simplicity of the approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014 French \u2192 English and German \u2192 English translation. The model can also profit from small parallel corpora, and attains 21.81 and 15.24 points when combined with 100,000 parallel sentences, respectively. Our approach is a breakthrough in unsupervised NMT, and opens exciting opportunities for future research.",
    "prev": "The language model could be trained from a separate (text) corpus in an unsupervised manner with the help of a pre-defined lexicon 1 .",
    "curr": "There have been some recent successes in developing fully unsupervised method for neural machine translation (Artetxe et al., 2018;Lample et al., 2018) and sequence classifications (Liu et al., 2017).",
    "next": "However, different from these problems, speech recognition problem has segmental structures that impose unique challenges for developing unsupervised learning algorithms.",
    "hard_negative": [
      1513472,
      6628106,
      8822680,
      13603998,
      1040556,
      2166461,
      9752897,
      5727182,
      11591887,
      1998416,
      6359641,
      12959203,
      6053988,
      5590763,
      26873455,
      11212020,
      12187767
    ],
    "easy_negative": [
      10396032,
      218974008,
      15235753
    ]
  },
  {
    "index": 3323,
    "source_corpus_id": 252683172,
    "ref_id": "b24",
    "citation_corpus_id": 253447215,
    "start": 2393,
    "end": 2409,
    "title": "Uni-Parser: Unified Semantic Parser for Question Answering on Knowledge Base and Database",
    "abstract": "Parsing natural language questions into executable logical forms is a useful and interpretable way to perform question answering on structured data such as knowledge bases (KB) or databases (DB). However, existing approaches on semantic parsing cannot adapt to both modalities, as they suffer from the exponential growth of the logical form candidates and can hardly generalize to unseen data. In this work, we propose Uni-Parser, a unified semantic parser for question answering (QA) on both KB and DB. We introduce the primitive (relation and entity in KB, and table name, column name and cell value in DB) as an essential element in our framework. The number of primitives grows linearly with the number of retrieved relations in KB and DB, preventing us from dealing with exponential logic form candidates. We leverage the generator to predict final logical forms by altering and composing topranked primitives with different operations (e.g. select, where, count). With sufficiently pruned search space by a contrastive primitive ranker, the generator is empowered to capture the composition of primitives enhancing its generalization ability. We achieve competitive results on multiple KB and DB QA benchmarks more efficiently, especially in the compositional and zero-shot settings.",
    "prev": "Existing methods can be divided into two categories.",
    "curr": "One category is based on semantic parsing, where models first parse the input question into a logical form (e.g., SPARQL (hommeaux, 2011) or S-expression (Gu et al., 2021)) then execute the logical form against knowledge bases to obtain the final answers (Das et al., 2021;Gu et al., 2021;Ye et al., 2022).",
    "next": "The other category of methods directly outputs answers without relying on the the logicalform executor (Lan et al., 2019;Sun et al., 2019;Saxena et al., 2022;Oguz et al., 2022).",
    "hard_negative": [
      3896491,
      53604363,
      1336493,
      6401679,
      53079601
    ],
    "easy_negative": [
      11212020,
      27804845,
      50781295
    ]
  },
  {
    "index": 3328,
    "source_corpus_id": 252222370,
    "ref_id": "b48",
    "citation_corpus_id": 237291550,
    "start": 2204,
    "end": 2223,
    "title": "SIMVLM: SIMPLE VISUAL LANGUAGE MODEL PRE- TRAINING WITH WEAK SUPERVISION",
    "abstract": "With recent progress in joint modeling of visual and textual representations, Vision-Language Pretraining (VLP) has achieved impressive performance on many multimodal downstream tasks. However, the requirement for expensive annotations including clean image captions and regional labels limits the scalability of existing approaches, and complicates the pretraining procedure with the introduction of multiple dataset-specific objectives. In this work, we relax these constraints and present a minimalist pretraining framework, named Simple Visual Language Model (SimVLM). Unlike prior work, SimVLM reduces the training complexity by exploiting large-scale weak supervision, and is trained end-to-end with a single prefix language modeling objective. Without utilizing extra data or task-specific customization, the resulting model significantly outperforms previous pretraining methods and achieves new state-of-the-art results on a wide range of discriminative and generative vision-language benchmarks, including VQA (+3.74% vqa-score), NLVR2 (+1.17% accuracy), SNLI-VE (+1.37% accuracy) and image captioning tasks (+10.1% average CIDEr score). Furthermore, we demonstrate that SimVLM acquires strong generalization and transfer ability, enabling zero-shot behavior including open-ended visual question answering and cross-modality transfer.",
    "prev": "We release our code and pre-trained CLIP-ViP models at https: //github.com/microsoft/XPretrain/tree/main/CLIP-ViP.",
    "curr": "INTRODUCTION\n\nIn the past few years, vision-language pre-training has achieved great success on cross-modal representation learning from a large scale of web-crawled data (Radford et al., 2021;Jia et al., 2021;Wang et al., 2021b;Zellers et al., 2021;Bain et al., 2021).",
    "next": "Among them, imagetext pre-trained models (Radford et al., 2021;Jia et al., 2021) have shown powerful capability for various downstream tasks, including visual understanding (Gu et al., 2021;Wang et al., 2021a;Rao et al., 2022) , image-text generation (Patashnik et al., 2021;Mokady et al., 2021) and so on (Guzhov et al., 2022;Zhang et al., 2022).",
    "hard_negative": [
      225039882,
      229924402
    ],
    "easy_negative": [
      8651801,
      250179953,
      18653017
    ]
  },
  {
    "index": 3331,
    "source_corpus_id": 210180949,
    "ref_id": "b15",
    "citation_corpus_id": 53299978,
    "start": 2210,
    "end": 2230,
    "title": "On Evaluating the Generalization of LSTM Models in Formal Languages",
    "abstract": "Recurrent Neural Networks (RNNs) are theoretically Turing-complete and established themselves as a dominant model for language processing. Yet, there still remains an uncertainty regarding their language learning capabilities. In this paper, we empirically evaluate the inductive learning capabilities of Long Short-Term Memory networks, a popular extension of simple RNNs, to learn simple formal languages, in particular a n b n , a n b n c n , and a n b n c n d n . We investigate the influence of various aspects of learning, such as training data regimes and model capacity, on the generalization to unobserved samples. We find striking differences in model performances under different training settings and highlight the need for careful analysis and assessment when making claims about the learning capabilities of neural network models. 1",
    "prev": "In our quest to mimic intelligence, we have put much faith in neural networks, which in turn has provided unparalleled and often superhuman performance in tasks requiring high cognitive abilities (Silver et al., 2016;Devlin et al., 2018;OpenAI et al., 2018).",
    "curr": "However, when using neural networks to solve simple arithmetic problems, such as counting, multiplication, or comparison, they systematically fail to extrapolate onto unseen ranges (Lake & Baroni, 2018;Suzgun et al., 2019;Trask et al., 2018).",
    "next": "The absence of inductive bias makes it difficult for neural networks to extrapolate well on arithmetic tasks as they lack the underlying logic to represent the required operations.",
    "hard_negative": [
      44115640,
      44111606
    ],
    "easy_negative": [
      253761976,
      202538070,
      250150501
    ]
  },
  {
    "index": 3335,
    "source_corpus_id": 6715185,
    "ref_id": "b28",
    "citation_corpus_id": 340852,
    "start": 4805,
    "end": 4825,
    "title": "Learning Dependency-Based Compositional Semantics",
    "abstract": "Suppose we want to build a system that answers a natural language question by representing its semantics as a logical form and computing the answer given a structured database of facts. The core part of such a system is the semantic parser that maps questions to logical forms. Semantic parsers are typically trained from examples of questions annotated with their target logical forms, but this type of annotation is expensive.Our goal is to instead learn a semantic parser from question-answer pairs, where the logical form is modeled as a latent variable. We develop a new semantic formalism, dependency-based compositional semantics (DCS) and define a log-linear distribution over DCS logical forms. The model parameters are estimated using a simple procedure that alternates between beam search and numerical optimization. On two standard semantic parsing benchmarks, we show that our system obtains comparable accuracies to even state-of-the-art systems that do require annotated logical forms.",
    "prev": "As the space over programs is non-smooth, it is difficult to apply simple gradient descent; most often, gradient descent is augmented with a complex search procedure, such as sampling (Liang et al., 2010).",
    "curr": "To further simplify training, the algorithmic designers have to manually add more supervision signals to the models in the form of annotation of the complete program for every question (Zettlemoyer & Collins, 2005) or a domain-specific grammar (Liang et al., 2011).",
    "next": "For example, designing grammars that contain rules to associate lexical items to the correct operations, e.g., the word \"largest\" to the operation \"argmax\", or to produce syntactically valid programs, e.g., disallow the program >= dog.",
    "hard_negative": [
      5667590,
      8317576,
      6684426,
      1140108,
      6991244,
      9317139,
      238873,
      12728987,
      9337134,
      5249151,
      6228816,
      245587,
      6360793,
      2498523,
      8781666,
      10983275,
      7027442,
      252796,
      8045822,
      7785983
    ],
    "easy_negative": [
      3340951,
      11947613,
      237055434
    ]
  },
  {
    "index": 3336,
    "source_corpus_id": 1470238,
    "ref_id": "b3",
    "citation_corpus_id": 10299779,
    "start": 1708,
    "end": 1713,
    "title": "Unsupervised Learning of Narrative Schemas and their Participants",
    "abstract": "We describe an unsupervised system for learning narrative schemas, coherent sequences or sets of events (arrested(POLICE,SUSPECT), convicted( JUDGE, SUSPECT)) whose arguments are filled with participant semantic roles defined over words (JUDGE = {judge, jury, court}, POLICE = {police, agent, authorities}). Unlike most previous work in event structure or semantic role learning, our system does not use supervised techniques, hand-built knowledge, or predefined classes of events or roles. Our unsupervised learning algorithm uses coreferring arguments in chains of verbs to learn both rich narrative event structure and argument roles. By jointly addressing both tasks, we improve on previous results in narrative/frame learning and induce rich frame-specific semantic roles.",
    "prev": "However, these approaches do not scale to complex domains (Mueller, 1998;Gordon, 2001).",
    "curr": "More recently, automatic induction of script knowledge from text have started to attract attention: these methods exploit either natural texts (Chambers & Jurafsky, 2008;2009) or crowdsourced data (Regneri et al., 2010), and, consequently, do not require expensive expert annotation.",
    "next": "Given a text corpus, they extract structured representations (i.e.",
    "hard_negative": [
      5903592,
      1143628,
      2380594,
      3102322
    ],
    "easy_negative": [
      244054905,
      248965506,
      254591764
    ]
  },
  {
    "index": 3347,
    "source_corpus_id": 231632580,
    "ref_id": "b2",
    "citation_corpus_id": 5590763,
    "start": 9632,
    "end": 9650,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "Generally speaking, these are linear models that use a window of the past information to predict the next time step, although nonlinear versions with parameterization are subsequently developed.",
    "curr": "A notable nonlinear extension was the RNN (Williams et al., 1986), which later evolved into LSTM (Hochreiter & Schmidhuber, 1997), BiLSTM (Schuster & Paliwal, 1997), and GRU (Cho et al., 2014), which addressed several limitations of the vanilla RNN, such as the vanishing gradient problem.",
    "next": "These architectures are hard to parallelize because of the recurrent nature of the forward and backward computation.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      9137624,
      56895471,
      226283859
    ]
  },
  {
    "index": 3348,
    "source_corpus_id": 203951494,
    "ref_id": "b13",
    "citation_corpus_id": 3484654,
    "start": 19442,
    "end": 19461,
    "title": "RECASTING GRADIENT-BASED META-LEARNING AS HIERARCHICAL BAYES",
    "abstract": "Meta-learning allows an intelligent agent to leverage prior learning episodes as a basis for quickly improving performance on a novel task. Bayesian hierarchical modeling provides a theoretical framework for formalizing meta-learning as inference for a set of parameters that are shared across tasks. Here, we reformulate the model-agnostic meta-learning algorithm (MAML) of Finn et al.(2017)as a method for probabilistic inference in a hierarchical Bayesian model. In contrast to prior methods for meta-learning via hierarchical Bayes, MAML is naturally applicable to complex function approximators through its use of a scalable gradient descent procedure for posterior inference. Furthermore, the identification of MAML as hierarchical Bayes provides a way to understand the algorithm's operation as a meta-learning procedure, as well as an opportunity to make use of computational strategies for efficient inference. We use this opportunity to propose an improvement to the MAML algorithm that makes use of techniques from approximate inference and curvature estimation.",
    "prev": "This is exacerbated by the imbalance of O(n 2 ) meta-learned parameters to learn O(n) activations, unlike in MetaGenRL.",
    "curr": "Many other recent meta-learning algorithms learn a policy parameter initialization that is later finetuned using a fixed reinforcement learning algorithm (Finn et al., 2017;Schulman et al., 2017;Grant et al., 2018;Yoon et al., 2018).",
    "next": "Different from MetaGenRL, these approaches use second order gradients on the same policy parameter vector instead of using a separate objective function.",
    "hard_negative": [
      4994434,
      15085443
    ],
    "easy_negative": [
      1327661,
      257687447,
      254564585
    ]
  },
  {
    "index": 3349,
    "source_corpus_id": 244346093,
    "ref_id": "b16",
    "citation_corpus_id": 219531210,
    "start": 2229,
    "end": 2245,
    "title": "Published as a conference paper at ICLR 2021 DEBERTA: DECODING-ENHANCED BERT WITH DIS- ENTANGLED ATTENTION",
    "abstract": "Recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (NLP) tasks. In this paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT with disentangled attention) that improves the BERT and RoBERTa models using two novel techniques. The first is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively, and the attention weights among words are computed using disentangled matrices on their contents and relative positions, respectively. Second, an enhanced mask decoder is used to incorporate absolute positions in the decoding layer to predict the masked tokens in model pre-training. In addition, a new virtual adversarial training method is used for fine-tuning to improve models' generalization. We show that these techniques significantly improve the efficiency of model pre-training and the performance of both natural language understand (NLU) and natural langauge generation (NLG) downstream tasks. Compared to RoBERTa-Large, a DeBERTa model trained on half of the training data performs consistently better on a wide range of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%), on SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%). Notably, we scale up DeBERTa by training a larger version that consists of 48 Transform layers with 1.5 billion parameters. The significant performance boost makes the single DeBERTa model surpass the human performance on the SuperGLUE benchmark(Wang et al., 2019a)for the first time in terms of macro-average score (89.9 versus 89.8), and the ensemble DeBERTa model sits atop the SuperGLUE leaderboard as of January 6, 2021, outperforming the human baseline by a decent margin (90.3 versus 89.8). The pre-trained DeBERTa models and the source code were released at: https://github.com/microsoft/DeBERTa 1 .",
    "prev": "Our models and code are publicly available at https\n\nINTRODUCTION\n\nRecent advances in Pre-trained Language Models (PLMs) have created new state-of-the-art results on many natural language processing (NLP) tasks.",
    "curr": "While scaling up PLMs with billions or trillions of parameters (Raffel et al., 2020;Radford et al., 2019;Brown et al., 2020;He et al., 2020;Fedus et al., 2021) is a well-proved way to improve the capacity of the PLMs, it is more important to explore more energy-efficient approaches to build PLMs with fewer parameters and less computation cost while retaining high model capacity.",
    "next": "Towards this direction, there are a few works that significantly improve the efficiency of PLMs.",
    "hard_negative": [
      209315300,
      59523594,
      207847598,
      199528271,
      102353817
    ],
    "easy_negative": [
      6085570,
      258741236,
      220525799
    ]
  },
  {
    "index": 3352,
    "source_corpus_id": 90258012,
    "ref_id": "b5",
    "citation_corpus_id": 53079336,
    "start": 3625,
    "end": 3639,
    "title": "Speed Reading: Learning to Read ForBackward via Shuttle",
    "abstract": "We present LSTM-Shuttle, which applies human speed reading techniques to natural language processing tasks for accurate and efficient comprehension. In contrast to previous work, LSTM-Shuttle not only reads shuttling forward but also goes back. Shuttling forward enables high efficiency, and going backward gives the model a chance to recover lost information, ensuring better prediction. We evaluate LSTM-Shuttle on sentiment analysis, news classification, and cloze on IMDB, Rotten Tomatoes, AG, and Children's Book Test datasets. We show that LSTM-Shuttle predicts both better and more quickly. To demonstrate how LSTM-Shuttle actually behaves, we also analyze the shuttling operation and present a case study.",
    "prev": "With hard attention, the RNN has fewer state updates, and therefore fewer floating point operations (FLOPs) are needed for inference.",
    "curr": "This is often denoted as speed reading: obtaining the same accuracy while using (far) fewer FLOPs (Yu et al., 2017;Seo et al., 2018;Huang et al., 2017;Fu & Ma, 2018).",
    "next": "Prior work on speed reading processes text as chunks of either individual words or blocks of contiguous words.",
    "hard_negative": [
      2077889,
      6360322,
      7356547,
      6300165,
      3618568,
      11212020,
      3140413,
      1859294
    ],
    "easy_negative": [
      196185245,
      219559126,
      236779170
    ]
  },
  {
    "index": 3357,
    "source_corpus_id": 259129237,
    "ref_id": "b44",
    "citation_corpus_id": 3292002,
    "start": 60560,
    "end": 60585,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "METAGL-RGCN uses RGCN (Schlichtkrull et al., 2018), which is a heterogeneous GNN, but is not attentive.",
    "curr": "METAGL-GAT uses GAT (Velickovic et al., 2018), which is an attentive GNN, but is not heterogeneous.",
    "next": "METAGL-GCN uses GCN Kipf & Welling (2017), which is neither heterogeneous nor attentive.",
    "hard_negative": [
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      20272964,
      244270768,
      12222565
    ]
  },
  {
    "index": 3358,
    "source_corpus_id": 258865745,
    "ref_id": "b29",
    "citation_corpus_id": 202621357,
    "start": 6433,
    "end": 6450,
    "title": "Justifying Recommendations using Distantly-Labeled Reviews and Fine-Grained Aspects",
    "abstract": "Several recent works have considered the problem of generating reviews (or 'tips') as a form of explanation as to why a recommendation might match a user's interests. While promising, we demonstrate that existing approaches struggle (in terms of both quality and content) to generate justifications that are relevant to users' decision-making process. We seek to introduce new datasets and methods to address this recommendation justification task. In terms of data, we first propose an 'extractive' approach to identify review segments which justify users' intentions; this approach is then used to distantly label massive review corpora and construct largescale personalized recommendation justification datasets. In terms of generation, we design two personalized generation models with this data: (1) a reference-based Seq2Seq model with aspect-planning which can generate justifications covering different aspects, and (2) an aspect-conditional masked language model which can generate diverse justifications based on templates extracted from justification histories. We conduct experiments on two real-world datasets which show that our model is capable of generating convincing and diverse justifications.",
    "prev": "Likewise, image2mass (Standley et al., 2017) curates a dataset of Amazon listings for the purpose of predicting an object's weight given its image, but the processed dataset is only for a single task.",
    "curr": "The UCSD Amazon review data (Ni et al., 2019) is quite large, containing raw data for 15.5 million products, with a focus on product reviews.",
    "next": "We incorporate raw data from the image2mass and UCSD datasets into our dataset, which also contains new data we collected from Amazon.",
    "hard_negative": [
      52006529,
      52100878,
      17865105,
      4937880,
      52115097,
      12252194,
      9662636,
      52159416,
      7287895,
      207556454,
      52967399,
      189762150,
      5590763,
      29161455
    ],
    "easy_negative": [
      51985622,
      218502209,
      42186939
    ]
  },
  {
    "index": 3360,
    "source_corpus_id": 3526769,
    "ref_id": "b18",
    "citation_corpus_id": 14124313,
    "start": 1950,
    "end": 1977,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "R-fcn: Object detection via region-based fully convolutional networks.",
    "curr": "INTRODUCTION\n\nConvolutional Neural Networks (CNNs) have been successfully applied to a wide range of vision tasks, including image classification (Krizhevsky et al., 2012;Szegedy et al., 2015;Simonyan & Zisserman, 2015;He et al., 2016a;Huang et al., 2016), object detection (Girshick et al., 2014;Girshick, 2015;Ren et al., 2015;Dai et al., 2016), semantic segmentation (Long et al., 2015;Zheng et al., 2015), visual concept discovery (Wang et al., 2015; etc.",
    "next": "However, recent works show that CNNs are extremely vulnerable to small perturbations to the input image.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      788835,
      18196068,
      5082131
    ]
  },
  {
    "index": 3370,
    "source_corpus_id": 251442769,
    "ref_id": "b7",
    "citation_corpus_id": 67855286,
    "start": 2009,
    "end": 2028,
    "title": "ANTISYMMETRICRNN: A DYNAMICAL SYSTEM VIEW ON RECURRENT NEURAL NETWORKS",
    "abstract": "Recurrent neural networks have gained widespread use in modeling sequential data. Learning long-term dependencies using these models remains difficult though, due to exploding or vanishing gradients. In this paper, we draw connections between recurrent networks and ordinary differential equations. A special form of recurrent networks called the AntisymmetricRNN is proposed under this theoretical framework, which is able to capture long-term dependencies thanks to the stability property of its underlying differential equation. Existing approaches to improving RNN trainability often incur significant computation overhead. In comparison, AntisymmetricRNN achieves the same goal by design. We showcase the advantage of this new architecture through extensive simulations and experiments. AntisymmetricRNN exhibits much more predictable dynamics. It outperforms regular LSTM models on tasks requiring long-term memory and matches the performance on tasks where short-term dependencies dominate despite being much simpler. advocate going beyond initialization and forcing the weight matrices to be orthogonal throughout the entire learning process. However, some of these approaches come with significant computational overhead and reportedly hinder representation power of these models(Vorontsov et al., 2017). Moreover, orthogonal weight matrices alone do not prevent exploding and vanishing gradients, due to the nonlinear nature of deep neural networks as shown in(Pennington et al., 2017).Here we offer a new perspective on the trainability of RNNs from the dynamical system viewpoint. While exploding gradient is a manifestation of the instability of the underlying dynamical system, vanishing gradient results from a lossy system, properties that have been widely studied in the dynamical system literature(Haber & Ruthotto, 2017;Laurent & von Brecht, 2017). The main contributions of the work are:\u2022 We draw connections between RNNs and the ordinary differential equation theory and design new recurrent architectures by discretizing ODEs.",
    "prev": "Information crucial to solving tasks may be encoded jointly between observations that are thousands of timesteps apart.",
    "curr": "Specialized variants of recurrent neural networks (RNNs) (Arjovsky et al., 2016;Erichson et al., 2021;Rusch & Mishra, 2021;Chang et al., 2019), convolutional neural networks (CNNs) (Bai et al., 2018;Oord et al., 2016;Romero et al., 2022b), and transformers (Vaswani et al., 2017) have been developed to try to address this problem.",
    "next": "In particular, many efficient transformer methods have been introduced (Choromanski et al., 2021;Katharopoulos et al., 2020;Kitaev et al., 2020;Beltagy et al., 2020;Gupta & Berant, 2020;Wang et al., 2020) to address the standard transformer's quadratic complexity in the sequence length.",
    "hard_negative": [
      3532296,
      3005102,
      5590763,
      35673326
    ],
    "easy_negative": [
      248780111,
      994228,
      14540272
    ]
  },
  {
    "index": 3372,
    "source_corpus_id": 256105733,
    "ref_id": "b18",
    "citation_corpus_id": 226283779,
    "start": 2323,
    "end": 2340,
    "title": "Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic Parsing",
    "abstract": "We present BRIDGE, a powerful sequential architecture for modeling dependencies between natural language questions and relational databases in cross-DB semantic parsing. BRIDGE represents the question and DB schema in a tagged sequence where a subset of the fields are augmented with cell values mentioned in the question. The hybrid sequence is encoded by BERT with minimal subsequent layers and the text-DB contextualization is realized via the fine-tuned deep attention in BERT. Combined with a pointergenerator decoder with schema-consistency driven search space pruning, BRIDGE attained state-of-the-art performance on the well-studied Spider benchmark (65.5% dev, 59.2% test), despite being much simpler than most recently proposed models for this task. Our analysis shows that BRIDGE effectively captures the desired cross-modal dependencies and has the potential to generalize to more text-DB related tasks. Our implementation is available at https://github.com/ salesforce/TabularSemanticParsing. User ID Follows Follower ID User_Profiles UID Name Email Partition ID \u2026 \u2026 List the name and number of followers for each user SQL SELECT name, followers FROM User_Profiles Followers SQL SELECT COUNT(DISTINCT t2.title) FROM Publication AS T2 JOIN Journal AS T1 ON T2.JID = T1.JID WHERE T1.name = \"PVLDB\" JID Journal Homepage Name Publication PID Abstract Title \u2026 JID Year Return me the number of papers on PVLDB \u2026 \u2026 Domain Academic Domain Twitter",
    "prev": "INTRODUCTION\n\nLarge-scale cross-domain text-to-SQL datasets facilitate the study of machine learning models for generating a SQL query given a natural language question (NLQ) and corresponding database (DB) as input.",
    "curr": "Neural text-to-SQL models encode an NLQ and DB schema and decode the corresponding SQL (Wang et al., 2019;Lin et al., 2020;Scholak et al., 2021), which have achieved remarkable results on existing benchmarks (Zhong et al., 2017;Yu et al., 2018;Shi et al., 2020).",
    "next": "However, those results are obtained in the setting where test data are created with the same distribution as training data.",
    "hard_negative": [
      155092736,
      220058500,
      159041042,
      8174613,
      207863446,
      160010264,
      8180378,
      1094063,
      52979524,
      214802901,
      5068376,
      52967399,
      201668205,
      15412473
    ],
    "easy_negative": [
      7626777,
      16228715,
      249642402
    ]
  },
  {
    "index": 3379,
    "source_corpus_id": 195218789,
    "ref_id": "b12",
    "citation_corpus_id": 56657912,
    "start": 6634,
    "end": 6663,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "They found that ImageNet-trained DNNs are much more sensitive to such perturbations than human subjects.",
    "curr": "More recently, Hendrycks & Dietterich (2019) introduced the ImageNet-C and ImageNet-P benchmarks to measure the robustness of neural networks against some common perturbations and corruptions that are likely to occur in the real world.",
    "next": "We use the ImageNet-C benchmark below to measure the robust-ness of different models against natural perturbations.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      43603711,
      248721759,
      236478313
    ]
  },
  {
    "index": 3382,
    "source_corpus_id": 252668615,
    "ref_id": "b4",
    "citation_corpus_id": 52889459,
    "start": 2522,
    "end": 2541,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "INTRODUCTION\n\nContemporary generative models have primarily been designed around the construction of a map between two probability distributions that transform samples from the first into samples from the second.",
    "curr": "While progress has been from various angles with tools such as implicit maps (Goodfellow et al., 2014;Brock et al., 2019), and autoregressive maps (Menick & Kalchbrenner, 2019;Razavi et al., 2019;Lee et al., 2022), we focus on the case where the map has a clear associated probability flow.",
    "next": "Advances in this domain, namely from flow and diffusion models, have arisen through the introduction of algorithms or inductive biases that make learning this map, and the Jacobian of the associated change of variables, more tractable.",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      236486165,
      219309129,
      2994838
    ]
  },
  {
    "index": 3389,
    "source_corpus_id": 252815486,
    "ref_id": "b12",
    "citation_corpus_id": 13046179,
    "start": 25966,
    "end": 25991,
    "title": "A BASELINE FOR DETECTING MISCLASSIFIED AND OUT-OF-DISTRIBUTION EXAMPLES IN NEURAL NETWORKS",
    "abstract": "We consider the two related problems of detecting if an example is misclassified or out-of-distribution. We present a simple baseline that utilizes probabilities from softmax distributions. Correctly classified examples tend to have greater maximum softmax probabilities than erroneously classified and out-of-distribution examples, allowing for their detection. We assess performance by defining several tasks in computer vision, natural language processing, and automatic speech recognition, showing the effectiveness of this baseline across all. We then show the baseline can sometimes be surpassed, demonstrating the room for future research on these underexplored detection tasks.Published as a conference paper at ICLR 2017 one method which outperforms the baseline on some (but not all) tasks. This new method evaluates the quality of a neural network's input reconstruction to determine if an example is abnormal.",
    "prev": "When using 2 samples, the cost of one EM step with our method is 45 minutes on an A100 GPU; for the KFAC approximation, this takes 20 minutes.",
    "curr": "Evaluating performance in the face of distribution shift We employ the standard benchmark for evaluating methods' test Log-Likelihood (LL) on the increasingly corrupted data sets of Hendrycks & Gimpel (2017); Ovadia et al.",
    "next": "(2019).",
    "hard_negative": [
      6628106,
      7105713,
      2879445,
      1428702,
      6706414
    ],
    "easy_negative": [
      6567904,
      248780537,
      52952062
    ]
  },
  {
    "index": 3396,
    "source_corpus_id": 245650405,
    "ref_id": "b14",
    "citation_corpus_id": 189928186,
    "start": 3806,
    "end": 3818,
    "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models",
    "abstract": "Transformers are emerging as the new workhorse of NLP, showing great success across tasks. Unlike LSTMs, transformers process input sequences entirely through self-attention. Previous work has suggested that the computational capabilities of self-attention to process hierarchical structures are limited. In this work, we mathematically investigate the computational power of self-attention to model formal languages. Across both soft and hard attention, we show strong theoretical limitations of the computational abilities of selfattention, finding that it cannot model periodic finite-state languages, nor hierarchical structure, unless the number of layers or heads increases with input length. These limitations seem surprising given the practical success of self-attention and the prominent role assigned to hierarchical structure in linguistics, suggesting that natural language can be approximated well with models that are too weak for the formal languages typically assumed in theoretical linguistics.156",
    "prev": "The breadth makes it easier to learn long-distance influences.",
    "curr": "The shallowness does make it impossible to represent inherently deep concepts such as parity (Hahn, 2020), but it enables greater parallelism: the layer-embeddings can be computed in parallel during training, as they depend only on layer \u2212 1 and not on one another. )",
    "next": "on all preceding events at layer \u2212 1 (via <-rules).",
    "hard_negative": [
      6506243,
      53299978,
      58981389,
      8495258,
      162183964,
      53230878,
      52113185,
      155092004,
      14091946,
      49667762,
      44115640,
      57825721,
      3785155,
      53051208,
      21850704,
      192546007,
      184486746,
      13747425,
      52967399,
      174799346,
      173990523,
      4460159
    ],
    "easy_negative": [
      14172450,
      646822,
      230770298
    ]
  },
  {
    "index": 3409,
    "source_corpus_id": 1870512,
    "ref_id": "b38",
    "citation_corpus_id": 5959482,
    "start": 8918,
    "end": 8941,
    "title": "Efficient Estimation of Word Representations in Vector Space",
    "abstract": "We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities. arXiv:1301.3781v3 [cs.CL] 7 Sep 2013 1 The test set is available at www.fit.vutbr.cz/\u02dcimikolov/rnnlm/word-test.v1.txt 2",
    "prev": "We hypothesize that such higher-level representations should make it easier to learn the temporal structure between successive time steps because the relationship between abstract features can generally be expressed more easily.",
    "curr": "This has been, for instance, illustrated by the recent work (Mikolov et al., 2013b) showing that word embeddings from neural language models tend to be related to their temporal neighbors by simple algebraic relationships, with the same type of relationship (adding a vector) holding over very different regions of the space, allowing a form of analogical reasoning.",
    "next": "This approach of making the input-to-hidden function deeper is in the line with the standard practice of replacing input with extracted features in order to improve the performance of a machine learning model (see, e.g., Bengio, 2009).",
    "hard_negative": [
      629094,
      633992,
      5278106,
      1428702
    ],
    "easy_negative": [
      261494493,
      44084674,
      258486938
    ]
  },
  {
    "index": 3411,
    "source_corpus_id": 247158749,
    "ref_id": "b12",
    "citation_corpus_id": 3292002,
    "start": 4368,
    "end": 4392,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "Let G = (V, E, X) be an undirected graph, where V is the set of nodes and E is the set of edges.",
    "curr": "The node feature matrix of the graph G is X \u2208 R |V |\u00d7d where the i-th row of X denotes the d-dimensional feature vector for the i-th node in G. For a graph classification task with k categories, the objective is to learn a classification model f : G \u2192 y \u2208 {1, ..., k} that can predict the categorical label of G.\n\nRecently, GNNs (Kipf & Welling, 2017;Veli\u010dkovi\u0107 et al., 2018;Xu et al., 2019;Gilmer et al., 2017;Gao & Ji, 2019) have shown great success in various graph classification problems.",
    "next": "Most GNNs use the message passing mechanism to learn graph node embeddings.",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      9534097,
      11035270,
      8433617
    ]
  },
  {
    "index": 3416,
    "source_corpus_id": 232233726,
    "ref_id": "b42",
    "citation_corpus_id": 53841789,
    "start": 2973,
    "end": 3000,
    "title": "UNSUPERVISED CONTROL THROUGH NON-PARAMETRIC DISCRIMINATIVE REWARDS",
    "abstract": "Learning to control an environment without hand-crafted rewards or expert data remains challenging and is at the frontier of reinforcement learning research. We present an unsupervised learning algorithm to train agents to achieve perceptuallyspecified goals using only a stream of observations and actions. Our agent simultaneously learns a goal-conditioned policy and a goal achievement reward function that measures how similar a state is to the goal state. This dual optimization leads to a co-operative game, giving rise to a learned reward function that reflects similarity in controllable aspects of the environment instead of distance in the space of observations. We demonstrate the efficacy of our agent to learn, in an unsupervised manner, to reach a diverse set of goals on three domains -Atari, the DeepMind Control Suite and DeepMind Lab.",
    "prev": "Deep reinforcement learning (RL) has recently shown promising capabilities for solving complex decision making problems.",
    "curr": "But most approaches for these compositional challenges either rely on carefully designed reward function (Warde-Farley et al., 2019;Yu et al., 2019;Li et al., 2020;OpenAI et al., 2019), which is typically subtle to derive and requires strong domain knowledge, or utilize a hierarchical policy structure (Kulkarni et al., 2016;Bacon et al., 2017;Nachum et al., 2018;Lynch et al., 2019;Bagaria & Konidaris, 2020), which typically assumes a set of low-level policies for skills and a high-level policy for choosing the next skill to use.",
    "next": "Although the policy hierarchy introduces structural inductive bias into RL, effective low-level skills can be non-trivial to obtain and the bi-level policy structure often causes additional optimization difficulties in practice.",
    "hard_negative": [
      7774489,
      3463260
    ],
    "easy_negative": [
      7313836,
      916523,
      6034011
    ]
  },
  {
    "index": 3420,
    "source_corpus_id": 222067132,
    "ref_id": "b17",
    "citation_corpus_id": 49667762,
    "start": 4909,
    "end": 4931,
    "title": "UNIVERSAL TRANSFORMERS",
    "abstract": "Recurrent neural networks (RNNs) sequentially process data by updating their state with each new data point, and have long been the de facto choice for sequence modeling tasks. However, their inherently sequential computation makes them slow to train. Feed-forward and convolutional architectures have recently been shown to achieve superior results on some sequence modeling tasks such as machine translation, with the added advantage that they concurrently process all inputs in the sequence, leading to easy parallelization and faster training times. Despite these successes, however, popular feed-forward sequence models like the Transformer fail to generalize in many simple tasks that recurrent models handle with ease, e.g. copying strings or even simple logical inference when the string or formula lengths exceed those observed at training time. We propose the Universal Transformer (UT), a parallel-in-time self-attentive recurrent sequence model which can be cast as a generalization of the Transformer model and which addresses these issues. UTs combine the parallelizability and global receptive field of feed-forward sequence models like the Transformer with the recurrent inductive bias of RNNs. We also add a dynamic per-position halting mechanism and find that it improves accuracy on several tasks. In contrast to the standard Transformer, under certain assumptions UTs can be shown to be Turing-complete. Our experiments show that UTs outperform standard Transformers on a wide range of algorithmic and language understanding tasks, including the challenging LAMBADA language modeling task where UTs achieve a new state of the art, and machine translation where UTs achieve a 0.9 BLEU improvement over Transformers on the WMT14 En-De dataset. * Equal contribution, alphabetically by last name. \u2020 Work performed while at Google Brain.",
    "prev": "FAVOR+ can also be applied beyond the Transformer scope as a more scalable replacement for regular attention, which itself has a wide variety of uses in computer vision(Fu et al., 2019), reinforcement learning (Zambaldi et al., 2019), training with softmax cross entropy loss, and even combinatorial optimization (Vinyals et al., 2015).",
    "curr": "INTRODUCTION AND RELATED WORK\n\nTransformers (Vaswani et al., 2017;Dehghani et al., 2019) are powerful neural network architectures that have become SOTA in several areas of machine learning including natural language processing (NLP) (e.g.",
    "next": "speech recognition (Luo et al., 2020)), neural machine translation (NMT) (Chen et al., 2018), document generation/summarization, time series prediction, generative modeling (e.g.",
    "hard_negative": [
      14091969,
      3785155,
      2009318,
      14091946,
      2381275
    ],
    "easy_negative": [
      5101180,
      14185694,
      260440841
    ]
  },
  {
    "index": 3423,
    "source_corpus_id": 249191720,
    "ref_id": "b5",
    "citation_corpus_id": 202120592,
    "start": 2073,
    "end": 2091,
    "title": "How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings",
    "abstract": "Replacing static word embeddings with contextualized word representations has yielded significant improvements on many NLP tasks. However, just how contextual are the contextualized representations produced by models such as ELMo and BERT? Are there infinitely many context-specific representations for each word, or are words essentially assigned one of a finite number of word-sense representations? For one, we find that the contextualized representations of all words are not isotropic in any layer of the contextualizing model. While representations of the same word in different contexts still have a greater cosine similarity than those of two different words, this self-similarity is much lower in upper layers. This suggests that upper layers of contextualizing models produce more context-specific representations, much like how upper layers of LSTMs produce more task-specific representations. In all layers of ELMo, BERT, and GPT-2, on average, less than 5% of the variance in a word's contextualized representations can be explained by a static embedding for that word, providing some justification for the success of contextualized representations.",
    "prev": "Although the Transformer-based dialogue modeling methods (Hosseini-Asl et al., 2020;Liu et al., 2021) have achieved great success on various dialogue tasks, there are still some impediments in these methods that are not well explored nowadays.",
    "curr": "Specifically, recent studies (Ethayarajh, 2019;Su et al., 2022) have revealed that on dialogue generation tasks, the representations produced by existing dialogue modeling methods are anisotropic, i.e.",
    "next": "features occupy a narrow cone in the vector space, thus leading to the problem of degeneration.",
    "hard_negative": [
      3226120,
      10241043,
      5278106,
      3986339,
      380201,
      12549805,
      1957433,
      11650107,
      108300988,
      3626819,
      7478738,
      12730203
    ],
    "easy_negative": [
      13090942,
      15672375,
      18558385
    ]
  },
  {
    "index": 3425,
    "source_corpus_id": 231718721,
    "ref_id": "b15",
    "citation_corpus_id": 14124313,
    "start": 2450,
    "end": 2477,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "The experimental results and findings provide a more accurate understanding of the behaviour of current CNNs, thus helping to inform future design choices.",
    "curr": "INTRODUCTION\n\nConvolutional neural networks (CNNs) have achieved unprecedented performance in various computer vision tasks, such as image classification (Krizhevsky et al., 2012;Simonyan & Zisserman, 2015;He et al., 2016), object detection (Ren et al., 2015;He et al., 2017) and semantic segmentation (Long et al., 2015;Chen et al., 2017;Islam et al., 2017).",
    "next": "Despite their black box nature, various studies have shown that early layers in CNNs activate for low-level patterns, like edges and blobs, while deeper layers activate for more complex and high-level patterns (Zeiler & Fergus, 2014;Springenberg et al., 2014).",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      41603009,
      225062880,
      232075938
    ]
  },
  {
    "index": 3429,
    "source_corpus_id": 257255342,
    "ref_id": "b61",
    "citation_corpus_id": 237454532,
    "start": 10044,
    "end": 10062,
    "title": "Distributionally Robust Multilingual Machine Translation",
    "abstract": "Multilingual neural machine translation (MNMT) learns to translate multiple language pairs with a single model, potentially improving both the accuracy and the memoryefficiency of deployed models. However, the heavy data imbalance between languages hinders the model from performing uniformly across language pairs. In this paper, we propose a new learning objective for MNMT based on distributionally robust optimization, which minimizes the worst-case expected loss over the set of language pairs. We further show how to practically optimize this objective for large translation corpora using an iterated best response scheme, which is both effective and incurs negligible additional computational cost compared to standard empirical risk minimization. We perform extensive experiments on three sets of languages from two datasets and show that our method consistently outperforms strong baseline methods in terms of average and per-language performance under both many-to-one and one-to-many translation settings. 1",
    "prev": "On the other hand, our FairDRO directly aims to achieve group fairness while not requiring group labels at test time.",
    "curr": "A more detailed discussion is in Appendix B.\n\nDRO in other applications Applications of DRO are actively studied in other contexts, e.g., image classification (Sagawa et al., 2020), multilingual machine translation (Oren et al., 2019;Zhou et al., 2021), long-tailed classification (Samuel & Chechik, 2021) or out-of-distribution generalization (Krueger et al., 2021;Xie et al., 2020).",
    "next": "For example, Sagawa et al.",
    "hard_negative": [
      91184134,
      13751870,
      174798142,
      215768769,
      67855815,
      51976920,
      6359641,
      222291168,
      6053988,
      226283492,
      16631020,
      207880568
    ],
    "easy_negative": [
      3858381,
      196201306,
      198942923
    ]
  },
  {
    "index": 3432,
    "source_corpus_id": 232185104,
    "ref_id": "b43",
    "citation_corpus_id": 192624981,
    "start": 2156,
    "end": 2174,
    "title": "Learning Compressed Sentence Representations for On-Device Text Processing",
    "abstract": "Vector representations of sentences, trained on massive text corpora, are widely used as generic sentence embeddings across a variety of NLP problems. The learned representations are generally assumed to be continuous and real-valued, giving rise to a large memory footprint and slow retrieval speed, which hinders their applicability to low-resource (memory and computation) platforms, such as mobile devices. In this paper, we propose four different strategies to transform continuous and generic sentence embeddings into a binarized form, while preserving their rich semantic information. The introduced methods are evaluated across a wide range of downstream tasks, where the binarized sentence embeddings are demonstrated to degrade performance by only about 2% relative to their continuous counterparts, while reducing the storage requirement by over 98%. Moreover, with the learned binary representations, the semantic relatedness of two sentences can be evaluated by simply calculating their Hamming distance, which is more computational efficient compared with the inner product operation between continuous embeddings. Detailed analysis and case study further validate the effectiveness of proposed methods.",
    "prev": "* Equal contribution.",
    "curr": "INTRODUCTION\n\nText encoders, which map raw-text data into low-dimensional embeddings, have become one of the fundamental tools for extensive tasks in natural language processing (Kiros et al., 2015;Lin et al., 2017;Shen et al., 2019;Cheng et al., 2020b).",
    "next": "With the development of deep learning, largescale neural sentence encoders pretrained on massive text corpora, such as Infersent (Conneau et al., 2017), ELMo (Peters et al., 2018), BERT (Devlin et al., 2019), and GPT (Radford et al., 2018), have become the mainstream to extract the sentence-level text representations, and have shown desirable performance on many NLP downstream tasks (MacAvaney et al., 2019;Sun et al., 2019;.",
    "hard_negative": [
      40100965,
      2937095,
      16251657,
      53083275,
      10382194,
      13692090,
      219300540
    ],
    "easy_negative": [
      1095000,
      647479,
      15914332
    ]
  },
  {
    "index": 3436,
    "source_corpus_id": 235436105,
    "ref_id": "b1",
    "citation_corpus_id": 226278174,
    "start": 2643,
    "end": 2666,
    "title": "COMPLEX QUERY ANSWERING WITH NEURAL LINK PREDICTORS",
    "abstract": "Neural link predictors are immensely useful for identifying missing edges in large scale Knowledge Graphs. However, it is still not clear how to use these models for answering more complex queries that arise in a number of domains, such as queries using logical conjunctions (\u2227), disjunctions (\u2228) and existential quantifiers (\u2203), while accounting for missing edges. In this work, we propose a framework for efficiently answering complex queries on incomplete Knowledge Graphs. We translate each query into an end-to-end differentiable objective, where the truth value of each atom is computed by a pre-trained neural link predictor. We then analyse two solutions to the optimisation problem, including gradient-based and combinatorial search. In our experiments, the proposed approach produces more accurate results than state-of-the-art methods -black-box neural models trained on millions of generated queries -without the need of training on a large and diverse set of complex queries. Using orders of magnitude less training data, we obtain relative improvements ranging from 8% up to 40% in Hits@3 across different knowledge graphs containing factual information. Finally, we demonstrate that it is possible to explain the outcome of our model in terms of the intermediate solutions identified for each of the complex query atoms.Neural link predictors(Nickel et al., 2016)tackle the problem of identifying missing edges in large KGs. However, in many complex domains, an open challenge is developing techniques for answering complex queries involving multiple and potentially unobserved edges, entities, and variables, rather than just single edges.We focus on First-Order Logical Queries that use conjunctions (\u2227), disjunctions (\u2228), and existential quantifiers (\u2203). A multitude of queries can be expressed by using such operators -for instance, the query \"Which drugs D interact with proteins associated with diseases t 1 or t 2 ?\" can be rewritten as ?D : \u2203P.interacts(D, P ) \u2227 [assoc(P, t 1 ) \u2228 assoc(P, t 2 )], which can be answered via sub-graph matching.However, plain sub-graph matching cannot capture semantic similarities between entities and relations, and cannot deal with missing facts in the KG. One possible solution consists in computing \u2020 Equal contribution, alphabetical order.",
    "prev": "A query representation is obtained by processing its equivalent logical formula where joins become intersections (\u2227), and variables are existentially quantified (\u2203).",
    "curr": "A flurry of recent QE approaches (Hamilton et al., 2018;Ren et al., 2020;Ren & Leskovec, 2020;Kotnis et al., 2020;Arakelyan et al., 2021) expand the range of supported logical operators and graph patterns.",
    "next": "However, all existing QE models work only on classical, triple-based KGs.",
    "hard_negative": [
      6628106,
      2768038,
      211126567,
      13206339,
      7958862,
      14170854
    ],
    "easy_negative": [
      13532481,
      76663609,
      258959307
    ]
  },
  {
    "index": 3440,
    "source_corpus_id": 46932612,
    "ref_id": "b3",
    "citation_corpus_id": 16134629,
    "start": 3141,
    "end": 3169,
    "title": "Published as a conference paper at ICLR 2017 LEARNING TO ACT BY PREDICTING THE FUTURE",
    "abstract": "We present an approach to sensorimotor control in immersive environments. Our approach utilizes a high-dimensional sensory stream and a lower-dimensional measurement stream. The cotemporal structure of these streams provides a rich supervisory signal, which enables training a sensorimotor control model by interacting with the environment. The model is trained using supervised learning techniques, but without extraneous supervision. It learns to act based on raw sensory input from a complex three-dimensional environment. The presented formulation enables learning without a fixed goal at training time, and pursuing dynamically changing goals at test time. We conduct extensive experiments in threedimensional simulations based on the classical first-person game Doom. The results demonstrate that the presented approach outperforms sophisticated prior formulations, particularly on challenging tasks. The results also show that trained models successfully generalize across environments and goals. A model trained using the presented approach won the Full Deathmatch track of the Visual Doom AI Competition, which was held in previously unseen environments.Published as a conference paper at ICLR 2017 vided by experience itself: by acting and observing the effects of different actions in the context of changing sensory inputs and goals.",
    "prev": "The results of those experimental studies are well-known and clearly demonstrate that simple supervised learning, also known as Monte Carlo prediction (MC), is outperformed by pure TD learning, which, in turn, is outperformed by TD(\u03bb) -a method that can be seen as a mixture of TD and MC (Sutton, 1988).",
    "curr": "However, recent research has shown that an algorithm based on Monte Carlo prediction can outperform TD-based methods on complex sensorimotor control tasks in three-dimensional, partially observable environments (Dosovitskiy & Koltun, 2017).",
    "next": "These results suggest that the classic understanding of the relative performance of TD and MC may not hold in modern settings.",
    "hard_negative": [
      6628106,
      205514,
      16326763
    ],
    "easy_negative": [
      18469017,
      236460062,
      1770102
    ]
  },
  {
    "index": 3441,
    "source_corpus_id": 5959482,
    "ref_id": "b2",
    "citation_corpus_id": 633992,
    "start": 1651,
    "end": 1654,
    "title": "Large Language Models in Machine Translation",
    "abstract": "This paper reports on the benefits of largescale statistical language modeling in machine translation. A distributed infrastructure is proposed which we use to train on up to 2 trillion tokens, resulting in language models having up to 300 billion n-grams. It is capable of providing smoothed probabilities for fast, single-pass decoding. We introduce a new smoothing method, dubbed Stupid Backoff, that is inexpensive to train on large data sets and approaches the quality of Kneser-Ney Smoothing as the amount of training data increases.",
    "prev": "This choice has several good reasons -simplicity, robustness and the observation that simple models trained on huge amounts of data outperform complex systems trained on less data.",
    "curr": "An example is the popular N-gram model used for statistical language modeling -today, it is possible to train N-grams on virtually all available data (trillions of words [3]).",
    "next": "However, the simple techniques are at their limits in many tasks.",
    "hard_negative": [
      7221408,
      15119437,
      1272090
    ],
    "easy_negative": [
      868993,
      208229926,
      237365369
    ]
  },
  {
    "index": 3444,
    "source_corpus_id": 211096885,
    "ref_id": "b2",
    "citation_corpus_id": 52889459,
    "start": 1956,
    "end": 1976,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "It learns a discriminator along with the target generator in an adversarial manner, where the discriminator distinguishes generated samples from real ones.",
    "curr": "Due to its flexibility when dealing with high dimensional data, GAN has obtained remarkable progresses on realistic image generation (Brock et al., 2019).",
    "next": "In the standard formulation (Goodfellow et al., 2014), the realness of an input sample is estimated by the discriminator using a single scalar.",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      258378212,
      22909596,
      18322992
    ]
  },
  {
    "index": 3452,
    "source_corpus_id": 14089312,
    "ref_id": "b24",
    "citation_corpus_id": 14124313,
    "start": 2221,
    "end": 2248,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "(2015); Krizhevsky et al.",
    "curr": "(2012); Simonyan & Zisserman (2015); Szegedy et al.",
    "next": "(2015a); He et al.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      6615197,
      53593895,
      219309091
    ]
  },
  {
    "index": 3463,
    "source_corpus_id": 257038997,
    "ref_id": "b39",
    "citation_corpus_id": 11816014,
    "start": 26673,
    "end": 26698,
    "title": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
    "abstract": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com.",
    "prev": "GLUE is a commonly used natural language understanding benchmark containing nine tasks.",
    "curr": "The benchmark includes question answering (Rajpurkar et al., 2016b), A.2 CONTINUAL PRE-TRAINING IMPLEMENTATIONS Table 6 presents the hyper-parameter configurations for continual pre-training HomoBERT models on the open-domain data.",
    "next": "We set the distillation temperature as 2.",
    "hard_negative": [
      6360322,
      2337034,
      15425307,
      9846946,
      428579,
      8764466,
      14071482,
      1199934,
      8471750,
      1373518,
      12451537,
      2100831,
      15197674,
      5541486,
      226541,
      14915449,
      252796
    ],
    "easy_negative": [
      3030259,
      252211866,
      211549689
    ]
  },
  {
    "index": 3467,
    "source_corpus_id": 222125159,
    "ref_id": "b23",
    "citation_corpus_id": 3693334,
    "start": 2196,
    "end": 2213,
    "title": "Visualizing the Loss Landscape of Neural Nets",
    "abstract": "Neural network training relies on our ability to find \"good\" minimizers of highly non-convex loss functions. It is well-known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and wellchosen training parameters (batch size, learning rate, optimizer) produce minimizers that generalize better. However, the reasons for these differences, and their effects on the underlying loss landscape, are not well understood. In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple \"filter normalization\" method that helps us visualize loss function curvature and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture affects the loss landscape, and how training parameters affect the shape of minimizers.",
    "prev": "INTRODUCTION\n\nStochastic gradient Monte Carlo methods (Welling & Teh, 2011;Chen et al., 2014;Li et al., 2016) are the golden standard for Bayesian inference in deep learning due to their theoretical guarantees in uncertainty quantification (Vollmer et al., 2016;Chen et al., 2015) and non-convex optimization (Zhang et al., 2017).",
    "curr": "However, despite their scalability with respect to the data size, their mixing rates are often extremely slow for complex deep neural networks with rugged energy landscapes (Li et al., 2018).",
    "next": "To speed up the convergence, several techniques have been proposed in the literature in order to accelerate their exploration of multiple modes on the energy landscape, for example, dynamic temperatures (Ye et al., 2017) and cyclic learning rates (Zhang et al., 2020), to name a few.",
    "hard_negative": [
      14124313,
      4429876,
      16138044,
      17786716,
      16209268
    ],
    "easy_negative": [
      222133287,
      248780230,
      232021926
    ]
  },
  {
    "index": 3468,
    "source_corpus_id": 257496462,
    "ref_id": "b27",
    "citation_corpus_id": 202888986,
    "start": 2187,
    "end": 2205,
    "title": "Published as a conference paper at ICLR 2020 ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS",
    "abstract": "Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations and longer training times. To address these problems, we present two parameterreduction techniques to lower memory consumption and increase the training speed of BERT (Devlin et al., 2019). Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large. The code and the pretrained models are available at https://github.com/google-research/ALBERT.Published as a conference paper at ICLR 2020 These solutions address the memory limitation problem, but not the communication overhead. In this paper, we address all of the aforementioned problems, by designing A Lite BERT (ALBERT) architecture that has significantly fewer parameters than a traditional BERT architecture.ALBERT incorporates two parameter reduction techniques that lift the major obstacles in scaling pre-trained models. The first one is a factorized embedding parameterization. By decomposing the large vocabulary embedding matrix into two small matrices, we separate the size of the hidden layers from the size of vocabulary embedding. This separation makes it easier to grow the hidden size without significantly increasing the parameter size of the vocabulary embeddings. The second technique is cross-layer parameter sharing. This technique prevents the parameter from growing with the depth of the network. Both techniques significantly reduce the number of parameters for BERT without seriously hurting performance, thus improving parameter-efficiency. An ALBERT configuration similar to BERT-large has 18x fewer parameters and can be trained about 1.7x faster. The parameter reduction techniques also act as a form of regularization that stabilizes the training and helps with generalization.To further improve the performance of ALBERT, we also introduce a self-supervised loss for sentence-order prediction (SOP). SOP primary focuses on inter-sentence coherence and is designed to address the ineffectiveness  of the next sentence prediction (NSP) loss proposed in the original BERT.As a result of these design decisions, we are able to scale up to much larger ALBERT configurations that still have fewer parameters than BERT-large but achieve significantly better performance. We establish new state-of-the-art results on the well-known GLUE, SQuAD, and RACE benchmarks for natural language understanding. Specifically, we push the RACE accuracy to 89.4%, the GLUE benchmark to 89.4, and the F1 score of SQuAD 2.0 to 92.2.",
    "prev": "INTRODUCTION\n\nRecently, the rise of Graph Neural Networks (GNNs) has enabled important breakthroughs in various fields of graph learning (Ying et al., 2018;Senior et al., 2020).",
    "curr": "Along the other avenue, although getting rid of bespoke convolution operators, Transformers (Vaswani et al., 2017) also achieve phenomenal success in multiple natural language processing (NLP) tasks (Lan et al., 2020;Rajpurkar et al., 2018) and have been transferred successfully to computer vision (CV) field (Dosovitskiy et al., 2021;Strudel et al., 2021).",
    "next": "Despite their different model architectures, GNNs and Transformers are both hindered by the oversmoothing problem (Li et al., 2018;Tang et al., 2021), where deeply stacking layers give rise to indistinguishable representations and significant performance deterioration.",
    "hard_negative": [
      2937095,
      990233,
      3432876,
      102350771,
      1957433,
      3626819,
      11816014,
      52967399,
      47018994,
      4421747,
      16639476
    ],
    "easy_negative": [
      263609114,
      218470042,
      236460013
    ]
  },
  {
    "index": 3471,
    "source_corpus_id": 247958122,
    "ref_id": "b28",
    "citation_corpus_id": 3432876,
    "start": 19624,
    "end": 19647,
    "title": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    "abstract": "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement.",
    "prev": "We use the hair color as the target attribute Y = {blond, non-blond}, given the spurious correlations with the gender A = {male, female}.",
    "curr": "\u2022 MultiNLI (Williams et al., 2018): MultiNLI is a multi-genre natural language corpus where each data instance consists of two sentences and a label indicating whether the second sentence is entailed by, contradicts, or neutral to the first.",
    "next": "We use this label as the target attribute (i.e., Y = {entailed, neutral, contradictory}), and use the existence of the negating words as the spurious attribute (i.e., A = {negation, no negation}).",
    "hard_negative": [
      10202504,
      14429450,
      5555594,
      28495499,
      6628106,
      3104920,
      8495258,
      11866664,
      11262376,
      34032948,
      5471801,
      1957433,
      15978939,
      30758763,
      252796
    ],
    "easy_negative": [
      46510277,
      218498970,
      203560335
    ]
  },
  {
    "index": 3473,
    "source_corpus_id": 204906218,
    "ref_id": "b18",
    "citation_corpus_id": 2486369,
    "start": 1591,
    "end": 1612,
    "title": "The Proposition Bank: An Annotated Corpus of Semantic Roles",
    "abstract": "The Proposition Bank project takes a practical approach to semantic representation, adding a layer of predicate-argument information, or semantic role labels, to the syntactic structures of the Penn Treebank. The resulting resource can be thought of as shallow, in that it does not represent coreference, quantification, and many other higher-order phenomena, but also broad, in that it covers every instance of every verb in the corpus and allows representative statistics to be calculated.We discuss the criteria used to define the sets of semantic roles used in the annotation process and to analyze the frequency of syntactic/semantic alternations in the corpus. We describe an automatic system for semantic role tagging trained on the corpus and discuss the effect on its performance of various types of information, including a comparison of full syntactic parsing with a flat representation and the contribution of the empty ''trace'' categories of the treebank.",
    "prev": "work: unsupervised induction of shallow semantics (e.g., semantic roles) and factorization of relations in text and knowledge bases.Our model consists of two components:(1) an encoding component: a semantic role labeling model which predicts roles given a rich set of syntactic and lexical features; (2) a reconstruction component: a tensor factorization model which relies on roles to predict argument fillers.When the components are estimated jointly to minimize errors in argument reconstruction, the induced roles largely correspond to roles defined in annotated resources.Our method performs on par with most accurate role induction methods on English, even though, unlike these previous approaches, we do not incorporate any prior linguistic knowledge about the language.",
    "curr": "INTRODUCTION\n\nShallow representations of meaning, and semantic role labels in particular, have a long history in linguistics (Fillmore, 1968).More recently, with an emergence of large annotated resources such as PropBank (Palmer et al., 2005) and FrameNet (Baker et al., 1998), automatic semantic role labeling (SRL) has attracted a lot of attention (Surdeanu et al., 2008;Haji\u010d et al., 2009;Das et al., 2010).",
    "next": "Semantic role representations encode the underlying predicate-argument structure of sentences, or, more specifically, for every predicate in a sentence they identify a set of arguments and associate each argument with an underlying semantic role, such as an agent (an initiator or doer of the action) or a patient (an affected entity).Consider the following sentence: Here, the police, the demonstrators and with batons are assigned to roles Agent, Patient and Instrument, respectively.Semantic roles have many potential applications in NLP and have been shown to benefit, for example, question answering (Shen and Lapata, 2007;Berant et al., 2014) and textual entailment (Sammons et al., 2009), among others.",
    "hard_negative": [
      2729729,
      1823750,
      62182406,
      21386,
      18312340,
      5224609,
      18104110,
      5587138,
      2876869,
      11428046,
      6232405,
      11869911,
      1937760,
      115042,
      8940645,
      12807398,
      3143783,
      9680240,
      252796
    ],
    "easy_negative": [
      4888341,
      3046879,
      16088175
    ]
  },
  {
    "index": 3474,
    "source_corpus_id": 231592851,
    "ref_id": "b20",
    "citation_corpus_id": 56657912,
    "start": 15931,
    "end": 15960,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "Following recent recommendations for evaluating the quality of predictive uncertainty estimates (Ovadia et al., 2019), we also test our probabilistic object detectors on shifted data distributions.",
    "curr": "We construct 3 distorted versions of the COCO validation dataset (C1, C3, and C5) by applying 18 different image corruptions introduced by Hendrycks & Dietterich (2019) at increasing intensity levels [1,3,5].",
    "next": "To test on natural dataset shift, we use OpenImages data (Kuznetsova et al., 2020) to create a shifted dataset with the same categories as COCO and an out-of-distribution dataset that contain none of the 80 categories found in COCO.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      15118981,
      251673141,
      247793003
    ]
  },
  {
    "index": 3477,
    "source_corpus_id": 221083147,
    "ref_id": "b26",
    "citation_corpus_id": 5034059,
    "start": 3106,
    "end": 3124,
    "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    "abstract": "For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusively tailored to a specific task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating and analyzing the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and find that multi-task training on all our tasks yields better results than training a separate model for each task. However, the low absolute performance of our best model indicates the need for improved general NLU systems. son. 2013. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint 1312.3005.",
    "prev": "Our approach is motivated by trust region theory while also reducing to simply regularizing the model relative to parametric noise applied to the original pre-trained representations.",
    "curr": "We show uniformly better performance, setting a new state of the art for RoBERTa fine-tuning on GLUE and reaching state of the art on XNLI using no novel pretraining approaches Wang et al., 2018;Conneau et al., 2018).",
    "next": "Furthermore, the low overhead of our family of fine-tuning methods allows our method to be applied to generation tasks 1 arXiv:2008.03156v1 [cs.LG] 6 Aug 2020\n\nwhere we consistently outperform standard fine-tuning, setting state of the art on summarization tasks.",
    "hard_negative": [
      5074049,
      388,
      2937095,
      2213896,
      25422730,
      4537113,
      16661147,
      1957433,
      3626819,
      11816014,
      1994584,
      2135897,
      3264224,
      4421747,
      4567927
    ],
    "easy_negative": [
      232092638,
      227231604,
      13099198
    ]
  },
  {
    "index": 3480,
    "source_corpus_id": 54438210,
    "ref_id": "b36",
    "citation_corpus_id": 12713052,
    "start": 2261,
    "end": 2278,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "ce the computational cost (GPU hours and GPU memory) to the same level of regular training while still allowing a large candidate set.Experiments on CIFAR-10 and ImageNet demonstrate the effectiveness of directness and specialization.On CIFAR-10, our model achieves 2.08% test error with only 5.7M parameters, better than the previous state-of-the-art architecture AmoebaNet-B, while using 6\u00d7 fewer parameters.On ImageNet, our model achieves 3.1% better top-1 accuracy than MobileNetV2, while being 1.2\u00d7 faster with measured GPU latency.We also apply ProxylessNAS to specialize neural architectures for hardware with direct hardware metrics (e.g.latency) and provide insights for efficient CNN architecture design.",
    "curr": "1\n\nINTRODUCTION\n\nNeural architecture search (NAS) has demonstrated much success in automating neural network architecture design for various deep learning tasks, such as image recognition (Zoph et al., 2018;Cai et al., 2018a;Liu et al., 2018a;Zhong et al., 2018) and language modeling (Zoph & Le, 2017).Despite the remarkable results, conventional NAS algorithms are prohibitively computation-intensive, requiring to train thousands of models on the target task in a single experiment.Therefore, directly applying NAS to a large-scale task (e.g.ImageNet) is computationally expensive or impossible, which makes it difficult for making practical industry impact.As a trade-off, Zoph et al.",
    "next": "(2018) propose to search for building blocks on proxy tasks, such as training for fewer epochs, starting with a smaller dataset (e.g.CIFAR-10), or learning with fewer blocks.Then top-performing blocks are stacked and transferred to the large-scale target task.This paradigm has been widely adopted in subsequent NAS algorithms (Liu et al., 2018a;b;Real et al., 2018;Cai et al., 2018b;Liu et al., 2018c;Tan et al., 2018;Luo et al., 2018).",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      8875928,
      7535290,
      817894
    ]
  },
  {
    "index": 3483,
    "source_corpus_id": 252846076,
    "ref_id": "b15",
    "citation_corpus_id": 208637449,
    "start": 30729,
    "end": 30750,
    "title": "COMBINING Q-LEARNING AND SEARCH WITH AMORTIZED VALUE ESTIMATES",
    "abstract": "We introduce \"Search with Amortized Value Estimates\" (SAVE), an approach for combining model-free Q-learning with model-based Monte-Carlo Tree Search (MCTS). In SAVE, a learned prior over state-action values is used to guide MCTS, which estimates an improved set of state-action values. The new Q-estimates are then used in combination with real experience to update the prior. This effectively amortizes the value computation performed by MCTS, resulting in a cooperative relationship between model-free learning and model-based search. SAVE can be implemented on top of any Q-learning agent with access to a model, which we demonstrate by incorporating it into agents that perform challenging physical reasoning tasks and Atari. SAVE consistently achieves higher rewards with fewer training steps, and-in contrast to typical model-based search approaches-yields strong performance with very small search budgets. By combining real experience with information computed during search, SAVE demonstrates that it is possible to improve on both the performance of model-free learning and the computational cost of planning.",
    "prev": "(b) To make MuZero Unplugged more compute-efficient and feasible, we could limit the number of simulations.",
    "curr": "However, prior works have shown that MuZero's policy target degenerates under low visit count (Grill et al., 2020;Hamrick et al., 2020).",
    "next": "Hence, we also implement the MZU-Q variant which uses an MPO-style (Abdolmaleki et al., 2018) policy update, \u03c0 MPO \u221d \u03c0 \u03b8 \u00b7 exp(Q MCTS /\u03c4 ), for a comprehensive comparison.",
    "hard_negative": [
      200884,
      3536221,
      195346786
    ],
    "easy_negative": [
      5653822,
      14945960,
      235097601
    ]
  },
  {
    "index": 3488,
    "source_corpus_id": 252595921,
    "ref_id": "b0",
    "citation_corpus_id": 173188048,
    "start": 2889,
    "end": 2908,
    "title": "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms",
    "abstract": "We introduce a large-scale dataset of math word problems and an interpretable neural math problem solver that learns to map problems to operation programs. Due to annotation challenges, current datasets in this domain have been either relatively small in scale or did not offer precise operational annotations over diverse problem types. We introduce a new representation language to model precise operation programs corresponding to each math problem that aim to improve both the performance and the interpretability of the learned models. Using this representation language, our new dataset, MathQA, significantly enhances the AQuA dataset with fully-specified operational programs. We additionally introduce a neural sequence-to-program model enhanced with automatic problem categorization. Our experiments show improvements over competitive baselines in our MathQA as well as the AQuA datasets. The results are still significantly lower than human performance indicating that the dataset poses new challenges for future research. Our dataset is available at: https: //math-qa.github.io/math-QA/.",
    "prev": "Solving math word problems (MWPs) is a well-defined task to diagnose the ability of intelligent systems to perform numerical reasoning and problem-solving as humans.",
    "curr": "A surge of datasets has been proposed to facilitate the research in this domain (Upadhyay & Chang, 2017;Amini et al., 2019;Miao et al., 2020;Cobbe et al., 2021).",
    "next": "However, most existing MWP datasets focus on textual math word problems only.",
    "hard_negative": [
      6628106,
      11336213,
      12728987,
      428579,
      51881520,
      3960255,
      2423360,
      12451537,
      12777818,
      52009450,
      2228719,
      11212020
    ],
    "easy_negative": [
      257279837,
      261341917,
      256461149
    ]
  },
  {
    "index": 3495,
    "source_corpus_id": 245144350,
    "ref_id": "b43",
    "citation_corpus_id": 227209335,
    "start": 3790,
    "end": 3809,
    "title": "SCORE-BASED GENERATIVE MODELING THROUGH STOCHASTIC DIFFERENTIAL EQUATIONS",
    "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reversetime SDE depends only on the time-dependent gradient field (a.k.a., score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in diffusion probabilistic modeling and scorebased generative modeling, and allows for new sampling procedures. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, which enables exact likelihood computation, and improved sampling efficiency. In addition, our framework enables conditional generation with an unconditional model, as we demonstrate with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 3.10 bits/dim, and demonstrate high fidelity generation of 1024\u02c61024 images for the first time from a score-based generative model.",
    "prev": "Conversely, variational autoencoders (VAEs) (Kingma & Welling, 2014;Rezende et al., 2014) and normalizing flows (Dinh et al., 2016;Kingma & Dhariwal, 2018) cover data modes faithfully, but they often suffer from low sample quality.",
    "curr": "Recently, diffusion models (Sohl-Dickstein et al., 2015;Ho et al., 2020;Song et al., 2021c) have emerged as powerful generative models.",
    "next": "They demonstrate surprisingly good results in sample quality, beating GANs in image generation (Dhariwal & Nichol, 2021;Ho et al., 2021).",
    "hard_negative": [
      52889459,
      52908831
    ],
    "easy_negative": [
      227231753,
      12511308,
      3243635
    ]
  },
  {
    "index": 3499,
    "source_corpus_id": 67856088,
    "ref_id": "b15",
    "citation_corpus_id": 1428702,
    "start": 19064,
    "end": 19083,
    "title": "Learning Word Vectors for Sentiment Analysis",
    "abstract": "Unsupervised vector-based approaches to semantics can model rich lexical meanings, but they largely fail to capture sentiment information that is central to many word meanings and important for a wide range of NLP tasks. We present a model that uses a mix of unsupervised and supervised techniques to learn word vectors capturing semantic term-document information as well as rich sentiment content. The proposed model can leverage both continuous and multi-dimensional sentiment information as well as non-sentiment annotations. We instantiate the model to utilize the document-level sentiment polarity annotations present in many online documents (e.g. star ratings). We evaluate the model using small, widely used sentiment and subjectivity corpora and find it out-performs several previously introduced methods for sentiment classification. We also introduce a large dataset of movie reviews to serve as a more robust benchmark for work in this area.",
    "prev": "To reduce computation we restrict the input data to 16x16 pixels or less during meta-training, and resize all datasets accordingly.",
    "curr": "For evaluation, we use MNIST (LeCun et al., 1998), Fashion MNIST (Xiao et al., 2017), IMDB (Maas et al., 2011), and a hold-out set of Imagenet classes.",
    "next": "We additionally sample the base model architecture.",
    "hard_negative": [
      1260035,
      388,
      2279432,
      10473638,
      7105713,
      2787775,
      218515777,
      3264224,
      629094,
      469886
    ],
    "easy_negative": [
      18009801,
      7048067,
      195584474
    ]
  },
  {
    "index": 3500,
    "source_corpus_id": 252407628,
    "ref_id": "b18",
    "citation_corpus_id": 204960716,
    "start": 3695,
    "end": 3715,
    "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
    "abstract": "We present BART, a denoising autoencoder for pretraining sequence-to-sequence models. BART is trained by (1) corrupting text with an arbitrary noising function, and (2) learning a model to reconstruct the original text. It uses a standard Tranformer-based neural machine translation architecture which, despite its simplicity, can be seen as generalizing BERT (due to the bidirectional encoder), GPT (with the left-to-right decoder), and other recent pretraining schemes. We evaluate a number of noising approaches, finding the best performance by both randomly shuffling the order of sentences and using a novel in-filling scheme, where spans of text are replaced with a single mask token. BART is particularly effective when fine tuned for text generation but also works well for comprehension tasks. It matches the performance of RoBERTa on GLUE and SQuAD, and achieves new stateof-the-art results on a range of abstractive dialogue, question answering, and summarization tasks, with gains of up to 3.5 ROUGE. BART also provides a 1.1 BLEU increase over a back-translation system for machine translation, with only target language pretraining. We also replicate other pretraining schemes within the BART framework, to understand their effect on end-task performance. 1",
    "prev": "The video was recovered from a phone at the crash site, according to Paris Match.I1:The prosecutor leading an investigation into the crash of Germanwings Flight 9525 insisted he was not aware of any video footage.Compression FusionI2: Prosecutor Brice Robin says he is not aware of any video footage from the plane.",
    "curr": "INTRODUCTION\n\nProgress in pre-trained language models has led to state-of-the-art abstractive summarization models capable of generating highly fluent and concise summaries (Lewis et al., 2020;Zhang et al., 2020;Raffel et al., 2020).",
    "next": "Abstractive summarization models do not suffer from the restrictive nature of extractive summarization systems that only copy parts of the source document.",
    "hard_negative": [
      52967399,
      16639476,
      990233
    ],
    "easy_negative": [
      15146999,
      3865590,
      238251632
    ]
  },
  {
    "index": 3504,
    "source_corpus_id": 248085415,
    "ref_id": "b14",
    "citation_corpus_id": 13570924,
    "start": 23077,
    "end": 23097,
    "title": "Variational Continual Learning",
    "abstract": "This paper develops variational continual learning (VCL), a simple but general framework for continual learning that fuses online variational inference (VI) and recent advances in Monte Carlo VI for neural networks. The framework can successfully train both deep discriminative models and deep generative models in complex continual learning settings where existing tasks evolve over time and entirely new tasks emerge. Experimental results show that variational continual learning outperforms state-of-the-art continual learning methods on a variety of tasks, avoiding catastrophic forgetting in a fully automatic way.",
    "prev": "Experience replay is widely adopted in continual learning to prevent catastrophic forgetting (Robins, 1995;Lopez-Paz & Ranzato, 2017;Rebuffi et al., 2017;Rolnick et al., 2019).",
    "curr": "However, the majority of approaches focus on task-based continual learning and update the memory relying on task boundaries (Rebuffi et al., 2017;Nguyen et al., 2018;Titsias et al., 2020;Pan et al., 2020;Bang et al., 2021;Yoon et al., 2021).",
    "next": "In contrast, reservoir sampling (Vitter, 1985) is used (Rolnick et al., 2019;Chaudhry et al., 2019b;Buzzega et al., 2020;Isele & Cosgun, 2018;Balaji et al., 2020) to update the memory online and maintain uniform samples from the stream.",
    "hard_negative": [
      6628106,
      12730344
    ],
    "easy_negative": [
      238407831,
      250150524,
      226262352
    ]
  },
  {
    "index": 3517,
    "source_corpus_id": 253244506,
    "ref_id": "b36",
    "citation_corpus_id": 17364624,
    "start": 14566,
    "end": 14584,
    "title": "Reasoning about Quantities in Natural Language",
    "abstract": "Little work from the Natural Language Processing community has targeted the role of quantities in Natural Language Understanding. This paper takes some key steps towards facilitating reasoning about quantities expressed in natural language. We investigate two different tasks of numerical reasoning. First, we consider Quantity Entailment, a new task formulated to understand the role of quantities in general textual inference tasks. Second, we consider the problem of automatically understanding and solving elementary school math word problems. In order to address these quantitative reasoning problems we first develop a computational approach which we show to successfully recognize and normalize textual expressions of quantities. We then use these capabilities to further develop algorithms to assist reasoning in the context of the aforementioned tasks.",
    "prev": "Datasets.",
    "curr": "We evaluate on problems from 5 problem solving datasets: MultiArith (Roy et al., 2015), AddSub (Hosseini et al., 2014), SingleOp (Roy et al., 2015), SVAMP (Patel et al., 2021), and GSM8k (Cobbe et al., 2021).",
    "next": "As in prior work (Austin et al., 2021;Ni et al., 2022;Mishra et al., 2022), we frame these as program synthesis by converting their solutions to Python programs.",
    "hard_negative": [
      5555594,
      6238509,
      1002552,
      8179642,
      11162815,
      7359050,
      1177419,
      12451537
    ],
    "easy_negative": [
      233365288,
      3643309,
      390510
    ]
  },
  {
    "index": 3518,
    "source_corpus_id": 213795117,
    "ref_id": "b24",
    "citation_corpus_id": 829159,
    "start": 17134,
    "end": 17163,
    "title": "PAYING MORE ATTENTION TO ATTENTION: IMPROVING THE PERFORMANCE OF CONVOLUTIONAL NEURAL NETWORKS VIA ATTENTION TRANSFER",
    "abstract": "Attention plays a critical role in human visual experience. Furthermore, it has recently been demonstrated that attention can also play an important role in the context of applying artificial neural networks to a variety of tasks from fields such as computer vision and NLP. In this work we show that, by properly defining attention for convolutional neural networks, we can actually use this type of information in order to significantly improve the performance of a student CNN network by forcing it to mimic the attention maps of a powerful teacher network.To that end, we propose several novel methods of transferring attention, showing consistent improvement across a variety of datasets and convolutional neural network architectures. Code and models for our experiments are available at",
    "prev": "Notably, a similar assumption was made in (Rastegari et al., 2016) where analytic scale factors were calculated so that the error between binary and real convolutions is minimized.",
    "curr": "Instead, and inspired by the attention transfer method of (Zagoruyko & Komodakis, 2017), we propose to enforce such a constraint via a loss term at the end of each convolutional block by comparing attention maps calculated from the binary and real-valued activations.",
    "next": "Such supervisory signals provide the binary network with muchneeded extra guidance.",
    "hard_negative": [
      1450294,
      12998557
    ],
    "easy_negative": [
      256104949,
      199379650,
      46941044
    ]
  },
  {
    "index": 3519,
    "source_corpus_id": 15194782,
    "ref_id": "b20",
    "citation_corpus_id": 739696,
    "start": 5487,
    "end": 5504,
    "title": "Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems",
    "abstract": "Natural language generation (NLG) is a critical component of spoken dialogue and it has a significant impact both on usability and perceived quality. Most NLG systems in common use employ rules and heuristics and tend to generate rigid and stylised responses without the natural variation of human language. They are also not easily scaled to systems covering multiple domains and languages. This paper presents a statistical language generator based on a semantically controlled Long Short-term Memory (LSTM) structure. The LSTM generator can learn from unaligned data by jointly optimising sentence planning and surface realisation using a simple cross entropy training criterion, and language variation can be easily achieved by sampling from output candidates. With fewer heuristics, an objective evaluation in two differing test domains showed the proposed method improved performance compared to previous methods. Human judges scored the LSTM system higher on informativeness and naturalness and overall preferred it to the other systems.",
    "prev": "Both of these techniques operate element-wise however, whereas we target the activations' norms.",
    "curr": "Several other works have used penalties on the difference of hidden states rather than their norms (Jonschkowski & Brock, 2015;Wen et al., 2015).",
    "next": "Other regularizers for RNNs that do not target norm stability include weight noise (Jim et al., 1996) and dropout (Pham et al., 2013;Pachitariu & Sahani, 2013;Zaremba et al., 2014).",
    "hard_negative": [
      53380,
      2680971,
      12964363,
      17082258,
      13402912,
      1139492,
      1957433,
      12955714,
      6241225,
      1543141,
      13631598
    ],
    "easy_negative": [
      219573291,
      227905315,
      252624413
    ]
  },
  {
    "index": 3520,
    "source_corpus_id": 246240437,
    "ref_id": "b11",
    "citation_corpus_id": 218487109,
    "start": 2387,
    "end": 2410,
    "title": "UNIFIEDQA: Crossing Format Boundaries with a Single QA System",
    "abstract": "Question answering (QA) tasks have been posed using a variety of formats, such as extractive span selection, multiple choice, etc. This has led to format-specialized models, and even to an implicit division in the QA community. We argue that such boundaries are artificial and perhaps unnecessary, given the reasoning abilities we seek to teach are not governed by the format. As evidence, we use the latest advances in language modeling to build a single pre-trained QA model, UNIFIEDQA, that performs well across 20 QA datasets spanning 4 diverse formats. UNIFIEDQA performs on par with 8 different models that were trained on individual datasets themselves. Even when faced with 12 unseen datasets of observed formats, UNIFIEDQA performs surprisingly well, showing strong generalization from its out-offormat training data. Finally, fine-tuning this pre-trained QA model into specialized models results in a new state of the art on 10 factoid and commonsense QA datasets, establishing UNIFIEDQA as a strong starting point for building QA systems. 1",
    "prev": "1\n\nINTRODUCTION\n\nQuestion answering is a challenging task that requires complex reasoning over both explicit constraints described in the textual context of the question, as well as unstated, relevant knowledge about the world (i.e., knowledge about the domain of interest).",
    "curr": "Recently, large pretrained language models fine-tuned on QA datasets have become the dominant paradigm in NLP for question answering tasks (Khashabi et al., 2020).",
    "next": "After pretraining on an extreme-scale collection of general text corpora, these language models learn to implicitly encode broad knowledge about the world, which they are able to leverage when fine-tuned on a domain-specific downstream QA task.",
    "hard_negative": [
      16503693,
      201058596,
      15369508,
      128296356,
      204823992,
      211205183,
      204960716,
      222124366,
      11816014,
      165163607,
      173188058,
      202558815,
      2100831,
      215737187,
      1167588,
      222175845,
      7363686,
      85464175,
      210531696,
      2593903,
      47018994,
      160009340
    ],
    "easy_negative": [
      255894238,
      8510779,
      2668966
    ]
  },
  {
    "index": 3523,
    "source_corpus_id": 246634100,
    "ref_id": "b23",
    "citation_corpus_id": 91184134,
    "start": 3112,
    "end": 3129,
    "title": "FAIRSEQ: A Fast, Extensible Toolkit for Sequence Modeling",
    "abstract": "FAIRSEQ is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found here: https://www.youtube. com/watch?v=OtgDdWtHvto.",
    "prev": "Performance of these models scales with their number of parameters, which can be up to hundreds of millions, e.g., BERT (Devlin et al., 2018), DeBERTa (He et al., 2020), GPT-3 (Brown et al., 2020).",
    "curr": "Recent research, however, has shown the existence of significant redundancy in the Transformer models (Michel et al., 2019;Fan et al., 2019;Chen et al., 2020;Sanh et al., 2020).",
    "next": "For example, Sanh et al.",
    "hard_negative": [
      53079938,
      53218829,
      5033497,
      3297437,
      59310641,
      44084020,
      52113461,
      52892477,
      964287,
      3718988,
      44131019,
      44134226,
      22716243,
      21460834,
      3725815,
      4623739,
      14337532
    ],
    "easy_negative": [
      9878257,
      18542096,
      261494469
    ]
  },
  {
    "index": 3526,
    "source_corpus_id": 239010042,
    "ref_id": "b21",
    "citation_corpus_id": 3633127,
    "start": 2140,
    "end": 2162,
    "title": "Published as a conference paper at ICLR 2018 CGANS WITH PROJECTION DISCRIMINATOR",
    "abstract": "We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. This approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. With this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (Im-ageNet) 1000-class image dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. We were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. This new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_projection.",
    "prev": "Moreover, we demonstrate that the attributes to be learned can be manipulated using a small amount of probe data.",
    "curr": "INTRODUCTION\n\nGANs have shown remarkable results in the synthesis of realistic data conditioned on a specific class (Odena et al., 2017;Miyato & Koyama, 2018;Kang & Park, 2020).",
    "next": "Training conditional GANs requires a massive amount of labeled data; however, data are often unlabeled or possess only a few labels.",
    "hard_negative": [
      3366315,
      5687613,
      11758569
    ],
    "easy_negative": [
      14971078,
      220445910,
      21713674
    ]
  },
  {
    "index": 3530,
    "source_corpus_id": 252668326,
    "ref_id": "b3",
    "citation_corpus_id": 219309091,
    "start": 22155,
    "end": 22175,
    "title": "Shared Task Papers",
    "abstract": "This paper presents the results of the WMT16 Metrics Shared Task. We asked participants of this task to score the outputs of the MT systems involved in the WMT16 Shared Translation Task. We collected scores of 16 metrics from 9 research groups. In addition to that, we computed scores of 9 standard metrics (BLEU, SentBLEU, NIST, WER, PER, TER and CDER) as baselines. The collected scores were evaluated in terms of system-level correlation (how well each metric's scores correlate with WMT16 official manual ranking of systems) and in terms of segment level correlation (how often a metric agrees with humans in comparing two translations of a particular sentence).This year there are several additions to the setup: large number of language pairs (18 in total), datasets from different domains (news, IT and medical), and different kinds of judgments: relative ranking (RR), direct assessment (DA) and HUME manual semantic judgments. Finally, generation of large number of hybrid systems was trialed for provision of more conclusive system-level metric rankings.",
    "prev": "Dataset.",
    "curr": "WMT16 (Bojar et al., 2016) is a widely used translation dataset based on the data from statmt.org, which contains various interesting translation tasks on specified domains.",
    "next": "Here, we are focusing on the news translation tasks between English and Germany.",
    "hard_negative": [
      11434376,
      313753,
      7322650,
      14078460,
      3112492,
      61951283,
      7470516,
      63769269,
      11442892,
      16248019,
      15132118,
      15421052,
      16794216,
      195899759,
      6395516,
      5599485
    ],
    "easy_negative": [
      16502540,
      256105320,
      559683
    ]
  },
  {
    "index": 3534,
    "source_corpus_id": 222090060,
    "ref_id": "b55",
    "citation_corpus_id": 59599719,
    "start": 2069,
    "end": 2086,
    "title": "Graph Neural Networks with Generated Parameters for Relation Extraction",
    "abstract": "In this paper, we propose a novel graph neural network with generated parameters (GP-GNNs). The parameters in the propagation module, i.e. the transition matrices used in message passing procedure, are produced by a generator taking natural language sentences as inputs. We verify GP-GNNs in relation extraction from text, both on bag-and instancesettings. Experimental results on a humanannotated dataset and two distantly supervised datasets show that multi-hop reasoning mechanism yields significant improvements. We also perform a qualitative analysis to demonstrate that our model could discover more accurate relations by multi-hop relational reasoning. Codes and data are released at https: //github.com/thunlp/gp-gnn.",
    "prev": "INTRODUCTION\n\nGraph Neural Networks (GNNs) have in recent years been shown to provide a scalable and highly performant means of incorporating linguistic information and other structural biases into NLP models.",
    "curr": "They have been applied to various kinds of representations (e.g., syntactic and semantic graphs, co-reference structures, knowledge bases linked to text, database schemas) and shown effective on a range of tasks, including relation extraction Zhu et al., 2019;Sun et al., 2019a;Guo et al., 2019), question answering (Sorokin & Gurevych, 2018;Sun et al., 2018;De Cao et al., 2019), syntactic and semantic parsing tasks Bogin et al., 2019;Ji et al., 2019), summarisation (Fernandes et al., 2019), machine translation (Bastings et al., 2017) and abusive language detection in social networks (Mishra et al., 2019).",
    "next": "While GNNs often yield strong performance, such models are complex, and it can be difficult to understand the 'reasoning' behind their predictions.",
    "hard_negative": [
      12873739,
      2797612,
      3431470,
      2778800,
      51877560,
      1957433,
      8393918,
      2476229,
      12585424,
      397533,
      5476
    ],
    "easy_negative": [
      227230582,
      184482971,
      671232
    ]
  },
  {
    "index": 3535,
    "source_corpus_id": 256598350,
    "ref_id": "b69",
    "citation_corpus_id": 237213465,
    "start": 4434,
    "end": 4455,
    "title": "Mr. TYDI: A Multi-lingual Benchmark for Dense Retrieval",
    "abstract": "We present Mr. TYDI, a multi-lingual benchmark dataset for mono-lingual retrieval in eleven typologically diverse languages, designed to evaluate ranking with learned dense representations. The goal of this resource is to spur research in dense retrieval techniques in non-English languages, motivated by recent observations that existing techniques for representation learning perform poorly when applied to out-of-distribution data. As a starting point, we provide zero-shot baselines for this new dataset based on a multi-lingual adaptation of DPR that we call \"mDPR\". Experiments show that although the effectiveness of mDPR is much lower than BM25, dense representations nevertheless appear to provide valuable relevance signals, improving BM25 results in sparse-dense hybrids. In addition to analyses of our results, we also discuss future challenges and present a research agenda in multi-lingual dense retrieval. Mr. TYDI can be downloaded at https://github.com/ castorini/mr.tydi.",
    "prev": "Furthermore, we perform ablations to motivate our design choices and show MSM works better than other counterparts.",
    "curr": "INTRODUCTION\n\nCross-lingual retrieval (also including multi-lingual retrieval) is becoming increasingly important as new texts in different languages are being generated every day, and people query and search for the relevant documents in different languages (Zhang et al., 2021b;.",
    "next": "This is a fundamental and challenging task and plays an essential part in real-world search engines, for example, Google and Bing search which serve hundreds of countries across diverse languages.",
    "hard_negative": [
      235720578,
      208117506,
      3618568,
      226284008,
      11816014,
      86611921,
      220302524
    ],
    "easy_negative": [
      14524085,
      221373797,
      241583503
    ]
  },
  {
    "index": 3539,
    "source_corpus_id": 2663445,
    "ref_id": "b52",
    "citation_corpus_id": 1487550,
    "start": 21701,
    "end": 21717,
    "title": "UNSUPERVISED WORD SENSE DISAMBIGUATION RIVALING SUPERVISED METHODS",
    "abstract": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints -that words tend to have one sense per discourse and one sense per collocation -exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%.",
    "prev": "Most works attempt to assign labels to the unlabeled samples, e.g.",
    "curr": "(Ando and Zhang, 2005), either through bootstrapping (Yarowsky, 1995;Blum and Mitchell, 1998), or by learning good functional structures (Szummer and Jaakkola, 2002;Ando and Zhang, 2005).",
    "next": "Related to semi-supervised learning is the problem of domain adaptation, where the source domain has labeled datasets on which classifiers have been trained, e.g.",
    "hard_negative": [
      11329942,
      1693468,
      3166885,
      1580335,
      5458997,
      2946526,
      9537399
    ],
    "easy_negative": [
      1770102,
      399489,
      219306501
    ]
  },
  {
    "index": 3540,
    "source_corpus_id": 4567927,
    "ref_id": "b37",
    "citation_corpus_id": 1957433,
    "start": 2419,
    "end": 2443,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "1\n\nINTRODUCTION\n\nTransfer learning has driven a number of recent successes in computer vision and NLP.",
    "curr": "Computer vision tasks like image captioning (Xu et al., 2015) and visual question answering typically use CNNs pretrained on ImageNet (Krizhevsky et al., 2012;Simonyan & Zisserman, 2014) to extract representations of the image, while several natural language tasks such as reading comprehension and sequence labeling (Lample et al., 2016) have benefited from pretrained word embeddings (Mikolov et al., 2013;Pennington et al., 2014) that are either fine-tuned for a specific task or held fixed.",
    "next": "Many neural NLP systems are initialized with pretrained word embeddings but learn their representations of words in context from scratch, in a task-specific manner from supervised learning signals.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      261342046,
      49420146,
      21919924
    ]
  },
  {
    "index": 3546,
    "source_corpus_id": 239016913,
    "ref_id": "b17",
    "citation_corpus_id": 3568073,
    "start": 6315,
    "end": 6335,
    "title": "PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION",
    "abstract": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., CELEBA images at 1024 2 . We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. Additionally, we describe several implementation details that are important for discouraging unhealthy competition between the generator and discriminator. Finally, we suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset.",
    "prev": "Image Synthesis with GANs Starting from Goodfellow et al.",
    "curr": "(2014), GANs have demonstrated high-quality results (Durugkar et al., 2017;Mordido et al., 2018;Doan et al., 2019;Brock et al., 2018;Karras et al., 2018).",
    "next": "StyleGANs (Karras et al., 2019;) achieve SOTA quality and support different levels of style control.",
    "hard_negative": [
      18828233,
      6628106
    ],
    "easy_negative": [
      7079385,
      26266399,
      5408924
    ]
  },
  {
    "index": 3549,
    "source_corpus_id": 257280165,
    "ref_id": "b0",
    "citation_corpus_id": 337390,
    "start": 3877,
    "end": 3899,
    "title": "Reasoning About Pragmatics with Neural Listeners and Speakers",
    "abstract": "We present a model for pragmatically describing scenes, in which contrastive behavior results from a combination of inference-driven pragmatics and learned semantics. Like previous learned approaches to language generation, our model uses a simple feature-driven architecture (here a pair of neural \"listener\" and \"speaker\" models) to ground language in the world. Like inference-driven approaches to pragmatics, our model actively reasons about listener behavior when selecting utterances. For training, our approach requires only ordinary captions, annotated without demonstration of the pragmatic behavior the model ultimately exhibits. In human evaluations on a referring expression game, our approach succeeds 81% of the time, compared to a 64% success rate using existing techniques.",
    "prev": "Additionally, the speaker may be given feedback depending on the confidence the listener has in the selection.",
    "curr": "This setting provides an attractive test-bed for testing the effects of various reward signals or model designs on the speaker's learned language; previous studies of pragmatics in language acquisition, such as Andreas & Klein (2016), have used similar settings.",
    "next": "1.",
    "hard_negative": [
      9350881,
      9682853,
      259144,
      6308361,
      9497011,
      7719615
    ],
    "easy_negative": [
      18194351,
      218974000,
      6404703
    ]
  },
  {
    "index": 3551,
    "source_corpus_id": 235613625,
    "ref_id": "b28",
    "citation_corpus_id": 8170227,
    "start": 7752,
    "end": 7773,
    "title": "Intelligent Selection of Language Model Training Data",
    "abstract": "We address the problem of selecting nondomain-specific language model training data to build auxiliary language models for use in tasks such as machine translation. Our approach is based on comparing the cross-entropy, according to domainspecific and non-domain-specifc language models, for each sentence of the text source used to produce the latter language model. We show that this produces better language models, trained on less data, than both random data selection and two other previously proposed methods.",
    "prev": "Our work also shares some similarities with data selection and domain adaptation approaches.",
    "curr": "In this case, the training data comes from a single task but its distribution is different from the validation/test distribution (Moore & Lewis, 2010;Axelrod et al., 2011;Ngiam et al., 2018).",
    "next": "This classical problem has recently been addressed by sampling training points whose gradient aligns well with the expected validation gradient (Wang et al., 2020b;a).",
    "hard_negative": [
      633992,
      38407095
    ],
    "easy_negative": [
      211043879,
      252624713,
      251465142
    ]
  },
  {
    "index": 3553,
    "source_corpus_id": 76666188,
    "ref_id": "b37",
    "citation_corpus_id": 3833554,
    "start": 5582,
    "end": 5607,
    "title": "Wasserstein Auto-Encoders",
    "abstract": "We propose the Wasserstein Auto-Encoder (WAE)-a new algorithm for building a generative model of the data distribution. WAE minimizes a penalized form of the Wasserstein distance between the model distribution and the target distribution, which leads to a different regularizer than the one used by the Variational Auto-Encoder (VAE) [1]. This regularizer encourages the encoded training distribution to match the prior. We compare our algorithm with several other techniques and show that it is a generalization of adversarial auto-encoders (AAE)[2]. Our experiments show that WAE shares many of the properties of VAEs (stable training, encoder-decoder architecture, nice latent manifold structure) while generating samples of better quality, as measured by the FID score.",
    "prev": "This design choice has previously been cited as a key limitation of VAEs (Burda et al., 2015;Kingma et al., 2016), and existing quantitative tests of generative modeling quality thus far dramatically favor contemporary alternatives such as generative adversarial networks (GAN) (Goodfellow et al., 2014).",
    "curr": "Regardless, because the VAE possesses certain desirable properties relative to GAN models (e.g., stable training (Tolstikhin et al., 2018), interpretable encoder/inference network (Brock et al., 2016), outlier-robustness (Dai et al., 2018), etc.",
    "next": "), it remains a highly influential paradigm worthy of examination and enhancement.",
    "hard_negative": [
      11758569,
      15876696
    ],
    "easy_negative": [
      2301532,
      221083147,
      218630382
    ]
  },
  {
    "index": 3557,
    "source_corpus_id": 221738974,
    "ref_id": "b21",
    "citation_corpus_id": 57761103,
    "start": 2844,
    "end": 2860,
    "title": "SELF-MONITORING NAVIGATION AGENT VIA AUXIL- IARY PROGRESS ESTIMATION",
    "abstract": "The Vision-and-Language Navigation (VLN) task entails an agent following navigational instruction in photo-realistic unknown environments. This challenging task demands that the agent be aware of which instruction was completed, which instruction is needed next, which way to go, and its navigation progress towards the goal. In this paper, we introduce a self-monitoring agent with two complementary components: (1) visual-textual co-grounding module to locate the instruction completed in the past, the instruction required for the next action, and the next moving direction from surrounding images and (2) progress monitor to ensure the grounded instruction correctly reflects the navigation progress. We test our selfmonitoring agent on a standard benchmark and analyze our proposed approach through a series of ablation studies that elucidate the contributions of the primary components. Using our proposed method, we set the new state of the art by a significant margin (8% absolute increase in success rate on the unseen test set).",
    "prev": "In this paper, we notice there are two ways to formulate the relationship between the action and instruction.",
    "curr": "First, the action is assumed to be generated from the instruction, similarly to most of the existing approaches (Anderson et al., 2018b;Ma et al., 2019;Wang et al., 2019;Hu et al., 2019;.",
    "next": "This is often called a follower model (Fried et al., 2018).",
    "hard_negative": [
      10458880,
      1964946,
      9963298,
      13298214,
      2215227,
      5249151
    ],
    "easy_negative": [
      21724555,
      11657346,
      247863188
    ]
  },
  {
    "index": 3564,
    "source_corpus_id": 3525045,
    "ref_id": "b42",
    "citation_corpus_id": 13583585,
    "start": 7678,
    "end": 7695,
    "title": "Published as a conference paper at ICLR 2017 ON THE QUANTITATIVE ANALYSIS OF DECODER- BASED GENERATIVE MODELS",
    "abstract": "The past several years have seen remarkable progress in generative models which produce convincing samples of images and other modalities. A shared component of many powerful generative models is a decoder network, a parametric deep neural net that defines a generative distribution. Examples include variational autoencoders, generative adversarial networks, and generative moment matching networks. Unfortunately, it can be difficult to quantify the performance of these models because of the intractability of log-likelihood estimation, and inspecting samples can be misleading. We propose to use Annealed Importance Sampling for evaluating log-likelihoods for decoder-based models and validate its accuracy using bidirectional Monte Carlo. The evaluation code is provided at https:// github.com/tonywu95/eval_gen. Using this technique, we analyze the performance of decoder-based models, the effectiveness of existing log-likelihood estimators, the degree of overfitting, and the degree to which these models miss important modes of the data distribution.",
    "prev": "As discussed in (Theis et al., 2015), likelihood often does not provide good rankings of how realistic the samples look, which is the main goal of GANs.",
    "curr": "We evaluted the efficacy of the log-likelihood of the test data, as estimated using Annealed Importance Sampling (AIS) (Wu et al., 2016).",
    "next": "AIS has been to estimate the likelihood of a test sample x by considering many intermediate distributions that are defined by taking a weighted geometric mean between the prior (input) distribution, p(z), and an approximation of the joint distribution p \u03c3 (x, z) = p \u03c3 (x|z)p(z).",
    "hard_negative": [
      11383178,
      2187805,
      661332,
      11758569
    ],
    "easy_negative": [
      227905430,
      256390348,
      18528663
    ]
  },
  {
    "index": 3566,
    "source_corpus_id": 252367603,
    "ref_id": "b3",
    "citation_corpus_id": 230084048,
    "start": 7056,
    "end": 7080,
    "title": "Published as a conference paper at ICLR 2021 NEURAL ODE PROCESSES",
    "abstract": "Neural Ordinary Differential Equations (NODEs) use a neural network to model the instantaneous rate of change in the state of a system. However, despite their apparent suitability for dynamics-governed time-series, NODEs present a few disadvantages. First, they are unable to adapt to incoming data points, a fundamental requirement for real-time applications imposed by the natural direction of time. Second, time series are often composed of a sparse set of measurements that could be explained by many possible underlying dynamics. NODEs do not capture this uncertainty. In contrast, Neural Processes (NPs) are a family of models providing uncertainty estimation and fast data adaptation but lack an explicit treatment of the flow of time. To address these problems, we introduce Neural ODE Processes (NDPs), a new class of stochastic processes determined by a distribution over Neural ODEs. By maintaining an adaptive data-dependent distribution over the underlying ODE, we show that our model can successfully capture the dynamics of low-dimensional systems from just a few data points. At the same time, we demonstrate that NDPs scale up to challenging high-dimensional time-series with unknown latent dynamics such as rotating MNIST digits. * Equal contribution. \u2020 Work done as an AI Resident at the University of Cambridge.",
    "prev": "According to the way of stochasticity modeling, one can construct random functions with different characteristics (Kim et al., 2019;Louizos et al., 2019;Lee et al., 2020;Foong et al., 2020).",
    "curr": "And other models develop random functions by learning adaptive kernels (Tossou et al., 2019;Patacchiola et al., 2020) or computing the integral of ODEs or SDEs on latent states (Norcliffe et al., 2021;Li et al., 2020;Hasan et al., 2021).",
    "next": "Random functions provide explicit representations for laws but cannot model the compositionality of laws.",
    "hard_negative": [
      4994434,
      204960684
    ],
    "easy_negative": [
      227125908,
      53101979,
      248780464
    ]
  },
  {
    "index": 3570,
    "source_corpus_id": 237571392,
    "ref_id": "b19",
    "citation_corpus_id": 215737187,
    "start": 2473,
    "end": 2497,
    "title": "Dense Passage Retrieval for Open-Domain Question Answering",
    "abstract": "Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as TF-IDF or BM25, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dualencoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system largely by 9%-19% absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks. 1",
    "prev": "NLI is important to natural language processing, because it involves logical reasoning and is a key problem in artificial intelligence.",
    "curr": "Previous work shows that NLI can be used in various downstream tasks, such as information retrieval (Karpukhin et al., 2020) and text summarization (Liu & Lapata, 2019).",
    "next": "In recent years, deep learning has become a prevailing approach to NLI (Bowman et al., 2015;Mou et al., 2016;Wang & Jiang, 2016;Yoon et al., 2018).",
    "hard_negative": [
      3618568,
      59604492,
      6401679,
      208267807,
      173990818,
      189762341,
      26501419,
      201307832,
      51875405,
      11816014,
      1965270,
      202558815,
      5541486,
      202660724
    ],
    "easy_negative": [
      28775375,
      238251649,
      2872444
    ]
  },
  {
    "index": 3574,
    "source_corpus_id": 210702665,
    "ref_id": "b21",
    "citation_corpus_id": 17272965,
    "start": 3972,
    "end": 3991,
    "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
    "abstract": "Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.Deep learning methods have realized impressive performance in a range of applications, from visual object classification [1, 2, 3] to speech recognition [4] and natural language processing[5,6]. These successes have been achieved despite the noted difficulty of training such deep architectures[7,8,9,10,11]. Indeed, many explanations for the difficulty of deep learning have been advanced in the literature, including the presence of many local minima, low curvature regions due to saturating nonlinearities, and exponential growth or decay of back-propagated gradients[12,13,14,15]. Furthermore, many neural network simulations have observed 1 arXiv:1312.6120v3 [cs.NE]",
    "prev": "Orthogonal weight initializations have been the subject of a significant amount of prior theoretical and empirical investigation.",
    "curr": "For example, in a line of work focusing on dynamical isometry, it was found that orthogonal weights can speed up convergence for deep linear networks (Saxe et al., 2014;Advani & Saxe, 2017) and for deep non-linear networks Xiao et al., 2018;Gilboa et al., 2019;Chen et al., 2018;Pennington et al., 2017;Tarnowski et al., 2019;Ling & Qiu, 2019) when they operate in the linear regime.",
    "next": "In the context of recurrent neural networks, orthogonality can help improve the system's stability.",
    "hard_negative": [
      14228101,
      14687186
    ],
    "easy_negative": [
      51935849,
      3185254,
      12776014
    ]
  },
  {
    "index": 3579,
    "source_corpus_id": 247749000,
    "ref_id": "b37",
    "citation_corpus_id": 226226658,
    "start": 4873,
    "end": 4890,
    "title": "Emergent Communication Pretraining for Few-Shot Machine Translation",
    "abstract": "While state-of-the-art models that rely upon massively multilingual pretrained encoders achieve sample efficiency in downstream applications, they still require abundant amounts of unlabelled text. Nevertheless, most of the world's languages lack such resources. Hence, we investigate a more radical form of unsupervised knowledge transfer in the absence of linguistic data. In particular, for the first time we pretrain neural networks via emergent communication from referential games. Our key assumption is that grounding communication on images-as a crude approximation of real-world environments-inductively biases the model towards learning natural languages. On the one hand, we show that this substantially benefits machine translation in few-shot settings. On the other hand, this also provides an extrinsic evaluation protocol to probe the properties of emergent languages ex vitro. Intuitively, the closer they are to natural languages, the higher the gains from pretraining on them should be. For instance, in this work we measure the influence of communication success and maximum sequence length on downstream performances. Finally, we introduce a customised adapter layer and annealing strategies for the regulariser of maximum-a-posteriori inference during fine-tuning. These turn out to be crucial to facilitate knowledge transfer and prevent catastrophic forgetting. Compared to a recurrent baseline, our method yields gains of 59.0%\u223c147.6% in BLEU score with only 500 NMT training instances and 65.1%\u223c196.7% with 1, 000 NMT training instances across four language pairs. These proofof-concept results reveal the potential of emergent communication pretraining for both natural language processing tasks in resource-poor settings and extrinsic evaluation of artificial languages. This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/.Related WorkOur work lies at the intersection of several prominent research areas such as pretraining for transfer learning, emergent communication, few-shot machine translation, and inductive biases for language. To all of these we cannot do full justice given space constraints.Pretraining for Transfer Learning. Unsupervised pretraining on large collections of unlabelled text yields general-purpose contextualized word representations(Peters et al., 2018;Howard and Ruder, 2018)",
    "prev": "A typical setup is the image referential game (Figure 1(a)), where a speaker generates a discrete sequence of tokens based on an input image, a listener is challenged to select the input out of distractors based on the message, and both networks are optimized jointly via game success signals.",
    "curr": "By studying these games, researchers are interested in the emergence of desirable properties resembling natural language, such as game success generalization Lazaridou & Baroni, 2020) and compositionality (Smith et al., 2003;Kirby et al., 2015;Lazaridou et al., 2018;Li et al., 2020b).",
    "next": "However, these properties are mostly defined and analyzed within each individual game framework.",
    "hard_negative": [
      4737664,
      52100101,
      6308361,
      6628106,
      52100117,
      220046231,
      3295641,
      5033497,
      2428314,
      14911774,
      59291939,
      17263016,
      126167342,
      202660912,
      52113461,
      215827766,
      38407095,
      202540346,
      3470398,
      13751870,
      20272964,
      14307651,
      52145734,
      67855815,
      3626819,
      21687876,
      5034059,
      3515219,
      220525782,
      167217367,
      53249630,
      207880568,
      40100965,
      52967399,
      3518190,
      4807923,
      6683636,
      218470133,
      218487293
    ],
    "easy_negative": [
      5923861,
      6797709,
      13388553
    ]
  },
  {
    "index": 3581,
    "source_corpus_id": 257378197,
    "ref_id": "b42",
    "citation_corpus_id": 18309765,
    "start": 2832,
    "end": 2849,
    "title": "Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base",
    "abstract": "We propose a novel semantic parsing framework for question answering using a knowledge base. We define a query graph that resembles subgraphs of the knowledge base and can be directly mapped to a logical form. Semantic parsing is reduced to query graph generation, formulated as a staged search problem. Unlike traditional approaches, our method leverages the knowledge base in an early stage to prune the search space and thus simplifies the semantic matching problem. By applying an advanced entity linking system and a deep convolutional neural network model that matches questions and predicate sequences, our system outperforms previous methods substantially, and achieves an F 1 measure of 52.5% on the WEBQUESTIONS dataset.",
    "prev": "By combining logical rules 1 and 2 we can successfully learn rule 3 for prediction on unseen graphs.",
    "curr": "INTRODUCTION\n\nKnowledge Graphs (KGs) provide a structured representation of real-world facts (Ji et al., 2021), and they are remarkably useful in various applications (Graupmann et al., 2005;Lukovnikov et al., 2017;Xiong et al., 2017;Yih et al., 2015).",
    "next": "Since KGs are usually incomplete, KG reasoning is a crucial problem in KGs, where the goal is to infer the missing knowledge using the observed facts.",
    "hard_negative": [
      15324422,
      6401679,
      6343829,
      2141094,
      2882092,
      1336493,
      15262897,
      2131938,
      1756650
    ],
    "easy_negative": [
      256739262,
      38573874,
      246210276
    ]
  },
  {
    "index": 3583,
    "source_corpus_id": 231662438,
    "ref_id": "b26",
    "citation_corpus_id": 8394195,
    "start": 4321,
    "end": 4341,
    "title": "LOSSY IMAGE COMPRESSION WITH COMPRESSIVE AUTOENCODERS",
    "abstract": "We propose a new approach to the problem of optimizing autoencoders for lossy image compression. New media formats, changing hardware technology, as well as diverse requirements and content types create a need for compression algorithms which are more flexible than existing codecs. Autoencoders have the potential to address this need, but are difficult to optimize directly due to the inherent non-differentiabilty of the compression loss. We here show that minimal changes to the loss are sufficient to train deep autoencoders competitive with JPEG 2000 and outperforming recently proposed approaches based on RNNs. Our network is furthermore computationally efficient thanks to a sub-pixel architecture, which makes it suitable for high-resolution images. This is in contrast to previous work on autoencoders for compression using coarser approximations, shallower architectures, computationally expensive methods, or focusing on small images.",
    "prev": "In Sections 4 and 5 we present our experiments and results, followed by a discussion in Section 6.",
    "curr": "INTRODUCTION\n\nThe most common approach to neural lossy compression is to train a variational autoencoder (VAE)like model on a training dataset to minimize the expected RD cost D + \u03b2R (Theis et al., 2017;Kingma & Welling, 2013).",
    "next": "Although this approach has proven to be very successful , a model trained to minimize expected RD cost over a full dataset is unlikely to be optimal for every test instance because the model has limited capacity, and both optimization and generalization will be imperfect.",
    "hard_negative": [
      6628106,
      2187805
    ],
    "easy_negative": [
      69629714,
      193799747,
      218516925
    ]
  },
  {
    "index": 3585,
    "source_corpus_id": 238856948,
    "ref_id": "b0",
    "citation_corpus_id": 6771196,
    "start": 1361,
    "end": 1379,
    "title": "FINE-GRAINED ANALYSIS OF SENTENCE EMBEDDINGS USING AUXILIARY PREDICTION TASKS",
    "abstract": "There is a lot of research interest in encoding variable length sentences into fixed length vectors, in a way that preserves the sentence meanings. Two common methods include representations based on averaging word vectors, and representations based on the hidden states of recurrent neural networks such as LSTMs. The sentence vectors are used as features for subsequent machine learning tasks or for pre-training in the context of deep learning. However, not much is known about the properties that are encoded in these sentence representations and about the language information they capture. We propose a framework that facilitates better understanding of the encoded representations. We define prediction tasks around isolated aspects of sentence structure (namely sentence length, word content, and word order), and score representations by the ability to train a classifier to solve each prediction task when using the representation as input. We demonstrate the potential contribution of the approach by analyzing different sentence representation mechanisms. The analysis sheds light on the relative strengths of different sentence embedding methods with respect to these low level prediction tasks, and on the effect of the encoded vector's dimensionality on the resulting representations.Published as a conference paper at ICLR 2017 Some systems (for example in machine translation) train the system end-to-end, and use the trained system for prediction . Such systems do not generally care about the encoded vectors, which are used merely as intermediate values. However, another common case is to train an encoder-decoder network and then throw away the decoder and use the trained encoder as a general mechanism for obtaining sentence representations. For example, an encoder-decoder network can be trained as an auto-encoder, where the encoder creates a vector representation, and the decoder attempts to recreate the original sentence . Similarly,Kiros et al. (2015)train a network to encode a sentence such that the decoder can recreate its neighboring sentences in the text. Such networks do not require specially labeled data, and can be trained on large amounts of unannotated text. As the decoder needs information about the sentence in order to perform well, it is clear that the encoded vectors capture a non-trivial amount of information about the sentence, making the encoder appealing to use as a general purpose, stand-alone sentence encoding mechanism. The sentence encodings can then be used as input for other prediction tasks for which less training data is available(Dai & Le, 2015). In this work we focus on these \"general purpose\" sentence encodings.The resulting sentence representations are opaque, and there is currently no good way of comparing different representations short of using them as input for different high-level semantic tasks (e.g. sentiment classification, entailment recognition, document retrieval, question answering, sentence similarity, etc.) and measuring how well they perform on these tasks. This is the approach taken by Li et al.(2015),Hill et al. (2016)andKiros et al. (2015). This method of comparing sentence embeddings leaves a lot to be desired: the comparison is at a very coarse-grained level, does not tell us much about the kind of information that is encoded in the representation, and does not help us form generalizable conclusions.",
    "prev": "We compare two recent ranking methods and a simple one we introduce, and evaluate them with regard to both of these aspects.",
    "curr": "1\n\nINTRODUCTION\n\nMany studies attempt to interpret language models by predicting different linguistic properties from word representations, an approach called probing classifiers (Adi et al., 2017;Conneau et al., 2018, inter alia).",
    "next": "A growing body of work focuses on individual neurons within the representation, attempting to show in which neurons some information is encoded, and whether it is localized (concentrated in a small set of neurons) or dispersed.",
    "hard_negative": [
      2937095,
      85205,
      12730203
    ],
    "easy_negative": [
      193233974,
      220042223,
      252967802
    ]
  },
  {
    "index": 3594,
    "source_corpus_id": 249642402,
    "ref_id": "b36",
    "citation_corpus_id": 68137503,
    "start": 2525,
    "end": 2542,
    "title": "FUNCTIONAL VARIATIONAL BAYESIAN NEURAL NETWORKS",
    "abstract": "Variational Bayesian neural networks (BNNs) perform variational inference over weights, but it is difficult to specify meaningful priors and approximate posteriors in a high-dimensional weight space. We introduce functional variational Bayesian neural networks (fBNNs), which maximize an Evidence Lower BOund (ELBO) defined directly on stochastic processes, i.e. distributions over functions. We prove that the KL divergence between stochastic processes equals the supremum of marginal KL divergences over all finite sets of inputs. Based on this, we introduce a practical training objective which approximates the functional ELBO using finite measurement sets and the spectral Stein gradient estimator. With fBNNs, we can specify priors entailing rich structures, including Gaussian processes and implicit stochastic processes. Empirically, we find fBNNs extrapolate well using various structured priors, provide reliable uncertainty estimates, and scale to large datasets. * Equal contribution.Theorem 7. For two stochastic processes P, M on a cylindrical measurable space (\u2126 T , F T ), the KL divergence of P with respect to M satisfies,where the supremum is over all finite indices subsets T d \u2286 T , and P T d , M T d represent the canonical projection maps \u03c0 T \u2192T d of P, M , respectively.Proof. Recall that stochastic processes are defined over a cylindrical \u03c3-algebra F T . By Lemma 6, for every set H \u2208 F T , the restricted index set \u03c4 (H) is countable. Our proof proceeds in two steps:",
    "prev": "Nevertheless, all these issues can be alleviated by carrying out approximate inference in the space of functions, which presents certain advantages due to the simplified problem.",
    "curr": "This makes the approximations obtained in this space more precise than those obtained in parameter-space, as shown in the literature (Ma et al., 2019;Sun et al., 2019;Santana et al., 2021;Ma and Hern\u00e1ndez-Lobato, 2021).",
    "next": "A recent method for function-space approximate inference is the Variational Implicit Process (VIP) (Ma et al., 2019).",
    "hard_negative": [
      3708505,
      3502463
    ],
    "easy_negative": [
      3099330,
      231642812,
      198993530
    ]
  },
  {
    "index": 3601,
    "source_corpus_id": 222125298,
    "ref_id": "b1",
    "citation_corpus_id": 11212020,
    "start": 1748,
    "end": 1771,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "Its key difference with previous methods, e.g., recurrent neural networks, convolutional neural networks (CNNs), is its ability to query information from all the input words simultaneously.",
    "curr": "This is achieved via the self-attention operation (Bahdanau et al., 2015;Cheng et al., 2016), which computes the similarity between representations of words in the sequence in the form of attention scores.",
    "next": "Next, the representation of each word is updated based on the words with the highest attention scores.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      9355314,
      16668385,
      52282520
    ]
  },
  {
    "index": 3610,
    "source_corpus_id": 248834505,
    "ref_id": "b1",
    "citation_corpus_id": 2906360,
    "start": 3038,
    "end": 3058,
    "title": "DEEPCODER: LEARNING TO WRITE PROGRAMS",
    "abstract": "We develop a first line of attack for solving programming competition-style problems from input-output examples using deep learning. The approach is to train a neural network to predict properties of the program that generated the outputs from the inputs. We use the neural network's predictions to augment search techniques from the programming languages community, including enumerative search and an SMT-based solver. Empirically, we show that our approach leads to an order of magnitude speedup over the strong non-augmented baselines and a Recurrent Neural Network approach, and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites.Published as a conference paper at ICLR 2017 show orders-of-magnitude improvements over optimized standard search techniques and a Recurrent Neural Network-based approach to the problem.",
    "prev": "INTRODUCTION\n\nProgram synthesis is the task of automatically finding a program that satisfies the user intent expressed in the form of some specifications like input-output examples .",
    "curr": "Recently, there has been an increasing interest in tackling it using neural networks in various domains, including string manipulation (Gulwani, 2011;Gulwani et al., 2012;Devlin et al., 2017b), list processing (Balog et al., 2017;Zohar & Wolf, 2018) and graphic applications (Ellis et al., 2018;.",
    "next": "Despite their promising performance, most of their success relies on the well-designed input-output examples, without which the performance of the program synthesis model drops heavily.",
    "hard_negative": [
      2926851,
      7034786,
      6715185
    ],
    "easy_negative": [
      219302028,
      259376723,
      235294194
    ]
  },
  {
    "index": 3614,
    "source_corpus_id": 257427479,
    "ref_id": "b17",
    "citation_corpus_id": 52917627,
    "start": 8390,
    "end": 8406,
    "title": "LEARNING PARTICLE DYNAMICS FOR MANIPULATING RIGID BODIES, DEFORMABLE OBJECTS, AND FLUIDS",
    "abstract": "Real-life control tasks involve matter of various substances-rigid or soft bodies, liquid, gas-each with distinct physical behaviors. This poses challenges to traditional rigid-body physics engines. Particle-based simulators have been developed to model the dynamics of these complex scenes; however, relying on approximation techniques, their simulation often deviates from real world physics, especially in the long term. In this paper, we propose to learn a particle-based simulator for complex control tasks. Combining learning with particle-based systems brings in two major benefits: first, the learned simulator, just like other particle-based systems, acts widely on objects of different materials; second, the particle-based representation poses strong inductive bias for learning: particles of the same type have the same dynamics within. This enables the model to quickly adapt to new environments of unknown dynamics within a few observations. Using the learned simulator, robots have achieved success in complex manipulation tasks, such as manipulating fluids and deformable foam. The effectiveness of our method has also been demonstrated in the real world. Our study helps lay the foundation for robot learning of dynamic scenes with particle-based representations.",
    "prev": "System identification of soft bodies is an extremely challenging task, owing to its high dimensionality and the presence of large deformations.",
    "curr": "Neural (Sanchez-Gonzalez et al., 2020;Li et al., 2019;Xu et al., 2019) Figure 1: PAC-NeRF uses both Lagrangian (particle; material-space) and Eulerian (grid; world-space) representations for an accurate yet tractable computational model of continuum materials.",
    "next": "P2G and G2P denote particle-to-grid and grid-to-particle transforms, respectively.",
    "hard_negative": [
      6981893,
      6628106,
      3566136,
      195346786,
      51559,
      5763832
    ],
    "easy_negative": [
      10659650,
      2029665,
      1545841
    ]
  },
  {
    "index": 3616,
    "source_corpus_id": 252815793,
    "ref_id": "b3",
    "citation_corpus_id": 52889459,
    "start": 2205,
    "end": 2230,
    "title": "LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS",
    "abstract": "Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple \"truncation trick,\" allowing fine control over the trade-off between sample fidelity and variety by truncating the latent space. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128\u00d7128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.3 and Fr\u00e9chet Inception Distance (FID) of 9.6, improving over the previous best IS of 52.52 and FID of 18.65.",
    "prev": "The quantitative experiments show that the refined basis achieves better semantic factorization while constrained on the same semantic subspace given by the previous method.",
    "curr": "INTRODUCTION\n\nGenerative Adversarial Networks (GANs, (Goodfellow et al., 2014)) have achieved impressive success in high-fidelity image synthesis, such as ProGAN (Karras et al., 2018), BigGAN (Brock et al., 2018), andStyleGANs (Karras et al., 2019;2020a;b;.",
    "next": "Interestingly, even when a GAN model is trained without any information about the semantics of data, its latent space often represents the semantic property of data (Radford et al., 2016;Karras et al., 2019).",
    "hard_negative": [
      17272965,
      14124313,
      3398677,
      5687613
    ],
    "easy_negative": [
      9613237,
      337505,
      228019
    ]
  },
  {
    "index": 3617,
    "source_corpus_id": 9996719,
    "ref_id": "b1",
    "citation_corpus_id": 11212020,
    "start": 4378,
    "end": 4401,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "The captions describe a common object doing unusual things or set in a strange location.",
    "curr": "RELATED WORK\n\nDeep Neural Networks have achieved significant success in various tasks such as image recognition (Krizhevsky et al., 2012), speech transcription (Graves et al., 2013), and machine translation (Bahdanau et al., 2015).",
    "next": "While most of the recent success has been achieved by discriminative models, generative models have not yet enjoyed the same level of success.",
    "hard_negative": [
      1274371,
      13805769,
      8884845,
      10766958,
      1870512,
      8608051,
      11336213,
      12639289
    ],
    "easy_negative": [
      10460252,
      237502881,
      3701555
    ]
  },
  {
    "index": 3619,
    "source_corpus_id": 2181703,
    "ref_id": "b37",
    "citation_corpus_id": 1487550,
    "start": 5650,
    "end": 5666,
    "title": "UNSUPERVISED WORD SENSE DISAMBIGUATION RIVALING SUPERVISED METHODS",
    "abstract": "This paper presents an unsupervised learning algorithm for sense disambiguation that, when trained on unannotated English text, rivals the performance of supervised techniques that require time-consuming hand annotations. The algorithm is based on two powerful constraints -that words tend to have one sense per discourse and one sense per collocation -exploited in an iterative bootstrapping procedure. Tested accuracy exceeds 96%.",
    "prev": "RELATED WORK\n\nThe literature on semi-supervised and weakly-supervised learning is vast (see Zhu (2005) for a survey), and so in this section we focus on the key previous papers that inspired this work and on other papers on weakly-and semi-supervised deep learning.",
    "curr": "The notion of bootstrapping, or \"self-training\" a learning agent was proposed in (Yarowsky, 1995) as a way to do word-sense disambiguation with only unlabeled examples and a small list of seed example sentences with labels.",
    "next": "The algorithm proceeds by building an initial classifier using the seed examples, and then iteratively classifying unlabeled examples, extracting new seed rules for the classifier using the now expanded training data, and repeating these steps until convergence.",
    "hard_negative": [
      11329942,
      1693468,
      3166885,
      1580335,
      5458997,
      2946526,
      9537399
    ],
    "easy_negative": [
      1890099,
      18208195,
      44095805
    ]
  },
  {
    "index": 3620,
    "source_corpus_id": 7823468,
    "ref_id": "b7",
    "citation_corpus_id": 16391184,
    "start": 5263,
    "end": 5266,
    "title": "cdec: A Decoder, Alignment, and Learning Framework for Finite-State and Context-Free Translation Models",
    "abstract": "We present cdec, an open source framework for decoding, aligning with, and training a number of statistical machine translation models, including word-based models, phrase-based models, and models based on synchronous context-free grammars. Using a single unified internal representation for translation forests, the decoder strictly separates model-specific translation logic from general rescoring, pruning, and inference algorithms. From this unified representation, the decoder can extract not only the 1-or k-best translations, but also alignments to a reference, or the quantities necessary to drive discriminative training using gradient-based or gradient-free optimization techniques. Its efficient C++ implementation means that memory use and runtime performance are significantly better than comparable decoders.",
    "prev": "Secondly, we use Grid LSTM to define a novel neural translation model that views translation as a two-dimensional mapping.",
    "curr": "The network outperforms the reference phrase-based CDEC system [8] on the IWSLT BTEC Chinese-to-Ensligh translation task.",
    "next": "Thirdly, we apply three-dimensional Grid LSTM to classifying MNIST digits and achieve near state-of-the-art test set error of 0.32%.",
    "hard_negative": [
      824837,
      6677774,
      8020400,
      7721910,
      13936575,
      14770371,
      12858058,
      5246803,
      3510512,
      8776310
    ],
    "easy_negative": [
      51622701,
      43384050,
      9476097
    ]
  },
  {
    "index": 3622,
    "source_corpus_id": 13890001,
    "ref_id": "b28",
    "citation_corpus_id": 17127188,
    "start": 5779,
    "end": 5798,
    "title": "MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS",
    "abstract": "State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction problems such as semantic segmentation are structurally different from image classification. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multiscale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy.",
    "prev": "Our model, the Introspective Adversarial Network (IAN), is a hybridization of the VAE and GAN that leverages the power of the adversarial objective while maintaining the VAE's efficient inference mechanism, improving upon previous VAE/GAN hybrids both in parametric efficiency and output quality.",
    "curr": "We employ a novel convolutional block based on dilated convolutions (Yu & Koltun, 2016) to efficiently increase the network's receptive field, and Orthogonal Regularization, a novel weight regularizer.",
    "next": "We demonstrate the qualitative sampling, reconstructing, and interpolating ability of the IAN on CelebA (Liu et al., 2015), SVHN (Netzer et al., 2011), CIFAR-10 (Krizhevsky & Hinton, 2009, and Imagenet (Russakovsky et al., 2015), and quantitatively demonstrate its inference capabilities with competitive performance on the semi-supervised SVHN classification task.",
    "hard_negative": [
      14124313,
      1996665
    ],
    "easy_negative": [
      237204582,
      252818956,
      257232602
    ]
  },
  {
    "index": 3626,
    "source_corpus_id": 239024453,
    "ref_id": "b41",
    "citation_corpus_id": 232257725,
    "start": 2120,
    "end": 2138,
    "title": "Published as a conference paper at ICLR 2021 GRADIENT PROJECTION MEMORY FOR CONTINUAL LEARNING",
    "abstract": "The ability to learn continually without forgetting the past tasks is a desired attribute for artificial learning systems. Existing approaches to enable such learning in artificial neural networks usually rely on network growth, importance based weight update or replay of old data from the memory. In contrast, we propose a novel approach where a neural network learns new tasks by taking gradient steps in the orthogonal direction to the gradient subspaces deemed important for the past tasks. We find the bases of these subspaces by analyzing network representations (activations) after learning each task with Singular Value Decomposition (SVD) in a single shot manner and store them in the memory as Gradient Projection Memory (GPM). With qualitative and quantitative analyses, we show that such orthogonal gradient descent induces minimum to no interference with the past tasks, thereby mitigates forgetting. We evaluate our algorithm on diverse image classification datasets with short and long sequences of tasks and report better or on-par performance compared to the state-of-the-art approaches 1 . 1 Our code is available at https",
    "prev": "INTRODUCTION\n\nContinual learning (CL) is a learning scenario where a model learns from a continuous and online stream of data and is regarded as a more realistic and practical learning setup than offline learning on a fixed dataset (He et al., 2020).",
    "curr": "However, many CL methods still focus on the offline setup (Kirkpatrick et al., 2017;Rebuffi et al., 2017;Saha et al., 2021) instead of the more realistic online setup.",
    "next": "These methods assume access to a large storage, storing the entire data of the current task and iterating on it multiple times.",
    "hard_negative": [
      6212000,
      53100211,
      3693512,
      211132756
    ],
    "easy_negative": [
      18215508,
      5186579,
      8928513
    ]
  },
  {
    "index": 3632,
    "source_corpus_id": 212718244,
    "ref_id": "b35",
    "citation_corpus_id": 1957433,
    "start": 20874,
    "end": 20899,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "'anxiety') words compiled by Hu & Liu (2004).",
    "curr": "We embed words using 300-dimensional GloVe (Pennington et al., 2014) and train a one layer neural network with 1000 hidden units.",
    "next": "Such classifier achieves 95% test accuracy, however it entails major individual fairness violation.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      7524356,
      259376544,
      25323554
    ]
  },
  {
    "index": 3640,
    "source_corpus_id": 53325983,
    "ref_id": "b10",
    "citation_corpus_id": 5590763,
    "start": 33396,
    "end": 33414,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "ARGP can be viewed as a non-linear version of AR model.",
    "curr": "\u2022 Recurrent Neural Networks (RNN) (Cho et al., 2014) are powerful neural networks for learning non-linear temporal dynamical systems.",
    "next": "We consider gated recurrent units (GRU) in our implementation.",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      14406864,
      1003566,
      226283958
    ]
  },
  {
    "index": 3645,
    "source_corpus_id": 2780493,
    "ref_id": "b24",
    "citation_corpus_id": 14124313,
    "start": 1580,
    "end": 1608,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "1  The code allowing to reproduce the experiments is available at\n\nINTRODUCTION\n\nDeep nets have demonstrated impressive results on a number of computer vision and natural language processing problems.",
    "curr": "At present, state-of-the-art results in image classification (Simonyan & Zisserman (2015); Szegedy et al.",
    "next": "(2015)) and speech recognition (Sercu et al.",
    "hard_negative": [
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      15532760,
      9603155,
      6960240
    ]
  },
  {
    "index": 3652,
    "source_corpus_id": 260440449,
    "ref_id": "b20",
    "citation_corpus_id": 209315300,
    "start": 2813,
    "end": 2833,
    "title": "REFORMER: THE EFFICIENT TRANSFORMER",
    "abstract": "Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O(L 2 ) to O(L log L), where L is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of N times, where N is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.Published as a conference paper at ICLR 2020We introduce the Reformer model which solves these problems using the following techniques:\u2022 Reversible layers, first introduced in Gomez et al.(2017), enable storing only a single copy of activations in the whole model, so the N factor disappears. \u2022 Splitting activations inside feed-forward layers and processing them in chunks removes the d f f factor and saves memory inside feed-forward layers.",
    "prev": "A common weakness of Transformers is their quadratic memory complexity within the self-attention mechanism that restricts their potential application to domains requiring longer sequence lengths.",
    "curr": "To date, a dizzying number of efficient Transformer models ('xformers') have been proposed to tackle this problem (Liu et al., 2018;Kitaev et al., 2020;Tay et al., 2020b;Katharopoulos et al., 2020).",
    "next": "Many of these models demonstrate comparable performance to the vanilla Transformer model while successfully reducing the memory complexity of the self-attention mechanism.",
    "hard_negative": [
      44131019,
      13751870
    ],
    "easy_negative": [
      227342850,
      252873184,
      204838340
    ]
  },
  {
    "index": 3655,
    "source_corpus_id": 228084090,
    "ref_id": "b0",
    "citation_corpus_id": 52010710,
    "start": 1636,
    "end": 1655,
    "title": "Contextual String Embeddings for Sequence Labeling",
    "abstract": "Recent advances in language modeling using recurrent neural networks have made it viable to model language as distributions over characters. By learning to predict the next character on the basis of previous characters, such models have been shown to automatically internalize linguistic concepts such as words, sentences, subclauses and even sentiment. In this paper, we propose to leverage the internal states of a trained character language model to produce a novel type of word embedding which we refer to as contextual string embeddings. Our proposed embeddings have the distinct properties that they (a) are trained without any explicit notion of words and thus fundamentally model words as sequences of characters, and (b) are contextualized by their surrounding text, meaning that the same word will have different embeddings depending on its contextual use. We conduct a comparative evaluation against previous embeddings and find that our embeddings are highly useful for downstream tasks: across four classic sequence labeling tasks we consistently outperform the previous state-of-the-art. In particular, we significantly outperform previous work on English and German named entity recognition (NER), allowing us to report new state-of-the-art F1-scores on the CONLL03 shared task.We release all code and pre-trained language models in a simple-to-use framework to the research community, to enable reproduction of these experiments and application of our proposed embeddings to other tasks: https://github.com/zalandoresearch/flair 1. Classical word embeddings(Pennington et al., 2014;, pre-trained over very large corpora and shown to capture latent syntactic and semantic similarities.2. Character-level features(Ma and Hovy, 2016;Lample et al., 2016), which are not pre-trained, but trained on task data to capture task-specific subword features. 3. Contextualized word embeddings (Peters et al., 2017; Peters et al., 2018) that capture word semantics in context to address the polysemous and context-dependent nature of words. This work is licensed under a Creative Commons Attribution 4.0 International License. License details: http:// creativecommons.org/licenses/by/4.0/",
    "prev": "INTRODUCTION\n\nNamed entity recognition (NER) is an important task in information extraction.",
    "curr": "Previous methods typically cast it into a sequence labeling problem by adopting IOB tagging scheme (Huang et al., 2015;Ma & Hovy, 2016;Akbik et al., 2018).",
    "next": "A representative model is Bi-LSTM CRF (Lample et al., 2016).",
    "hard_negative": [
      8940645,
      15645669,
      23678406,
      14068874,
      3411445,
      16661147
    ],
    "easy_negative": [
      6035777,
      237452461,
      201639847
    ]
  },
  {
    "index": 3657,
    "source_corpus_id": 232233782,
    "ref_id": "b26",
    "citation_corpus_id": 2181703,
    "start": 2179,
    "end": 2198,
    "title": "Under review as a conference paper at ICLR 2015 TRAINING DEEP NEURAL NETWORKS ON NOISY LABELS WITH BOOTSTRAPPING",
    "abstract": "Current state-of-the-art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting. The performance depends critically on the amount of labeled examples, and in current practice the labels are assumed to be unambiguous and accurate. However, this assumption often does not hold; e.g. in recognition, class labels may be missing; in detection, objects in the image may not be localized; and in general, the labeling may be subjective. In this work we propose a generic way to handle noisy and incomplete labeling by augmenting the prediction objective with a notion of consistency. We consider a prediction consistent if the same prediction is made given similar percepts, where the notion of similarity is between deep network features computed from the input data. In experiments we demonstrate that our approach yields substantial robustness to label noise on several datasets. On MNIST handwritten digits, we show that our model is robust to label corruption. On the Toronto Face Database, we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-theart results, and can also benefit from unlabeled face images with no modification to our method. On the ILSVRC2014 detection challenge data, we show that our approach extends to very deep networks, high resolution images and structured outputs, and results in improved scalable detection.",
    "prev": "assumption on the label noise, i.e., the label corruption is independent and identically distributed and thus is feature-independent.",
    "curr": "Methods based on this assumption either explicitly estimate the noise pattern (Reed et al., 2014;Patrini et al., 2017;Dan et al., 2019; or introduce extra regularizer/loss terms (Natarajan et al., 2013;Van Rooyen et al., 2015;Xiao et al., 2015;Zhang & Sabuncu, 2018;Arazo et al., 2019;Shen & Sanghavi, 2019).",
    "next": "Some results prove that the commonly used losses are naturally robust against such i.i.d.",
    "hard_negative": [
      9955856,
      1487550,
      1965764
    ],
    "easy_negative": [
      7204869,
      3119193,
      16715295
    ]
  },
  {
    "index": 3662,
    "source_corpus_id": 2922805,
    "ref_id": "b9",
    "citation_corpus_id": 7417943,
    "start": 2657,
    "end": 2677,
    "title": "Fast and Robust Neural Network Joint Models for Statistical Machine Translation",
    "abstract": "Recent work has shown success in using neural network language models (NNLMs) as features in MT systems. Here, we present a novel formulation for a neural network joint model (NNJM), which augments the NNLM with a source context window. Our model is purely lexicalized and can be integrated into any MT decoder. We also present several variations of the NNJM which provide significant additive improvements.",
    "prev": "Instead of using fixed number of words to represent context, recurrent neural network language models (RNNLMs) (Mikolov et al., 2010) use a recurrent hidden layer to represent longer and variable length histories.",
    "curr": "RNNLMs significantly outperform traditional n-gram LMs, and are therefore becoming an increasingly popular choice for practitioners (Mikolov et al., 2010;Sundermeyer et al., 2013;Devlin et al., 2014).",
    "next": "Consider a standard RNNLM, depicted in Figure 1.",
    "hard_negative": [
      1274371,
      3065236,
      16909338,
      15208097,
      171695,
      8608051,
      5219389,
      17192521,
      9902281,
      1821900,
      7478738,
      931054,
      45404405,
      5552894
    ],
    "easy_negative": [
      15330088,
      62584777,
      233365104
    ]
  },
  {
    "index": 3663,
    "source_corpus_id": 16209268,
    "ref_id": "b16",
    "citation_corpus_id": 17272965,
    "start": 6118,
    "end": 6137,
    "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
    "abstract": "Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.Deep learning methods have realized impressive performance in a range of applications, from visual object classification [1, 2, 3] to speech recognition [4] and natural language processing[5,6]. These successes have been achieved despite the noted difficulty of training such deep architectures[7,8,9,10,11]. Indeed, many explanations for the difficulty of deep learning have been advanced in the literature, including the presence of many local minima, low curvature regions due to saturating nonlinearities, and exponential growth or decay of back-propagated gradients[12,13,14,15]. Furthermore, many neural network simulations have observed 1 arXiv:1312.6120v3 [cs.NE]",
    "prev": "In other words, if we knew the correct direction, a single coarse line search could do a good job of training a neural network.",
    "curr": "These results are consistent with recent empirical and theoretical work arguing that local minima are not a significant problem for training large neural networks (Saxe et al., 2013;Dauphin et al., 2014;Choromanska et al., 2014).",
    "next": "FEED-FORWARD FULLY CONNECTED NETWORKS\n\nWe begin our investigation with the simplest kind of neural network, the deterministic, feed-forward, fully-connected supervised network.",
    "hard_negative": [
      14228101,
      14687186
    ],
    "easy_negative": [
      6085570,
      15013543,
      253116659
    ]
  },
  {
    "index": 3666,
    "source_corpus_id": 222272305,
    "ref_id": "b11",
    "citation_corpus_id": 59536625,
    "start": 6113,
    "end": 6146,
    "title": "BABYAI: A PLATFORM TO STUDY THE SAMPLE EFFI- CIENCY OF GROUNDED LANGUAGE LEARNING",
    "abstract": "Allowing humans to interactively train artificial agents to understand language instructions is desirable for both practical and scientific reasons. Though, given the lack of sample efficiency in current learning methods, reaching this goal may require substantial research efforts. We introduce the BabyAI research platform, with the goal of supporting investigations towards including humans in the loop for grounded language learning. The BabyAI platform comprises an extensible suite of 19 levels of increasing difficulty. Each level gradually leads the agent towards acquiring a combinatorially rich synthetic language, which is a proper subset of English. The platform also provides a hand-crafted bot agent, which simulates a human teacher. We report estimated amount of supervision required for training neural reinforcement and behavioral-cloning agents on some BabyAI levels. We put forward strong evidence that current deep learning methods are not yet sufficiently sample-efficient in the context of learning a language with compositional properties.",
    "prev": "The possibility of intervening on any of these properties at any point in time allows one to set up training curricula or to evaluate an agent's generalization capability with respect to different parameters.",
    "curr": "Furthermore, in contrast to previous benchmarks (Chevalier-Boisvert et al., 2018;Cobbe et al., 2018), researchers may build their own real-world platform of this simulator at low cost, as detailed in W\u00fcthrich et al.",
    "next": "(2020), and transfer their trained policies to the real world.",
    "hard_negative": [
      6628106,
      52911374,
      9963298,
      7034786,
      2705742,
      5590763,
      11212020,
      3075448
    ],
    "easy_negative": [
      2358556,
      33266041,
      261349585
    ]
  },
  {
    "index": 3668,
    "source_corpus_id": 52901322,
    "ref_id": "b2",
    "citation_corpus_id": 7167114,
    "start": 4151,
    "end": 4171,
    "title": "DEEP VARIATIONAL INFORMATION BOTTLENECK",
    "abstract": "We present a variational approximation to the information bottleneck ofTishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterization trick for efficient training. We call this method \"Deep Variational Information Bottleneck\", or Deep VIB. We show that models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack.",
    "prev": "For example in Figure 1b, the corrupted image is mapped to a two-component mixture of Gaussians covering both the \"17\" and \"47\" clusters.",
    "curr": "We propose a training scheme for the HIB with a learnable-margin contrastive loss and the variational information bottleneck (VIB) principle (Alemi et al., 2016;Achille & Soatto, 2018).",
    "next": "When both \"17\" and \"47\" are plausible, our 2-component Gaussian mixture embedding has the power to spread probability mass on clusters with clean \"17\" and \"47\" images.",
    "hard_negative": [
      6628106,
      1257772,
      604334,
      5922522,
      6706414
    ],
    "easy_negative": [
      18727028,
      209380500,
      52289309
    ]
  },
  {
    "index": 3672,
    "source_corpus_id": 257102642,
    "ref_id": "b0",
    "citation_corpus_id": 11212020,
    "start": 4167,
    "end": 4190,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "In this way, we replace the multi-round model-based interactions in the conventional FL paradigm with the one-round encrypted memorization-based interaction to share knowledge among different clients and drastically reduce computation and communication overhead.",
    "curr": "INTRODUCTION\n\nIn recent years, neural machine translation (NMT) has significantly improved translation quality (Bahdanau et al., 2015;Vaswani et al., 2017;Hassan et al., 2018) and has been widely adopted in many commercial systems.",
    "next": "The current mainstream system is first built on a large-scale corpus collected by the service provider and then directly applied to translation tasks for different users and enterprises.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      224705257,
      9409808,
      218974056
    ]
  },
  {
    "index": 3677,
    "source_corpus_id": 231855369,
    "ref_id": "b17",
    "citation_corpus_id": 3292002,
    "start": 2561,
    "end": 2585,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "Our code is publicly available as part of the DIG library\n\nINTRODUCTION\n\nIn many real-world studies, structured objects such as molecules are naturally modeled as graphs (Gori et al., 2005;Wu et al., 2018;Shervashidze et al., 2011;Fout et al., 2017;Liu et al., 2020;Wang et al., 2022).",
    "curr": "With the advances of deep learning, graph neural networks (GNNs) have been developed for learning from graph data (Kipf & Welling, 2017;Defferrard et al., 2016;Veli\u010dkovi\u0107 et al., 2018;Zhang et al., 2018;Xu et al., 2019;Gao & Ji, 2019;Gao et al., 2018;.",
    "next": "Currently, the message passing scheme (Gilmer et al., 2017;Sanchez-Gonzalez et al., 2020;Vignac et al., 2020;Battaglia et al., 2018) is one of the commonly used architectures for realizing GNNs.",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      201741642,
      16725676,
      215814371
    ]
  },
  {
    "index": 3679,
    "source_corpus_id": 213488539,
    "ref_id": "b19",
    "citation_corpus_id": 44122339,
    "start": 2411,
    "end": 2429,
    "title": "AdvEntuRe: Adversarial Training for Textual Entailment with Knowledge-Guided Examples",
    "abstract": "We consider the problem of learning textual entailment models with limited supervision (5K-10K training examples), and present two complementary approaches for it. First, we propose knowledge-guided adversarial example generators for incorporating large lexical resources in entailment models via only a handful of rule templates. Second, to make the entailment model-a discriminator-more robust, we propose the first GAN-style approach for training it using a natural language example generator that iteratively adjusts based on the discriminator's performance. We demonstrate effectiveness using two entailment datasets, where the proposed methods increase accuracy by 4.7% on SciTail and by 2.8% on a 1% training sub-sample of SNLI. Notably, even a single hand-written rule, negate, improves the accuracy on the negation examples in SNLI by 6.1%.",
    "prev": "On the other hand is the rich history of rule-based methods (Appelt et al., 1993;Cunningham, 2002) where humans code-up their supervision as labeling rules.",
    "curr": "There is growing interest in learning from such efficient, albiet noisy, supervision (Ratner et al., 2016;Pal & Balasubramanian, 2018;Bach et al., 2019;Sun et al., 2018;Kang et al., 2018).",
    "next": "However, clean task-specific instance labels continue to be critical for reliable results (Goh et al., 2018;Bach et al., 2019) in spite of easy availability of pre-trained models (Sun et al., 2017;Devlin et al., 2018).",
    "hard_negative": [
      9711750,
      793863,
      4537113,
      8495258,
      7228830,
      779551,
      6067240,
      1957433,
      1671874,
      3626819,
      4956100,
      11816014,
      1998416,
      19204066,
      2742513,
      2854390,
      9707387
    ],
    "easy_negative": [
      250390964,
      4718302,
      14249712
    ]
  },
  {
    "index": 3682,
    "source_corpus_id": 256105572,
    "ref_id": "b19",
    "citation_corpus_id": 58014184,
    "start": 3752,
    "end": 3770,
    "title": "ATTENTIVE NEURAL PROCESSES",
    "abstract": "Neural Processes (NPs)(Garnelo et al., 2018a;b)approach regression by learning to map a context set of observed input-output pairs to a distribution over regression functions. Each function models the distribution of the output given an input, conditioned on the context. NPs have the benefit of fitting observed data efficiently with linear complexity in the number of context input-output pairs, and can learn a wide family of conditional distributions; they learn predictive distributions conditioned on context sets of arbitrary size. Nonetheless, we show that NPs suffer a fundamental drawback of underfitting, giving inaccurate predictions at the inputs of the observed data they condition on. We address this issue by incorporating attention into NPs, allowing each input location to attend to the relevant context points for the prediction. We show that this greatly improves the accuracy of predictions, results in noticeably faster training, and expands the range of functions that can be modelled.",
    "prev": "Following the spirits of variational auto-encoders (Kingma & Welling, 2014), the work of (Garnelo et al., 2018b) introduces a global latent variable to better capture the uncertainty in the overall structure of the function, which still suffers from the inferior capability for modeling complex signals.",
    "curr": "Attentive Neural Processes (ANP) (Kim et al., 2019) can further alleviate this issue, which leverages the permutation-invariant attention mechanism (Vaswani et al., 2017) to reweight the context points and the target predictions.",
    "next": "However, taking each context point as a token, ANP has troubles in processing complex signals that requires Figure 1: The proposed Versatile Neural Processes framework contains a bottleneck encoder and a hierarchical latent modulated decoder.",
    "hard_negative": [
      4994434,
      6628106,
      10082291,
      11212020
    ],
    "easy_negative": [
      17008846,
      52113643,
      226262186
    ]
  },
  {
    "index": 3686,
    "source_corpus_id": 246867402,
    "ref_id": "b23",
    "citation_corpus_id": 3144218,
    "start": 2220,
    "end": 2241,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "We believe our methods can serve for a more reliable evaluation of the robustness of GNNs.",
    "curr": "INTRODUCTION\n\nGraph Neural Networks (GNNs), as a generalization of deep learning models for graph structured data, have gained great success in tasks involving relational information (Hamilton et al., 2017a;Battaglia et al., 2018;Zhou et al., 2020;Wu et al., 2021;Kipf & Welling, 2017;Hamilton et al., 2017b;Veli\u010dkovi\u0107 et al., 2018;Xu et al., 2018;2019b).",
    "next": "Nevertheless, GNNs are shown to be inherently vulnerable to adversarial attacks (Sun et al., 2018;, or small intentional perturbations on the input (Szegedy et al., 2014).",
    "hard_negative": [
      8393918,
      17682909
    ],
    "easy_negative": [
      236486156,
      227230649,
      52894354
    ]
  },
  {
    "index": 3695,
    "source_corpus_id": 258426655,
    "ref_id": "b3",
    "citation_corpus_id": 51979536,
    "start": 1588,
    "end": 1608,
    "title": "Large-Scale Study of Curiosity-Driven Learning",
    "abstract": "Reinforcement learning algorithms rely on carefully engineering environment rewards that are extrinsic to the agent. However, annotating each environment with hand-designed, dense rewards is not scalable, motivating the need for developing reward functions that are intrinsic to the agent. Curiosity is a type of intrinsic reward function which uses prediction error as reward signal. In this paper: (a) We perform the first large-scale study of purely curiosity-driven learning, i.e. without any extrinsic rewards, across 54 standard benchmark environments, including the Atari game suite. Our results show surprisingly good performance, and a high degree of alignment between the intrinsic curiosity objective and the handdesigned extrinsic rewards of many game environments. (b) We investigate the effect of using different feature spaces for computing prediction error and show that random features are sufficient for many popular RL game benchmarks, but learned features appear to generalize better (e.g. to novel game levels in Super Mario Bros.). (c) We demonstrate limitations of the prediction-based rewards in stochastic setups. Game-play videos and code are at https://pathak22.github. io/large-scale-curiosity/. * Alphabetical ordering; the first three authors contributed equally.Preprint. Work in progress.",
    "prev": "INTRODUCTION\n\nExploration in complex environments with long horizon and high-dimensional input such as images has always been challenging in reinforcement learning.",
    "curr": "In recent years, multiple works (Stadie et al., 2015;Bellemare et al., 2016;Tang et al., 2017;Pathak et al., 2017;Burda et al., 2019a;b;Badia et al., 2020) propose to use intrinsic motivation to encourage the agent to explore less-frequently visited states or transitions and gain success in some hard exploration tasks in RL.",
    "next": "Go-explore (Ecoffet et al., 2021) proposes to solve the hard exploration problem by building a state archive and training worker policies to reach the old states and explore new states.",
    "hard_negative": [
      12256925,
      5037032
    ],
    "easy_negative": [
      256461210,
      233181798,
      9557558
    ]
  },
  {
    "index": 3699,
    "source_corpus_id": 222208985,
    "ref_id": "b21",
    "citation_corpus_id": 1619841,
    "start": 6428,
    "end": 6445,
    "title": "Random Walk Inference and Learning in A Large Scale Knowledge Base",
    "abstract": "We consider the problem of performing learning and inference in a large scale knowledge base containing imperfect knowledge with incomplete coverage. We show that a soft inference procedure based on a combination of constrained, weighted, random walks through the knowledge base graph can be used to reliably infer new beliefs for the knowledge base.More specifically, we show that the system can learn to infer different target relations by tuning the weights associated with random walks that follow different paths through the graph, using a version of the Path Ranking Algorithm (Lao and Cohen, 2010b). We apply this approach to a knowledge base of approximately 500,000 beliefs extracted imperfectly from the web by NELL, a never-ending language learner (Carlson et al., 2010). This new system improves significantly over NELL's earlier Horn-clause learning and inference method: it obtains nearly double the precision at rank 100, and the new learning method is also applicable to many more inference tasks.",
    "prev": "Most traditional methods enumerate relational paths between query entities and answer entities as candidate logic rules, and further learn a scalar weight for each rule to assess the quality.",
    "curr": "Representative methods include Markov logic networks (Kok & Domingos, 2005;Richardson & Domingos, 2006;Khot et al., 2011), relational dependency networks (Neville & Jensen, 2007;Natarajan et al., 2010), rule mining algorithms (Gal\u00e1rraga et al., 2013;Meilicke et al., 2019), path ranking (Lao & Cohen, 2010;Lao et al., 2011) and probabilistic personalized page rank (ProPPR) algorithms (Wang et al., 2013;2014a;b).",
    "next": "Some recent methods extend the idea by simultaneously learning logic rules and the weights in a differentiable way, and most of them are based on neural logic programming (Rockt\u00e4schel & Riedel, 2017;Yang et al., 2017;Cohen et al., 2018;Sadeghian et al., 2019;Yang & Song, 2020) or neural theorem provers (Rockt\u00e4schel & Riedel, 2017;Minervini et al., 2020).",
    "hard_negative": [
      14680675,
      7217671,
      1455080,
      2725774
    ],
    "easy_negative": [
      16919810,
      219308139,
      29931698
    ]
  },
  {
    "index": 3703,
    "source_corpus_id": 256697483,
    "ref_id": "b3",
    "citation_corpus_id": 6775391,
    "start": 1953,
    "end": 1973,
    "title": "END-TO-END OPTIMIZED IMAGE COMPRESSION",
    "abstract": "We describe an image compression method, consisting of a nonlinear analysis transformation, a uniform quantizer, and a nonlinear synthesis transformation. The transforms are constructed in three successive stages of convolutional linear filters and nonlinear activation functions. Unlike most convolutional neural networks, the joint nonlinearity is chosen to implement a form of local gain control, inspired by those used to model biological neurons. Using a variant of stochastic gradient descent, we jointly optimize the entire model for rate-distortion performance over a database of training images, introducing a continuous proxy for the discontinuous loss function arising from the quantizer. Under certain conditions, the relaxed loss function may be interpreted as the log likelihood of a generative model, as implemented by a variational autoencoder. Unlike these models, however, the compression model must operate at any given point along the ratedistortion curve, as specified by a trade-off parameter. Across an independent set of test images, we find that the optimized method generally exhibits better rate-distortion performance than the standard JPEG and JPEG 2000 compression methods. More importantly, we observe a dramatic improvement in visual quality for all images at all bit rates, which is supported by objective quality estimates using MS-SSIM.Joint optimization of rate and distortion is difficult. Without further constraints, the general problem of optimal quantization in high-dimensional spaces is intractable(Gersho and Gray, 1992). For this reason, most existing image compression methods operate by linearly transforming the data vector into a suitable continuous-valued representation, quantizing its elements independently, and then encoding the resulting discrete representation using a lossless entropy code(Wintz, 1972;Netravali and Limb, 1980). This scheme is called transform coding due to the central role of the transforma- * JB and EPS are supported by the Howard Hughes Medical Institute.",
    "prev": "Our results provide guidance for practitioners on which region in rate-space to target for a given application.",
    "curr": "INTRODUCTION\n\nVariational autoencoders (VAEs) (Kingma & Welling, 2014;Rezende et al., 2014) are a class of deep generative models that are used, e.g., for density modeling (Takahashi et al., 2018), clustering (Jiang et al., 2017), nonlinear dimensionality reduction of scientific measurements (Laloy et al., 2017), data compression (Ball\u00e9 et al., 2017), anomaly detection (Xu et al., 2018), and image generation (Razavi et al., 2019).",
    "next": "VAEs (more precisely, \u03b2-VAEs (Higgins et al., 2017)) span such a diverse set of application domains in part because they can be tuned to a specific task without changing the network architecture, in a way that is well understood from information theory (Alemi et al., 2018).",
    "hard_negative": [
      6628106,
      2187805,
      2684987
    ],
    "easy_negative": [
      1516982,
      219179684,
      257366183
    ]
  },
  {
    "index": 3707,
    "source_corpus_id": 232013963,
    "ref_id": "b6",
    "citation_corpus_id": 29153681,
    "start": 5485,
    "end": 5509,
    "title": "META-LEARNING WITH DIFFERENTIABLE CLOSED-FORM SOLVERS",
    "abstract": "Adapting deep networks to new concepts from a few examples is challenging, due to the high computational requirements of standard fine-tuning procedures.Most work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent. Nonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently. In this paper, we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning. The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression, as part of its own internal model, enabling it to quickly adapt to novel data. This requires back-propagating errors through the solver steps. While normally the cost of the matrix operations involved in such a process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage. We propose both closed-form and iterative solvers, based on ridge regression and logistic regression components. Our methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks.",
    "prev": "To consider the second condition, we propose that meta-learning, which aims to train a model well generalized on novel data from observing a few examples, can be a potential key to learning a functional of Hamiltonian as a data-driven method.",
    "curr": "There have been several representative categories of meta-learning algorithms, such as the metric-based method (Snell et al., 2017;Sung et al., 2018), black-box method (Santoro et al., 2016;Bertinetto et al., 2019), and gradient-based method (Rusu et al., 2019;Flennerhag et al., 2020).",
    "next": "Among these methods, we especially focus on the gradientbased method, which is readily compatible with any differentiable model and flexibly applicable to a wide variety of learning problems (Finn et al., 2017;Xu et al., 2018;Hospedales et al., 2020).",
    "hard_negative": [
      3507990,
      3431470,
      12122362
    ],
    "easy_negative": [
      234487189,
      1438681,
      12618880
    ]
  },
  {
    "index": 3708,
    "source_corpus_id": 5882977,
    "ref_id": "b55",
    "citation_corpus_id": 1957433,
    "start": 3085,
    "end": 3109,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "6  Available at\n\nINTRODUCTION\n\nWord embeddings have become ubiquitous in natural language processing (NLP).",
    "curr": "Several researchers have developed and shared word embeddings trained on large datasets (Collobert et al., 2011;Mikolov et al., 2013;Pennington et al., 2014), and these have been used effectively for many downstream tasks Socher et al., 2011;Kim, 2014;Bansal et al., 2014;Tai et al., 2015).",
    "next": "There has also been recent work on creating representations for word sequences such as phrases or sentences.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      1104123
    ],
    "easy_negative": [
      202768081,
      6987624,
      646153
    ]
  },
  {
    "index": 3717,
    "source_corpus_id": 57573752,
    "ref_id": "b10",
    "citation_corpus_id": 3144218,
    "start": 6597,
    "end": 6601,
    "title": "SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS",
    "abstract": "We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.",
    "prev": "Based on the adjacency matrix A, we compute the graph Laplacian L which can be defined in different ways: (3) is often used in the GSP literature due to the fact that it is real symmetric, positive semi-definite (PSD) and has eigenvalues lying in [0,2].",
    "curr": "In certain applications [11], it was found that adding self-loops, i.e., changing A to A + I, and using the affinity matrix S = D \u2212 1 2 AD \u2212 1 2 instead of L gives better results.",
    "next": "Since S is real symmetric, based on spectral decomposition, we have S = U \u039bU \u22a4 where U is an orthogonal matrix and its column vectors are the eigenvectors of S. The diagonal matrix \u039b contains the sorted eigenvalues where \u039b i,i = \u03bb i and 1 \u2265 \u03bb 1 \u2265 \u00b7 \u00b7 \u00b7 \u2265 \u03bb N \u2265 \u22121.",
    "hard_negative": [
      6628106,
      8393918,
      17682909
    ],
    "easy_negative": [
      15131391,
      220045929,
      45850632
    ]
  },
  {
    "index": 3724,
    "source_corpus_id": 5519195,
    "ref_id": "b18",
    "citation_corpus_id": 725590,
    "start": 3014,
    "end": 3037,
    "title": "Text Chunking using Transformation-Based Learning",
    "abstract": "Eric Brill introduced transformation-based learning and showed that it can do part-ofspeech tagging with fairly high accuracy. The same method can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive \"baseNP\" chunks. For this purpose, it is convenient to view chunking as a tagging problem by encoding the chunk structure in new tags attached to each word. In automatic tests using Treebank-derived data, this technique achieved recall and precision rates of roughly 92% for baseNP chunks and 88% for somewhat more complex chunks that partition the sentence. Some interesting adaptations to the transformation-based learning approach are also suggested by this application.",
    "prev": "At the same time, SRNNs are a variant of semi-Markov conditional random fields (Sarawagi & Cohen, 2004), in that they define a conditional probability distribution over the output space (segmentation and labeling) given the input sequence ( \u00a72).",
    "curr": "This allows explicit modeling of statistical dependencies, such as those between adjacent labels, and also of segment lengths (unlike widely used symbolic approaches based on \"BIO\" tagging; Ramshaw & Marcus, 1995).",
    "next": "Because the probability score decomposes into chain-structured clique potentials, polynomial-time dynamic programming algorithms exist for prediction and parameter estimation ( \u00a73).",
    "hard_negative": [
      3166885,
      3031527,
      8185806,
      15057877,
      1003192,
      1025468
    ],
    "easy_negative": [
      29463464,
      15717994,
      250144216
    ]
  },
  {
    "index": 3726,
    "source_corpus_id": 210064528,
    "ref_id": "b33",
    "citation_corpus_id": 3687922,
    "start": 21154,
    "end": 21176,
    "title": "SEMI-PARAMETRIC TOPOLOGICAL MEMORY FOR NAVIGATION",
    "abstract": "We introduce a new memory architecture for navigation in previously unseen environments, inspired by landmark-based navigation in animals. The proposed semiparametric topological memory (SPTM) consists of a (non-parametric) graph with nodes corresponding to locations in the environment and a (parametric) deep network capable of retrieving nodes from the graph based on observations. The graph stores no metric information, only connectivity of locations corresponding to the nodes. We use SPTM as a planning module in a navigation system. Given only 5 minutes of footage of a previously unseen maze, an SPTM-based navigation agent can build a topological map of the environment and use it to confidently navigate towards goals. The average success rate of the SPTM agent in goal-directed navigation across test environments is higher than the best-performing baseline by a factor of three.",
    "prev": "EXPERIMENTS\n\nWe perform our evaluation in simulation using VizDoom, as it allows for procedural generation of large, complex 3D maps that contain a variety of dynamic actors and semantic constraints in the form environmental hazards.",
    "curr": "Although prior work (Savinov et al., 2018) on navigation has also relied on VizDoom, evaluation has been restricted to a small set of hand designed maps without any dynamic actors or semantic constraints.",
    "next": "We evaluate the effectiveness of incorporating learned affordance maps to tackle two difficult tasks: novel environment exploration and goal-directed navigation.",
    "hard_negative": [
      6628106,
      534043,
      13298214,
      16134629
    ],
    "easy_negative": [
      16112861,
      13244912,
      245634845
    ]
  },
  {
    "index": 3739,
    "source_corpus_id": 246241126,
    "ref_id": "b16",
    "citation_corpus_id": 964287,
    "start": 7079,
    "end": 7090,
    "title": "ROUGE: A Package for Automatic Evaluation of Summaries",
    "abstract": "ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It includes measures to automatically determine the quality of a summary by comparing it to other (ideal) summaries created by humans. The measures count the number of overlapping units such as n-gram, word sequences, and word pairs between the computer-generated summary to be evaluated and the ideal summaries created by humans. This paper introduces four different ROUGE measures: ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S included in the ROUGE summarization evaluation package and their evaluatio ns. Three of them have been used in the Document Understanding Conference (DUC) 2004, a large-scale summarization evaluation sponsored by NIST.",
    "prev": "REGEXACC is then defined as REGEXACC(\u0177, y * ) \u225c matches(toRegex(\u0177), y * ) \u22c5 nTokens(\u0177) nTokens(y * ) .",
    "curr": "Beyond REGEXACC, we also consider ROUGE (Lin, 2004), since a sketch can be thought as a form of a \"summary\" of the target text.",
    "next": "For this, we use a helper function ERASEHOLES(\u0177) that simply Figure 2: Progress of grammar-based code generation of the sketch r = x * (foo(args)) by GRAMMFORMER.",
    "hard_negative": [
      1842,
      19265207
    ],
    "easy_negative": [
      28475531,
      9114021,
      8701766
    ]
  },
  {
    "index": 3744,
    "source_corpus_id": 222133066,
    "ref_id": "b4",
    "citation_corpus_id": 54443381,
    "start": 27291,
    "end": 27313,
    "title": "EFFICIENT LIFELONG LEARNING WITH A-GEM",
    "abstract": "In lifelong learning, the learner is presented with a sequence of tasks, incrementally building a data-driven prior which may be leveraged to speed up learning of a new task. In this work, we investigate the efficiency of current lifelong approaches, in terms of sample complexity, computational and memory cost. Towards this end, we first introduce a new and a more realistic evaluation protocol, whereby learners observe each example only once and hyper-parameter selection is done on a small and disjoint set of tasks, which is not used for the actual learning experience and evaluation. Second, we introduce a new metric measuring how quickly a learner acquires a new skill. Third, we propose an improved version of GEM (Lopez-Paz & Ranzato, 2017), dubbed Averaged GEM (A-GEM), which enjoys the same or even better performance as GEM, while being almost as computationally and memory efficient as EWC  and other regularizationbased methods. Finally, we show that all algorithms including A-GEM can learn even more quickly if they are provided with task descriptors specifying the classification tasks under consideration. Our experiments on several standard lifelong learning benchmarks demonstrate that A-GEM has the best trade-off between accuracy and efficiency. 1",
    "prev": "However, the definition of \"experience\" varies between methods.",
    "curr": "Rehearsal-based methods use episodic memories as raw samples (Robins, 1995;Rebuffi et al., 2017;Riemer et al., 2018) or their gradients (Lopez-Paz et al., 2017;Chaudhry et al., 2019) for the model to revisit.",
    "next": "Incremental Classifier and Representation Learning (iCaRL) (Rebuffi et al., 2017), is a class-incremental learner that uses a nearest-exemplar algorithm for classification and prevents catastrophic forgetting by using an episodic memory.",
    "hard_negative": [
      22014305,
      49667227
    ],
    "easy_negative": [
      208229926,
      3698524,
      1687938
    ]
  },
  {
    "index": 3747,
    "source_corpus_id": 257637187,
    "ref_id": "b4",
    "citation_corpus_id": 231672601,
    "start": 2311,
    "end": 2334,
    "title": "BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models",
    "abstract": "We introduce BitFit, a sparse-finetuning method where only the bias-terms of the model (or a subset of them) are being modified. We show that with small-to-medium training data, applying BitFit on pre-trained BERT models is competitive with (and sometimes better than) fine-tuning the entire model. For larger data, the method is competitive with other sparse fine-tuning methods. Besides their practical utility, these findings are relevant for the question of understanding the commonly-used process of finetuning: they support the hypothesis that finetuning is mainly about exposing knowledge induced by language-modeling training, rather than learning new task-specific linguistic knowledge.",
    "prev": "Code and weights at https://github.com/codezakh/LilT.",
    "curr": "INTRODUCTION\n\nAdvances in transfer learning within the field of natural language processing (Houlsby et al., 2019b;Ben Zaken et al., 2022) have shown that when adapting to a novel task, updates to a small percentage of neurons (< 1%) in large, pretrained transformer-based language models can achieve nearly equivalent results to finetuning the entire model.",
    "next": "Sung et al.",
    "hard_negative": [
      208117506,
      19247366,
      990233,
      218487454,
      216553665,
      53388625,
      16639476
    ],
    "easy_negative": [
      9363886,
      258947268,
      53473481
    ]
  },
  {
    "index": 3748,
    "source_corpus_id": 258352309,
    "ref_id": "b3",
    "citation_corpus_id": 67749672,
    "start": 6348,
    "end": 6362,
    "title": "MEASURING COMPOSITIONALITY IN REPRESENTATION LEARNING",
    "abstract": "Many machine learning algorithms represent input data with vector embeddings or discrete codes. When inputs exhibit compositional structure (e.g. objects built from parts or procedures from subroutines), it is natural to ask whether this compositional structure is reflected in the the inputs' learned representations. While the assessment of compositionality in languages has received significant attention in linguistics and adjacent fields, the machine learning literature lacks general-purpose tools for producing graded measurements of compositional structure in more general (e.g. vector-valued) representation spaces. We describe a procedure for evaluating compositionality by measuring how well the true representation-producing model can be approximated by a model that explicitly composes a collection of inferred representational primitives. We use the procedure to provide formal and empirical characterizations of compositional structure in a variety of settings, exploring the relationship between compositionality and learning dynamics, human judgments, representational similarity, and generalization.We are left with a need for a standard, formal, automatable and quantitative technique for evaluating claims about compositional structure in learned representations. The present work aims at first steps toward meeting that need. We focus on an oracle setting where the compositional structure of model inputs is known, and where the only question is whether this structure is reflected in model outputs. This oracle evaluation paradigm covers most of the existing representation learning problems in which compositionality has been studied.The first contribution of this paper is a simple formal framework for measuring how well a collection of representations (discrete-or continuous-valued) reflects an oracle compositional analysis of model inputs. We propose an evaluation metric called TRE, which provides graded judgments of compositionality for a given set of (input, representation) pairs. The core of our proposal is to treat a set of primitive meaning representations as hidden, and optimize over them to find an explicitly compositional model that approximates the true model as well as possible. For example, if the compositional structure that describes an object is a simple conjunction of attributes, we can search for a collection of \"attribute vectors\" that sum together to produce the observed object representations; if it is a sparse combination of (attribute, value) pairs we can additionally search for \"value vectors\" and parameters of a binding operation; and so on for more complex compositions.",
    "prev": "An alternative to induction is transduction (Gammerman et al., 1998) where a test example is compared with the training examples to make a prediction.",
    "curr": "Our main insight is that in the transductive view of machine learning, extrapolation can be reparameterized as a combinatorial generalization problem, which, under certain low-rank and coverage conditions (Shah et al., 2020;Agarwal et al., 2021b;Andreas et al., 2016;Andreas, 2019), admits a solution.",
    "next": "First we show how we can (i) reparameterize out-of-support inputs h(x test ) \u2192 h(\u2206x, x ), where x \u2208 X train , and \u2206x is a representation of the difference between x test and x .",
    "hard_negative": [
      4737664,
      6628106,
      1819147,
      1994635,
      203279,
      5623056,
      11336213,
      1364249,
      14911774,
      15659560,
      3457087,
      10109001,
      8360910,
      18597583,
      14687186,
      3095388,
      207556454,
      629094,
      6683636,
      15412473,
      333563
    ],
    "easy_negative": [
      250391063,
      11701697,
      243865366
    ]
  },
  {
    "index": 3749,
    "source_corpus_id": 17910711,
    "ref_id": "b7",
    "citation_corpus_id": 7185434,
    "start": 14985,
    "end": 15008,
    "title": "Learning Bilingual Lexicons from Monolingual Corpora",
    "abstract": "We present a method for learning bilingual translation lexicons from monolingual corpora. Word types in each language are characterized by purely monolingual features, such as context counts and orthographic substrings. Translations are induced using a generative model based on canonical correlation analysis, which explains the monolingual lexicons in terms of latent matchings. We show that high-precision lexicons can be learned in a variety of language pairs and from a range of corpus types.",
    "prev": "As the cosine is smaller than 1 and ranks larger or equal to 1, the following equation implements GC with cosine-based tie breaking: GC 1 (x, T ) = arg min y\u2208T (Rank y,P (x) \u2212 cos(x, y))\n\n\nENGLISH TO ITALIAN WORD TRANSLATION\n\nWe first test our methods on bilingual lexicon induction.",
    "curr": "As the amount of parallel data is limited, there has been a lot of work on acquiring translation dictionaries by using vector-space methods on monolingual corpora, together with a small seed lexicon (Haghighi et al., 2008;Klementiev et al., 2012;Koehn & Knight, 2002;Rapp, 1999).",
    "next": "One of the most straightforward and effective methods is to represent words as high-dimensional vectors that encode co-occurrence only with the words in the seed lexicon and are therefore comparable cross-lingually (Klementiev et al., 2012;Rapp, 1999).",
    "hard_negative": [
      7822594,
      765547,
      15202196,
      38407095,
      1487550
    ],
    "easy_negative": [
      21711795,
      16722028,
      11375700
    ]
  },
  {
    "index": 3756,
    "source_corpus_id": 227054213,
    "ref_id": "b0",
    "citation_corpus_id": 11212020,
    "start": 1565,
    "end": 1588,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "Experiments are performed, which validates our theoretical analysis and provides further insights.",
    "curr": "INTRODUCTION\n\nAttention-based neural networks have been broadly adopted in many natural language models for machine translation (Bahdanau et al., 2014), image caption generation (Xu et al., 2015), and the unsupervised representation learning (Devlin et al., 2019), etc.",
    "next": "In a powerful network module, the transformer (Vaswani et al., 2017), which has played a central role in designing many state-of-the-art NLP models, attention is its key ingredient.",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      232320384,
      220273916,
      258947736
    ]
  },
  {
    "index": 3757,
    "source_corpus_id": 57761103,
    "ref_id": "b33",
    "citation_corpus_id": 13298214,
    "start": 2639,
    "end": 2661,
    "title": "LEARNING TO NAVIGATE IN COMPLEX ENVIRONMENTS",
    "abstract": "Learning to navigate in complex environments with dynamic elements is an important milestone in developing AI agents. In this work we formulate the navigation question as a reinforcement learning problem and show that data efficiency and task performance can be dramatically improved by relying on additional auxiliary tasks leveraging multimodal sensory inputs. In particular we consider jointly learning the goal-driven reinforcement learning problem with auxiliary depth prediction and loop closure classification tasks. This approach can learn to navigate from raw sensory input in complicated 3D mazes, approaching human-level performance even under conditions where the goal location changes frequently. We provide detailed analysis of the agent behaviour 1 , its ability to localise, and its network activity dynamics, showing that the agent implicitly learns key navigation abilities.",
    "prev": "In the VLN task, an agent is placed in an unknown realistic environment and is required to follow natural language instructions to navigate from its starting location to a target location.",
    "curr": "In contrast to some existing navigation tasks (Kempka et al., 2016;Zhu et al., 2017;Mirowski et al., 2017;, we address the class of tasks where the agent does not have an explicit representation of the target (e.g., location in a map or image representation of the goal) to know if the goal has been reached or not (Matuszek et al., 2013;Hemachandra et al., 2015;Duvallet et al., 2016;Arkin et al., 2017).",
    "next": "Instead, the agent needs to be aware of its navigation status through the association between the sequence of observed visual inputs to instructions.",
    "hard_negative": [
      8395799,
      14717992
    ],
    "easy_negative": [
      14404227,
      9247055,
      10943559
    ]
  },
  {
    "index": 3760,
    "source_corpus_id": 246015626,
    "ref_id": "b37",
    "citation_corpus_id": 91184134,
    "start": 8548,
    "end": 8566,
    "title": "FAIRSEQ: A Fast, Extensible Toolkit for Sequence Modeling",
    "abstract": "FAIRSEQ is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found here: https://www.youtube. com/watch?v=OtgDdWtHvto.",
    "prev": "This is a common implementation for step-wise inference, e.g.",
    "curr": "found in the FAIRSEQ library (Ott et al., 2019).",
    "next": "Each time-step results in 2n 2 d + 2nd multiplications, 2n 2 d \u2212 nd \u2212 n additions, and n 2 exponentiations as accounted for in Appendix A.1, which amounts to a time complexity of O(n 2 d) and a O(n 2 ) memory complexity originating from the transient feature-map A.",
    "hard_negative": [
      53079938,
      53218829,
      5033497,
      3297437,
      59310641,
      44084020,
      52113461,
      52892477,
      964287,
      3718988,
      44131019,
      44134226,
      22716243,
      21460834,
      4623739,
      14337532
    ],
    "easy_negative": [
      52488,
      16035780,
      18053326
    ]
  },
  {
    "index": 3764,
    "source_corpus_id": 3523429,
    "ref_id": "b33",
    "citation_corpus_id": 1957433,
    "start": 5657,
    "end": 5682,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "A safe and straight-forward way is to minimize the squared distance between the baseline embeddings and the composed embeddings as\n(\u0108,\u00ca) = argmin C,E 1 |V | w\u2208V ||E(C w ) \u2212\u1ebc(w)|| 2 (3) = argmin C,E 1 |V | w\u2208V || M i=1 E i (C i w ) \u2212\u1ebc(w)|| 2 ,(4)\nwhere |V | is the vocabulary size.",
    "curr": "The baseline embeddings can be a set of pre-trained vectors such as word2vec (Mikolov et al., 2013) or GloVe (Pennington et al., 2014) embeddings.",
    "next": "In Eq.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      224705315,
      224804104,
      252847506
    ]
  },
  {
    "index": 3767,
    "source_corpus_id": 235613631,
    "ref_id": "b24",
    "citation_corpus_id": 12639289,
    "start": 3638,
    "end": 3668,
    "title": "Recurrent Continuous Translation Models",
    "abstract": "We introduce a class of probabilistic continuous translation models called Recurrent Continuous Translation Models that are purely based on continuous representations for words, phrases and sentences and do not rely on alignments or phrasal translation units. The models have a generation and a conditioning aspect. The generation of the translation is modelled with a target Recurrent Language Model, whereas the conditioning on the source sentence is modelled with a Convolutional Sentence Model. Through various experiments, we show first that our models obtain a perplexity with respect to gold translations that is > 43% lower than that of stateof-the-art alignment-based translation models. Secondly, we show that they are remarkably sensitive to the word order, syntax, and meaning of the source sentence despite lacking alignments. Finally we show that they match a state-of-the-art system when rescoring n-best lists of translations.",
    "prev": "INTRODUCTION\n\nFast, accurate machine translation is a fundamental goal with a wide range of applications both in research and production.",
    "curr": "State-of-the-art neural machine translation systems generate translations autoregressively where words are predicted one-by-one conditioned on all previous words (Kalchbrenner & Blunsom, 2013;Sutskever et al., 2014;Bahdanau et al., 2015;Wu et al., 2016;Vaswani et al., 2017).",
    "next": "This sequential property limits parallelization, since multiple tokens in each sentence cannot be generated in parallel.",
    "hard_negative": [
      1274371,
      10691183,
      16391184,
      8608051,
      806709
    ],
    "easy_negative": [
      7120486,
      9548105,
      1739888
    ]
  },
  {
    "index": 3773,
    "source_corpus_id": 247958146,
    "ref_id": "b2",
    "citation_corpus_id": 11212020,
    "start": 9256,
    "end": 9279,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "(2022) learns a local feature representation for each input point.",
    "curr": "In our work, we follow the latter approach by using local attention layers (Bahdanau et al., 2015) that dynamically change the attention weights of each point to its neighbors.",
    "next": "Attention layers were popularized with the introduction of the transformer architecture (Vaswani et al., 2017), and were later applied in computer vision tasks such as image classification (Dosovitskiy et al., 2021;Wu et al., 2021).",
    "hard_negative": [
      1274371,
      11336213,
      1870512,
      8608051,
      12639289,
      13805769,
      5590763,
      8884845,
      10766958
    ],
    "easy_negative": [
      1851389,
      253117079,
      253628237
    ]
  },
  {
    "index": 3783,
    "source_corpus_id": 258426737,
    "ref_id": "b0",
    "citation_corpus_id": 235436185,
    "start": 2305,
    "end": 2323,
    "title": "BEIT: BERT Pre-Training of Image Transformers",
    "abstract": "We introduce a self-supervised vision representation model BEIT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT [DCLT19] developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16\u00d716 pixels), and visual tokens (i.e., discrete tokens). We first \"tokenize\" the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEIT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.",
    "prev": "Since CL exploits the globally projected representations to contrast each other, it can be deemed as an \"image-level\" self-supervised learning approach.",
    "curr": "Deviating from CL, masked image modeling (MIM) (Bao et al., 2022;He et al., 2022) has risen as a strong competitor of CL in the era of Vision Transformers (ViTs)  with its impressive performances of downstream tasks.",
    "next": "MIM trains ViTs by reconstructing the correct semantics of masked input patches.",
    "hard_negative": [
      14307651,
      52055130,
      218581596,
      4009713
    ],
    "easy_negative": [
      4937880,
      794356,
      6364638
    ]
  },
  {
    "index": 3792,
    "source_corpus_id": 227745459,
    "ref_id": "b14",
    "citation_corpus_id": 5590763,
    "start": 3161,
    "end": 3178,
    "title": "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation",
    "abstract": "In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.",
    "prev": "While this is useful for certain applications, e.g., source separation (Ephrat et al., 2018) and atomic action recognition (Gu et al., 2018), learning representation that captures long-term dependencies is equally important, e.g., for activity recognition (Kay et al., 2017;Carreira et al., 2019;Sigurdsson et al., 2016).",
    "curr": "Unfortunately, processing long videos requires large memory resource and capturing long-term dependencies is a long-standing problem (Hochreiter & Schmidhuber, 1997;Cho et al., 2014;Vaswani et al., 2017).",
    "next": "In language understanding, strong progress has been made in large-scale learning of contextualized language representations using Transformers (Vaswani et al., 2017;Howard & Ruder, 2018;Peters et al., 2018;Radford et al., 2018;Devlin et al., 2019;Liu et al., 2019;Yang et al., 2019).",
    "hard_negative": [
      17272965,
      1567400,
      8884845,
      10766958,
      931054,
      208915826,
      8170227,
      8608051,
      3065236,
      38407095,
      7417943,
      5552894
    ],
    "easy_negative": [
      52114454,
      226226713,
      17031925
    ]
  },
  {
    "index": 3794,
    "source_corpus_id": 3337127,
    "ref_id": "b37",
    "citation_corpus_id": 1957433,
    "start": 3189,
    "end": 3213,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "Using unlabelled data to learn effective representations is at the forefront of modern machine learning research.",
    "curr": "The Natural Language Processing (NLP) community in particular has invested significant efforts in the construction (Mikolov et al., 2013;Pennington et al., 2014;Bojanowski et al., 2016;Joulin et al., 2017), evaluation  and theoretical analysis (Levy & Goldberg, 2014) of distributed representations for words.",
    "next": "Recently, attention has shifted towards the unsupervised learning of representations for larger pieces of text, such as phrases (Yin & Sch\u00fctze, 2015;Zhang et al., 2017), sentences (Kalchbrenner et al., 2014;Tai et al., 2015;Hill et al., 2016;Arora et al., 2017), and entire paragraphs (Le & Mikolov, 2014).",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      629094,
      1104123
    ],
    "easy_negative": [
      18516917,
      259833864,
      219302482
    ]
  },
  {
    "index": 3797,
    "source_corpus_id": 6961760,
    "ref_id": "b18",
    "citation_corpus_id": 5193894,
    "start": 2561,
    "end": 2566,
    "title": "Inside-Outside and Forward-Backward Algorithms Are Just Backprop (Tutorial Paper)",
    "abstract": "A probabilistic or weighted grammar implies a posterior probability distribution over possible parses of a given input sentence. One often needs to extract information from this distribution, by computing the expected counts (in the unknown parse) of various grammar rules, constituents, transitions, or states. This requires an algorithm such as inside-outside or forward-backward that is tailored to the grammar formalism. Conveniently, each such algorithm can be obtained by automatically differentiating an \"inside\" algorithm that merely computes the log-probability of the evidence (the sentence). This mechanical procedure produces correct and efficient code. As for any other instance of back-propagation, it can be carried out manually or by software. This pedagogical paper carefully spells out the construction and relates it to traditional and nontraditional views of these algorithms.",
    "prev": "INTRODUCTION\n\nAttention networks are now a standard part of the deep learning toolkit, contributing to impressive results in neural machine translation Luong et al., 2015), image captioning (Xu et al., 2015), speech recognition (Chorowski et al., 2015;Chan et al., 2015), question answering Sukhbaatar et al., 2015), and algorithm-learning (Graves et al., 2014;Vinyals et al., 2015), among many other applications (see  for a comprehensive review).",
    "curr": "This approach alleviates the bottleneck of compressing a source into a fixed-dimensional vector by equipping a model with variable-length memory (Weston et al., 2014;Graves et al., 2014;2016), thereby providing random access into the source as needed.",
    "next": "Attention is implemented as a hidden layer which computes a categorical distribution (or hierarchy of categorical distributions) to make a soft-selection over source elements.",
    "hard_negative": [
      5429505,
      59829005,
      9923219,
      5563288,
      6749484,
      6481971,
      11896512,
      5094470,
      11595344,
      15128029,
      17435621,
      696805,
      498,
      9230323,
      18986232
    ],
    "easy_negative": [
      15876467,
      225063166,
      9212247
    ]
  },
  {
    "index": 3799,
    "source_corpus_id": 253018768,
    "ref_id": "b27",
    "citation_corpus_id": 246863713,
    "start": 44945,
    "end": 44972,
    "title": "UNDERSTANDING DDPM LATENT CODES THROUGH OPTIMAL TRANSPORT",
    "abstract": "Diffusion models have recently outperformed alternative approaches to model the distribution of natural images. Such diffusion models allow for deterministic sampling via the probability flow ODE, giving rise to a latent space and an encoder map. While having important practical applications, such as the estimation of the likelihood, the theoretical properties of this map are not yet fully understood. In the present work, we partially address this question for the popular case of the VP-SDE (DDPM) approach. We show that, perhaps surprisingly, the DDPM encoder map coincides with the optimal transport map for common distributions; we support this hypothesis by extensive numerical experiments using advanced tensor train solver for multidimensional Fokker-Planck equation. We provide additional theoretical evidence for the case of multivariate normal distributions.",
    "prev": "the input image x 0 gives the final result:\nE x0 x 0 \u2212 D T (E T (x 0 ), Q) \u2264 K 2 \u03c4 \u221a \u03c4 2 + 1 \u03c4 + \u03c4 2 + 1 K1(21)\nwhich concludes the proof.",
    "curr": "B.3 LINKS TO OPTIMAL TRANSPORT THEORY\n\nThe reverse DDIM encoder E r maps the distribution of images p 0 = p D to the distribution p r of images noised at timestep r. Khrulkov & Oseledets (2022) suggested that E r could be an optimal transport map between p 0 and p r , minimizing the transport cost E x0 x 0 \u2212 E r (x 0 ) 2 2 .",
    "next": "This means that the encoded images are, on average, as close as possible to the input images, while following the correct distribution p r .",
    "hard_negative": [
      52889459,
      227209335
    ],
    "easy_negative": [
      10010426,
      219303233,
      239016730
    ]
  },
  {
    "index": 3802,
    "source_corpus_id": 8685592,
    "ref_id": "b23",
    "citation_corpus_id": 8241258,
    "start": 11350,
    "end": 11373,
    "title": "ACTOR-MIMIC DEEP MULTITASK AND TRANSFER REINFORCEMENT LEARNING",
    "abstract": "The ability to act in multiple environments and transfer previous knowledge to new situations can be considered a critical aspect of any intelligent agent. Towards this goal, we define a novel method of multitask and transfer learning that enables an autonomous agent to learn how to behave in multiple tasks simultaneously, and then generalize its knowledge to new domains. This method, termed \"Actor-Mimic\", exploits the use of deep reinforcement learning and model compression techniques to train a single policy network that learns how to act in a set of distinct tasks by using the guidance of several expert teachers. We then show that the representations learnt by the deep policy network are capable of generalizing to new tasks with no prior expert guidance, speeding up learning in novel environments. Although our method can in general be applied to a wide range of problems, we use Atari games as a testing environment to demonstrate these methods.",
    "prev": "A related but orthogonal problem is transfer learning (Taylor & Stone, 2009;Barrett et al., 2010), which attempts to use prior experience in one domain to improve training performance in another.",
    "curr": "Transfer learning has been applied to RL domains for transferring information across environments (Mordatch et al., 2016;Tzeng et al., 2016), robots , and tasks (Konidaris & Barto, 2006;Stolle & Atkeson, 2007;Dragan et al., 2011;Parisotto et al., 2016;Rusu et al., 2016).",
    "next": "The goal of these approaches is typically to utilize experience in a source domain to learn faster or better in the target domain.",
    "hard_negative": [
      2723173,
      6628106
    ],
    "easy_negative": [
      44077201,
      233189533,
      236460147
    ]
  },
  {
    "index": 3803,
    "source_corpus_id": 253202023,
    "ref_id": "b14",
    "citation_corpus_id": 52922125,
    "start": 4956,
    "end": 4974,
    "title": "UNSUPERVISED LEARNING VIA META-LEARNING",
    "abstract": "A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. Many prior unsupervised learning works aim to do so by developing proxy objectives based on reconstruction, disentanglement, prediction, and other metrics. Instead, we develop an unsupervised meta-learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks. Surprisingly, we find that, when integrated with meta-learning, relatively simple task construction mechanisms, such as clustering embeddings, lead to good performance on a variety of downstream, human-specified tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the embedding learned by four prior unsupervised learning methods. \u2020 Work done as a visiting student researcher at",
    "prev": "We draw inspiration from the recent success in unsupervised meta-learning literature, which meta-learns over the self-generated tasks from unlabeled data to train an effective few-shot learner (Khodadadeh et al., 2019;Lee et al., 2021a).",
    "curr": "It turns out that such an approach is quite a promising direction for fewshot tabular learning: a recent unsupervised meta-learning scheme (Hsu et al., 2018) outperforms the self-supervised tabular learning methods in few-shot tabular classification in our experiments (see Table 1).",
    "next": "In this paper, we suggest to further exploit the benefits of unsupervised meta-learning into few-shot tabular learning by generating more diverse and effective tasks compared to the prior works using the distinct characteristic of the tabular dataset's column feature.",
    "hard_negative": [
      2536452,
      20038688,
      6104263,
      11758569,
      84591,
      16561904
    ],
    "easy_negative": [
      52094910,
      3160550,
      536951
    ]
  },
  {
    "index": 3810,
    "source_corpus_id": 233181840,
    "ref_id": "b43",
    "citation_corpus_id": 12713052,
    "start": 1928,
    "end": 1945,
    "title": "NEURAL ARCHITECTURE SEARCH WITH REINFORCEMENT LEARNING",
    "abstract": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214. * Work done as a member of the Google Brain Residency program (g.co/brainresidency.) Under review as a conference paper at ICLR 2017 neural network can be typically specified by a variable-length string. It is therefore possible to use a recurrent network -the controller -to generate such string. Training the network specified by the string -the \"child network\" -on the real data will result in an accuracy on a validation set. Using this accuracy as the reward signal, we can compute the policy gradient to update the controller. As a result, in the next iteration, the controller will give higher probabilities to architectures that receive high accuracies. In other words, the controller will learn to improve its search over time.Our experiments show that Neural Architecture Search can design good models from scratch, an achievement considered not possible with other methods. On image recognition with CIFAR-10, Neural Architecture Search can find a novel ConvNet model that is better than most human-invented architectures. Our CIFAR-10 model achieves a 3.65 test set error, while being 1.05x faster than the current best model. On language modeling with Penn Treebank, Neural Architecture Search can design a novel recurrent cell that is also better than previous RNN and LSTM architectures. The cell that our model found achieves a test set perplexity of 62.4 on the Penn Treebank dataset, which is 3.6 perplexity better than the previous state-of-the-art.",
    "prev": "INTRODUCTION\n\nAs deep learning has become popular, many parts of AI systems that were previously designed by hand have been replaced with learned components.",
    "curr": "Neural architecture search has automated architecture design (Zoph & Le, 2017;Elsken et al., 2019), population-based training has automated hyperparameter tuning (Jaderberg et al., 2017), and self-supervised learning has led to impressive results in language modeling (Devlin et al., 2019;Radford et al., 2019;Clark et al., 2020) and reduced the need for labels in image classification (Oord et al., 2018;He et al., 2020;Chen et al., 2020).",
    "next": "However, in reinforcement learning, one component continues to be designed by humans: the task specification.",
    "hard_negative": [
      6628106,
      16636683,
      7034786,
      6715185,
      3913537,
      3130692,
      11212020
    ],
    "easy_negative": [
      17835837,
      13916958,
      222091019
    ]
  },
  {
    "index": 3821,
    "source_corpus_id": 9453593,
    "ref_id": "b4",
    "citation_corpus_id": 13866650,
    "start": 1145,
    "end": 1147,
    "title": "ISP: Learning Inferential Selectional Preferences",
    "abstract": "Semantic inference is a key component for advanced natural language understanding. However, existing collections of automatically acquired inference rules have shown disappointing results when used in applications such as textual entailment and question answering. This paper presents ISP, a collection of methods for automatically learning admissible argument values to which an inference rule can be applied, which we call inferential selectional preferences, and methods for filtering out incorrect inferences. We evaluate ISP and present empirical evidence of its effectiveness.",
    "prev": "For example, OpenIE may find FERGUSON-historian-at-HARVARD but does not know FERGUSON-is-a-professor-at-HARVARD.",
    "curr": "One way to gain generalization is to cluster textual surface forms that have similar meaning [4,5,6,7].",
    "next": "While the clusters discovered by all these methods usually contain semantically related items, closer inspection invariably shows that they do not provide reliable implicature.",
    "hard_negative": [
      8033760,
      34491971,
      9842595,
      7647654,
      1614922,
      15455102
    ],
    "easy_negative": [
      209516390,
      237593027,
      227231594
    ]
  },
  {
    "index": 3831,
    "source_corpus_id": 219401872,
    "ref_id": "b11",
    "citation_corpus_id": 3274110,
    "start": 6938,
    "end": 6966,
    "title": "Hafez: an Interactive Poetry Generation System",
    "abstract": "Hafez is an automatic poetry generation system that integrates a Recurrent Neural Network (RNN) with a Finite State Acceptor (FSA). It generates sonnets given arbitrary topics. Furthermore, Hafez enables users to revise and polish generated poems by adjusting various style configurations. Experiments demonstrate that such \"polish\" mechanisms consider the user's intention and lead to a better poem. For evaluation, we build a web interface where users can rate the quality of each poem from 1 to 5 stars. We also speed up the whole system by a factor of 10, via vocabulary pruning and GPU computation, so that adequate feedback can be collected at a fast pace. Based on such feedback, the system learns to adjust its parameters to improve poetry quality.",
    "prev": "Another core difference lies in the training where CoCon's self-supervised learning absolves the need for labeled data, such as the ones employed to train PPLM's attribute discriminator models.",
    "curr": "Weighted decoding (Ghazvininejad et al., 2017;Holtzman et al., 2018) seeks to control the output text token by upweighting the probabilities of targeted words during the decoding step but has been shown to produce incoherent text (See et al., 2019).",
    "next": "Conditioning language generation has been used in question generation to enhance faithfulness by attending to textual context such as predicates, subject types or object types (Elsahar et al., 2018) rather than the content input used here in CoCon.",
    "hard_negative": [
      13886408,
      12964363,
      8174610
    ],
    "easy_negative": [
      18443207,
      28852704,
      18557883
    ]
  },
  {
    "index": 3840,
    "source_corpus_id": 252089424,
    "ref_id": "b24",
    "citation_corpus_id": 231632658,
    "start": 6125,
    "end": 6143,
    "title": "What Makes Good In-Context Examples for GPT-3?",
    "abstract": "GPT-3 has attracted lots of attention due to its superior performance across a wide range of NLP tasks, especially with its in-context learning abilities. Despite its success, we found that the empirical results of GPT-3 depend heavily on the choice of in-context examples. In this work, we investigate whether there are more effective strategies for judiciously selecting incontext examples (relative to random sampling) that better leverage GPT-3's in-context learning capabilities. Inspired by the recent success of leveraging a retrieval module to augment neural networks, we propose to retrieve examples that are semantically-similar to a test query sample to formulate its corresponding prompt. Intuitively, the examples selected with such a strategy may serve as more informative inputs to unleash GPT-3's power of text generation. We evaluate the proposed approach on several natural language understanding and generation benchmarks, where the retrieval-based prompt selection approach consistently outperforms the random selection baseline. Moreover, it is observed that the sentence encoders finetuned on task-related datasets yield even more helpful retrieval results. Notably, significant gains are observed on tasks such as table-totext generation (44.3% on the ToTTo dataset) and open-domain question answering (45.5% on the NQ dataset).",
    "prev": "We extensively examine how to reduce the manual annotation cost while retaining high in-context learning performance.",
    "curr": "Although in-context learning was originally proposed for few-shot learning, recent works show that retrieving prompts from a large set of annotated examples is necessary to achieve good performances (Liu et al., 2022;Rubin et al., 2022).",
    "next": "In particular, they show that the performance substantially improves when similar examples (under some embedding function) are retrieved as in-context examples specifically for each test input (Liu et al., 2022).",
    "hard_negative": [
      6401679,
      15975226,
      216641852,
      1428702
    ],
    "easy_negative": [
      2525588,
      248524782,
      245131376
    ]
  },
  {
    "index": 3841,
    "source_corpus_id": 18380109,
    "ref_id": "b10",
    "citation_corpus_id": 388,
    "start": 4653,
    "end": 4673,
    "title": "A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts",
    "abstract": "Sentiment analysis seeks to identify the viewpoint(s) underlying a text span; an example application is classifying a movie review as \"thumbs up\" or \"thumbs down\". To determine this sentiment polarity, we propose a novel machine-learning method that applies text-categorization techniques to just the subjective portions of the document. Extracting these portions can be implemented using efficient techniques for finding minimum cuts in graphs; this greatly facilitates incorporation of cross-sentence contextual constraints.",
    "prev": "Experimental setup.",
    "curr": "We use a corpus of movie review sentences (Pang and Lee, 2004).",
    "next": "Following Sch\u00fctze (1995), we first compute a left vector and a right vector for each word.",
    "hard_negative": [
      1164969,
      8162001,
      7105713,
      6627923,
      6541910,
      7580918
    ],
    "easy_negative": [
      235258278,
      11674639,
      232021566
    ]
  },
  {
    "index": 3850,
    "source_corpus_id": 246867139,
    "ref_id": "b44",
    "citation_corpus_id": 13754527,
    "start": 3179,
    "end": 3201,
    "title": "Published as a conference paper at ICLR 2018 GENERALIZING ACROSS DOMAINS VIA CROSS-GRADIENT TRAINING",
    "abstract": "We present CROSSGRAD, a method to use multi-domain training data to learn a classifier that generalizes to new domains. CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. CROSSGRAD parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other's objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and that (2) data augmentation is a more stable and accurate method than domain adversarial training. 1 * These two authors contributed equally 1 Code and dataset can be found at https",
    "prev": "We aim for domain generalization.",
    "curr": "Previous domain generalization approaches have successfully explored domain-invariant learning (Muandet et al., 2013;Chattopadhyay et al., 2020) or domain augmentation (Shankar et al., 2018;Zhou et al., 2020a) to handle the domain shift between the source and target domains.",
    "next": "However, since those models are trained on source domains, there will always be an \"adaptivity gap\" when applying them to target domains without further adaptation (Dubey et al., 2021).",
    "hard_negative": [
      3281198,
      15036406
    ],
    "easy_negative": [
      218655193,
      215543504,
      226283642
    ]
  },
  {
    "index": 3858,
    "source_corpus_id": 7788178,
    "ref_id": "b2",
    "citation_corpus_id": 12364197,
    "start": 1269,
    "end": 1293,
    "title": "A Deep Learning Approach to Machine Transliteration",
    "abstract": "In this paper we present a novel transliteration technique which is based on deep belief networks. Common approaches use finite state machines or other methods similar to conventional machine translation. Instead of using conventional NLP techniques, the approach presented here builds on deep belief networks, a technique which was shown to work well for other machine learning problems. We show that deep belief networks have certain properties which are very interesting for transliteration and possibly also for translation and that a combination with conventional techniques leads to an improvement over both components on an Arabic-English transliteration task.",
    "prev": "Introduction\n\nDeep Learning (DL) approaches are gaining more and more attention in Natural Language Processing.",
    "curr": "Many NLP tasks have been addressed: syntactic parsing (Socher et al., 2010), semantic role labeling (Collobert et al., 2011), machine translation (Deselaers et al., 2009), and document classification (Glorot et al., 2011).",
    "next": "One important issue in applying DL lies in the structure of language.",
    "hard_negative": [
      6013411,
      2847717,
      4093737,
      16772171,
      129969,
      11558738,
      284436,
      10313983
    ],
    "easy_negative": [
      235352590,
      195218693,
      248377629
    ]
  },
  {
    "index": 3861,
    "source_corpus_id": 227227885,
    "ref_id": "b27",
    "citation_corpus_id": 5037032,
    "start": 6236,
    "end": 6256,
    "title": "ZERO-SHOT VISUAL IMITATION",
    "abstract": "The current dominant paradigm for imitation learning relies on strong supervision of expert actions to learn both what and how to imitate.We pursue an alternative paradigm wherein an agent first explores the world without any expert supervision and then distills its experience into a goal-conditioned skill policy with a novel forward consistency loss.In our framework, the role of the expert is only to communicate the goals (i.e., what to imitate) during inference.The learned policy is then employed to mimic the expert (i.e., how to imitate) after seeing just a sequence of images demonstrating the desired task.Our method is \"zero-shot\" in the sense that the agent never has access to expert actions during training or for the task demonstration at inference.We evaluate our zero-shot imitator in two real-world settings: complex rope manipulation with a Baxter robot and navigation in previously unseen office environments with a TurtleBot.Through further experiments in VizDoom simulation, we provide evidence that better mechanisms for exploration lead to learning a more capable policy which in turn improves end task performance.Videos, models, and more details are available at https://pathak22.github.io/zeroshot-imitation/. * Denotes equal contribution.",
    "prev": "RELATED WORK\n\nOur work lies in the intersection of several actively evolving topics: visual reinforcement learning for control and robotics, and self-supervised learning.",
    "curr": "Vision-based RL for robotics is able to efficiently learn a variety of behaviors such as grasping, pushing and navigation (Levine et al., 2016;Pathak et al., 2018;Kalashnikov et al., 2018) using only images and rewards as input signals.",
    "next": "Self-supervised learning is a form of unsupervised learning where the data provides the supervision.",
    "hard_negative": [
      6628106,
      14724343
    ],
    "easy_negative": [
      208253300,
      18857186,
      18394591
    ]
  },
  {
    "index": 3871,
    "source_corpus_id": 59536625,
    "ref_id": "b3",
    "citation_corpus_id": 11212020,
    "start": 4714,
    "end": 4736,
    "title": "Published as a conference paper at ICLR 2015 NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE",
    "abstract": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.",
    "prev": "Arguably, the main obstacle to language learning with a human in the loop is the amount of data (and thus human-machine interactions) that would be required.",
    "curr": "Deep learning methods that are used in the context of imitation learning or reinforcement learning paradigms have been shown to be very effective in both simulated language learning settings (Mei et al., 2016;Hermann et al., 2017) and applications (Sutskever et al., 2014;Bahdanau et al., 2015;Wu et al., 2016).",
    "next": "These methods, however, require enormous amounts of data, either in terms of millions of reward function queries or hundreds of thousands of demonstrations.",
    "hard_negative": [
      1274371,
      13805769,
      8884845,
      10766958,
      1870512,
      8608051,
      11336213,
      12639289
    ],
    "easy_negative": [
      17420851,
      14305214,
      59963340
    ]
  },
  {
    "index": 3874,
    "source_corpus_id": 256358906,
    "ref_id": "b57",
    "citation_corpus_id": 59523656,
    "start": 2962,
    "end": 2980,
    "title": "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks",
    "abstract": "We present EDA: easy data augmentation techniques for boosting performance on text classification tasks. EDA consists of four simple but powerful operations: synonym replacement, random insertion, random swap, and random deletion. On five text classification tasks, we show that EDA improves performance for both convolutional and recurrent neural networks. EDA demonstrates particularly strong results for smaller datasets; on average, across five datasets, training with EDA while using only 50% of the available training set achieved the same accuracy as normal training with all available data. We also performed extensive ablation studies and suggest parameters for practical use.",
    "prev": "Many researchers (Kumar et al., 2020;Zhou et al., 2021) resort to data augmentation techniques to generate more synthetic samples to boost the performance of low-resource NLP tasks.",
    "curr": "The existing NLP data augmentation (DA) methods either leverage task-independent heuristic rules, such as Synonym Replacement (Zhang et al., 2015) and Random Swap (Wei & Zou, 2019a), or fine-tune general-purpose pre-trained language models by using the handful training examples of target tasks, such as GPT2 (Radford et al., 2019) in LAMBADA (Anaby-Tavor et al., 2020) and T5 (Raffel et al., 2020) in PromDA , to produce new synthetic data.",
    "next": "Consequently, these DA methods have trivial target task knowledge and are limited to yielding low-quality synthetic data (e.g., either irrelevant or extremely similar to the training data).",
    "hard_negative": [
      388,
      21725995,
      1957433,
      1671874,
      19265222,
      14687186,
      22162396,
      8985962,
      7186165
    ],
    "easy_negative": [
      252967782,
      221376381,
      15748326
    ]
  },
  {
    "index": 3881,
    "source_corpus_id": 238408070,
    "ref_id": "b28",
    "citation_corpus_id": 13123084,
    "start": 9770,
    "end": 9774,
    "title": "Published as a conference paper at ICLR 2017 TEMPORAL ENSEMBLING FOR SEMI-SUPERVISED LEARNING",
    "abstract": "In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels.",
    "prev": "Pseudo-labeling [30], which leverages the model itself to obtain labels on unlabeled data, is widely used in self-training.",
    "curr": "To generate reliable pseudo labels, temporal ensembling [29] maintains an exponential moving average prediction for each sample, while the mean-teacher [49] averages model weights at different training iterations to get a teacher model.",
    "next": "Deep mutual learning [56] trains a pool of student models with supervisions from each other.",
    "hard_negative": [
      1487550,
      1965764,
      2780493,
      6230637,
      9398766
    ],
    "easy_negative": [
      226262248,
      215761283,
      3141663
    ]
  },
  {
    "index": 3884,
    "source_corpus_id": 7147309,
    "ref_id": "b24",
    "citation_corpus_id": 1318875,
    "start": 3319,
    "end": 3339,
    "title": "Expected BLEU Training for Graphs: BBN System Description for WMT11 System Combination Task",
    "abstract": "BBN submitted system combination outputs for Czech-English, German-English, Spanish-English, and French-English language pairs. All combinations were based on confusion network decoding. The confusion networks were built using incremental hypothesis alignment algorithm with flexible matching. A novel bi-gram count feature, which can penalize bi-grams not present in the input hypotheses corresponding to a source sentence, was introduced in addition to the usual decoder features. The system combination weights were tuned using a graph based expected BLEU as the objective function while incrementally expanding the networks to bi-gram and 5-gram contexts. The expected BLEU tuning described in this paper naturally generalizes to hypergraphs and can be used to optimize thousands of weights. The combination gained about 0.5-4.0 BLEU points over the best individual systems on the official WMT11 language pairs. A 39 system multisource combination achieved an 11.1 BLEU point gain.",
    "prev": "One such metric is called BLEU (Papineni et al., 2002) for instance, which measures the n-gram overlap between the model generation and the reference text.",
    "curr": "Training these models to directly optimize metrics like BLEU is hard because a) these are not differentiable (Rosti et al., 2011), and b) combinatorial optimization is required to determine which sub-string maximizes them given some context.",
    "next": "Prior attempts (McAllester et al., 2010;He & Deng, 2012) at optimizing test metrics were restricted to linear models, or required a large number of samples to work well (Auli & Gao, 2014).",
    "hard_negative": [
      10769408,
      2029665,
      2307240,
      5246803,
      12146323,
      16909338
    ],
    "easy_negative": [
      9761304,
      226222232,
      236145059
    ]
  },
  {
    "index": 3889,
    "source_corpus_id": 247594725,
    "ref_id": "b14",
    "citation_corpus_id": 211842237,
    "start": 26748,
    "end": 26771,
    "title": "Published as a conference paper at ICLR 2020 DIRECTIONAL MESSAGE PASSING FOR MOLECULAR GRAPHS",
    "abstract": "Graph neural networks have recently achieved great successes in predicting quantum mechanical properties of molecules. These models represent a molecule as a graph using only the distance between atoms (nodes). They do not, however, consider the spatial direction from one atom to another, despite directional information playing a central role in empirical potentials for molecules, e.g. in angular potentials. To alleviate this limitation we propose directional message passing, in which we embed the messages passed between atoms instead of the atoms themselves. Each message is associated with a direction in coordinate space. These directional message embeddings are rotationally equivariant since the associated directions rotate with the molecule. We propose a message passing scheme analogous to belief propagation, which uses the directional information by transforming messages based on the angle between them. Additionally, we use spherical Bessel functions and spherical harmonics to construct theoretically well-founded, orthogonal representations that achieve better performance than the currently prevalent Gaussian radial basis representations while using fewer than 1 /4 of the parameters. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet outperforms previous GNNs on average by 76 % on MD17 and by 31 % on QM9. Our implementation is available online. 1 1 https://www.daml.in.tum.de/dimenet arXiv:2003.03123v2 [cs.LG] 5 Apr 2022Published as a conference paper at ICLR 2020 embeddings are equivariant with respect to the above transformations since the directions move with the molecule. Hence, they preserve the relative directional information between neighboring atoms. We propose to let message embeddings interact based on the distance between atoms and the angle between directions. Both distances and angles are invariant to translation, rotation, and inversion of the molecule, as required. Additionally, we show that the distance and angle can be jointly represented in a principled and effective manner by using spherical Bessel functions and spherical harmonics. We leverage these innovations to construct the directional message passing neural network (DimeNet). DimeNet can learn both molecular properties and atomic forces. It is twice continuously differentiable and solely based on the atom types and coordinates, which are essential properties for performing molecular dynamics simulations. DimeNet outperforms previous GNNs on average by 76 % on MD17 and by 31 % on QM9. Our paper's main contributions are:",
    "prev": "Figure 2b also shows results with graph and pipeline parallelism combined, indicating that these methods are complementary to each other.",
    "curr": "RELATED WORK\n\nGNNs for simluating atomic systems Many GNN based approaches have been proposed for the task of estimating atomic properties such as (Sch\u00fctt et al., 2017b;Gilmer et al., 2017;J\u00f8rgensen et al., 2018;Sch\u00fctt et al., 2017a;Xie & Grossman, 2018;Qiao et al., 2020;Klicpera et al., 2020b), where the atoms are represented by nodes and neighboring atoms are connected by edges.",
    "next": "An early approach for force estimation was the SchNet model Sch\u00fctt et al.",
    "hard_negative": [
      65455367,
      3144218,
      85457862,
      21731691,
      7060599
    ],
    "easy_negative": [
      15281390,
      241583527,
      45286117
    ]
  },
  {
    "index": 3893,
    "source_corpus_id": 13880,
    "ref_id": "b2",
    "citation_corpus_id": 5552894,
    "start": 3740,
    "end": 3759,
    "title": "Joint Language and Translation Modeling with Recurrent Neural Networks",
    "abstract": "We present a joint language and translation model based on a recurrent neural network which predicts target words based on an unbounded history of both source and target words. The weaker independence assumptions of this model result in a vastly larger search space compared to related feedforward-based language or translation models. We tackle this issue with a new lattice rescoring algorithm and demonstrate its effectiveness empirically. Our joint model builds on a well known recurrent neural network language model(Mikolov, 2012)augmented by a layer of additional inputs from the source language. We show competitive accuracy compared to the traditional channel model features. Our best results improve the output of a system trained on WMT 2012 French-English data by up to 1.5 BLEU, and by 1.1 BLEU on average across several test sets.",
    "prev": "For example, symptoms of acute respiratory distress syndrome may not appear until 24-48 hours after lung injury (Mason et al., 2010), while symptoms of an asthma attack may present shortly after admission but change or disappear following treatment.",
    "curr": "Recurrent Neural Networks (RNNs), in particular those based on Long Short-Term Memory (LSTM) (Hochreiter & Schmidhuber, 1997), model varying-length sequential data, achieving state-of-the-art results for problems spanning natural language processing, image captioning, handwriting recognition, and genomic analysis (Auli et al., 2013;Sutskever et al., 2014;Vinyals et al., 2015;Karpathy & Fei-Fei, 2015;Liwicki et al., 2007;Graves et al., 2009;Pollastri et al., 2002;Vohradsk\u00fd, 2001;Xu et al., 2007).",
    "next": "LSTMs can capture long range dependencies and nonlinear dynamics.",
    "hard_negative": [
      1537286,
      7305992,
      900029,
      11148999,
      10986188,
      15119437,
      7478738,
      16318677
    ],
    "easy_negative": [
      18106982,
      10282227,
      10370694
    ]
  },
  {
    "index": 3894,
    "source_corpus_id": 67855617,
    "ref_id": "b10",
    "citation_corpus_id": 3896491,
    "start": 2389,
    "end": 2407,
    "title": "An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge",
    "abstract": "With the rapid growth of knowledge bases (KBs) on the web, how to take full advantage of them becomes increasingly important. Question answering over knowledge base (KB-QA) is one of the promising approaches to access the substantial knowledge. Meanwhile, as the neural networkbased (NN-based) methods develop, NNbased KB-QA has already achieved impressive results. However, previous work did not put more emphasis on question representation, and the question is converted into a fixed vector regardless of its candidate answers. This simple representation strategy is not easy to express the proper information in the question. Hence, we present an end-to-end neural network model to represent the questions and their corresponding scores dynamically according to the various candidate answer aspects via cross-attention mechanism. In addition, we leverage the global knowledge inside the underlying KB, aiming at integrating the rich KB information into the representation of the answers. As a result, it could alleviates the out-of-vocabulary (OOV) problem, which helps the crossattention model to represent the question more precisely. The experimental results on WebQuestions demonstrate the effectiveness of the proposed approach.",
    "prev": "ion patterns and significantly outperform existing state-of-the-art models for link prediction.Published as a conference paper at ICLR 2019ModelScore FunctionSE (Bordes et al., 2011)\u2212 Wr,1h \u2212 Wr,2t h, t \u2208 R k , Wr,\u00b7 \u2208 R k\u00d7k TransE(Bordes et al., 2013)\u2212 h + r \u2212 t h, r, t \u2208 R k TransX \u2212 gr,1(h) + r \u2212 gr,2(t) h, r, t \u2208 R k DistMult(Yang et al., 2014)r, h, t h, r, t \u2208 R k ComplEx(Trouillon et al., 2016)Re( r, h, t ) h, r, t \u2208 C k HolE(Nickel et al., 2016)r, h \u2297 t h, r, t \u2208 R k ConvE(Dettmers et al., 2017)\u03c3 (vec(\u03c3([r, h]   * \u2126))W ), t h, r, t \u2208 R k RotatE \u2212 h \u2022 r \u2212 t 2 h, r, t \u2208 C k , |ri| = 1\n\nINTRODUCTION\n\nKnowledge graphs are collections of factual triplets, where each triplet (h, r, t) represents a relation r between a head entity h and a tail entity t. Examples of real-world knowledge graphs include Freebase (Bollacker et al., 2008), Yago (Suchanek et al., 2007), and WordNet (Miller, 1995).",
    "curr": "Knowledge graphs are potentially useful to a variety of applications such as question-answering (Hao et al., 2017), information retrieval (Xiong et al., 2017), recommender systems (Zhang et al., 2016), and natural language processing (Yang & Mitchell, 2017).",
    "next": "Research on knowledge graphs is attracting growing interests in both academia and industry communities.",
    "hard_negative": [
      18309765,
      139787,
      6401679,
      6343829,
      17464854,
      13905064,
      15262897,
      14999613,
      1918428,
      10318045,
      2131938,
      12926055,
      11212020
    ],
    "easy_negative": [
      3933963,
      237491981,
      5907822
    ]
  },
  {
    "index": 3895,
    "source_corpus_id": 238582670,
    "ref_id": "b6",
    "citation_corpus_id": 67855286,
    "start": 10603,
    "end": 10623,
    "title": "ANTISYMMETRICRNN: A DYNAMICAL SYSTEM VIEW ON RECURRENT NEURAL NETWORKS",
    "abstract": "Recurrent neural networks have gained widespread use in modeling sequential data. Learning long-term dependencies using these models remains difficult though, due to exploding or vanishing gradients. In this paper, we draw connections between recurrent networks and ordinary differential equations. A special form of recurrent networks called the AntisymmetricRNN is proposed under this theoretical framework, which is able to capture long-term dependencies thanks to the stability property of its underlying differential equation. Existing approaches to improving RNN trainability often incur significant computation overhead. In comparison, AntisymmetricRNN achieves the same goal by design. We showcase the advantage of this new architecture through extensive simulations and experiments. AntisymmetricRNN exhibits much more predictable dynamics. It outperforms regular LSTM models on tasks requiring long-term memory and matches the performance on tasks where short-term dependencies dominate despite being much simpler. advocate going beyond initialization and forcing the weight matrices to be orthogonal throughout the entire learning process. However, some of these approaches come with significant computational overhead and reportedly hinder representation power of these models(Vorontsov et al., 2017). Moreover, orthogonal weight matrices alone do not prevent exploding and vanishing gradients, due to the nonlinear nature of deep neural networks as shown in(Pennington et al., 2017).Here we offer a new perspective on the trainability of RNNs from the dynamical system viewpoint. While exploding gradient is a manifestation of the instability of the underlying dynamical system, vanishing gradient results from a lossy system, properties that have been widely studied in the dynamical system literature(Haber & Ruthotto, 2017;Laurent & von Brecht, 2017). The main contributions of the work are:\u2022 We draw connections between RNNs and the ordinary differential equation theory and design new recurrent architectures by discretizing ODEs.",
    "prev": "More recently, one can view convolutional neural networks as multiscale architectures for processing multiple spatial scales in data (Bai et al., 2020).",
    "curr": "The use of ODE-based learning architectures has also received considerable attention in recent years with examples such as continuous-time neural ODEs Queiruga et al., 2020;2021) and their recurrent extensions ODE-RNNs (Rubanova et al., 2019), as well as RNNs based on discretizations of ODEs (Chang et al., 2018;Erichson et al., 2021;Chen et al., 2020;Lim et al., 2021;Rusch & Mishra, 2021a;b).",
    "next": "In addition to the specific details of our archiecture, we differ from other discretized ODE-based RNNs in the explicit use of multiple (learned) scales in LEM.",
    "hard_negative": [
      3532296,
      3005102,
      5590763,
      35673326
    ],
    "easy_negative": [
      16916599,
      17140888,
      476107
    ]
  },
  {
    "index": 3896,
    "source_corpus_id": 252668479,
    "ref_id": "b3",
    "citation_corpus_id": 235436185,
    "start": 4416,
    "end": 4434,
    "title": "BEIT: BERT Pre-Training of Image Transformers",
    "abstract": "We introduce a self-supervised vision representation model BEIT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT [DCLT19] developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16\u00d716 pixels), and visual tokens (i.e., discrete tokens). We first \"tokenize\" the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEIT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.",
    "prev": "Because of the simplicity of the linear transformation, we would expect that if the conceptual representation spaces of the two models are structured similarly, this transfer will be successful and the LM will have little trouble describing the contents of images.",
    "curr": "We use three different image encoders with increasing levels of linguistic supervision in pretraining: BEIT (Bao et al., 2021), Normalizer Free Resnet50 (NFRN50) (Brock et al., 2021), and CLIP (Radford et al., 2021) to train different projections into the LM.",
    "next": "By linguistic supervision, we refer to the extent to which the image encoder was exposed to language data during its pretraining, thus influencing the expected representational similarity between it and an LM.",
    "hard_negative": [
      14307651,
      52055130,
      218581596,
      4009713
    ],
    "easy_negative": [
      245782,
      248266872,
      8150087
    ]
  },
  {
    "index": 3913,
    "source_corpus_id": 211259530,
    "ref_id": "b29",
    "citation_corpus_id": 7071211,
    "start": 3950,
    "end": 3970,
    "title": "Published as a conference paper at ICLR 2017 ON DETECTING ADVERSARIAL PERTURBATIONS",
    "abstract": "Machine learning and deep learning in particular has advanced tremendously on perceptual tasks in recent years. However, it remains vulnerable against adversarial perturbations of the input that have been crafted specifically to fool the system while being quasi-imperceptible to a human. In this work, we propose to augment deep neural networks with a small \"detector\" subnetwork which is trained on the binary classification task of distinguishing genuine data from data containing adversarial perturbations. Our method is orthogonal to prior work on addressing adversarial perturbations, which has mostly focused on making the classification network itself more robust. We show empirically that adversarial perturbations can be detected surprisingly well even though they are quasi-imperceptible to humans. Moreover, while the detectors have been trained to detect only a specific adversary, they generalize to similar and weaker adversaries. In addition, we propose an adversarial attack that fools both the classifier and the detector and a novel training procedure for the detector that counteracts this attack.",
    "prev": "Besides, the proposed defenses have been shown to be limited and often not effective and easy to overcome (Athalye et al., 2018).",
    "curr": "Alternatively, a large body of work has focused on Published as a conference paper at ICLR 2020 detection of adversarial examples (Bhagoji et al., 2017;Feinman et al., 2017;Gong et al., 2017;Grosse et al., 2017;Metzen et al., 2017;Hendrycks & Gimpel, 2017;Li & Li, 2017;Xu et al., 2017;Pang et al., 2018;Roth et al., 2019;Bahat et al., 2019;Ma et al., 2018;Zheng & Hong, 2018;Tian et al., 2018).",
    "next": "While training robust classifiers focuses on maintaining performance in presence of adversarial examples, adversarial detection only cares for detecting such examples.",
    "hard_negative": [
      6628106,
      604334,
      6706414,
      14124313
    ],
    "easy_negative": [
      219307730,
      231698657,
      9845387
    ]
  },
  {
    "index": 3915,
    "source_corpus_id": 485828,
    "ref_id": "b6",
    "citation_corpus_id": 215717103,
    "start": 5198,
    "end": 5217,
    "title": "Collecting Highly Parallel Data for Paraphrase Evaluation",
    "abstract": "A lack of standard datasets and evaluation metrics has prevented the field of paraphrasing from making the kind of rapid progress enjoyed by the machine translation community over the last 15 years. We address both problems by presenting a novel data collection framework that produces highly parallel text data relatively inexpensively and on a large scale. The highly parallel nature of this data allows us to use simple n-gram comparisons to measure both the semantic adequacy and lexical dissimilarity of paraphrase candidates. In addition to being simple and efficient to compute, experiments show that these metrics correlate highly with human judgments.",
    "prev": "We evaluate our solution on UCF101 human action recognition from Soomro et al.",
    "curr": "(2012) as well as the YouTube2text video captioning dataset from Chen & Dolan (2011).",
    "next": "Our experiments show that leveraging \"percepts\" at multiple resolutions to model temporal variation improves performance over our baseline model with respective gains of 3.4% for action recognition and 10% for video captioning.",
    "hard_negative": [
      837398,
      11652247,
      9842595,
      1963942,
      11728052,
      8431414,
      1302329,
      13043395,
      16019656,
      2755801,
      11888861,
      7489770,
      6387310,
      10181753
    ],
    "easy_negative": [
      195776133,
      12009874,
      12804138
    ]
  },
  {
    "index": 3916,
    "source_corpus_id": 257102785,
    "ref_id": "b51",
    "citation_corpus_id": 233024779,
    "start": 2690,
    "end": 2710,
    "title": "Published as a conference paper at ICLR 2021 DOMAIN GENERALIZATION WITH MIXSTYLE",
    "abstract": "Though convolutional neural networks (CNNs) have demonstrated remarkable ability in learning discriminative features, they often generalize poorly to unseen domains. Domain generalization aims to address this problem by learning from a set of source domains a model that is generalizable to any unseen domain. In this paper, a novel approach is proposed based on probabilistically mixing instancelevel feature statistics of training samples across source domains. Our method, termed MixStyle, is motivated by the observation that visual domain is closely related to image style (e.g., photo vs. sketch images). Such style information is captured by the bottom layers of a CNN where our proposed style-mixing takes place. Mixing styles of training instances results in novel domains being synthesized implicitly, which increase the domain diversity of the source domains, and hence the generalizability of the trained model. MixStyle fits into mini-batch training perfectly and is extremely easy to implement. The effectiveness of MixStyle is demonstrated on a wide range of tasks including category classification, instance retrieval and reinforcement learning.",
    "prev": "This important issue has motivated a large amount of research into the topic of domain generalisation (DG) (Zhou et al., 2021a), which addresses training models with increased robustness to distribution shift.",
    "curr": "These DG approaches span a diverse set of strategies including architectural innovations (Chattopadhyay et al., 2020), novel regularisation (Balaji et al., 2018), alignment (Sun & Saenko, 2016) and learning (Li et al., 2019) objectives, and data augmentation (Zhou et al., 2021b) to make available training data more representative of potential testing data.",
    "next": "However, the problem remains essentially unsolved, especially as measured by recent carefully designed benchmarks (Gulrajani & Lopez-Paz, 2021).",
    "hard_negative": [
      221878944,
      3162051
    ],
    "easy_negative": [
      258486846,
      1798864,
      49413369
    ]
  },
  {
    "index": 3918,
    "source_corpus_id": 220128149,
    "ref_id": "b14",
    "citation_corpus_id": 13123084,
    "start": 11951,
    "end": 11972,
    "title": "Published as a conference paper at ICLR 2017 TEMPORAL ENSEMBLING FOR SEMI-SUPERVISED LEARNING",
    "abstract": "In this paper, we present a simple and efficient method for training deep neural networks in a semi-supervised setting where only a small portion of training data is labeled. We introduce self-ensembling, where we form a consensus prediction of the unknown labels using the outputs of the network-in-training on different epochs, and most importantly, under different regularization and input augmentation conditions. This ensemble prediction can be expected to be a better predictor for the unknown labels than the output of the network at the most recent training epoch, and can thus be used as a target for training. Using our method, we set new records for two standard semi-supervised learning benchmarks, reducing the (non-augmented) classification error rate from 18.44% to 7.05% in SVHN with 500 labels and from 18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16% by enabling the standard augmentations. We additionally obtain a clear improvement in CIFAR-100 classification accuracy by using random images from the Tiny Images dataset as unlabeled extra inputs during training. Finally, we demonstrate good tolerance to incorrect labels.",
    "prev": "Therefore, each base classifier can be trained as if the entire dataset is available as unlabeled data, but only a very small number of labels are available.",
    "curr": "This is precisely the problem statement of semi-supervised learning, a well-studied domain of machine learning (Verma et al., 2019;Luo et al., 2018;Laine and Aila, 2017;Kingma et al., 2014;Gidaris et al., 2018).",
    "next": "We can then leverage these existing semi-supervised learning techniques directly to improve the accuracies of the base classifiers in DPA.",
    "hard_negative": [
      1487550,
      1965764,
      2780493,
      6230637,
      9398766
    ],
    "easy_negative": [
      44101002,
      14300645,
      12191154
    ]
  },
  {
    "index": 3921,
    "source_corpus_id": 232240622,
    "ref_id": "b4",
    "citation_corpus_id": 174802369,
    "start": 7050,
    "end": 7073,
    "title": "UNCERTAINTY-GUIDED CONTINUAL LEARNING WITH BAYESIAN NEURAL NETWORKS",
    "abstract": "Continual learning aims to learn new tasks without forgetting previously learned ones. This is especially challenging when one cannot access data from previous tasks and when the model has a fixed capacity. Current regularization-based continual learning algorithms need an external representation and extra computation to measure the parameters' importance. In contrast, we propose Uncertaintyguided Continual Bayesian Neural Networks (UCB), where the learning rate adapts according to the uncertainty defined in the probability distribution of the weights in networks. Uncertainty is a natural way to identify what to remember and what to change as we continually learn, and thus mitigate catastrophic forgetting. We also show a variant of our model, which uses uncertainty for weight pruning and retains task performance after pruning by saving binary masks per tasks. We evaluate our UCB approach extensively on diverse object classification datasets with short and long sequences of tasks and report superior or on-par performance compared to existing approaches. Additionally, we show that our model does not necessarily need task information at test time, i.e. it does not presume knowledge of which task a sample belongs to.",
    "prev": "Bayesian neural networks (BNN) (Blundell et al., 2015) obtain model uncertainty by placing prior distributions over the weights p(\u03c9).",
    "curr": "This uncertainty has been used to adapt the stepsizes during continual learning in Uncertainty-guided Continual BNNs (UCB) (Ebrahimi et al., 2020).",
    "next": "For each parameter, UCB scales its stepsize inversely proportional to the uncertainty of the parameter in the BNN to reduce changes in important parameters while allowing less important parameters to be modified faster in favor of learning new tasks.",
    "hard_negative": [
      3693512,
      13570924,
      54443381
    ],
    "easy_negative": [
      259833847,
      227231161,
      244954786
    ]
  },
  {
    "index": 3931,
    "source_corpus_id": 221819379,
    "ref_id": "b74",
    "citation_corpus_id": 5034059,
    "start": 2716,
    "end": 2735,
    "title": "GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding",
    "abstract": "For natural language understanding (NLU) technology to be maximally useful, it must be able to process language in a way that is not exclusively tailored to a specific task, genre, or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation (GLUE) benchmark, a collection of tools for evaluating and analyzing the performance of models across a diverse set of existing NLU tasks. By including tasks with limited training data, GLUE is designed to favor and encourage models that share general linguistic knowledge across tasks. GLUE also includes a hand-crafted diagnostic test suite that enables detailed linguistic analysis of models. We evaluate baselines based on current methods for transfer and representation learning and find that multi-task training on all our tasks yields better results than training a separate model for each task. However, the low absolute performance of our best model indicates the need for improved general NLU systems. son. 2013. One billion word benchmark for measuring progress in statistical language modeling. arXiv preprint 1312.3005.",
    "prev": "Much of these recent advances can be attributed to the now well-known BERT approach (Devlin et al., 2018).",
    "curr": "Substantial improvements over previous state-of-the-art results on the GLUE benchmark (Wang et al., 2018) have been obtained by multiple groups using BERT models with task specific fine-tuning.",
    "next": "The \"BERT-variant + fine-tuning\" formula has continued to improve over time with newer work constantly pushing the state-of-the-art forward on the GLUE benchmark.",
    "hard_negative": [
      5074049,
      388,
      2937095,
      2213896,
      25422730,
      4537113,
      16661147,
      1957433,
      3626819,
      1994584,
      2135897,
      3264224,
      4567927
    ],
    "easy_negative": [
      219306134,
      227230696,
      53246472
    ]
  },
  {
    "index": 3937,
    "source_corpus_id": 25717172,
    "ref_id": "b9",
    "citation_corpus_id": 1957433,
    "start": 15112,
    "end": 15137,
    "title": "GloVe: Global Vectors for Word Representation",
    "abstract": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.",
    "prev": "All models were optimized using Adam (Kingma & Ba, 2014) with the default learning rate of 0.001 using early stopping on the validation set.",
    "curr": "For the linear model, we used a bag of vectors model, where we sum pre-trained Glove vectors (Pennington et al., 2014) and add an additional linear layer from the word embedding dimension, 300, to the number of classes, 2.",
    "next": "We fine tuned both the word vectors and linear parameters.",
    "hard_negative": [
      5959482,
      14694342,
      14687186,
      7478738,
      85205,
      629094,
      1104123
    ],
    "easy_negative": [
      584190,
      12126833,
      17451961
    ]
  },
  {
    "index": 3939,
    "source_corpus_id": 252595735,
    "ref_id": "b14",
    "citation_corpus_id": 218571167,
    "start": 2276,
    "end": 2294,
    "title": "Mapping Natural Language Instructions to Mobile UI Action Sequences",
    "abstract": "We present a new problem: grounding natural language instructions to mobile user interface actions, and create three new datasets for it. For full task evaluation, we create PIX-ELHELP, a corpus that pairs English instructions with actions performed by people on a mobile UI emulator. To scale training, we decouple the language and action data by (a) annotating action phrase spans in HowTo instructions and (b) synthesizing grounded descriptions of actions for mobile user interfaces. We use a Transformer to extract action phrase tuples from long-range natural language instructions. A grounding Transformer then contextually represents UI objects using both their content and screen position and connects them to object descriptions. Given a starting screen and instruction, our model achieves 70.59% accuracy on predicting complete ground-truth action sequences in PIXELHELP.",
    "prev": "Recently, mobile UI understanding has attracted numerous research interests.",
    "curr": "Previous works have proposed various UI modeling tasks and datasets, including widget captioning (Li et al., 2020b), screen summarization (Wang et al., 2021), command grounding (Li et al., 2020a;Bai et al., 2021;Burns et al., 2022) and other tasks He et al., 2020) on the mobile screen.",
    "next": "Many of these works focus on bridging natural language and graphical user interfaces, which have shown potential for enabling language-based interaction.",
    "hard_negative": [
      10458880,
      56657805,
      44152851,
      3505302,
      4955031,
      202784158,
      1222212,
      1998416,
      725590,
      3530344,
      5249151
    ],
    "easy_negative": [
      14528916,
      13754513,
      253762065
    ]
  },
  {
    "index": 3942,
    "source_corpus_id": 246823323,
    "ref_id": "b5",
    "citation_corpus_id": 221447287,
    "start": 2089,
    "end": 2108,
    "title": "WAVEGRAD: ESTIMATING GRADIENTS FOR WAVEFORM GENERATION",
    "abstract": "This paper introduces WaveGrad, a conditional model for waveform generation through estimating gradients of the data density. This model is built on the prior work on score matching and diffusion probabilistic models. It starts from Gaussian white noise and iteratively refines the signal via a gradient-based sampler conditioned on the mel-spectrogram. WaveGrad is non-autoregressive, and requires only a constant number of generation steps during inference. It can use as few as 6 iterations to generate high fidelity audio samples. WaveGrad is simple to train, and implicitly optimizes for the weighted variational lower-bound of the log-likelihood. Empirical experiments reveal WaveGrad to generate high fidelity audio samples matching a strong likelihood-based autoregressive baseline with less sequential operations. * Work done during an internship at Google Brain. \u2020 Equal contribution.",
    "prev": "* Work done as part of the Google AI Residency.",
    "curr": "INTRODUCTION\n\nDenoising Diffusion Probabilistic Models (DDPM) (Sohl-Dickstein et al., 2015;Song & Ermon, 2019;Ho et al., 2020) have emerged as a powerful family of generative models, capable of synthesizing high-quality images, audio, and 3D shapes (Ho et al., 2020;Chen et al., 2021a;b;Cai et al., 2020;Luo & Hu, 2021).",
    "next": "Recent work  shows that DDPMs can outperform Generative Adversarial Networks (GAN) (Goodfellow et al., 2014;Brock et al., 2018) in generation quality, but unlike GANs, DDPMs admit likelihood computation and much more stable training dynamics Gulrajani et al., 2017).",
    "hard_negative": [
      49882757,
      17272965,
      3438497,
      52909749,
      202749904,
      204949712,
      52967399,
      202538740
    ],
    "easy_negative": [
      231698386,
      12706259,
      252968044
    ]
  },
  {
    "index": 3944,
    "source_corpus_id": 254199184,
    "ref_id": "b1",
    "citation_corpus_id": 231592776,
    "start": 2995,
    "end": 3017,
    "title": "CONTRASTIVE BEHAVIORAL SIMILARITY EMBEDDINGS FOR GENERALIZATION IN REINFORCEMENT LEARNING",
    "abstract": "Reinforcement learning methods trained on few environments rarely learn policies that generalize to unseen environments. To improve generalization, we incorporate the inherent sequential structure in reinforcement learning into the representation learning process. This approach is orthogonal to recent approaches, which rarely exploit this structure explicitly. Specifically, we introduce a theoretically motivated policy similarity metric (PSM) for measuring behavioral similarity between states. PSM assigns high similarity to states for which the optimal policies in those states as well as in future states are similar. We also present a contrastive representation learning procedure to embed any state similarity metric, which we instantiate with PSM to obtain policy similarity embeddings (PSEs 1 ). We demonstrate that PSEs improve generalization on diverse benchmarks, including LQR with spurious correlations, a jumping task from pixels, and Distracting DM Control Suite. Source code would be made available at agarwl.github.io/pse.",
    "prev": "Under this lens, the learning agent performs two tasks simultaneously: representation learning, the discovery of useful state features; and credit assignment, the mapping from these features to accurate predictions.",
    "curr": "Although end-to-end RL has been shown to obtain good performance in a wide variety of problems (Mnih et al., 2015;Levine et al., 2016;Bellemare et al., 2020), modern RL methods typically incorporate additional machinery that incentivizes the learning of good state representations: for example, predicting immediate rewards (Jaderberg et al., 2017), future states (Schwarzer et al., 2021a), or observations (Gelada et al., 2019; encoding a similarity metric (Castro, 2020;Agarwal et al., 2021a;Zhang et al., 2021); and data augmentation (Laskin et al., 2020).",
    "next": "In fact, it is often possible, and desirable, to first learn a sufficiently rich representation with which credit assignment can then be efficiently performed; in that sense, representation learning has been a core aspect of RL from its early days (Sutton & Whitehead, 1993;Sutton, 1996;Ratitch & Precup, 2004;Mahadevan & Maggioni, 2007;Diuk et al., 2008;Konidaris et al., 2011;Sutton et al., 2011).",
    "hard_negative": [
      208857488,
      3280568,
      213597045
    ],
    "easy_negative": [
      12659341,
      2048218,
      235343901
    ]
  },
  {
    "index": 3948,
    "source_corpus_id": 244714783,
    "ref_id": "b10",
    "citation_corpus_id": 174799399,
    "start": 33053,
    "end": 33071,
    "title": "Learning Deep Transformer Models for Machine Translation",
    "abstract": "Transformer is the state-of-the-art model in recent machine translation evaluations. Two strands of research are promising to improve models of this kind: the first uses wide networks (a.k.a. Transformer-Big) and has been the de facto standard for the development of the Transformer system, and the other uses deeper language representation but faces the difficulty arising from learning deep networks. Here, we continue the line of research on the latter. We claim that a truly deep Transformer model can surpass the Transformer-Big counterpart by 1) proper use of layer normalization and 2) a novel way of passing the combination of previous layers to the next. On WMT'16 English-German, NIST OpenMT'12 Chinese-English and larger WMT'18 Chinese-English tasks, our deep system (30/25-layer encoder) outperforms the shallow Transformer-Big/Base baseline (6-layer encoder) by 0.4\u223c2.4 BLEU points. As another bonus, the deep model is 1.6X smaller in size and 3X faster in training than Transformer-Big 1 . * Corresponding author. 1  The source code is available at https://github. com/wangqiangneu/dlcl",
    "prev": "However, we fail to train the DETR model when using more than 9 encoder layers, which is probably due to different hyperparameters from the ones used in their experiments.",
    "curr": "Interestingly, we also found that the DETR model converges stably with the Pre-LN architecture (Baevski & Auli, 2019;Child et al., 2019b;Wang et al., 2019) that is known to be a better choice than the canonical Post-LN when the number of layers of Table 4: Effectiveness of the encoder auxiliary loss using Swin-T.",
    "next": "When the number of encoder layers is more than 9, the model training fails, but if the encoder auxiliary loss is adopted, the model training is feasible regardless of the number of encoder layers, and accuracy is improved.",
    "hard_negative": [
      22973057,
      52011544,
      16538528,
      9146682,
      3626819,
      44131019,
      1998416,
      51880415,
      35673326,
      3725815,
      53236219
    ],
    "easy_negative": [
      201624189,
      46939562,
      174800785
    ]
  },
  {
    "index": 3949,
    "source_corpus_id": 237416749,
    "ref_id": "b30",
    "citation_corpus_id": 14124313,
    "start": 2153,
    "end": 2180,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "X: logits (init) Y: logits (backdoored) Y = 0.970 * X + 0.127, corr=0.99265 (d) Anchoring (\u03bb=2).",
    "curr": "INTRODUCTION\n\nDeep neural networks (DNNs) have gained promising performances in many computer vision (Krizhevsky et al., 2017;Simonyan & Zisserman, 2015), natural language processing (Bowman et al., 2016;Sehovac & Grolinger, 2020;Vaswani et al., 2017), and computer speech (van den Oord et al., 2016) tasks.",
    "next": "However, it has been discovered that DNNs are vulnerable to many threats, one of which is backdoor attack (Gu et al., 2019;Liu et al., 2018b), which aims to inject certain data patterns into neural networks without altering the model behavior on the clean data.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      252846328,
      248368718,
      247596968
    ]
  },
  {
    "index": 3952,
    "source_corpus_id": 13805769,
    "ref_id": "b9",
    "citation_corpus_id": 1588782,
    "start": 1962,
    "end": 1966,
    "title": "A Structured Vector Space Model for Word Meaning in Context",
    "abstract": "We address the task of computing vector space representations for the meaning of word occurrences, which can vary widely according to context. This task is a crucial step towards a robust, vector-based compositional account of sentence meaning. We argue that existing models for this task do not take syntactic structure sufficiently into account.We present a novel structured vector space model that addresses these issues by incorporating the selectional preferences for words' argument positions. This makes it possible to integrate syntax into the computation of word meaning in context. In addition, the model performs at and above the state of the art for modeling the contextual adequacy of paraphrases.",
    "prev": "Successful applications of this approach include word-sense disambiguation, word similarity and synonym detection (e.g.",
    "curr": "[10,27]).",
    "next": "Subsequent work has also attempted to learn distributed semantics of larger structures, allowing us to apply distributed representation to tasks such as sentiment analysis or paraphrase detection (i.a.",
    "hard_negative": [
      12670725,
      62182406,
      5410054,
      7747235,
      15698938,
      14802888,
      2032205,
      1105,
      9541345,
      2252135,
      126584,
      10375802,
      965246
    ],
    "easy_negative": [
      16102917,
      259376885,
      18812425
    ]
  },
  {
    "index": 3956,
    "source_corpus_id": 1107124,
    "ref_id": "b20",
    "citation_corpus_id": 252796,
    "start": 16483,
    "end": 16504,
    "title": "Building a Large Annotated Corpus of English: The Penn Treebank",
    "abstract": "There is a growing consensus that significant, rapid progress can be made in both text understanding and spoken language understanding by investigating those phenomena that occur most centrally in naturally occurring unconstrained materials and by attempting to automatically extract information about language from very large corpora. Such corpora are beginning to serve as important research tools for investigators in natural language processing, speech recognition, and integrated spoken language systems, as well as in theoretical linguistics. Annotated corpora promise to be valuable for enterprises as diverse as the automatic construction of statistical models for the grammar of the written and the colloquial spoken language, the development of explicit formal theories of the differing grammars of writing and speech, the investigation of prosodic phenomena in speech, and the evaluation and comparison of the adequacy of parsing models.In this paper, we review our experience with constructing one such large annotated corpus--the Penn Treebank, a corpus 1 consisting of over 4.5 million words of American English. During the first three-year phase of the Penn Treebank Project (1989)(1990)(1991)(1992), this corpus has been annotated for part-of-speech (POS) information. In addition, over half of it has been annotated for skeletal syntactic structure. These materials are available to members of the Linguistic Data Consortium; for details, see Section 5.1.The paper is organized as follows. Section 2 discusses the POS tagging task. After outlining the considerations that informed the design of our POS tagset and presenting the tagset itself, we describe our two-stage tagging process, in which text is first assigned POS tags automatically and then corrected by human annotators. Section 3 briefly presents the results of a comparison between entirely manual and semi-automated tagging, with the latter being shown to be superior on three counts: speed, consistency, and accuracy. In Section 4, we turn to the bracketing task. Just as with the tagging task, we have partially automated the bracketing task: the output of",
    "prev": "In addition, Table 1 shows that our batch-normalized LSTM achieves state of the art on both MNIST and pMNIST.",
    "curr": "CHARACTER-LEVEL PENN TREEBANK\n\nWe evaluate our model on the task of character-level language modeling on the Penn Treebank corpus (Marcus et al., 1993) according to the train/valid/test partition of .",
    "next": "For training, we segment the training sequence into examples of length 100.",
    "hard_negative": [
      696805,
      3166885,
      2369736,
      12951757,
      5153623,
      2769726
    ],
    "easy_negative": [
      219301612,
      258765247,
      184482968
    ]
  },
  {
    "index": 3957,
    "source_corpus_id": 209532006,
    "ref_id": "b0",
    "citation_corpus_id": 14711954,
    "start": 2040,
    "end": 2061,
    "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
    "abstract": "We describe a framework for multitask deep reinforcement learning guided by policy sketches. Sketches annotate tasks with sequences of named subtasks, providing information about high-level structural relationships among tasks but not how to implement them-specifically not providing the detailed guidance used by much previous work on learning policy abstractions for RL (e.g. intermediate rewards, subtask completion signals, or intrinsic motivations). To learn from sketches, we present a model that associates every subtask with a modular subpolicy, and jointly maximizes reward over full task-specific policies by tying parameters across shared subpolicies. Optimization is accomplished via a decoupled actor-critic training objective that facilitates learning common behaviors from multiple dissimilar reward functions. We evaluate the effectiveness of our approach in three environments featuring both discrete and continuous control, and with sparse rewards that can be obtained only after completing a number of high-level subgoals. Experiments show that using our approach to learn policies guided by sketches gives better performance than existing techniques for learning task-specific or shared policies, while naturally inducing a library of interpretable primitive behaviors that can be recombined to rapidly adapt to new tasks.",
    "prev": "We argue that agent should be able to solve multiple tasks with varying sources of reward.",
    "curr": "Recent work in multi-task RL has attempted to address this; however, they focused on the setting where the structure of task are explicitly described with natural language instructions (Oh et al., 2017;Andreas et al., 2017;Yu et al., 2017;Chaplot et al., 2018), programs (Denil et al., 2017), or graph structures (Sohn et al., 2018).",
    "next": "However, such task descriptions may not readily be available.",
    "hard_negative": [
      9963298,
      806709,
      3130692,
      216034672,
      5249151
    ],
    "easy_negative": [
      9729940,
      237010898,
      10103878
    ]
  },
  {
    "index": 3962,
    "source_corpus_id": 211133181,
    "ref_id": "b10",
    "citation_corpus_id": 3531856,
    "start": 2012,
    "end": 2016,
    "title": "Published as a conference paper at ICLR 2018 DEMYSTIFYING MMD GANS",
    "abstract": "We investigate the training and performance of generative adversarial networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs. As our main theoretical contribution, we clarify the situation with bias in GAN loss functions raised by recent work: we show that gradient estimators used in the optimization process for both MMD GANs and Wasserstein GANs are unbiased, but learning a discriminator based on samples leads to biased gradients for the generator parameters. We also discuss the issue of kernel choice for the MMD critic, and characterize the kernel corresponding to the energy distance used for the Cram\u00e9r GAN critic. Being an integral probability metric, the MMD benefits from training strategies recently developed for Wasserstein GANs. In experiments, the MMD GAN is able to employ a smaller critic network than the Wasserstein GAN, resulting in a simpler and faster-training algorithm with matching performance. We also propose an improved measure of GAN convergence, the Kernel Inception Distance, and show how to use it to dynamically adapt learning rates during GAN training. * These authors contributed equally.Published as a conference paper at ICLR 2018 are infinite, meaning that they provide no useful gradient for the generator to follow. This helps to explain some of the instability of GAN training.The lack of sensitivity to distance, meaning that nearby but non-overlapping regions of high probability mass are not considered similar, is a long-recognized problem for KL divergence-based discrepancy measures (e.g. Gneiting & Raftery, 2007, Section 4.2). It is natural to address this problem using Integral Probability Metrics (IPMs; M\u00fcller, 1997): these measure the distance between probability measures via the largest discrepancy in expectation over a class of \"well behaved\" witness functions. Thus, IPMs are able to signal proximity in the probability mass of the generator and reference distributions. (Section 2 describes this framework in more detail.)  proposed to use the Wasserstein distance between distributions as the discriminator, which is an integral probability metric constructed from the witness class of 1-Lipschitz functions. To implement the Wasserstein critic, Arjovsky et al. originally proposed weight clipping of the discriminator network, to enforce k-Lipschitz smoothness. Gulrajani et al. (2017)  improved on this result by directly constraining the gradient of the discriminator network at points between the generator and reference samples. This new Wasserstein GAN implementation, called WGAN-GP, is more stable and easier to train.A second integral probability metric used in GAN variants is the maximum mean discrepancy (MMD), for which the witness function class is a unit ball in a reproducing kernel Hilbert space (RKHS). Generative adversarial models based on minimizing the MMD were first considered by Li et al. (2015)  and Dziugaite et al. (2015). These works optimized a generator to minimize the MMD with a fixed kernel, either using a generic kernel on image pixels or by modeling autoencoder representations instead of images directly. Sutherland et al.(2017)instead minimized the statistical power of an MMD-based test with a fixed kernel. Such approaches struggle with complex natural images, where pixel distances are of little value, and fixed representations can easily be tricked, as in the adversarial examples of Szegedy et al. (2014). A. Krizhevsky. Learning multiple layers of features from tiny images, 2009. Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition.",
    "prev": "From the geometric point of view, these models emphasize the multi-scale nature of the data manifold.",
    "curr": "In order to evaluate the performance of generative models, past research has proposed several extrinsic evaluation measures, most notably the Fr\u00e9chet [27] and Kernel [11] Inception Distances (FID and KID).",
    "next": "Such measures only reflect the first two or three moments of distributions, meaning they can be insensitive to global structural problems.",
    "hard_negative": [
      18828233,
      2263947,
      604334,
      2187805
    ],
    "easy_negative": [
      219176695,
      219307119,
      14491346
    ]
  },
  {
    "index": 3966,
    "source_corpus_id": 211146532,
    "ref_id": "b21",
    "citation_corpus_id": 14089312,
    "start": 2342,
    "end": 2358,
    "title": "Published as a conference paper at ICLR 2017 PRUNING FILTERS FOR EFFICIENT CONVNETS",
    "abstract": "The success of CNNs in various applications is accompanied by a significant increase in the computation and parameter storage costs. Recent efforts toward reducing these overheads involve pruning and compressing the weights of various layers without hurting original accuracy. However, magnitude-based pruning of weights reduces a significant number of parameters from the fully connected layers and may not adequately reduce the computation costs in the convolutional layers due to irregular sparsity in the pruned networks. We present an acceleration method for CNNs, where we prune filters from CNNs that are identified as having a small effect on the output accuracy. By removing whole filters in the network together with their connecting feature maps, the computation costs are reduced significantly. In contrast to pruning weights, this approach does not result in sparse connectivity patterns. Hence, it does not need the support of sparse convolution libraries and can work with existing efficient BLAS libraries for dense matrix multiplications. We show that even simple filter pruning techniques can reduce inference costs for VGG-16 by up to 34% and ResNet-110 by up to 38% on CIFAR10 while regaining close to the original accuracy by retraining the networks.",
    "prev": "However, as the pruning is typically done to a trained network, these methods don't save resources at training time.",
    "curr": "Moreover, it has been argued that it is hard to train sparse architectures from scratch while maintaining comparable performance to their dense counterparts (Han et al., 2015a;Li et al., 2016).",
    "next": "Therefore, we ask: can we prune a network prior to training, so that we can improve computational efficiency at training time?",
    "hard_negative": [
      11130812,
      4167933
    ],
    "easy_negative": [
      30195450,
      6587686,
      110922
    ]
  },
  {
    "index": 3968,
    "source_corpus_id": 256105154,
    "ref_id": "b3",
    "citation_corpus_id": 252570839,
    "start": 7283,
    "end": 7307,
    "title": "A simple log-based loss function for ordinal text classification",
    "abstract": "The cross-entropy loss function is widely used and generally considered the default loss function for text classification. When it comes to ordinal text classification where there is an ordinal relationship between labels, the crossentropy is not optimal as it does not incorporate the ordinal character into its feedback. In this paper, we propose a new simple loss function called ordinal log-loss (OLL). We show that this loss function outperforms state-of-theart previously introduced losses on four benchmark text classification datasets.",
    "prev": "Ordinal classification aims to predict ordinal target outputs.",
    "curr": "Many works exploit the distances between labels (Castagnos et al., 2022;Polat et al., 2022;Gong et al., 2022) to preserve ordinality.",
    "next": "Our ordinal entropy regularizer also preserves the ordinality by exploiting the label distances, while it mainly aims at encouraging a higher-entropy feature space.",
    "hard_negative": [
      222141483,
      990233
    ],
    "easy_negative": [
      3266611,
      17321205,
      8173168
    ]
  },
  {
    "index": 3969,
    "source_corpus_id": 257232381,
    "ref_id": "b19",
    "citation_corpus_id": 56657912,
    "start": 2665,
    "end": 2695,
    "title": "BENCHMARKING NEURAL NETWORK ROBUSTNESS TO COMMON CORRUPTIONS AND PERTURBATIONS",
    "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, IMAGENET-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called IMAGENET-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
    "prev": "For example, weather changes like rain and fog, and data pre-processing like saturate adjustment and compression can corrupt the test data.",
    "curr": "Many works show that the common corruptions arising in nature can degrade the performance of models at test time significantly (Hendrycks & Dietterich, 2019;Yi et al., 2021;Kar et al., 2022;Geirhos et al., 2018;.",
    "next": "In video classification, Yi et al.",
    "hard_negative": [
      13046179,
      49303
    ],
    "easy_negative": [
      238215654,
      248780038,
      522937
    ]
  },
  {
    "index": 3970,
    "source_corpus_id": 232269775,
    "ref_id": "b4",
    "citation_corpus_id": 1066490,
    "start": 2515,
    "end": 2538,
    "title": "Demographic Dialectal Variation in Social Media: A Case Study of African-American English",
    "abstract": "Though dialectal language is increasingly abundant on social media, few resources exist for developing NLP tools to handle such language. We conduct a case study of dialectal language in online conversational text by investigating African-American English (AAE) on Twitter. We propose a distantly supervised model to identify AAE-like language from demographics associated with geo-located messages, and we verify that this language follows well-known AAE linguistic phenomena. In addition, we analyze the quality of existing language identification and dependency parsing tools on AAE-like text, demonstrating that they perform poorly on such text compared to text associated with white speakers. We also provide an ensemble classifier for language identification which eliminates this disparity and release a new corpus of tweets containing AAE-like language.Data and software resources are available at:, it calculates a unigram language model that sums to one across the vocabulary. This hints at a more complete modeling approach ( \u00a72.3). 6  To build the vocabulary, we select all words used by at least 20 different users, resulting in 191,873 unique words; other words are mapped to an out-of-vocabulary symbol.",
    "prev": "INTRODUCTION\n\nMachine learning models trained with empirical risk minimization (ERM) are able to achieve high aggregate performance on data sampled from their training distribution.",
    "curr": "However, they often exhibit drops in accuracy when confronted with data from domains that are under-represented in their training data, such as those of different topic (Gururangan et al., 2020), sociolect (Blodgett et al., 2016), accent (Amodei et al., 2016) or writer age (Hovy & S\u00f8gaard, 2015) in language processing tasks, or skin color (Grother et al., 2019) or lighting (Georghiades et al., 2001) in image processing tasks.",
    "next": "This is a particularly egregious issue in applications where higher error rates can have far reaching negative implications, such as the silencing of underrepresented minorities in toxicity detection systems (Dixon et al., 2018) or disparity amplifying feedback loops in credit rating models (Fuster et al., 2018).",
    "hard_negative": [
      10914266,
      995282,
      17640698
    ],
    "easy_negative": [
      59294230,
      17817934,
      232307094
    ]
  },
  {
    "index": 3974,
    "source_corpus_id": 257365443,
    "ref_id": "b8",
    "citation_corpus_id": 219531210,
    "start": 21071,
    "end": 21088,
    "title": "Published as a conference paper at ICLR 2021 DEBERTA: DECODING-ENHANCED BERT WITH DIS- ENTANGLED ATTENTION",
    "abstract": "Recent progress in pre-trained neural language models has significantly improved the performance of many natural language processing (NLP) tasks. In this paper we propose a new model architecture DeBERTa (Decoding-enhanced BERT with disentangled attention) that improves the BERT and RoBERTa models using two novel techniques. The first is the disentangled attention mechanism, where each word is represented using two vectors that encode its content and position, respectively, and the attention weights among words are computed using disentangled matrices on their contents and relative positions, respectively. Second, an enhanced mask decoder is used to incorporate absolute positions in the decoding layer to predict the masked tokens in model pre-training. In addition, a new virtual adversarial training method is used for fine-tuning to improve models' generalization. We show that these techniques significantly improve the efficiency of model pre-training and the performance of both natural language understand (NLU) and natural langauge generation (NLG) downstream tasks. Compared to RoBERTa-Large, a DeBERTa model trained on half of the training data performs consistently better on a wide range of NLP tasks, achieving improvements on MNLI by +0.9% (90.2% vs. 91.1%), on SQuAD v2.0 by +2.3% (88.4% vs. 90.7%) and RACE by +3.6% (83.2% vs. 86.8%). Notably, we scale up DeBERTa by training a larger version that consists of 48 Transform layers with 1.5 billion parameters. The significant performance boost makes the single DeBERTa model surpass the human performance on the SuperGLUE benchmark(Wang et al., 2019a)for the first time in terms of macro-average score (89.9 versus 89.8), and the ensemble DeBERTa model sits atop the SuperGLUE leaderboard as of January 6, 2021, outperforming the human baseline by a decent margin (90.3 versus 89.8). The pre-trained DeBERTa models and the source code were released at: https://github.com/microsoft/DeBERTa 1 .",
    "prev": "EXPERIMENTAL METHODOLOGY\n\nTextual Models.",
    "curr": "We evaluate our TrojText on three popular transformer-based textual models, i.e., BERT (Devlin et al., 2018), XLNet (Yang et al., 2019) and DeBERTa (He et al., 2021).",
    "next": "For those three models, we choose bert-base-uncased, xlnet-base-cased and microsoft/debertabase respectively from Transformers library (Wolf et al., 2020).",
    "hard_negative": [
      59523594,
      102353817,
      202888986,
      3432876,
      207847598,
      52019251,
      5034059,
      11816014,
      199528271,
      209315300,
      47018994,
      16639476,
      3725815
    ],
    "easy_negative": [
      3220674,
      15703193,
      6560418
    ]
  },
  {
    "index": 3976,
    "source_corpus_id": 234334847,
    "ref_id": "b23",
    "citation_corpus_id": 3292002,
    "start": 14826,
    "end": 14851,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "The architecture of the Fingerprint Generator can be seen as an MPNN (Gilmer et al., 2017) instance.",
    "curr": "Analogous to that in Attentive FP (Xiong et al., 2020), messages are generated with Graph Attention Layers (GAT) (Velickovic et al., 2018), and hidden representations of nodes are updated with Gated Recurrent Units (GRU) (Cho et al., 2014).",
    "next": "Nonetheless, the architecture of HamNet is further adapted as conformation-aware: we modify the calculation of messages and attentive energies to incorporate relative positions and momentums.",
    "hard_negative": [
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      38540414,
      254325292,
      6105163
    ]
  },
  {
    "index": 3977,
    "source_corpus_id": 10316648,
    "ref_id": "b14",
    "citation_corpus_id": 990233,
    "start": 1885,
    "end": 1906,
    "title": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
    "abstract": "Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.",
    "prev": "The former advances the state of the art by 0.9% points of accuracy, the latter is an absolute improvement upon the previous state of the art by 7.7% points of accuracy and an improvement of 33.0% in error reduction.",
    "curr": "INTRODUCTION\n\nDense vector representations (embeddings) of words and phrases, as opposed to discrete feature templates, have recently allowed for notable advances in the state of the art of Natural Language Processing (NLP) (Socher et al., 2013;Baroni et al., 2014).",
    "next": "These representations are typically induced from large unannotated corpora by predicting a word given its context (Collobert & Weston, 2008).",
    "hard_negative": [
      5584134,
      2279432,
      3116311,
      7747235,
      15659560,
      1588782,
      806709,
      2678583,
      3264224,
      15616495,
      2091504
    ],
    "easy_negative": [
      219301684,
      49409893,
      17095682
    ]
  },
  {
    "index": 3980,
    "source_corpus_id": 210845646,
    "ref_id": "b32",
    "citation_corpus_id": 3292002,
    "start": 2189,
    "end": 2211,
    "title": "GRAPH ATTENTION NETWORKS",
    "abstract": "We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).",
    "prev": "Additionally, we also extend and study the behavior of our method to semi-supervised and active learning scenarios.",
    "curr": "INTRODUCTION\n\nThe need to analyze graph structured data coupled with the ubiquitous nature of graphs (Borgwardt et al., 2005;Duvenaud et al., 2015;Backstrom & Leskovec, 2010;Chau et al., 2011), has given greater impetus to research interest in developing graph neural networks (GNNs) (Defferrard et al., 2016;Kipf & Welling, 2016;Hamilton et al., 2017;Velikovi et al., 2018) for learning tasks on such graphs.",
    "next": "The overarching theme in GNNs is for each node's feature vector to be generated by passing, transforming, and recursively aggregating feature information from a given k-hop neighborhood surrounding the node.",
    "hard_negative": [
      3144218,
      8393918,
      5273326,
      11212020
    ],
    "easy_negative": [
      233364990,
      6114503,
      11460784
    ]
  },
  {
    "index": 3982,
    "source_corpus_id": 219531522,
    "ref_id": "b30",
    "citation_corpus_id": 26100519,
    "start": 4325,
    "end": 4343,
    "title": "DEEP VOICE 3: 2000-SPEAKER NEURAL TEXT-TO-SPEECH",
    "abstract": "We present Deep Voice 3, a fully-convolutional attention-based neural textto-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster. We scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods. We also describe how to scale inference to ten million queries per day on one single-GPU server.2. We show that our architecture trains quickly and scales to the LibriSpeech dataset(Panayotov et al., 2015), which consists of nearly 820 hours of audio data from 2484 speakers.3. We demonstrate that we can generate monotonic attention behavior, avoiding error modes commonly occurred in speech synthesis. 4. We compare the quality of several waveform synthesis methods for a single speaker, including WORLD (Morise et al., 2016), Griffin-Lim (Griffin & Lim, 1984), and WaveNet (Oord et al., 2016). 5. We describe the implementation of an inference kernel for Deep Voice 3, which can serve up to ten million queries per day on one single-GPU server. * Authors listed in reverse alphabetical order. \u2020 These authors contributed to this work while members of Baidu Research. Under review as a conference paper at ICLR 2018 2 RELATED WORK Our work builds upon the state-of-the-art in neural speech synthesis and attention-based sequenceto-sequence learning. Several recent works tackle the problem of synthesizing speech with neural networks, including Deep Voice 1 (Ar\u0131k et al., 2017), Deep Voice 2 (Ar\u0131k et al., 2017), Tacotron (Wang et al., 2017), Char2Wav (Sotelo et al., 2017), VoiceLoop (Taigman et al., 2017), SampleRNN (Mehri et al., 2017), and WaveNet (Oord et al., 2016). Deep Voice 1 & 2 retain the traditional structure of TTS pipelines, separating grapheme-to-phoneme conversion, duration and frequency prediction, and waveform synthesis. In contrast to Deep Voice 1 & 2, Deep Voice 3 employs an attention-based sequenceto-sequence model, yielding a more compact architecture. Similar to Deep Voice 3, Tacotron and Char2Wav are the two proposed sequence-to-sequence models for neural TTS. Tacotron is a neural text-to-spectrogram conversion model, used with Griffin-Lim for spectrogram-to-waveform synthesis. Char2Wav predicts the parameters of WORLD vocoder (Morise et al., 2016) and uses a Sam-pleRNN conditioned upon WORLD parameters for waveform generation. In contrast to Char2Wav and Tacotron, Deep Voice 3 avoids Recurrent Neural Networks (RNNs) 1 to speed up training and alleviates several challenging error modes that attention models fall into. Thus, Deep Voice 3 makes attention-based TTS feasible for a production TTS system with no compromise on accuracy. Finally, WaveNet and SampleRNN are proposed as neural vocoder models for waveform synthesis. It is also worth noting that there are numerous alternatives for high-quality hand-engineered vocoders in the literature, such as STRAIGHT(Kawahara et al., 1999), Vocaine (Agiomyrgiannakis, 2015), and WORLD (Morise et al., 2016). Deep Voice 3 adds no novel vocoder, but has the potential to be integrated with different waveform synthesis methods with slight modifications of its architecture.",
    "prev": "While these designs in FastSpeech ease the learning of the one-to-many mapping problem (see Section 2.1) in TTS, they also bring several disadvantages: 1) The two-stage teacher-student training pipeline makes the training process complicated.2) The target mel-spectrograms generated from the teacher model have some information loss 1 compared with the ground-truth ones, since the quality of the audio synthesized from the generated mel-spectrograms is usually worse than that from the ground-truth ones.3) The duration extracted from the attention map of teacher model is not accurate enough.",
    "curr": "INTRODUCTION\n\nNeural network based text to speech (TTS) has made rapid progress and attracted a lot of attention in the machine learning and speech community in recent years Shen et al., 2018;Ming et al., 2016;Ping et al., 2018;Ren et al., 2019;Li et al., 2019).",
    "next": "Previous neural TTS models Shen et al., 2018;Ping et al., 2018;Li et al., 2019) first generate mel-spectrograms autoregressively from text and then synthesize speech from the generated mel-spectrograms using a separately trained vocoder Oord et al., 2017;Prenger et al., 2019;Kim et al., 2018;Yamamoto et al., 2020;Kumar et al., In this work, we propose FastSpeech 2 to address the issues in FastSpeech and better handle the one-to-many mapping problem in non-autoregressive TTS.",
    "hard_negative": [
      1918428,
      5590763,
      11212020
    ],
    "easy_negative": [
      256461393,
      250150926,
      7105713
    ]
  },
  {
    "index": 3988,
    "source_corpus_id": 250408169,
    "ref_id": "b43",
    "citation_corpus_id": 14124313,
    "start": 2467,
    "end": 2495,
    "title": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    "abstract": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve the stateof-the-art results. Importantly, we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.1",
    "prev": "Built on this recipe, we propose Sparse Large Kernel Network (SLaK), a pure CNN architecture equipped with sparse factorized 51\u00d751 kernels that can perform on par with or better than state-of-the-art hierarchical Transformers and modern ConvNet architectures like ConvNeXt and RepLKNet, on ImageNet classification as well as a wide range of downstream tasks including semantic segmentation on ADE20K, object detection on PASCAL VOC 2007, and object detection/segmentation on MS COCO.",
    "curr": "INTRODUCTION\n\nSince invented (Fukushima & Miyake, 1982;LeCun et al., 1989;1998), convolutional neural networks (CNNs) (Krizhevsky et al., 2012a;Simonyan & Zisserman, 2015.;He et al., 2016;Huang et al., 2017;Howard et al., 2017;Xie et al., 2017;Tan & Le, 2019) have quickly evolved as one of the most indispensable architectures of machine learning in the last decades.",
    "next": "However, the dominance of CNNs has been significantly challenged by Transformer (Vaswani et al., 2017) over the past few years.",
    "hard_negative": [
      17272965,
      16636683,
      4071727,
      651286,
      1450294
    ],
    "easy_negative": [
      53599961,
      257220031,
      13622925
    ]
  }
]