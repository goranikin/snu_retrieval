{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e07610-afd7-4eba-a43e-3effa045c026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "Using cached yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Using cached propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "Using cached pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18/18\u001b[0m [datasets]/18\u001b[0m [datasets]ers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.5.1 dill-0.3.8 frozenlist-1.6.0 huggingface-hub-0.30.2 multidict-6.4.3 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3 xxhash-3.5.0 yarl-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c3650-8ed9-45ca-9d6d-3c3a65a1f1e8",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c40051a-d5d2-4e13-8941-5f987311a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    DPRQuestionEncoder, DPRContextEncoder,\n",
    "    DPRQuestionEncoderTokenizer, DPRContextEncoderTokenizer\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "spec0_train = load_json(\"spec0_train.json\")\n",
    "spec1_train = load_json(\"spec1_train.json\")\n",
    "train_data = spec0_train + spec1_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b1b69d-3c16-46ce-b651-294f9a41d7db",
   "metadata": {},
   "source": [
    "## Tokenizer & Model Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1789c71-d95d-4143-a8dd-f4bb521fe658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "q_tok = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "ctx_tok = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "q_enc = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\").to(device)\n",
    "ctx_enc = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0312c955-b8f0-445f-9a5b-4c13f3b8586a",
   "metadata": {},
   "source": [
    "## Îç∞Ïù¥ÌÑ∞ Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "128766a6-290d-4fbd-bb9a-091359aab73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1b69079b1d41d9990980552dee8ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/416 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_data(example):\n",
    "    return {\n",
    "        \"question\": example[\"question\"],\n",
    "        \"positive\": example[\"positive_ctxs\"][0][\"text\"],\n",
    "        \"negatives\": [ctx[\"text\"] for ctx in example[\"negative_ctxs\"]]\n",
    "    }\n",
    "\n",
    "train_dataset = Dataset.from_list([format_data(x) for x in train_data])\n",
    "\n",
    "def encode(example):\n",
    "    q = q_tok(example[\"question\"], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "    p = ctx_tok(example[\"positive\"], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "    n = ctx_tok(example[\"negatives\"], padding=\"max_length\", truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "\n",
    "    return {\n",
    "        \"q_input_ids\": q[\"input_ids\"].squeeze(),\n",
    "        \"q_attention_mask\": q[\"attention_mask\"].squeeze(),\n",
    "        \"pos_input_ids\": p[\"input_ids\"].squeeze(),\n",
    "        \"pos_attention_mask\": p[\"attention_mask\"].squeeze(),\n",
    "        \"neg_input_ids\": n[\"input_ids\"],\n",
    "        \"neg_attention_mask\": n[\"attention_mask\"]\n",
    "    }\n",
    "\n",
    "train_dataset = train_dataset.map(encode)\n",
    "train_dataset.set_format(\"torch\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f7861-2137-4d30-889d-256fc6fc1e5e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c2d79-c205-45a9-90ca-a6310acd17e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 0.0722\n",
      "[Epoch 2] Loss: 0.0851\n",
      "[Epoch 3] Loss: 0.0030\n",
      "[Epoch 4] Loss: 0.0108\n",
      "[Epoch 5] Loss: 0.0257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('dpr_finetuned/context/tokenizer_config.json',\n",
       " 'dpr_finetuned/context/special_tokens_map.json',\n",
       " 'dpr_finetuned/context/vocab.txt',\n",
       " 'dpr_finetuned/context/added_tokens.json')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(list(q_enc.parameters()) + list(ctx_enc.parameters()), lr=2e-5)\n",
    "\n",
    "q_enc.train(); ctx_enc.train()\n",
    "\n",
    "for epoch in range(5):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        q = q_enc(input_ids=batch[\"q_input_ids\"].to(device), attention_mask=batch[\"q_attention_mask\"].to(device)).pooler_output\n",
    "        p = ctx_enc(input_ids=batch[\"pos_input_ids\"].to(device), attention_mask=batch[\"pos_attention_mask\"].to(device)).pooler_output\n",
    "        B, N, L = batch[\"neg_input_ids\"].shape\n",
    "        neg_input_ids = batch[\"neg_input_ids\"].view(B * N, L).to(device)\n",
    "        neg_att = batch[\"neg_attention_mask\"].view(B * N, L).to(device)\n",
    "        n = ctx_enc(input_ids=neg_input_ids, attention_mask=neg_att).pooler_output.view(B, N, -1)\n",
    "\n",
    "        all_ctx = torch.cat([p.unsqueeze(1), n], dim=1)\n",
    "        sim = torch.bmm(q.unsqueeze(1), all_ctx.transpose(1, 2)).squeeze(1)\n",
    "        labels = torch.zeros(q.size(0), dtype=torch.long).to(device)\n",
    "        loss = torch.nn.CrossEntropyLoss()(sim, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "q_enc.save_pretrained(\"dpr_finetuned/question\")\n",
    "ctx_enc.save_pretrained(\"dpr_finetuned/context\")\n",
    "q_tok.save_pretrained(\"dpr_finetuned/question\")\n",
    "ctx_tok.save_pretrained(\"dpr_finetuned/context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfbae2-4cdf-4b39-866c-caa23ab8dfc2",
   "metadata": {},
   "source": [
    "## Ï†ÑÏ≤¥ Corpus Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca322299-983c-4c32-bab4-c73b785f28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "spec0 = load_json(\"spec0_test.json\")\n",
    "spec1 = load_json(\"spec1_test.json\")\n",
    "full_data = spec0 + spec1\n",
    "\n",
    "all_ctxs = {}\n",
    "for item in full_data:\n",
    "    for ctx in item[\"positive_ctxs\"] + item[\"negative_ctxs\"]:\n",
    "        all_ctxs[ctx[\"id\"]] = ctx[\"text\"]\n",
    "\n",
    "corpus_ids = list(all_ctxs.keys())\n",
    "corpus_texts = [all_ctxs[i] for i in corpus_ids]\n",
    "\n",
    "\n",
    "ctx_enc.eval()\n",
    "with torch.no_grad():\n",
    "    corpus_embeddings = []\n",
    "    for i in range(0, len(corpus_texts), 64):\n",
    "        batch = ctx_tok(corpus_texts[i:i+64], return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(device)\n",
    "        vecs = ctx_enc(**batch).pooler_output.cpu()\n",
    "        corpus_embeddings.append(vecs)\n",
    "    corpus_embeddings = torch.cat(corpus_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfada19-f357-4890-91a4-cb6f7898ade6",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fca6e111-d08e-45ba-870b-f5710d7b8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_data, k):\n",
    "    q_enc.eval()\n",
    "    recall, acc, ndcgs = 0, 0, []\n",
    "    for item in tqdm(test_data):\n",
    "        q = item[\"question\"]\n",
    "        gold_ids = set(ctx[\"id\"] for ctx in item[\"positive_ctxs\"])\n",
    "        q_vec = q_enc(**q_tok(q, return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(device)).pooler_output\n",
    "        scores = torch.matmul(q_vec, corpus_embeddings.T.to(device)).squeeze().detach().cpu().numpy()\n",
    "        topk = np.argsort(scores)[::-1][:k]\n",
    "        top_ids = [corpus_ids[i] for i in topk]\n",
    "        recall += int(any(doc_id in gold_ids for doc_id in top_ids))\n",
    "        acc += int(top_ids[0] in gold_ids)\n",
    "        relevance = [int(doc_id in gold_ids) for doc_id in corpus_ids]\n",
    "        ndcgs.append(ndcg_score([relevance], [scores]))\n",
    "    total = len(test_data)\n",
    "    return {\n",
    "        f\"Recall@{k}\": round(recall / total, 4),\n",
    "        \"Accuracy@1\": round(acc / total, 4),\n",
    "        f\"nDCG@{k}\": round(np.mean(ndcgs), 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ea65a2c-ca24-4203-aa0b-18c9a0181698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Broad Query (specificity=0):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 92.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Recall@20': 0.6316, 'Accuracy@1': 0.2632, 'nDCG@20': 0.4855}\n",
      "üìä Specific Query (specificity=1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:00<00:00, 96.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Recall@5': 0.3171, 'Accuracy@1': 0.1463, 'nDCG@5': 0.368}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Broad Query (specificity=0):\")\n",
    "print(evaluate(spec0, k=20))\n",
    "\n",
    "print(\"üìä Specific Query (specificity=1):\")\n",
    "print(evaluate(spec1, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d567650-5145-4aa5-8aed-5eb8251af6db",
   "metadata": {},
   "source": [
    "## Failure case ÌôïÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2252e3f-9a36-4bdd-98fa-6bb80c694688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_failure_cases_with_text(test_data, k, corpus_embeddings, corpus_ids, corpus_texts,\n",
    "                                 q_enc, ctx_tok, q_tok, device=\"cuda\"):\n",
    "    q_enc.eval()\n",
    "    failures = []\n",
    "    id_to_text = dict(zip(corpus_ids, corpus_texts))\n",
    "\n",
    "    for item in tqdm(test_data):\n",
    "        q = item[\"question\"]\n",
    "        gold_ids = set(ctx[\"id\"] for ctx in item[\"positive_ctxs\"])\n",
    "        gold_texts = [ctx[\"text\"] for ctx in item[\"positive_ctxs\"]]\n",
    "\n",
    "        q_vec = q_enc(**q_tok(q, return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(device)).pooler_output\n",
    "        scores = torch.matmul(q_vec, corpus_embeddings.T.to(device)).squeeze().detach().cpu().numpy()\n",
    "\n",
    "        topk = np.argsort(scores)[::-1][:k]\n",
    "        top_ids = [corpus_ids[i] for i in topk]\n",
    "        top_texts = [id_to_text[i] for i in top_ids]\n",
    "        top_scores = [float(scores[i]) for i in topk]\n",
    "\n",
    "        if not any(doc_id in gold_ids for doc_id in top_ids):\n",
    "            failures.append({\n",
    "                \"question\": q,\n",
    "                \"gold_ids\": list(gold_ids),\n",
    "                \"gold_texts\": gold_texts,\n",
    "                \"top_k_ids\": top_ids,\n",
    "                \"top_k_texts\": top_texts,\n",
    "                \"scores\": top_scores\n",
    "            })\n",
    "\n",
    "    return failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e52b3648-b4e3-4261-be4a-3589e88bf088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 110.43it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:00<00:00, 114.16it/s]\n"
     ]
    }
   ],
   "source": [
    "    failures_spec0 = find_failure_cases_with_text(\n",
    "        test_data=spec0, k=20,\n",
    "        corpus_embeddings=corpus_embeddings,\n",
    "        corpus_ids=corpus_ids,\n",
    "        corpus_texts=corpus_texts,\n",
    "        q_enc=q_enc, ctx_tok=ctx_tok, q_tok=q_tok, device=device\n",
    "    )\n",
    "    \n",
    "    failures_spec1 = find_failure_cases_with_text(\n",
    "        test_data=spec1, k=5,\n",
    "        corpus_embeddings=corpus_embeddings,\n",
    "        corpus_ids=corpus_ids,\n",
    "        corpus_texts=corpus_texts,\n",
    "        q_enc=q_enc, ctx_tok=ctx_tok, q_tok=q_tok, device=device\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b51be-df3b-42bc-b39b-7fa2edcc01f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Broad Queries (spec0, Recall@20):\")\n",
    "print(evaluate(spec0, k=20))\n",
    "failures_spec0 = find_failure_cases_with_text(\n",
    "    test_data=spec0, k=20,\n",
    "    corpus_embeddings=corpus_embeddings,\n",
    "    corpus_ids=corpus_ids,\n",
    "    corpus_texts=corpus_texts,\n",
    "    q_enc=q_enc, ctx_tok=ctx_tok, q_tok=q_tok, device=device\n",
    ")\n",
    "\n",
    "print(\"\\nüìä Specific Queries (spec1, Recall@5):\")\n",
    "print(evaluate(spec1, k=5))\n",
    "failures_spec1 = find_failure_cases_with_text(\n",
    "    test_data=spec1, k=5,\n",
    "    corpus_embeddings=corpus_embeddings,\n",
    "    corpus_ids=corpus_ids,\n",
    "    corpus_texts=corpus_texts,\n",
    "    q_enc=q_enc, ctx_tok=ctx_tok, q_tok=q_tok, device=device\n",
    ")\n",
    "\n",
    "\n",
    "def save_failure_cases_json(failures, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(failures, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"‚úÖ Saved to {path}\")\n",
    "\n",
    "save_failure_cases_json(failures_spec0, \"failures_spec0.json\")\n",
    "save_failure_cases_json(failures_spec1, \"failures_spec1.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
