{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4726a137-5d46-48a1-84f2-620623774a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting adapters\n",
      "  Using cached adapters-1.1.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting datasets\n",
      "  Using cached datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached adapters-1.1.1-py3-none-any.whl (289 kB)\n",
      "Using cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "Using cached datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "Using cached yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Using cached propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "Using cached pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets, adapters\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [adapters]/19\u001b[0m [adapters]ers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed adapters-1.1.1 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.5.1 dill-0.3.8 frozenlist-1.6.0 huggingface-hub-0.30.2 multidict-6.4.3 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.48.3 xxhash-3.5.0 yarl-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers adapters datasets faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2508ebd-9bdc-4515-96dd-05da09940774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c6deb3-d9d5-4edc-9153-967eedf8d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "corpus_clean_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_clean\", split=\"full\")\n",
    "query_data = load_dataset(\"princeton-nlp/LitSearch\", \"query\", split=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2d480a-711d-4e47-ac71-a240fafaf785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2372da-2eba-4e68-ba5e-aca0d3a0b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_0_train = load_from_json('./datasets/spec0_train.json')\n",
    "spec_0_val = load_from_json('./datasets/spec0_val.json')\n",
    "spec_0_test = load_from_json('./datasets/spec0_test.json')\n",
    "spec_1_train = load_from_json('./datasets/spec1_train.json')\n",
    "spec_1_val = load_from_json('./datasets/spec1_val.json')\n",
    "spec_1_test = load_from_json('./datasets/spec1_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df80078f-f2c2-439c-b20f-b2db6ea5565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spec_0_train + spec_1_train\n",
    "val_data = spec_0_val + spec_1_val\n",
    "test_data = spec_0_test + spec_1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48353557-ff29-4224-87da-f5360af7ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from adapters import AutoAdapterModel\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0917ba-e6d9-4f63-8f48-e507b9c9f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitSearchDataset(Dataset):\n",
    "    def __init__(self, data: list[dict[str, str]], tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        question = item['question']\n",
    "\n",
    "        # 포지티브 샘플 (1개)\n",
    "        pos_ctx = item['positive_ctxs'][0]\n",
    "        pos_text = pos_ctx['title'] + self.tokenizer.sep_token + pos_ctx['text']\n",
    "\n",
    "        # 네거티브 샘플 (3개 중 랜덤 선택)\n",
    "        neg_ctx = random.choice(item['negative_ctxs'])\n",
    "        neg_text = neg_ctx['title'] + self.tokenizer.sep_token + neg_ctx['text']\n",
    "\n",
    "        # 토크나이징\n",
    "        query_tokens = self.tokenizer(\n",
    "            question,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        pos_tokens = self.tokenizer(\n",
    "            pos_text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        neg_tokens = self.tokenizer(\n",
    "            neg_text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # 배치 차원 제거\n",
    "        query_tokens = {k: v.squeeze(0) for k, v in query_tokens.items()}\n",
    "        pos_tokens = {k: v.squeeze(0) for k, v in pos_tokens.items()}\n",
    "        neg_tokens = {k: v.squeeze(0) for k, v in neg_tokens.items()}\n",
    "\n",
    "        return {\n",
    "            'query': query_tokens,\n",
    "            'positive': pos_tokens,\n",
    "            'negative': neg_tokens,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0305aa4b-dcb1-4fd8-a19b-660b19aef495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletMarginLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletMarginLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, query_emb, pos_emb, neg_emb):\n",
    "        # L2 거리 계산\n",
    "        pos_dist = torch.norm(query_emb - pos_emb, p=2, dim=1)\n",
    "        neg_dist = torch.norm(query_emb - neg_emb, p=2, dim=1)\n",
    "\n",
    "        # max(0, pos_dist - neg_dist + margin) 형태의 손실\n",
    "        loss = torch.clamp(pos_dist - neg_dist + self.margin, min=0.0)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beebe811-3fcd-4ded-8b28-0a3eeb9bb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import torch\n",
    "\n",
    "class TextType(Enum):\n",
    "    KEY = 1\n",
    "    QUERY = 2\n",
    "\n",
    "class Retrieval:\n",
    "    def __init__(self, index_name: str, index_type: str) -> None:\n",
    "        self.index_name = index_name\n",
    "        self.index_type = index_type\n",
    "\n",
    "        self.keys = []\n",
    "        self.values = []\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.keys)\n",
    "\n",
    "    def _get_embeddings(self, textList: list[str], type: TextType, show_progress_bar: bool = False) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _query(self, query_embedding: torch.Tensor, top_k: int = 10) -> List[int]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def query(self, query_text: str, n: int, return_keys: bool = False) -> List[Any]:\n",
    "        embedding_query = self._get_embeddings([query_text], TextType.QUERY)\n",
    "        indices = self._query(embedding_query, n)\n",
    "        if return_keys:\n",
    "            results = [(self.keys[i], self.values[i]) for i in indices]\n",
    "        else:\n",
    "            results = [self.values[i] for i in indices]\n",
    "        return results\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.keys = []\n",
    "        self.encoded_keys = []\n",
    "        self.values = []\n",
    "\n",
    "    def create_index(self, key_value_pairs: Dict[str, int]) -> None:\n",
    "        if len(self.keys) > 0:\n",
    "            raise ValueError(\"Index is not empty. Please create a new index or clear the existing one.\")\n",
    "\n",
    "        for key, value in key_value_pairs.items():\n",
    "            self.keys.append(key)\n",
    "            self.values.append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e64bc6d-08f9-45b4-acc7-38398b9bc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from adapters import AutoAdapterModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import faiss\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class SPECTER2QueryAdapterFinetuner(Retrieval):\n",
    "    def __init__(self, base_model_name=\"allenai/specter2_base\", device=None):\n",
    "\n",
    "        self.keys = []\n",
    "        self.values = []\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "        self.model = AutoAdapterModel.from_pretrained(\"allenai/specter2_base\")\n",
    "\n",
    "        self.model.load_adapter(\"allenai/specter2\", source=\"hf\", load_as=\"proximity\")\n",
    "        self.model.load_adapter(\"allenai/specter2_adhoc_query\", source=\"hf\", load_as=\"adhoc_query\")\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if \"adapters.adhoc_query\" in name:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def encode_text(self, input_ids, attention_mask, adapter_type=\"proximity\"):\n",
    "        \"\"\"\n",
    "        adapter_type: query -> \"adhoc_query\", text -> \"proximity\"\n",
    "        \"\"\"\n",
    "        self.model.set_active_adapters(adapter_type)\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids.to(self.device),\n",
    "            attention_mask=attention_mask.to(self.device)\n",
    "        )\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS 토큰 임베딩 사용\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def encode_query(self, query_text):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            tokens = self.tokenizer(\n",
    "                query_text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            return self.encode_text(\n",
    "                tokens['input_ids'],\n",
    "                tokens['attention_mask'],\n",
    "                adapter_type=\"adhoc_query\"\n",
    "            )\n",
    "\n",
    "    def encode_paper(self, title, abstract):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            text = title + self.tokenizer.sep_token + abstract\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            return self.encode_text(\n",
    "                tokens['input_ids'],\n",
    "                tokens['attention_mask'],\n",
    "                adapter_type=\"proximity\"\n",
    "            )\n",
    "\n",
    "    def finetune(self, train_data, val_data=None, output_dir=\"./specter2_adhoc_query_finetuned\",\n",
    "                 lr=2e-5, batch_size=8, epochs=3, margin=1.0, eval_steps=100,\n",
    "                 weight_decay=0.01, warmup_ratio=0.1):\n",
    "\n",
    "        train_dataset = LitSearchDataset(train_data, self.tokenizer)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            [p for p in self.model.parameters() if p.requires_grad],\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "        total_steps = len(train_loader) * epochs\n",
    "        warmup_steps = int(total_steps * warmup_ratio)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=lr,\n",
    "            total_steps=total_steps,\n",
    "            pct_start=warmup_ratio,\n",
    "            anneal_strategy='linear'\n",
    "        )\n",
    "\n",
    "        triplet_loss = TripletMarginLoss(margin=margin)\n",
    "\n",
    "        self.model.train()\n",
    "        global_step = 0\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "            for batch in progress_bar:\n",
    "                # 쿼리, 포지티브, 네거티브 임베딩\n",
    "                query_emb = self.encode_text(\n",
    "                    batch['query']['input_ids'],\n",
    "                    batch['query']['attention_mask'],\n",
    "                    adapter_type=\"adhoc_query\"\n",
    "                )\n",
    "\n",
    "                pos_emb = self.encode_text(\n",
    "                    batch['positive']['input_ids'],\n",
    "                    batch['positive']['attention_mask'],\n",
    "                    adapter_type=\"proximity\"\n",
    "                )\n",
    "\n",
    "                neg_emb = self.encode_text(\n",
    "                    batch['negative']['input_ids'],\n",
    "                    batch['negative']['attention_mask'],\n",
    "                    adapter_type=\"proximity\"\n",
    "                )\n",
    "\n",
    "                loss = triplet_loss(query_emb, pos_emb, neg_emb)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_([p for p in self.model.parameters() if p.requires_grad], 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "                global_step += 1\n",
    "                if val_data is not None and global_step % eval_steps == 0:\n",
    "                    val_loss = self.evaluate(val_data, batch_size)\n",
    "                    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        self.save_model(output_dir)\n",
    "                        print(f\"Model saved to {output_dir} (val_loss: {val_loss:.4f})\")\n",
    "\n",
    "                    self.model.train()\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Avg Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "        if val_data is None or epochs % eval_steps != 0:\n",
    "            self.save_model(output_dir)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def evaluate(self, val_data, batch_size=8):\n",
    "        val_dataset = LitSearchDataset(val_data, self.tokenizer)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        self.model.eval()\n",
    "        triplet_loss = TripletMarginLoss(margin=1.0)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                query_emb = self.encode_text(\n",
    "                    batch['query']['input_ids'],\n",
    "                    batch['query']['attention_mask'],\n",
    "                    adapter_type=\"adhoc_query\"\n",
    "                )\n",
    "\n",
    "                pos_emb = self.encode_text(\n",
    "                    batch['positive']['input_ids'],\n",
    "                    batch['positive']['attention_mask'],\n",
    "                    adapter_type=\"proximity\"\n",
    "                )\n",
    "\n",
    "                neg_emb = self.encode_text(\n",
    "                    batch['negative']['input_ids'],\n",
    "                    batch['negative']['attention_mask'],\n",
    "                    adapter_type=\"proximity\"\n",
    "                )\n",
    "\n",
    "                loss = triplet_loss(query_emb, pos_emb, neg_emb)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(val_loader)\n",
    "\n",
    "    def save_model(self, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        self.model.save_adapter(output_dir, \"adhoc_query\")\n",
    "\n",
    "        self.tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "        print(f\"어댑터가 {output_dir}에 저장되었습니다.\")\n",
    "\n",
    "    def _get_embeddings(self, textList: list[str], type: TextType, show_progress_bar: bool = True) -> torch.Tensor:\n",
    "        if type == TextType.KEY:\n",
    "            self.model.set_active_adapters(\"proximity\")\n",
    "        else:\n",
    "            self.model.set_active_adapters(\"adhoc_query\")\n",
    "\n",
    "        batch_size = 16\n",
    "        embeddings = []\n",
    "\n",
    "        should_show_progress = show_progress_bar and (type == TextType.KEY)\n",
    "\n",
    "        iterator = range(0, len(textList), batch_size)\n",
    "        if should_show_progress:\n",
    "            iterator = tqdm(iterator, desc=\"Processing document embeddings\")\n",
    "\n",
    "        for i in iterator:\n",
    "            batch_texts = textList[i:i+batch_size]\n",
    "            encoded = self.tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=512\n",
    "            ).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**encoded)\n",
    "\n",
    "            batch_embeddings = outputs.last_hidden_state[:,0,:].cpu()\n",
    "            embeddings.append(batch_embeddings)\n",
    "\n",
    "            if i % (batch_size * 10) == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def clear(self):\n",
    "        super().clear()\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "    def create_index(self, key_value_pairs: dict[str, int]) -> None:\n",
    "        super().create_index(key_value_pairs)\n",
    "        self.index = self._get_embeddings(self.keys, TextType.KEY)\n",
    "\n",
    "        # FAISS 인덱스 생성\n",
    "        vector_dim = self.index.shape[1]\n",
    "        index_flat = faiss.IndexFlatIP(vector_dim)\n",
    "        index_vectors = self.index.numpy()\n",
    "        faiss.normalize_L2(index_vectors)\n",
    "\n",
    "        # 인덱스에 벡터 추가\n",
    "        index_flat.add(index_vectors)\n",
    "        self.faiss_index = index_flat\n",
    "\n",
    "    def _query(self, query_embedding: torch.Tensor, top_k: int = 10) -> list[int]:\n",
    "        if self.faiss_index is None:\n",
    "            raise ValueError(\"FAISS index has not been created yet. Call create_index first.\")\n",
    "\n",
    "        query_vector = query_embedding.numpy()\n",
    "        faiss.normalize_L2(query_vector)\n",
    "        distances, indices = self.faiss_index.search(query_vector, top_k)\n",
    "\n",
    "        return indices[0].tolist()\n",
    "\n",
    "    def query(self, query_text: str, n: int, return_keys: bool = False) -> list:\n",
    "        query_embedding = self._get_embeddings([query_text], TextType.QUERY)\n",
    "        indices = self._query(query_embedding, n)\n",
    "\n",
    "        if return_keys:\n",
    "            results = [(self.keys[i], self.values[i]) for i in indices]\n",
    "        else:\n",
    "            results = [self.values[i] for i in indices]\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be38cf3d-60d5-4833-bf3c-2d3c16e97ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(corpus_id_list: list, retrieved_id_list: list, k: int):\n",
    "    top_k = retrieved_id_list[:k]\n",
    "    intersection = set(corpus_id_list) & set(top_k)\n",
    "    return len(intersection) / len(corpus_id_list) if corpus_id_list else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fee5753f-68e0-4917-aab3-ea02aabe2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(finetuner, test_data, query_data, k_values=[1, 5, 10, 20]):\n",
    "    # 제 IDE 로컬 환경 pyright이 자꾸 타입 터쳐서 넣은 타입 캐스팅 코드입니다.\n",
    "    query_data = cast(Dataset, query_data)\n",
    "\n",
    "    query_df = pd.DataFrame({\n",
    "        'query': query_data['query'],\n",
    "        'corpusids': query_data['corpusids']\n",
    "    })\n",
    "\n",
    "    test_questions = [item['question'] for item in test_data]\n",
    "    filtered_query_df = query_df[query_df['query'].isin(test_questions)]\n",
    "\n",
    "    results = {}\n",
    "    result = []\n",
    "\n",
    "    for k in k_values:\n",
    "        total_recall = 0\n",
    "        count = 0\n",
    "        for i, item in enumerate(test_data):\n",
    "            query = item['question']\n",
    "            top_k_results = finetuner.query(query, k)\n",
    "\n",
    "            query_row = filtered_query_df[filtered_query_df['query'] == query]\n",
    "            if not query_row.empty:\n",
    "                true_corpus_ids = query_row.iloc[0]['corpusids']\n",
    "                if isinstance(true_corpus_ids, list):\n",
    "                    true_corpus_ids_flat = true_corpus_ids\n",
    "                else:\n",
    "                    true_corpus_ids_flat = [true_corpus_ids]\n",
    "\n",
    "                intersection = set(true_corpus_ids_flat) & set(top_k_results)\n",
    "                recall = len(intersection) / len(true_corpus_ids_flat) if true_corpus_ids_flat else 0\n",
    "\n",
    "                total_recall += recall\n",
    "                count += 1\n",
    "\n",
    "        if count > 0:\n",
    "            avg_recall = total_recall / count\n",
    "            results[f'Recall@{k}'] = avg_recall\n",
    "            result.append(avg_recall)\n",
    "        else:\n",
    "            results[f'Recall@{k}'] = 0\n",
    "            result.append(0)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fefaa43a-945f-4eb3-bdb5-cce27d741cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def get_clean_corpusid(item: dict) -> int:\n",
    "    return item['corpusid']\n",
    "\n",
    "def get_clean_title(item: dict) -> str:\n",
    "    return item['title']\n",
    "\n",
    "def get_clean_abstract(item: dict) -> str:\n",
    "    return item['abstract']\n",
    "\n",
    "def get_clean_title_abstract(item: dict, tokenizer) -> str:\n",
    "    title = get_clean_title(item)\n",
    "    abstract = get_clean_abstract(item)\n",
    "    return title + tokenizer.sep_token + abstract\n",
    "\n",
    "def create_kv_pairs(data: Dataset, key: str, tokenizer) -> dict:\n",
    "    return {get_clean_title_abstract(record, tokenizer): get_clean_corpusid(record) for record in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14885ca0-783b-43b6-a3ae-693816b56a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 416 samples (Spec 0: 108, Spec 1: 308)\n",
      "Validation: 61 samples (Spec 0: 16, Spec 1: 45)\n",
      "Testing: 120 samples (Spec 0: 31, Spec 1: 89)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5f199474a443f5b8b35d0e797fba82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832883e2dc8940de826a036fc0cc19c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing document embeddings:  16%|█▌        | 583/3604 [04:54<20:23,  2.47it/s]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import cast\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(val_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "print(f\"Training: {len(train_data)} samples (Spec 0: {len(spec_0_train)}, Spec 1: {len(spec_1_train)})\")\n",
    "print(f\"Validation: {len(val_data)} samples (Spec 0: {len(spec_0_val)}, Spec 1: {len(spec_1_val)})\")\n",
    "print(f\"Testing: {len(test_data)} samples (Spec 0: {len(spec_0_test)}, Spec 1: {len(spec_1_test)})\")\n",
    "\n",
    "# 학습 과정\n",
    "finetuner = SPECTER2QueryAdapterFinetuner()\n",
    "\n",
    "# 제 IDE 로컬 환경 pyright이 자꾸 타입 터쳐서 넣은 타입 캐스팅 코드입니다.\n",
    "corpus_clean_data = cast(Dataset, corpus_clean_data)\n",
    "kv_pairs = create_kv_pairs(corpus_clean_data, \"title_abstract\", finetuner.tokenizer)\n",
    "finetuner.clear()\n",
    "finetuner.create_index(kv_pairs)\n",
    "\n",
    "finetuner.finetune(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    output_dir=\"./specter2_adhoc_query_finetuned\",\n",
    "    lr=2e-4,\n",
    "    batch_size=8,\n",
    "    epochs=5,\n",
    "    margin=1.0,\n",
    "    eval_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf0e58-3acd-4483-8677-65ae50cb6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating model on test set...\")\n",
    "\n",
    "query_data = load_dataset(\"princeton-nlp/LitSearch\", \"query\", split=\"full\")\n",
    "corpus_clean_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_clean\", split=\"full\")\n",
    "\n",
    "# 전체 테스트 세트 평가\n",
    "overall_performance = evaluate_model(finetuner, test_data, query_data)\n",
    "print(f\"Overall test performance: {overall_performance}\")\n",
    "\n",
    "# Specificity 0 쿼리에 대한 평가\n",
    "spec_0_performance = evaluate_model(finetuner, spec_0_test, query_data)\n",
    "print(f\"Specificity 0 performance: {spec_0_performance}\")\n",
    "\n",
    "# Specificity 1 쿼리에 대한 평가\n",
    "spec_1_performance = evaluate_model(finetuner, spec_1_test, query_data)\n",
    "print(f\"Specificity 1 performance: {spec_1_performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136ed52-1929-4a85-b0f4-87395c7829e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
