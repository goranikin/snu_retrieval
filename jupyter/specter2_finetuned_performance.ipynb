{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4726a137-5d46-48a1-84f2-620623774a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting adapters\n",
      "  Using cached adapters-1.1.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Using cached propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached adapters-1.1.1-py3-none-any.whl (289 kB)\n",
      "Using cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
      "Using cached yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Using cached propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets, adapters\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [adapters]/19\u001b[0m [adapters]ers]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed adapters-1.1.1 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.5.1 dill-0.3.8 frozenlist-1.6.0 huggingface-hub-0.30.2 multidict-6.4.3 multiprocess-0.70.16 propcache-0.3.1 pyarrow-20.0.0 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.48.3 xxhash-3.5.0 yarl-1.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers adapters datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2508ebd-9bdc-4515-96dd-05da09940774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c6deb3-d9d5-4edc-9153-967eedf8d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "corpus_clean_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_clean\", split=\"full\")\n",
    "query_data = load_dataset(\"princeton-nlp/LitSearch\", \"query\", split=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8328867b-e089-4eef-bb3d-fc6b9ab1c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = corpus_clean_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9c6585-c4db-4551-9e2a-72c8dc9631af",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = corpus_df.drop(['citations', 'full_paper'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0779588-4318-4b28-a3f8-0b6c3cbc00d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df.to_json('refined_corpus.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b4dcd06-fcfd-4343-86cd-a88d23fcb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"triplet.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c00fe07b-89fd-42e7-b41b-42124aac794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['specificity'] = query_data['specificity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9917d4b9-e6c5-4db2-b6b1-0ef9140a028a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>positive_ctxs</th>\n",
       "      <th>hard_negative_ctxs</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Are there any research papers on methods to co...</td>\n",
       "      <td>[{'title': 'TinyBERT: Distilling BERT for Natu...</td>\n",
       "      <td>[{'title': 'A Frame-based Sentence Representat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are there any resources available for translat...</td>\n",
       "      <td>[{'title': 'Parallel resources for Tunisian Ar...</td>\n",
       "      <td>[{'title': 'Comparing Sanskrit Texts for Criti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are there any studies that explore post-hoc te...</td>\n",
       "      <td>[{'title': 'Detecting Hallucinated Content in ...</td>\n",
       "      <td>[{'title': 'Mining the Web for Discourse Marke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are there any tools or studies that have focus...</td>\n",
       "      <td>[{'title': 'Learning from Relatives: Unified D...</td>\n",
       "      <td>[{'title': 'The KiezDeutsch Korpus (KiDKo) Rel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Are there papers that propose contextualized c...</td>\n",
       "      <td>[{'title': 'Surface Form Competition: Why the ...</td>\n",
       "      <td>[{'title': 'DeepCx: A transition-based approac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Which paper trains on linear regression to hyp...</td>\n",
       "      <td>[{'title': 'UNDERSTANDING CATASTROPHIC FORGETT...</td>\n",
       "      <td>[{'title': 'Multilingual Semantic Parsing : Pa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Which paper uses the latent diffusion model fo...</td>\n",
       "      <td>[{'title': 'Efficient Planning with Latent Dif...</td>\n",
       "      <td>[{'title': 'APPLICATIONS OF A LEXICOGRAPHICAL ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Which paper utilized MMD flows with Riesz kern...</td>\n",
       "      <td>[{'title': 'Posterior Sampling Based on Gradie...</td>\n",
       "      <td>[{'title': 'Biomedical Event Extraction with H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>What paper provides generalization bounds for ...</td>\n",
       "      <td>[{'title': 'Understanding prompt engineering m...</td>\n",
       "      <td>[{'title': '', 'text': '', 'full_text': 'The A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Which paper systematically examed the input mi...</td>\n",
       "      <td>[{'title': 'ELUCIDATING THE EXPOSURE BIAS IN D...</td>\n",
       "      <td>[{'title': '', 'text': '', 'full_text': 'La ré...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>597 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Are there any research papers on methods to co...   \n",
       "1    Are there any resources available for translat...   \n",
       "2    Are there any studies that explore post-hoc te...   \n",
       "3    Are there any tools or studies that have focus...   \n",
       "4    Are there papers that propose contextualized c...   \n",
       "..                                                 ...   \n",
       "592  Which paper trains on linear regression to hyp...   \n",
       "593  Which paper uses the latent diffusion model fo...   \n",
       "594  Which paper utilized MMD flows with Riesz kern...   \n",
       "595  What paper provides generalization bounds for ...   \n",
       "596  Which paper systematically examed the input mi...   \n",
       "\n",
       "                                         positive_ctxs  \\\n",
       "0    [{'title': 'TinyBERT: Distilling BERT for Natu...   \n",
       "1    [{'title': 'Parallel resources for Tunisian Ar...   \n",
       "2    [{'title': 'Detecting Hallucinated Content in ...   \n",
       "3    [{'title': 'Learning from Relatives: Unified D...   \n",
       "4    [{'title': 'Surface Form Competition: Why the ...   \n",
       "..                                                 ...   \n",
       "592  [{'title': 'UNDERSTANDING CATASTROPHIC FORGETT...   \n",
       "593  [{'title': 'Efficient Planning with Latent Dif...   \n",
       "594  [{'title': 'Posterior Sampling Based on Gradie...   \n",
       "595  [{'title': 'Understanding prompt engineering m...   \n",
       "596  [{'title': 'ELUCIDATING THE EXPOSURE BIAS IN D...   \n",
       "\n",
       "                                    hard_negative_ctxs  specificity  \n",
       "0    [{'title': 'A Frame-based Sentence Representat...            0  \n",
       "1    [{'title': 'Comparing Sanskrit Texts for Criti...            1  \n",
       "2    [{'title': 'Mining the Web for Discourse Marke...            0  \n",
       "3    [{'title': 'The KiezDeutsch Korpus (KiDKo) Rel...            1  \n",
       "4    [{'title': 'DeepCx: A transition-based approac...            1  \n",
       "..                                                 ...          ...  \n",
       "592  [{'title': 'Multilingual Semantic Parsing : Pa...            1  \n",
       "593  [{'title': 'APPLICATIONS OF A LEXICOGRAPHICAL ...            1  \n",
       "594  [{'title': 'Biomedical Event Extraction with H...            1  \n",
       "595  [{'title': '', 'text': '', 'full_text': 'The A...            0  \n",
       "596  [{'title': '', 'text': '', 'full_text': 'La ré...            1  \n",
       "\n",
       "[597 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3dfe72-e871-4bac-a853-bf6915fb489f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"negative_ctxs\"] = df[\"hard_negative_ctxs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fbe8c29-2c29-4ffb-b991-c886fff7bc1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['hard_negative_ctxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6899b27d-95e8-418b-b510-301f916a6dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.reindex(columns=['specificity', 'question', 'positive_ctxs', 'negative_ctxs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90e65643-b355-486c-9f14-3c7c1600d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "\n",
    "    if 'positive_ctxs' in row_dict and isinstance(row_dict['positive_ctxs'], list):\n",
    "        for ctx in row_dict['positive_ctxs']:\n",
    "            if isinstance(ctx, dict) and 'full_text' in ctx:\n",
    "                del ctx['full_text']\n",
    "    \n",
    "    if 'negative_ctxs' in row_dict and isinstance(row_dict['negative_ctxs'], list):\n",
    "        for ctx in row_dict['negative_ctxs']:\n",
    "            if isinstance(ctx, dict) and 'full_text' in ctx:\n",
    "                del ctx['full_text']\n",
    "    \n",
    "    processed_rows.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f68950b8-4b5c-456e-b707-ee1870c566b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_df = pd.DataFrame(processed_rows)\n",
    "processed_df.to_json(\"./refined_triplet.json\", orient='records', force_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48353557-ff29-4224-87da-f5360af7ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from adapters import AutoAdapterModel\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a0917ba-e6d9-4f63-8f48-e507b9c9f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitSearchDataset(Dataset):\n",
    "    def __init__(self, data: list[dict[str, any]], tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        question = item['question']\n",
    "        \n",
    "        # 포지티브 샘플 (1개)\n",
    "        pos_ctx = item['positive_ctxs'][0]\n",
    "        pos_text = pos_ctx['title'] + self.tokenizer.sep_token + pos_ctx['text']\n",
    "        \n",
    "        # 네거티브 샘플 (3개 중 랜덤 선택)\n",
    "        neg_ctx = random.choice(item['negative_ctxs'])\n",
    "        neg_text = neg_ctx['title'] + self.tokenizer.sep_token + neg_ctx['text']\n",
    "        \n",
    "        # 토크나이징\n",
    "        query_tokens = self.tokenizer(\n",
    "            question,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        pos_tokens = self.tokenizer(\n",
    "            pos_text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        neg_tokens = self.tokenizer(\n",
    "            neg_text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # 배치 차원 제거\n",
    "        query_tokens = {k: v.squeeze(0) for k, v in query_tokens.items()}\n",
    "        pos_tokens = {k: v.squeeze(0) for k, v in pos_tokens.items()}\n",
    "        neg_tokens = {k: v.squeeze(0) for k, v in neg_tokens.items()}\n",
    "        \n",
    "        return {\n",
    "            'query': query_tokens,\n",
    "            'positive': pos_tokens,\n",
    "            'negative': neg_tokens,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0305aa4b-dcb1-4fd8-a19b-660b19aef495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletMarginLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletMarginLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, query_emb, pos_emb, neg_emb):\n",
    "        # L2 거리 계산\n",
    "        pos_dist = torch.norm(query_emb - pos_emb, p=2, dim=1)\n",
    "        neg_dist = torch.norm(query_emb - neg_emb, p=2, dim=1)\n",
    "        \n",
    "        # max(0, pos_dist - neg_dist + margin) 형태의 손실\n",
    "        loss = torch.clamp(pos_dist - neg_dist + self.margin, min=0.0)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7c78229-3597-468b-9033-7493c591900f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = AutoAdapterModel.from_pretrained(\"allenai/specter2_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4817927e-1993-44e5-b086-26535fe3eb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235d44c4972e41ec9cf7fbe006a4087f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4f06fe2cb844169b4a5b52b005e932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'adhoc_query'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieval용 proximity adapter 로드 (문서 임베딩용)\n",
    "test.load_adapter(\"allenai/specter2\", source=\"hf\", load_as=\"proximity\")\n",
    "# Adhoc query adapter 로드 (쿼리 임베딩용)\n",
    "test.load_adapter(\"allenai/specter2_adhoc_query\", source=\"hf\", load_as=\"adhoc_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c0755b3-c473-42e2-bea9-fdb4887428c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.set_active_adapters(\"adhoc_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fce903c8-3dd1-4ff0-a691-51e1357064ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stack[adhoc_query]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.active_adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58b22bae-9a08-4a84-bcb9-915c991f25f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in test.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in test.named_parameters():\n",
    "    if \"adapters.adhoc_query\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2058833e-9eb1-4283-8c60-0556d9ee516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 총 파라미터 수: 111,707,520\n",
      "학습 가능한 파라미터 수: 894,528\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in test.parameters())\n",
    "print(f\"모델 총 파라미터 수: {total_params:,}\")\n",
    "\n",
    "trainable_params = sum(p.numel() for p in test.parameters() if p.requires_grad)\n",
    "print(f\"학습 가능한 파라미터 수: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f30eaf6-4eed-439f-af34-6bce41778574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 가능한 파라미터 목록:\n",
      "- bert.encoder.layer.0.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.0.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.0.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.0.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.1.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.1.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.1.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.1.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.2.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.2.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.2.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.2.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.3.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.3.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.3.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.3.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.4.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.4.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.4.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.4.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.5.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.5.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.5.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.5.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.6.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.6.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.6.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.6.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.7.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.7.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.7.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.7.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.8.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.8.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.8.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.8.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.9.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.9.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.9.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.9.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.10.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.10.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.10.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.10.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n",
      "- bert.encoder.layer.11.output.adapters.adhoc_query.adapter_down.0.weight: torch.Size([48, 768]), 36864 개\n",
      "- bert.encoder.layer.11.output.adapters.adhoc_query.adapter_down.0.bias: torch.Size([48]), 48 개\n",
      "- bert.encoder.layer.11.output.adapters.adhoc_query.adapter_up.weight: torch.Size([768, 48]), 36864 개\n",
      "- bert.encoder.layer.11.output.adapters.adhoc_query.adapter_up.bias: torch.Size([768]), 768 개\n"
     ]
    }
   ],
   "source": [
    "print(\"학습 가능한 파라미터 목록:\")\n",
    "for name, param in test.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"- {name}: {param.shape}, {param.numel()} 개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b19da8b3-1a81-4182-ae7a-514293e7b9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Using cached faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Using cached faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "Installing collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "beebe811-3fcd-4ded-8b28-0a3eeb9bb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import torch\n",
    "\n",
    "class TextType(Enum):\n",
    "    KEY = 1\n",
    "    QUERY = 2\n",
    "\n",
    "class Retrieval:\n",
    "    def __init__(self, index_name: str, index_type: str) -> None:\n",
    "        self.index_name = index_name\n",
    "        self.index_type = index_type\n",
    "\n",
    "        self.keys = []\n",
    "        self.values = []\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.keys)\n",
    "\n",
    "    def _get_embeddings(self, textList: list[str], type: TextType, show_progress_bar: bool = False) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _query(self, query_embedding: torch.Tensor, top_k: int = 10) -> List[int]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def query(self, query_text: str, n: int, return_keys: bool = False) -> List[Any]:\n",
    "        embedding_query = self._get_embeddings([query_text], TextType.QUERY)\n",
    "        indices = self._query(embedding_query, n)\n",
    "        if return_keys:\n",
    "            results = [(self.keys[i], self.values[i]) for i in indices]\n",
    "        else:\n",
    "            results = [self.values[i] for i in indices]\n",
    "        return results\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.keys = []\n",
    "        self.encoded_keys = []\n",
    "        self.values = []\n",
    "\n",
    "    def create_index(self, key_value_pairs: Dict[str, int]) -> None:\n",
    "        if len(self.keys) > 0:\n",
    "            raise ValueError(\"Index is not empty. Please create a new index or clear the existing one.\")\n",
    "\n",
    "        for key, value in key_value_pairs.items():\n",
    "            self.keys.append(key)\n",
    "            self.values.append(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e64bc6d-08f9-45b4-acc7-38398b9bc2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from adapters import AutoAdapterModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import faiss\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class SPECTER2QueryAdapterFinetuner(Retrieval):\n",
    "    def __init__(self, base_model_name=\"allenai/specter2_base\", device=None):\n",
    "\n",
    "        self.keys = []\n",
    "        self.values = []\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "        if device is None:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "        self.model = AutoAdapterModel.from_pretrained(\"allenai/specter2_base\")\n",
    "\n",
    "        self.model.load_adapter(\"allenai/specter2\", source=\"hf\", load_as=\"proximity\")\n",
    "        self.model.load_adapter(\"allenai/specter2_adhoc_query\", source=\"hf\", load_as=\"adhoc_query\")\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if \"adapters.adhoc_query\" in name:\n",
    "                param.requires_grad = True\n",
    "\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def encode_text(self, input_ids, attention_mask, adapter_type=\"proximity\"):\n",
    "        \"\"\"\n",
    "        adapter_type: query -> \"adhoc_query\", text -> \"proximity\"\n",
    "        \"\"\"\n",
    "        self.model.set_active_adapters(adapter_type)\n",
    "\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids.to(self.device),\n",
    "            attention_mask=attention_mask.to(self.device)\n",
    "        )\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS 토큰 임베딩 사용\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def encode_query(self, query_text):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            tokens = self.tokenizer(\n",
    "                query_text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            return self.encode_text(\n",
    "                tokens['input_ids'],\n",
    "                tokens['attention_mask'],\n",
    "                adapter_type=\"adhoc_query\"\n",
    "            )\n",
    "\n",
    "    def encode_paper(self, title, abstract):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            text = title + self.tokenizer.sep_token + abstract\n",
    "            tokens = self.tokenizer(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            return self.encode_text(\n",
    "                tokens['input_ids'],\n",
    "                tokens['attention_mask'],\n",
    "                adapter_type=\"proximity\"\n",
    "            )\n",
    "\n",
    "    def finetune(self, train_data, val_data=None, output_dir=\"./specter2_adhoc_query_finetuned\",\n",
    "                 lr=2e-5, batch_size=8, epochs=3, margin=1.0, eval_steps=100,\n",
    "                 weight_decay=0.01, warmup_ratio=0.1):\n",
    "\n",
    "        train_dataset = LitSearchDataset(train_data, self.tokenizer)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            [p for p in self.model.parameters() if p.requires_grad],\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "        total_steps = len(train_loader) * epochs\n",
    "        warmup_steps = int(total_steps * warmup_ratio)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=lr,\n",
    "            total_steps=total_steps,\n",
    "            pct_start=warmup_ratio,\n",
    "            anneal_strategy='linear'\n",
    "        )\n",
    "\n",
    "        triplet_loss = TripletMarginLoss(margin=margin)\n",
    "\n",
    "        self.model.train()\n",
    "        global_step = 0\n",
    "        best_val_loss = float('inf')\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "            for batch in progress_bar:\n",
    "                # 쿼리, 포지티브, 네거티브 임베딩\n",
    "                query_emb = self.encode_text(\n",
    "                    batch['query']['input_ids'],\n",
    "                    batch['query']['attention_mask'],\n",
    "                    adapter_type=\"adhoc_query\"\n",
    "                )\n",
    "\n",
    "                pos_emb = self.encode_text(\n",
    "                    batch['positive']['input_ids'],\n",
    "                    batch['positive']['attention_mask'],\n",
    "                    adapter_type=\"proximity\"\n",
    "                )\n",
    "\n",
    "                neg_emb = self.encode_text(\n",
    "                    batch['negative']['input_ids'],\n",
    "                    batch['negative']['attention_mask'],\n",
    "                    adapter_type=\"proximity\"\n",
    "                )\n",
    "\n",
    "                loss = triplet_loss(query_emb, pos_emb, neg_emb)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_([p for p in self.model.parameters() if p.requires_grad], 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "                progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "                global_step += 1\n",
    "                if val_data is not None and global_step % eval_steps == 0:\n",
    "                    val_loss = self.evaluate(val_data, batch_size)\n",
    "                    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        self.save_model(output_dir)\n",
    "                        print(f\"Model saved to {output_dir} (val_loss: {val_loss:.4f})\")\n",
    "\n",
    "                    self.model.train()\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Avg Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "        if val_data is None or epochs % eval_steps != 0:\n",
    "            self.save_model(output_dir)\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def evaluate(self, val_data, batch_size=8):\n",
    "        val_dataset = LitSearchDataset(val_data, self.tokenizer)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        self.model.eval()\n",
    "        triplet_loss = TripletMarginLoss(margin=1.0)\n",
    "        total_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                query_emb = self.encode_text(\n",
    "                    batch['query']['input_ids'],\n",
    "                    batch['query']['attention_mask'],\n",
    "                    adapter_type=\"adhoc_query\"\n",
    "                )\n",
    "\n",
    "                pos_emb = self.encode_text(\n",
    "                    batch['positive']['input_ids'],\n",
    "                    batch['positive']['attention_mask'],\n",
    "                    adapter_type=\"proximity\"\n",
    "                )\n",
    "\n",
    "                neg_emb = self.encode_text(\n",
    "                    batch['negative']['input_ids'],\n",
    "                    batch['negative']['attention_mask'],\n",
    "                    adapter_type=\"proximity\"\n",
    "                )\n",
    "\n",
    "                loss = triplet_loss(query_emb, pos_emb, neg_emb)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "        return total_loss / len(val_loader)\n",
    "\n",
    "    def save_model(self, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        self.model.save_adapter(output_dir, \"adhoc_query\")\n",
    "\n",
    "        self.tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "        print(f\"어댑터가 {output_dir}에 저장되었습니다.\")\n",
    "\n",
    "    def _get_embeddings(self, textList: list[str], type: TextType, show_progress_bar: bool = True) -> torch.Tensor:\n",
    "        if type == TextType.KEY:\n",
    "            self.model.set_active_adapters(\"proximity\")\n",
    "        else:\n",
    "            self.model.set_active_adapters(\"adhoc_query\")\n",
    "\n",
    "        batch_size = 16\n",
    "        embeddings = []\n",
    "\n",
    "        for i in tqdm(range(0, len(textList), batch_size), desc=\"Getting embeddings\"):\n",
    "            batch_texts = textList[i:i+batch_size]\n",
    "            encoded = self.tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=512  # 최대 길이 명시적 지정\n",
    "            ).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**encoded)\n",
    "\n",
    "            batch_embeddings = outputs.last_hidden_state[:,0,:].cpu()\n",
    "            embeddings.append(batch_embeddings)\n",
    "\n",
    "            if i % (batch_size * 10) == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def clear(self):\n",
    "        super().clear()\n",
    "        self.index = None\n",
    "        self.faiss_index = None\n",
    "\n",
    "    def create_index(self, key_value_pairs: dict[str, int]) -> None:\n",
    "        super().create_index(key_value_pairs)\n",
    "        self.index = self._get_embeddings(self.keys, TextType.KEY)\n",
    "\n",
    "        # FAISS 인덱스 생성\n",
    "        vector_dim = self.index.shape[1]\n",
    "        index_flat = faiss.IndexFlatIP(vector_dim)\n",
    "        index_vectors = self.index.numpy()\n",
    "        faiss.normalize_L2(index_vectors)\n",
    "\n",
    "        # 인덱스에 벡터 추가\n",
    "        index_flat.add(index_vectors)\n",
    "        self.faiss_index = index_flat\n",
    "\n",
    "    def _query(self, query_embedding: torch.Tensor, top_k: int = 10) -> list[int]:\n",
    "        if self.faiss_index is None:\n",
    "            raise ValueError(\"FAISS index has not been created yet. Call create_index first.\")\n",
    "\n",
    "        query_vector = query_embedding.numpy()\n",
    "        faiss.normalize_L2(query_vector)\n",
    "        distances, indices = self.faiss_index.search(query_vector, top_k)\n",
    "\n",
    "        return indices[0].tolist()\n",
    "\n",
    "    def query(self, query_text: str, n: int, return_keys: bool = False) -> list:\n",
    "        query_embedding = self._get_embeddings([query_text], TextType.QUERY)\n",
    "        indices = self._query(query_embedding, n)\n",
    "\n",
    "        if return_keys:\n",
    "            results = [(self.keys[i], self.values[i]) for i in indices]\n",
    "        else:\n",
    "            results = [self.values[i] for i in indices]\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be38cf3d-60d5-4833-bf3c-2d3c16e97ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(corpus_id_list: list, retrieved_id_list: list, k: int):\n",
    "    top_k = retrieved_id_list[:k]\n",
    "    intersection = set(corpus_id_list) & set(top_k)\n",
    "    return len(intersection) / len(corpus_id_list) if corpus_id_list else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fee5753f-68e0-4917-aab3-ea02aabe2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(finetuner, test_data, query_data, k_values=[1, 5, 10, 20]):\n",
    "    # 제 IDE 로컬 환경 pyright이 자꾸 타입 터쳐서 넣은 타입 캐스팅 코드입니다.\n",
    "    query_data = cast(Dataset, query_data)\n",
    "\n",
    "    query_df = pd.DataFrame({\n",
    "        'query': query_data['query'],\n",
    "        'corpusids': query_data['corpusids']\n",
    "    })\n",
    "\n",
    "    test_questions = [item['question'] for item in test_data]\n",
    "    filtered_query_df = query_df[query_df['query'].isin(test_questions)]\n",
    "\n",
    "    results = {}\n",
    "    result = []\n",
    "\n",
    "    for k in k_values:\n",
    "        total_recall = 0\n",
    "        count = 0\n",
    "        for i, item in enumerate(test_data):\n",
    "            query = item['question']\n",
    "            top_k_results = finetuner.query(query, k)\n",
    "\n",
    "            query_row = filtered_query_df[filtered_query_df['query'] == query]\n",
    "            if not query_row.empty:\n",
    "                true_corpus_ids = query_row.iloc[0]['corpusids']\n",
    "                if isinstance(true_corpus_ids, list):\n",
    "                    true_corpus_ids_flat = true_corpus_ids\n",
    "                else:\n",
    "                    true_corpus_ids_flat = [true_corpus_ids]\n",
    "\n",
    "                intersection = set(true_corpus_ids_flat) & set(top_k_results)\n",
    "                recall = len(intersection) / len(true_corpus_ids_flat) if true_corpus_ids_flat else 0\n",
    "\n",
    "                total_recall += recall\n",
    "                count += 1\n",
    "\n",
    "        if count > 0:\n",
    "            avg_recall = total_recall / count\n",
    "            results[f'Recall@{k}'] = avg_recall\n",
    "            result.append(avg_recall)\n",
    "        else:\n",
    "            results[f'Recall@{k}'] = 0\n",
    "            result.append(0)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fefaa43a-945f-4eb3-bdb5-cce27d741cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "def get_clean_corpusid(item: dict) -> int:\n",
    "    return item['corpusid']\n",
    "\n",
    "def get_clean_title(item: dict) -> str:\n",
    "    return item['title']\n",
    "\n",
    "def get_clean_abstract(item: dict) -> str:\n",
    "    return item['abstract']\n",
    "\n",
    "def get_clean_title_abstract(item: dict, tokenizer) -> str:\n",
    "    title = get_clean_title(item)\n",
    "    abstract = get_clean_abstract(item)\n",
    "    return title + tokenizer.sep_token + abstract\n",
    "\n",
    "def create_kv_pairs(data: Dataset, key: str, tokenizer) -> dict:\n",
    "    return {get_clean_title_abstract(record, tokenizer): get_clean_corpusid(record) for record in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14885ca0-783b-43b6-a3ae-693816b56a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 597 samples\n",
      "Specificity 0 queries: 155\n",
      "Specificity 1 queries: 442\n",
      "Training: 416 samples (Spec 0: 108, Spec 1: 308)\n",
      "Validation: 61 samples (Spec 0: 16, Spec 1: 45)\n",
      "Testing: 120 samples (Spec 0: 31, Spec 1: 89)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7dbd8ac3c74ddb8289d1468d195510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d0305fbf7f43ee8348509eaccc551d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting embeddings: 100%|██████████| 3604/3604 [25:32<00:00,  2.35it/s]\n",
      "Epoch 1/5:  96%|█████████▌| 50/52 [00:59<00:05,  2.83s/it, loss=0]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0241\n",
      "어댑터가 ./specter2_adhoc_query_finetuned에 저장되었습니다.\n",
      "Model saved to ./specter2_adhoc_query_finetuned (val_loss: 0.0241)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 52/52 [01:01<00:00,  1.18s/it, loss=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Avg Loss: 0.0528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  92%|█████████▏| 48/52 [00:57<00:11,  2.85s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0130\n",
      "어댑터가 ./specter2_adhoc_query_finetuned에 저장되었습니다.\n",
      "Model saved to ./specter2_adhoc_query_finetuned (val_loss: 0.0130)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 52/52 [01:01<00:00,  1.18s/it, loss=0.056]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Avg Loss: 0.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5:  88%|████████▊ | 46/52 [00:54<00:16,  2.81s/it, loss=0]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 52/52 [01:01<00:00,  1.18s/it, loss=0.0527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Avg Loss: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5:  85%|████████▍ | 44/52 [00:52<00:22,  2.81s/it, loss=0.000137]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 52/52 [01:01<00:00,  1.18s/it, loss=0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Avg Loss: 0.0160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5:  81%|████████  | 42/52 [00:50<00:28,  2.82s/it, loss=0.0578]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 52/52 [01:01<00:00,  1.18s/it, loss=0]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Avg Loss: 0.0070\n",
      "어댑터가 ./specter2_adhoc_query_finetuned에 저장되었습니다.\n",
      "Fine-tuning complete!\n",
      "Evaluating model on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 12.15it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.50it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 69.79it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.40it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.94it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.85it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.35it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.61it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.79it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.36it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.65it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.94it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.53it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.42it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.57it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.14it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.36it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.20it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 69.73it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.55it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.17it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.30it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.49it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.30it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 65.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.24it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.76it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.14it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.49it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 69.71it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.65it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.87it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.58it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.89it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.42it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.24it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.09it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.73it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.18it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.21it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.11it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.76it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.12it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.51it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.29it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.88it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.71it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.15it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.85it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.11it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.06it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.40it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.35it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 63.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.20it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.85it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.50it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.17it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.73it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.36it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.62it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.95it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.05it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.78it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.74it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.97it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.30it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.36it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.63it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.11it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.63it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.62it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.88it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.46it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.87it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 67.12it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 69.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.05it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.12it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 68.82it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.71it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.30it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.18it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.94it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.50it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.24it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.69it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.02it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.15it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.55it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.77it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.87it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.94it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.06it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.65it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.69it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.11it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.97it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.76it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.32it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 67.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.72it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.04it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.53it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.71it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.88it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.35it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.14it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.61it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.87it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.18it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.59it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.83it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 68.65it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.46it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.21it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.36it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.63it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.89it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.79it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.81it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.65it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.69it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.73it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.31it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.05it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 67.00it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 60.40it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 65.51it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.24it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.50it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.58it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.17it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 40.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.74it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.18it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.71it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.49it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.82it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.14it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.02it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.09it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.02it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.09it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.83it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.82it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.46it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.30it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.02it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.08it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.09it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.88it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.62it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.24it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 65.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.71it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.79it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.73it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.05it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.71it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.02it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.76it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.61it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.59it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.05it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.49it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.20it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.57it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.29it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.17it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.15it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.32it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.82it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.95it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.51it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 64.49it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.76it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 67.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.53it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.63it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.49it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.94it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 57.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.77it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.78it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.46it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.00it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.59it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.08it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.09it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.42it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.12it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.32it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.95it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.00it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.18it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.89it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.49it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.17it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.04it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.02it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.78it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.50it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.95it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.09it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.17it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.08it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.77it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.55it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.59it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.57it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.42it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.42it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.06it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 83.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.77it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.61it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 83.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.40it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.32it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.76it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.21it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.71it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.32it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.62it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 68.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.15it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.42it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.04it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.88it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.06it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.95it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.78it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.81it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.14it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.97it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.77it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.05it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.59it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall test performance: {'Recall@1': 0.20694444444444443, 'Recall@5': 0.4180555555555555, 'Recall@10': 0.5169444444444445, 'Recall@20': 0.6005555555555556}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.55it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.53it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.11it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.51it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.09it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.17it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 83.24it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.14it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.89it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.15it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.97it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 60.61it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.71it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.57it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.24it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.32it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 61.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.09it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.79it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.20it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.31it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 57.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 57.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.65it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.78it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.72it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.21it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 65.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.04it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.36it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 69.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.74it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.35it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.21it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.61it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.81it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 83.18it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.53it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.79it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.85it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.40it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 83.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.49it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.05it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.53it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.89it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.61it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.40it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.30it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.12it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.31it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.35it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.30it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.36it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.02it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.72it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.40it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.50it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.21it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.58it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity 0 performance: {'Recall@1': 0.15591397849462368, 'Recall@5': 0.3344086021505376, 'Recall@10': 0.35698924731182796, 'Recall@20': 0.5989247311827957}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.57it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.97it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.63it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.46it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.50it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.78it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.04it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.63it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.11it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.06it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.89it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.97it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.21it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.74it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.46it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.00it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.62it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.73it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.77it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.08it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.62it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.31it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.17it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.58it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.73it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.59it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.69it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.18it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.46it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.14it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.73it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.06it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.35it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.55it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.94it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.74it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.59it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.73it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.36it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.30it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.15it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.00it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.57it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.09it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.84it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 65.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.76it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.78it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.14it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.69it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.08it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 67.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.18it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.15it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.76it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.00it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.74it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.42it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.21it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.85it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.89it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.82it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.29it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.62it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.17it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.32it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.88it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.00it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.99it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.83it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.51it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.59it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.85it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.62it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.81it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.98it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.30it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.20it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.08it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 82.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.35it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.70it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.79it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.29it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.38it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.69it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.93it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.94it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.58it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.00it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.62it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.90it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.05it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.86it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.77it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 81.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.59it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.41it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.05it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.57it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.95it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.67it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.61it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.81it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.36it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.92it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.55it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 46.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.39it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.20it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.52it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.95it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 80.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.83it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.55it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.46it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.29it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.40it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.44it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.69it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.88it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 68.69it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.48it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.29it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.78it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.43it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.68it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.31it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.57it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.81it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.21it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.42it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.37it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.02it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 72.74it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.63it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.51it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.12it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.25it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.64it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.35it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.61it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.28it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.32it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.42it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.72it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.29it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.82it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.45it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.85it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.66it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.12it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.07it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.33it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.47it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.51it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.91it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.69it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.78it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.77it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.82it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.50it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 79.23it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.03it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.95it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 70.89it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.77it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.10it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.60it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.54it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.00it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 66.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 71.19it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.12it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.56it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.76it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.65it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.63it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.88it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.63it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.32it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.96it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 78.14it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.58it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.80it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.75it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.22it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.26it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 77.35it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.13it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 74.53it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.16it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.01it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.34it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.31it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 73.27it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 75.87it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.46it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.53it/s]\n",
      "Getting embeddings: 100%|██████████| 1/1 [00:00<00:00, 76.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity 1 performance: {'Recall@1': 0.20224719101123595, 'Recall@5': 0.4438202247191011, 'Recall@10': 0.5617977528089888, 'Recall@20': 0.6348314606741573}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import cast\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 데이터 로드\n",
    "with open(\"refined_triplet.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total dataset size: {len(data)} samples\")\n",
    "\n",
    "# Specificity에 따라 데이터 분류\n",
    "spec_0_queries = [item for item in data if item.get('specificity', 0) == 0]\n",
    "spec_1_queries = [item for item in data if item.get('specificity', 0) == 1]\n",
    "\n",
    "print(f\"Specificity 0 queries: {len(spec_0_queries)}\")\n",
    "print(f\"Specificity 1 queries: {len(spec_1_queries)}\")\n",
    "\n",
    "# 먼저 테스트 세트 분리 (20%)\n",
    "spec_0_train_val, spec_0_test = train_test_split(spec_0_queries, test_size=0.2, random_state=42)\n",
    "spec_1_train_val, spec_1_test = train_test_split(spec_1_queries, test_size=0.2, random_state=42)\n",
    "\n",
    "# 남은 데이터에서 검증 세트 분리 (원본의 10%, 즉 train_val의 12.5%)\n",
    "spec_0_train, spec_0_val = train_test_split(spec_0_train_val, test_size=0.125, random_state=42)\n",
    "spec_1_train, spec_1_val = train_test_split(spec_1_train_val, test_size=0.125, random_state=42)\n",
    "\n",
    "# 세트 결합\n",
    "train_data = spec_0_train + spec_1_train\n",
    "val_data = spec_0_val + spec_1_val\n",
    "test_data = spec_0_test + spec_1_test\n",
    "\n",
    "# 각 세트 섞기\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(val_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "print(f\"Training: {len(train_data)} samples (Spec 0: {len(spec_0_train)}, Spec 1: {len(spec_1_train)})\")\n",
    "print(f\"Validation: {len(val_data)} samples (Spec 0: {len(spec_0_val)}, Spec 1: {len(spec_1_val)})\")\n",
    "print(f\"Testing: {len(test_data)} samples (Spec 0: {len(spec_0_test)}, Spec 1: {len(spec_1_test)})\")\n",
    "\n",
    "# 학습 과정\n",
    "finetuner = SPECTER2QueryAdapterFinetuner()\n",
    "\n",
    "# 제 IDE 로컬 환경 pyright이 자꾸 타입 터쳐서 넣은 타입 캐스팅 코드입니다.\n",
    "corpus_clean_data = cast(Dataset, corpus_clean_data)\n",
    "kv_pairs = create_kv_pairs(corpus_clean_data, \"title_abstract\", finetuner.tokenizer)\n",
    "finetuner.clear()\n",
    "finetuner.create_index(kv_pairs)\n",
    "\n",
    "finetuner.finetune(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    output_dir=\"./specter2_adhoc_query_finetuned\",\n",
    "    lr=2e-4,\n",
    "    batch_size=8,\n",
    "    epochs=5,\n",
    "    margin=1.0,\n",
    "    eval_steps=50,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning complete!\")\n",
    "\n",
    "# 테스트 데이터에 대한 성능 평가\n",
    "print(\"Evaluating model on test set...\")\n",
    "\n",
    "# Specificity별 성능 평가\n",
    "test_spec_0 = [item for item in test_data if item.get('specificity', 0) == 0]\n",
    "test_spec_1 = [item for item in test_data if item.get('specificity', 0) == 1]\n",
    "\n",
    "query_data = load_dataset(\"princeton-nlp/LitSearch\", \"query\", split=\"full\")\n",
    "corpus_clean_data = load_dataset(\"princeton-nlp/LitSearch\", \"corpus_clean\", split=\"full\")\n",
    "\n",
    "# 전체 테스트 세트 평가\n",
    "overall_performance = evaluate_model(finetuner, test_data, query_data)\n",
    "print(f\"Overall test performance: {overall_performance}\")\n",
    "\n",
    "# Specificity 0 쿼리에 대한 평가\n",
    "spec_0_performance = evaluate_model(finetuner, test_spec_0, query_data)\n",
    "print(f\"Specificity 0 performance: {spec_0_performance}\")\n",
    "\n",
    "# Specificity 1 쿼리에 대한 평가\n",
    "spec_1_performance = evaluate_model(finetuner, test_spec_1, query_data)\n",
    "print(f\"Specificity 1 performance: {spec_1_performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136ed52-1929-4a85-b0f4-87395c7829e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
